name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  check:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        crate-path:
          - crates/ferra_lexer
    steps:
      - uses: actions/checkout@v3
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
          components: clippy, rustfmt
      - name: Format
        run: cargo fmt --manifest-path ${{ matrix.crate-path }}/Cargo.toml -- --check
      - name: Clippy
        run: cargo clippy --manifest-path ${{ matrix.crate-path }}/Cargo.toml --all-targets -- -D warnings
      - name: Test
        run: cargo test --manifest-path ${{ matrix.crate-path }}/Cargo.toml

  fmt:
    name: rustfmt
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
          components: rustfmt
      - run: cargo fmt -- --check

  clippy:
    name: clippy
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
          components: clippy
      - run: cargo clippy --all-targets -- -D warnings

  test:
    name: tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
      - run: cargo test --workspace

  build_and_test:
    name: Build & Test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          components: clippy, rustfmt

      - name: Check formatting
        run: cargo fmt -- --check

      - name: Run Clippy
        run: cargo clippy --all-targets -- -D warnings # Treat all warnings as errors

      - name: Run tests
        run: cargo test --all-targets --verbose

      # Add cargo audit step once dependencies are added
      # - name: Security audit
      #   run: |
      #     cargo install cargo-audit
      #     cargo audit 

  fuzz:
    name: Fuzz Testing
    runs-on: ubuntu-latest
    # Run fuzz tests on main branch pushes and nightly schedule
    if: github.ref == 'refs/heads/main' || github.event_name == 'schedule'
    steps:
      - uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Run proptest fuzz tests (extended)
        run: |
          cd crates/ferra_lexer
          # Run proptest with more cases for better coverage
          PROPTEST_CASES=10000 cargo test fuzz --release -- --nocapture
        env:
          RUST_BACKTRACE: 1

      - name: Report fuzz results
        run: echo "âœ… Proptest fuzzing completed successfully" 

  coverage:
    name: Code Coverage
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Install tarpaulin
        run: cargo install cargo-tarpaulin

      - name: Run coverage analysis
        run: |
          cargo tarpaulin --workspace --timeout 120 --out xml --output-dir coverage/ --ignore-tests

      - name: Upload coverage to codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage/cobertura.xml
          fail_ci_if_error: true
          flags: unittests
          name: codecov-umbrella
          verbose: true

      - name: Generate coverage report
        run: |
          cargo tarpaulin --workspace --timeout 120 --out html --output-dir coverage/ --ignore-tests
          echo "ðŸ“Š Coverage report generated in coverage/tarpaulin-report.html"

  benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Install cargo-criterion
        run: cargo install cargo-criterion

      - name: Run parser benchmarks and generate JSON output
        run: |
          cd crates/ferra_parser
          # Run benchmarks with JSON output
          cargo criterion --bench parser_benchmarks --message-format=json > benchmark_output.json || true
          # Ensure the file exists even if benchmarks don't run fully
          if [ ! -f benchmark_output.json ]; then
            echo '[]' > benchmark_output.json
          fi
          # Show what was generated for debugging
          echo "Generated benchmark output:"
          cat benchmark_output.json

      - name: Store benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        with:
          name: Ferra Parser Benchmarks
          tool: cargo
          output-file-path: crates/ferra_parser/benchmark_output.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: 200%
          comment-on-alert: true
          fail-on-alert: false
          gh-pages-branch: gh-pages
          benchmark-data-dir-path: dev/bench
          skip-fetch-gh-pages: false
          comment-always: false
          summary-always: false
          save-data-file: true

      - name: Generate performance report
        run: |
          echo "ðŸš€ Performance benchmarks completed and tracked" 