<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <style>html, body {
  margin: 0;
  padding: 0;
}

.app {
  margin: 10px;
  padding: 0;
}

.files-list {
  margin: 10px 0 0;
  width: 100%;
  border-collapse: collapse;
}
.files-list__head {
  border: 1px solid #999;
}
.files-list__head > tr > th {
  padding: 10px;
  border: 1px solid #999;
  text-align: left;
  font-weight: normal;
  background: #ddd;
}
.files-list__body {
}
.files-list__file {
  cursor: pointer;
}
.files-list__file:hover {
  background: #ccf;
}
.files-list__file > td {
  padding: 10px;
  border: 1px solid #999;
}
.files-list__file > td:first-child::before {
  content: '\01F4C4';
  margin-right: 1em;
}
.files-list__file_low {
  background: #fcc;
}
.files-list__file_medium {
  background: #ffc;
}
.files-list__file_high {
  background: #cfc;
}
.files-list__file_folder > td:first-child::before {
  content: '\01F4C1';
  margin-right: 1em;
}

.file-header {
  border: 1px solid #999;
  display: flex;
  justify-content: space-between;
  align-items: center;
  position: sticky;
  top: 0;
  background: white;
}

.file-header__back {
  margin: 10px;
  cursor: pointer;
  flex-shrink: 0;
  flex-grow: 0;
  text-decoration: underline;
  color: #338;
}

.file-header__name {
  margin: 10px;
  flex-shrink: 2;
  flex-grow: 2;
}

.file-header__stat {
  margin: 10px;
  flex-shrink: 0;
  flex-grow: 0;
}

.file-content {
  margin: 10px 0 0;
  border: 1px solid #999;
  padding: 10px;
  counter-reset: line;
  display: flex;
  flex-direction: column;
}

.code-line::before {
    content: counter(line);
    margin-right: 10px;
}
.code-line {
  margin: 0;
  padding: 0.3em;
  height: 1em;
  counter-increment: line;
}
.code-line_covered {
  background: #cfc;
}
.code-line_uncovered {
  background: #fcc;
}
</style>
</head>
<body>
    <div id="root"></div>
    <script>
        var data = {"files":[{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","src","lib.rs"],"content":"// SPDX-License-Identifier: Apache-2.0\n// Copyright (c) 2025 Ferra Language Project Contributors\n\nuse std::iter::Peekable;\nuse std::str::CharIndices;\nuse unicode_ident::{is_xid_continue, is_xid_start};\nuse unicode_normalization::UnicodeNormalization;\n\n/// All the different token kinds the Ferra lexer can emit.\n/// Marked non_exhaustive so we can add new variants (raw strings, etc.) later.\n#[non_exhaustive]\n#[derive(Debug, PartialEq, Clone)]\npub enum TokenKind {\n    // Keywords\n    Let,\n    Var,\n    Fn,\n    Async,\n    Data,\n    Match,\n    True,\n    False,\n\n    // Identifiers\n    Identifier,\n\n    // Literals\n    IntegerLiteral,\n    FloatLiteral,\n    StringLiteral,\n    CharacterLiteral,\n    BooleanLiteral,\n    ByteLiteral,            // e.g. b'a', b\"foo\"\n    RawStringLiteral,       // r\"...\" or r#\"...\"#\n    MultiLineStringLiteral, // \"\"\"...\"\"\"\n\n    // Comments (skipped by parser but useful for tooling)\n    // LineComment,  // `// ...`\n    // BlockComment, // `/* ... */`\n\n    // Operators \u0026 Punctuation\n    Plus,            // +\n    Minus,           // -\n    Star,            // *\n    Slash,           // /\n    Percent,         // %\n    EqualEqual,      // ==\n    NotEqual,        // !=\n    Less,            // \u003c\n    Greater,         // \u003e\n    LessEqual,       // \u003c=\n    GreaterEqual,    // \u003e=\n    LogicalAnd,      // \u0026\u0026\n    LogicalOr,       // ||\n    BitAnd,          // \u0026\n    BitOr,           // |\n    Caret,           // ^\n    ShiftLeft,       // \u003c\u003c\n    ShiftRight,      // \u003e\u003e\n    Coalesce,        // ??\n    Equal,           // =\n    PlusEqual,       // +=\n    MinusEqual,      // -=\n    StarEqual,       // *=\n    SlashEqual,      // /=\n    PercentEqual,    // %=\n    BitAndEqual,     // \u0026=\n    BitOrEqual,      // |=\n    CaretEqual,      // ^=\n    ShiftLeftEqual,  // \u003c\u003c=\n    ShiftRightEqual, // \u003e\u003e=\n    Bang,            // !\n    Question,        // ?\n    Dot,             // .\n    Comma,           // ,\n    Colon,           // :\n    Semicolon,       // ;\n    LParen,          // (\n    RParen,          // )\n    LBrace,          // {\n    RBrace,          // }\n    LBracket,        // [\n    RBracket,        // ]\n    Arrow,           // -\u003e\n    FatArrow,        // =\u003e\n    DotDot,          // ..\n    DotDotEqual,     // ..=\n    PathSep,         // ::\n    Underscore,      // _\n\n    // Structural tokens\n    Indent,\n    Dedent,\n    Newline,\n    Eof,\n\n    // Fallback for unrecognized input\n    Error,\n}\n\n/// A fully‐fledged token with metadata (kind, lexeme, literal, span).\n#[derive(Debug, PartialEq, Clone)]\npub struct Token {\n    pub kind: TokenKind,\n    /// The exact slice of source text.\n    pub lexeme: String,\n    /// Parsed literal value, if any.\n    pub literal: Option\u003cLiteralValue\u003e,\n    /// Source‐location span for diagnostics.\n    pub span: Span,\n}\n\n/// Different literal values a token might carry.\n#[non_exhaustive]\n#[derive(Debug, PartialEq, Clone)]\npub enum LiteralValue {\n    Integer(i64),\n    Float(f64),\n    String(String),\n    Char(char),\n    Boolean(bool),\n    Byte(u8),\n}\n\n/// Precise span (start/end positions) in the source file.\n#[derive(Debug, PartialEq, Clone)]\npub struct Span {\n    pub start: Position,\n    pub end: Position,\n}\n\n/// A single position: line, column, and byte offset.\n#[derive(Debug, PartialEq, Clone)]\npub struct Position {\n    pub line: usize,\n    pub column: usize,\n    pub offset: usize,\n}\n\nimpl Span {\n    /// Dummy span for early‐stage tests; replace with real tracking later.\n    pub fn dummy() -\u003e Self {\n        Span {\n            start: Position {\n                line: 0,\n                column: 0,\n                offset: 0,\n            },\n            end: Position {\n                line: 0,\n                column: 0,\n                offset: 0,\n            },\n        }\n    }\n}\n\nimpl Token {\n    /// Helper to emit a bare EOF token in tests.\n    pub fn eof_dummy() -\u003e Self {\n        Token {\n            kind: TokenKind::Eof,\n            lexeme: String::new(),\n            literal: None,\n            span: Span::dummy(),\n        }\n    }\n}\n\npub struct Lexer\u003c'a\u003e {\n    input: \u0026'a str,\n    chars: Peekable\u003cCharIndices\u003c'a\u003e\u003e,\n    line: usize,\n    column: usize,\n    indent_stack: Vec\u003cusize\u003e, // track indentation levels\n    pending_dedents: usize,   // track dedents to emit\n    at_line_start: bool,      // are we at the start of a new line?\n}\n\nimpl\u003c'a\u003e Lexer\u003c'a\u003e {\n    pub fn new(input: \u0026'a str) -\u003e Self {\n        // Shebang handling: if input starts with \"#!\", skip the first line\n        let input = if input.starts_with(\"#!\") {\n            match input.find('\\n') {\n                Some(idx) =\u003e \u0026input[idx + 1..],\n                None =\u003e \"\", // shebang is the whole file\n            }\n        } else {\n            input\n        };\n        Lexer {\n            input,\n            chars: input.char_indices().peekable(),\n            line: 1,\n            column: 1,\n            indent_stack: vec![0],\n            pending_dedents: 0,\n            at_line_start: true,\n        }\n    }\n\n    pub fn lex(mut self) -\u003e Vec\u003cToken\u003e {\n        let mut tokens = Vec::new();\n        while let Some(\u0026(idx, ch)) = self.chars.peek() {\n            // Handle dedents first\n            if self.pending_dedents \u003e 0 {\n                self.pending_dedents -= 1;\n                tokens.push(Token {\n                    kind: TokenKind::Dedent,\n                    lexeme: String::new(),\n                    literal: None,\n                    span: Span {\n                        start: Position {\n                            line: self.line,\n                            column: self.column,\n                            offset: idx,\n                        },\n                        end: Position {\n                            line: self.line,\n                            column: self.column,\n                            offset: idx,\n                        },\n                    },\n                });\n                continue;\n            }\n            // Indentation logic at start of line\n            if self.at_line_start {\n                let mut current_indent = 0;\n                let mut indent_char_type: Option\u003cchar\u003e = None; // 's' for space, 't' for tab\n                let mut mixed_indent_error = false;\n                let indent_start_offset = self.chars.peek().map_or(0, |(i, _)| *i);\n                let indent_start_col = self.column;\n\n                // Consume leading whitespace to calculate indent\n                while let Some(\u0026(_, ch)) = self.chars.peek() {\n                    if ch == ' ' {\n                        if indent_char_type == Some('t') {\n                            mixed_indent_error = true;\n                        }\n                        indent_char_type = Some('s');\n                        current_indent += 1;\n                        self.advance_char(); // Use normal advance_char\n                    } else if ch == '\\t' {\n                        if indent_char_type == Some('s') {\n                            mixed_indent_error = true;\n                        }\n                        indent_char_type = Some('t');\n                        current_indent += 4; // Tabs are 4 spaces\n                        self.advance_char();\n                    } else {\n                        break; // Not whitespace\n                    }\n                }\n\n                if mixed_indent_error {\n                    // Consume the rest of the mixed indent line up to non-whitespace or newline\n                    let mut _error_lexeme_len = 0;\n                    while let Some(\u0026(_, ch_err)) = self.chars.peek() {\n                        if ch_err != '\\n' \u0026\u0026 ch_err.is_whitespace() {\n                            _error_lexeme_len += ch_err.len_utf8();\n                            self.advance_char();\n                        } else {\n                            break;\n                        }\n                    }\n                    // The error lexeme is from indent_start_offset to current pos of self.chars\n                    let error_lexeme = self\n                        .input\n                        .get(indent_start_offset..self.current_offset())\n                        .unwrap_or(\"\")\n                        .to_string();\n\n                    tokens.push(Token {\n                        kind: TokenKind::Error,\n                        lexeme: error_lexeme,\n                        literal: Some(LiteralValue::String(\n                            \"Mixed tabs and spaces in indentation are not allowed.\".to_string(),\n                        )),\n                        span: Span {\n                            start: Position {\n                                line: self.line,\n                                column: indent_start_col,\n                                offset: indent_start_offset,\n                            },\n                            end: Position {\n                                line: self.line,\n                                column: self.column,\n                                offset: self.current_offset(),\n                            },\n                        },\n                    });\n                    // Skip to next line or handle rest of line as normal?\n                    // For now, let's assume the error token covers the bad indent, and lexing continues.\n                    // We need to ensure `at_line_start` is false now.\n                    self.at_line_start = false; // Processed the start of the line (even if it was an error)\n                } else {\n                    // Original indentation logic\n                    if current_indent \u003e *self.indent_stack.last().unwrap() {\n                        self.indent_stack.push(current_indent);\n                        tokens.push(Token {\n                            kind: TokenKind::Indent,\n                            lexeme: String::new(),\n                            literal: None,\n                            span: Span {\n                                start: Position {\n                                    line: self.line,\n                                    column: 1,\n                                    offset: idx,\n                                },\n                                end: Position {\n                                    line: self.line,\n                                    column: current_indent + 1,\n                                    offset: idx + current_indent,\n                                },\n                            },\n                        });\n                    } else if current_indent \u003c *self.indent_stack.last().unwrap() {\n                        while current_indent \u003c *self.indent_stack.last().unwrap() {\n                            self.indent_stack.pop();\n                            self.pending_dedents += 1;\n                        }\n                    }\n                    // Don't advance chars again - we already consumed leading whitespace in indentation calculation above\n                    self.at_line_start = false;\n                }\n                // After indentation processing, re-peek to get the current character\n                continue;\n            }\n            // Handle Newlines\n            if ch == '\\n' {\n                let start_offset = idx;\n                let start_col = self.column;\n                self.advance_char();\n                tokens.push(Token {\n                    kind: TokenKind::Newline,\n                    lexeme: \"\\n\".to_string(),\n                    literal: None,\n                    span: Span {\n                        start: Position {\n                            line: self.line - 1,\n                            column: start_col,\n                            offset: start_offset,\n                        },\n                        end: Position {\n                            line: self.line - 1,\n                            column: start_col + 1,\n                            offset: start_offset + 1,\n                        },\n                    },\n                });\n                self.at_line_start = true;\n                continue;\n            }\n            if ch.is_ascii_digit()\n                || (ch == '.'\n                    \u0026\u0026 self\n                        .peek_nth_char(1)\n                        .is_some_and(|(_, c)| c.is_ascii_digit()))\n            {\n                tokens.push(self.lex_number());\n                continue;\n            }\n\n            // Comments\n            if ch == '/' {\n                if self.peek_nth_char(1).is_some_and(|(_, c)| c == '/') {\n                    // Line comment\n                    self.advance_char(); // consume '/'\n                    self.advance_char(); // consume '/'\n                    while let Some(\u0026(_i, c)) = self.chars.peek() {\n                        if c == '\\n' {\n                            break; // End of line comment\n                        }\n                        self.advance_char();\n                    }\n                    continue;\n                } else if self.peek_nth_char(1).is_some_and(|(_, c)| c == '*') {\n                    // Block comment (with nesting support)\n                    let comment_start_line = self.line;\n                    let comment_start_col = self.column;\n                    let comment_start_offset = idx;\n\n                    self.advance_char(); // consume '/'\n                    self.advance_char(); // consume '*\n\n                    let mut nesting_level = 1;\n                    let mut closed = false;\n\n                    while let Some(\u0026(_i, c1)) = self.chars.peek() {\n                        self.advance_char(); // Consume current char. THIS MUTATES THE REAL self.line/col\n                        if c1 == '/' {\n                            if let Some(\u0026(_j, c2)) = self.chars.peek() {\n                                if c2 == '*' {\n                                    self.advance_char();\n                                    nesting_level += 1;\n                                }\n                            }\n                        } else if c1 == '*' {\n                            if let Some(\u0026(_j, c2)) = self.chars.peek() {\n                                if c2 == '/' {\n                                    self.advance_char();\n                                    nesting_level -= 1;\n                                    if nesting_level == 0 {\n                                        closed = true;\n                                        break;\n                                    }\n                                }\n                            }\n                        }\n                    }\n\n                    if !closed {\n                        let error_lexeme_str = self\n                            .input\n                            .get(comment_start_offset..self.current_offset())\n                            .unwrap_or(\"\");\n\n                        let mut calc_end_line = comment_start_line;\n                        let mut calc_end_col = comment_start_col;\n\n                        for c in error_lexeme_str.chars() {\n                            if c == '\\n' {\n                                calc_end_line += 1;\n                                calc_end_col = 1;\n                            } else {\n                                calc_end_col += 1;\n                            }\n                        }\n\n                        tokens.push(Token {\n                            kind: TokenKind::Error,\n                            lexeme: error_lexeme_str.to_string(),\n                            literal: Some(LiteralValue::String(\n                                \"Unterminated block comment: expected closing */ before end of file.\".to_string(),\n                            )),\n                            span: Span {\n                                start: Position {\n                                    line: comment_start_line,\n                                    column: comment_start_col,\n                                    offset: comment_start_offset,\n                                },\n                                end: Position {\n                                    line: calc_end_line,\n                                    column: calc_end_col,\n                                    offset: self.current_offset(),\n                                },\n                            },\n                        });\n                    }\n                    self.at_line_start = self.line != comment_start_line;\n                    continue;\n                }\n            }\n\n            // Skip other whitespace\n            if ch.is_whitespace() {\n                // but not newline, handled above\n                self.advance_char();\n                continue;\n            }\n\n            // String Literals: \"...\" or \"\"\"...\"\"\"\n            if ch == '\"' {\n                // Check for triple-quote multiline string\n                if self.peek_nth_char(1).is_some_and(|(_, c)| c == '\"')\n                    \u0026\u0026 self.peek_nth_char(2).is_some_and(|(_, c)| c == '\"')\n                {\n                    tokens.push(self.lex_multiline_string_literal(idx));\n                } else {\n                    tokens.push(self.lex_string_literal());\n                }\n                continue;\n            }\n\n            // Character Literals: '...'\n            if ch == '\\'' {\n                tokens.push(self.lex_char_literal());\n                continue;\n            }\n\n            // Underscore as punctuation if not part of an identifier\n            if ch == '_' {\n                // Peek next char: if it's not alphanumeric or _, treat as Underscore\n                if let Some((_, next_ch)) = self.peek_nth_char(1) {\n                    if !next_ch.is_ascii_alphanumeric() \u0026\u0026 next_ch != '_' {\n                        let start_offset = idx;\n                        let start_col = self.column;\n                        self.advance_char();\n                        let end_offset = self.current_offset();\n                        tokens.push(Token {\n                            kind: TokenKind::Underscore,\n                            lexeme: \"_\".to_string(),\n                            literal: None,\n                            span: Span {\n                                start: Position {\n                                    line: self.line,\n                                    column: start_col,\n                                    offset: start_offset,\n                                },\n                                end: Position {\n                                    line: self.line,\n                                    column: self.column,\n                                    offset: end_offset,\n                                },\n                            },\n                        });\n                        continue;\n                    }\n                } else {\n                    // End of input, so treat as Underscore\n                    let start_offset = idx;\n                    let start_col = self.column;\n                    self.advance_char();\n                    let end_offset = self.current_offset();\n                    tokens.push(Token {\n                        kind: TokenKind::Underscore,\n                        lexeme: \"_\".to_string(),\n                        literal: None,\n                        span: Span {\n                            start: Position {\n                                line: self.line,\n                                column: start_col,\n                                offset: start_offset,\n                            },\n                            end: Position {\n                                line: self.line,\n                                column: self.column,\n                                offset: end_offset,\n                            },\n                        },\n                    });\n                    continue;\n                }\n            }\n\n            // Byte literals: b'a' or b\"foo\"\n            if ch == 'b' {\n                if let Some((_, next_ch)) = self.peek_nth_char(1) {\n                    if next_ch == '\\'' || next_ch == '\"' {\n                        tokens.push(self.lex_byte_literal(idx)); // Pass idx for start_offset\n                        continue;\n                    }\n                }\n            }\n\n            // Raw String Literals: r\"...\" or r#\"...\"#\n            if ch == 'r' {\n                if let Some((_, next_ch)) = self.peek_nth_char(1) {\n                    if next_ch == '\"' || next_ch == '#' {\n                        tokens.push(self.lex_raw_string_literal(idx));\n                        continue;\n                    }\n                }\n            }\n\n            // Identifiers and keywords (Unicode-aware)\n            if is_xid_start(ch) {\n                // Use is_xid_start directly\n                let start = idx;\n                let start_col = self.column;\n                let mut ident_str = String::new();\n                ident_str.push(ch);\n                self.advance_char();\n\n                while let Some(\u0026(_, c)) = self.chars.peek() {\n                    if is_xid_continue(c) {\n                        // Use is_xid_continue directly\n                        ident_str.push(c);\n                        self.advance_char();\n                    } else {\n                        break;\n                    }\n                }\n                let end_offset = self.current_offset();\n\n                // NFC Normalization\n                let normalized_ident: String = ident_str.nfc().collect();\n\n                let kind = match normalized_ident.as_str() {\n                    \"let\" =\u003e TokenKind::Let,\n                    \"var\" =\u003e TokenKind::Var,\n                    \"fn\" =\u003e TokenKind::Fn,\n                    \"async\" =\u003e TokenKind::Async,\n                    \"data\" =\u003e TokenKind::Data,\n                    \"match\" =\u003e TokenKind::Match,\n                    \"true\" =\u003e TokenKind::True,\n                    \"false\" =\u003e TokenKind::False,\n                    \"and\" =\u003e TokenKind::LogicalAnd,\n                    \"or\" =\u003e TokenKind::LogicalOr,\n                    _ =\u003e TokenKind::Identifier,\n                };\n\n                let literal_value = match kind {\n                    TokenKind::True =\u003e Some(LiteralValue::Boolean(true)),\n                    TokenKind::False =\u003e Some(LiteralValue::Boolean(false)),\n                    _ =\u003e None,\n                };\n\n                tokens.push(Token {\n                    kind,\n                    lexeme: normalized_ident.to_string(),\n                    literal: literal_value,\n                    span: Span {\n                        start: Position {\n                            line: self.line,\n                            column: start_col,\n                            offset: start,\n                        },\n                        end: Position {\n                            line: self.line,\n                            column: self.column,\n                            offset: end_offset,\n                        },\n                    },\n                });\n                continue;\n            }\n\n            // Multi-character operators and punctuation (maximal munch)\n            let multi_char = [\n                (\"\u003c\u003c=\", TokenKind::ShiftLeftEqual),\n                (\"\u003e\u003e=\", TokenKind::ShiftRightEqual),\n                (\"==\", TokenKind::EqualEqual),\n                (\"!=\", TokenKind::NotEqual),\n                (\"\u003c=\", TokenKind::LessEqual),\n                (\"\u003e=\", TokenKind::GreaterEqual),\n                (\"\u0026\u0026\", TokenKind::LogicalAnd),\n                (\"||\", TokenKind::LogicalOr),\n                (\"+=\", TokenKind::PlusEqual),\n                (\"-=\", TokenKind::MinusEqual),\n                (\"*=\", TokenKind::StarEqual),\n                (\"/=\", TokenKind::SlashEqual),\n                (\"%=\", TokenKind::PercentEqual),\n                (\"\u0026=\", TokenKind::BitAndEqual),\n                (\"|=\", TokenKind::BitOrEqual),\n                (\"^=\", TokenKind::CaretEqual),\n                (\"\u003c\u003c\", TokenKind::ShiftLeft),\n                (\"\u003e\u003e\", TokenKind::ShiftRight),\n                (\"-\u003e\", TokenKind::Arrow),\n                (\"=\u003e\", TokenKind::FatArrow),\n                (\"..=\", TokenKind::DotDotEqual),\n                (\"..\", TokenKind::DotDot),\n                (\"::\", TokenKind::PathSep),\n                (\"??\", TokenKind::Coalesce),\n            ];\n            let mut matched = false;\n            for (op, kind) in multi_char.iter() {\n                if self.input.get(idx..).unwrap_or(\"\").starts_with(op) {\n                    let start_offset = idx;\n                    let start_col = self.column;\n                    for _ in 0..op.len() {\n                        self.advance_char();\n                    }\n                    let end_offset = self.current_offset();\n                    tokens.push(Token {\n                        kind: kind.clone(),\n                        lexeme: op.to_string(),\n                        literal: None,\n                        span: Span {\n                            start: Position {\n                                line: self.line,\n                                column: start_col,\n                                offset: start_offset,\n                            },\n                            end: Position {\n                                line: self.line,\n                                column: self.column,\n                                offset: end_offset,\n                            },\n                        },\n                    });\n                    matched = true;\n                    break;\n                }\n            }\n            if matched {\n                continue;\n            }\n\n            // Single-char punctuation\n            let kind = match ch {\n                '=' =\u003e TokenKind::Equal,\n                ';' =\u003e TokenKind::Semicolon,\n                '(' =\u003e TokenKind::LParen,\n                ')' =\u003e TokenKind::RParen,\n                '{' =\u003e TokenKind::LBrace,\n                '}' =\u003e TokenKind::RBrace,\n                ',' =\u003e TokenKind::Comma,\n                ':' =\u003e TokenKind::Colon,\n                '+' =\u003e TokenKind::Plus,\n                '-' =\u003e TokenKind::Minus,\n                '*' =\u003e TokenKind::Star,\n                '/' =\u003e TokenKind::Slash,\n                '\u003c' =\u003e TokenKind::Less,\n                '\u003e' =\u003e TokenKind::Greater,\n                '!' =\u003e TokenKind::Bang,\n                '.' =\u003e TokenKind::Dot,\n                '\u0026' =\u003e TokenKind::BitAnd,\n                '|' =\u003e TokenKind::BitOr,\n                '^' =\u003e TokenKind::Caret,\n                '_' =\u003e TokenKind::Underscore,\n                '%' =\u003e TokenKind::Percent,\n                '?' =\u003e TokenKind::Question,\n                _ =\u003e TokenKind::Error,\n            };\n            let lexeme = ch.to_string();\n            tokens.push(Token {\n                kind,\n                lexeme: lexeme.clone(),\n                literal: None,\n                span: Span {\n                    start: Position {\n                        line: self.line,\n                        column: self.column,\n                        offset: idx,\n                    },\n                    end: Position {\n                        line: self.line,\n                        column: self.column + 1,\n                        offset: idx + ch.len_utf8(),\n                    },\n                },\n            });\n            self.advance_char();\n\n            // At the very end, if nothing matched, emit Error for unrecognized input\n            if !ch.is_ascii() || ch.is_control() {\n                let start_offset = idx;\n                let start_col = self.column;\n                self.advance_char();\n                let end_offset = self.current_offset();\n                tokens.push(Token {\n                    kind: TokenKind::Error,\n                    lexeme: self\n                        .input\n                        .get(start_offset..end_offset)\n                        .unwrap_or(\"\")\n                        .to_string(),\n                    literal: Some(LiteralValue::String(\"Unrecognized input\".to_string())),\n                    span: Span {\n                        start: Position {\n                            line: self.line,\n                            column: start_col,\n                            offset: start_offset,\n                        },\n                        end: Position {\n                            line: self.line,\n                            column: self.column,\n                            offset: end_offset,\n                        },\n                    },\n                });\n                continue;\n            }\n        }\n        // At EOF, flush any remaining dedents\n        while self.indent_stack.len() \u003e 1 {\n            self.indent_stack.pop();\n            tokens.push(Token {\n                kind: TokenKind::Dedent,\n                lexeme: String::new(),\n                literal: None,\n                span: Span {\n                    start: Position {\n                        line: self.line,\n                        column: self.column,\n                        offset: self.current_offset(),\n                    },\n                    end: Position {\n                        line: self.line,\n                        column: self.column,\n                        offset: self.current_offset(),\n                    },\n                },\n            });\n        }\n        tokens.push(Token::eof_dummy());\n        tokens\n    }\n\n    fn advance_char(\u0026mut self) -\u003e Option\u003c(usize, char)\u003e {\n        let next = self.chars.next();\n        if let Some((_, ch)) = next {\n            if ch == '\\n' {\n                self.line += 1;\n                self.column = 1;\n            } else {\n                self.column += 1;\n            }\n        }\n        next\n    }\n\n    fn peek_nth_char(\u0026mut self, n: usize) -\u003e Option\u003c(usize, char)\u003e {\n        self.chars.clone().nth(n)\n    }\n\n    fn current_offset(\u0026mut self) -\u003e usize {\n        self.chars\n            .peek()\n            .map(|(i, _)| *i)\n            .unwrap_or(self.input.len())\n    }\n\n    /// Scan an integer or float, honoring underscores and exponents.\n    fn lex_number(\u0026mut self) -\u003e Token {\n        let start_offset = self.chars.peek().unwrap().0;\n        let start_line = self.line;\n        let start_col = self.column;\n\n        let mut lexeme = String::new();\n        let mut base = 10;\n\n        // Check for 0x, 0o, 0b prefixes\n        if self.chars.peek().is_some_and(|\u0026(_, c)| c == '0') {\n            lexeme.push('0');\n            self.advance_char();\n            if let Some(\u0026(_, next_char)) = self.chars.peek() {\n                match next_char.to_ascii_lowercase() {\n                    'x' =\u003e {\n                        base = 16;\n                        lexeme.push(next_char);\n                        self.advance_char();\n                    }\n                    'o' =\u003e {\n                        base = 8;\n                        lexeme.push(next_char);\n                        self.advance_char();\n                    }\n                    'b' =\u003e {\n                        base = 2;\n                        lexeme.push(next_char);\n                        self.advance_char();\n                    }\n                    '0'..='9' | '.' | 'e' | 'E' =\u003e { /* stay base 10 */ }\n                    _ =\u003e {}\n                }\n            }\n        }\n\n        let mut has_dot = false;\n        let mut has_exp = false;\n\n        // Allow leading dot for base 10 floats (e.g., .5)\n        if base == 10\n            \u0026\u0026 self.chars.peek().is_some_and(|\u0026(_, ch)| ch == '.')\n            \u0026\u0026 self\n                .peek_nth_char(1)\n                .is_some_and(|(_, c)| c.is_ascii_digit())\n        {\n            has_dot = true;\n            lexeme.push('.');\n            self.advance_char();\n        }\n\n        // Digit loop\n        while let Some(\u0026(_, ch)) = self.chars.peek() {\n            match ch {\n                '0'..='9' if ch.is_digit(base) =\u003e {\n                    lexeme.push(ch);\n                    self.advance_char();\n                }\n                'a'..='f' | 'A'..='F' if base == 16 =\u003e {\n                    lexeme.push(ch);\n                    self.advance_char();\n                }\n                '_' =\u003e {\n                    if lexeme\n                        .ends_with(|c: char| c.is_digit(base) || (base != 10 \u0026\u0026 lexeme.len() == 2))\n                    {\n                        lexeme.push(ch);\n                        self.advance_char();\n                    } else {\n                        break;\n                    }\n                }\n                // Float specific for base 10\n                '.' if base == 10 \u0026\u0026 !has_dot \u0026\u0026 !has_exp =\u003e {\n                    // If next char is a digit, treat as float part\n                    if self\n                        .peek_nth_char(1)\n                        .is_some_and(|(_, c)| c.is_ascii_digit())\n                    {\n                        has_dot = true;\n                        lexeme.push('.');\n                        self.advance_char();\n                    } else {\n                        // If next char is not a digit, treat as float with trailing dot (e.g., 7.)\n                        has_dot = true;\n                        lexeme.push('.');\n                        self.advance_char();\n                        break;\n                    }\n                }\n                'e' | 'E' if base == 10 \u0026\u0026 !has_exp =\u003e {\n                    has_exp = true;\n                    has_dot = true;\n                    lexeme.push(ch);\n                    self.advance_char();\n                    if let Some((_, next_ch)) = self.chars.peek() {\n                        if *next_ch == '+' || *next_ch == '-' {\n                            lexeme.push(*next_ch);\n                            self.advance_char();\n                        }\n                    }\n                    if !self.chars.peek().is_some_and(|\u0026(_, c)| c.is_ascii_digit()) {\n                        break;\n                    }\n                }\n                _ =\u003e break,\n            }\n        }\n\n        // Validate that if a prefix was consumed, there are actual digits after it\n        if (base == 16 \u0026\u0026 lexeme.eq_ignore_ascii_case(\"0x\"))\n            || (base == 8 \u0026\u0026 lexeme.eq_ignore_ascii_case(\"0o\"))\n            || (base == 2 \u0026\u0026 lexeme.eq_ignore_ascii_case(\"0b\"))\n        {\n            let end_offset = self.current_offset();\n            return Token {\n                kind: TokenKind::Error,\n                lexeme: lexeme.clone(),\n                literal: Some(LiteralValue::String(format!(\n                    \"Expected digits after base prefix '{}', but found none\",\n                    \u0026lexeme\n                ))),\n                span: Span {\n                    start: Position {\n                        line: start_line,\n                        column: start_col,\n                        offset: start_offset,\n                    },\n                    end: Position {\n                        line: self.line,\n                        column: self.column,\n                        offset: end_offset,\n                    },\n                },\n            };\n        }\n        if lexeme.ends_with('_') {\n            let end_offset = self.current_offset();\n            return Token {\n                kind: TokenKind::Error,\n                lexeme: lexeme.clone(),\n                literal: Some(LiteralValue::String(format!(\"Number literal cannot end with an underscore: '{}'. Remove the trailing underscore.\", lexeme))),\n                span: Span {\n                    start: Position { line: start_line, column: start_col, offset: start_offset },\n                    end: Position { line: self.line, column: self.column, offset: end_offset },\n                },\n            };\n        }\n\n        let end_offset = self.current_offset();\n        let span = Span {\n            start: Position {\n                line: start_line,\n                column: start_col,\n                offset: start_offset,\n            },\n            end: Position {\n                line: self.line,\n                column: self.column,\n                offset: end_offset,\n            },\n        };\n\n        let cleaned_lexeme: String = lexeme.chars().filter(|\u0026c| c != '_').collect();\n\n        if has_dot {\n            match cleaned_lexeme.parse::\u003cf64\u003e() {\n                Ok(val) =\u003e Token {\n                    kind: TokenKind::FloatLiteral,\n                    lexeme: lexeme.clone(),\n                    literal: Some(LiteralValue::Float(val)),\n                    span,\n                },\n                Err(_) =\u003e Token {\n                    kind: TokenKind::Error,\n                    lexeme: lexeme.clone(),\n                    literal: Some(LiteralValue::String(format!(\"Invalid float literal: '{}'. Expected a valid float (e.g., 1.23, 4e5, 7.), but got an invalid format.\", lexeme))),\n                    span,\n                },\n            }\n        } else {\n            let value_str_to_parse = if base != 10 {\n                if cleaned_lexeme.starts_with(\"0x\")\n                    || cleaned_lexeme.starts_with(\"0X\")\n                    || cleaned_lexeme.starts_with(\"0o\")\n                    || cleaned_lexeme.starts_with(\"0O\")\n                    || cleaned_lexeme.starts_with(\"0b\")\n                    || cleaned_lexeme.starts_with(\"0B\")\n                {\n                    \u0026cleaned_lexeme[2..]\n                } else {\n                    cleaned_lexeme.as_str()\n                }\n            } else {\n                cleaned_lexeme.as_str()\n            };\n\n            if value_str_to_parse.is_empty() \u0026\u0026 lexeme == \"0\" \u0026\u0026 base == 10 {\n                return Token {\n                    kind: TokenKind::IntegerLiteral,\n                    lexeme: \"0\".to_string(),\n                    literal: Some(LiteralValue::Integer(0)),\n                    span,\n                };\n            }\n            if value_str_to_parse.is_empty() \u0026\u0026 base != 10 {\n                return Token {\n                    kind: TokenKind::Error,\n                    lexeme: lexeme.clone(),\n                    literal: Some(LiteralValue::String(format!(\"Invalid integer literal for base {}: '{}'. Expected only valid digits for this base.\", base, lexeme))),\n                    span,\n                };\n            }\n\n            match i64::from_str_radix(value_str_to_parse, base) {\n                Ok(val) =\u003e Token {\n                    kind: TokenKind::IntegerLiteral,\n                    lexeme: lexeme.clone(),\n                    literal: Some(LiteralValue::Integer(val)),\n                    span,\n                },\n                Err(_) =\u003e Token {\n                    kind: TokenKind::Error,\n                    lexeme: lexeme.clone(),\n                    literal: Some(LiteralValue::String(format!(\"Invalid integer literal for base {}: '{}'. Expected only valid digits for this base.\", base, lexeme))),\n                    span,\n                },\n            }\n        }\n    }\n\n    // Helper function to parse \\u{...} escape sequences\n    // Consumes characters from self.chars.\n    // Returns Ok(char) or Err(Token) if parsing fails (error token is fully formed).\n    // Assumes '\\\\' and 'u' have already been consumed by the caller.\n    // lit_start_offset, lit_start_line, lit_start_col are for the *entire literal* being parsed (e.g. string or char literal)\n    // escape_start_offset, escape_start_line, escape_start_col are for the beginning of the \\u sequence itself.\n    fn parse_unicode_escape(\n        \u0026mut self,\n        _lit_start_offset: usize,\n        _lit_start_line: usize,\n        _lit_start_col: usize,\n        lit_kind: \u0026str,\n    ) -\u003e Result\u003cchar, Token\u003e {\n        // 'u' has been consumed. current_offset points to char after 'u'. self.column is col after 'u'.\n        let escape_u_offset = self.current_offset() - 'u'.len_utf8();\n        let escape_u_line = self.line; // Line of 'u'\n        let escape_u_col = self.column - 1; // Column of 'u'\n\n        if self.chars.peek().is_some_and(|\u0026(_, c)| c == '{') {\n            self.advance_char(); // consume '{'\n        } else {\n            let err_tok_end_pos = Position {\n                line: self.line,\n                column: self.column,\n                offset: self.current_offset(),\n            };\n            // Lexeme should be like \\uX or \\u\u003cEOF\u003e\n            let err_lexeme = self\n                .input\n                .get(escape_u_offset - '\\\\'.len_utf8()..err_tok_end_pos.offset)\n                .unwrap_or(\"\\\\u\")\n                .to_string();\n            let found_char = self\n                .chars\n                .peek()\n                .map(|(_, c)| c.to_string())\n                .unwrap_or_else(|| \"EOF\".to_string());\n            return Err(Token {\n                kind: TokenKind::Error,\n                lexeme: err_lexeme,\n                literal: Some(LiteralValue::String(format!(\n                    \"Invalid Unicode escape in {} literal: expected '{{' after \\\\u, found '{}'.\",\n                    lit_kind, found_char\n                ))),\n                span: Span {\n                    start: Position {\n                        line: escape_u_line,\n                        column: escape_u_col - 1,\n                        offset: escape_u_offset - '\\\\'.len_utf8(),\n                    }, // Span for \\u sequence\n                    end: err_tok_end_pos,\n                },\n            });\n        }\n\n        let mut hex_digits = String::new();\n        let mut num_hex_digits = 0;\n        let _hex_digits_start_offset = self.current_offset();\n        let _hex_digits_start_col = self.column;\n\n        while let Some(\u0026(_, ch)) = self.chars.peek() {\n            if ch.is_ascii_hexdigit() {\n                if num_hex_digits \u003c 6 {\n                    hex_digits.push(ch);\n                    self.advance_char();\n                    num_hex_digits += 1;\n                } else {\n                    // Too many hex digits\n                    self.advance_char(); // Consume the char that makes it too long to include in lexeme\n                    let err_tok_end_pos = Position {\n                        line: self.line,\n                        column: self.column,\n                        offset: self.current_offset(),\n                    };\n                    let err_lexeme = self\n                        .input\n                        .get(escape_u_offset - '\\\\'.len_utf8()..err_tok_end_pos.offset)\n                        .unwrap_or(\"\")\n                        .to_string();\n                    return Err(Token {\n                        kind: TokenKind::Error,\n                        lexeme: err_lexeme,\n                        literal: Some(LiteralValue::String(format!(\"Invalid Unicode escape in {} literal: too many hex digits (max 6) in \\\\u{{{}}}{{'.\", lit_kind, hex_digits))),\n                        span: Span { start: Position {line: escape_u_line, column: escape_u_col -1, offset: escape_u_offset - '\\\\'.len_utf8()}, end: err_tok_end_pos },\n                    });\n                }\n            } else if ch == '}' {\n                break;\n            } else {\n                // Invalid char in hex sequence\n                let err_tok_end_pos = Position {\n                    line: self.line,\n                    column: self.column,\n                    offset: self.current_offset(),\n                };\n                let err_lexeme = self\n                    .input\n                    .get(escape_u_offset - '\\\\'.len_utf8()..err_tok_end_pos.offset)\n                    .unwrap_or(\"\")\n                    .to_string();\n                return Err(Token {\n                    kind: TokenKind::Error,\n                    lexeme: err_lexeme,\n                    literal: Some(LiteralValue::String(format!(\"Invalid Unicode escape in {} literal: unexpected character '{}' in \\\\u{{{}}} sequence.\", lit_kind, ch, hex_digits))),\n                    span: Span { start: Position {line: escape_u_line, column: escape_u_col -1, offset: escape_u_offset - '\\\\'.len_utf8()}, end: err_tok_end_pos },\n                });\n            }\n        }\n\n        if self.chars.peek().is_none_or(|\u0026(_, c)| c != '}') {\n            // Unterminated: missing '}'\n            let err_tok_end_pos = Position {\n                line: self.line,\n                column: self.column,\n                offset: self.current_offset(),\n            };\n            let err_lexeme = self\n                .input\n                .get(escape_u_offset - '\\\\'.len_utf8()..err_tok_end_pos.offset)\n                .unwrap_or(\"\")\n                .to_string();\n            return Err(Token {\n                kind: TokenKind::Error,\n                lexeme: err_lexeme,\n                literal: Some(LiteralValue::String(format!(\"Invalid Unicode escape in {} literal: unclosed \\\\u{{{}}} sequence, missing '}}'.\", lit_kind, hex_digits))),\n                span: Span { start: Position {line: escape_u_line, column: escape_u_col-1, offset: escape_u_offset - '\\\\'.len_utf8()}, end: err_tok_end_pos },\n            });\n        }\n        self.advance_char(); // consume '}'\n\n        if num_hex_digits == 0 {\n            let err_tok_end_pos = Position {\n                line: self.line,\n                column: self.column,\n                offset: self.current_offset(),\n            };\n            let err_lexeme = self\n                .input\n                .get(escape_u_offset - '\\\\'.len_utf8()..err_tok_end_pos.offset)\n                .unwrap_or(\"\")\n                .to_string();\n            return Err(Token {\n                kind: TokenKind::Error,\n                lexeme: err_lexeme,\n                literal: Some(LiteralValue::String(format!(\n                    \"Invalid Unicode escape in {} literal: empty hex code \\\\u{{}}.\",\n                    lit_kind\n                ))),\n                span: Span {\n                    start: Position {\n                        line: escape_u_line,\n                        column: escape_u_col - 1,\n                        offset: escape_u_offset - '\\\\'.len_utf8(),\n                    },\n                    end: err_tok_end_pos,\n                },\n            });\n        }\n\n        match u32::from_str_radix(\u0026hex_digits, 16) {\n            Ok(codepoint) =\u003e match std::char::from_u32(codepoint) {\n                Some(ch_val) =\u003e Ok(ch_val),\n                None =\u003e {\n                    let err_tok_end_pos = Position {\n                        line: self.line,\n                        column: self.column,\n                        offset: self.current_offset(),\n                    };\n                    let err_lexeme = self\n                        .input\n                        .get(escape_u_offset - '\\\\'.len_utf8()..err_tok_end_pos.offset)\n                        .unwrap_or(\"\")\n                        .to_string();\n                    Err(Token {\n                        kind: TokenKind::Error,\n                        lexeme: err_lexeme,\n                        literal: Some(LiteralValue::String(format!(\"Invalid Unicode escape in {} literal: '\\\\u{{{}}}' is not a valid Unicode codepoint.\", lit_kind, hex_digits))),\n                        span: Span { start: Position {line: escape_u_line, column: escape_u_col-1, offset: escape_u_offset - '\\\\'.len_utf8()}, end: err_tok_end_pos },\n                    })\n                }\n            },\n            Err(_) =\u003e {\n                // Should not happen if num_hex_digits \u003e 0 and is_ascii_hexdigit passed\n                let err_tok_end_pos = Position {\n                    line: self.line,\n                    column: self.column,\n                    offset: self.current_offset(),\n                };\n                let err_lexeme = self\n                    .input\n                    .get(escape_u_offset - '\\\\'.len_utf8()..err_tok_end_pos.offset)\n                    .unwrap_or(\"\")\n                    .to_string();\n                Err(Token {\n                    kind: TokenKind::Error,\n                    lexeme: err_lexeme,\n                    literal: Some(LiteralValue::String(format!(\n                        \"Internal error parsing hex '{}' for {} literal.\",\n                        hex_digits, lit_kind\n                    ))),\n                    span: Span {\n                        start: Position {\n                            line: escape_u_line,\n                            column: escape_u_col - 1,\n                            offset: escape_u_offset - '\\\\'.len_utf8(),\n                        },\n                        end: err_tok_end_pos,\n                    },\n                })\n            }\n        }\n    }\n\n    fn lex_string_literal(\u0026mut self) -\u003e Token {\n        let start_offset = self.current_offset();\n        let start_line = self.line;\n        let start_col = self.column;\n\n        let mut content = String::new();\n\n        self.advance_char(); // consume the opening quote\n\n        let mut closed = false;\n        while let Some(\u0026(_idx, ch)) = self.chars.peek() {\n            match ch {\n                '\"' =\u003e {\n                    self.advance_char(); // consume the closing quote\n                    closed = true;\n                    break;\n                }\n                '\\\\' =\u003e {\n                    self.advance_char(); // consume backslash\n                    if let Some(\u0026(_escaped_idx, next_ch)) = self.chars.peek() {\n                        match next_ch {\n                            'n' =\u003e {\n                                content.push('\\n');\n                                self.advance_char();\n                            }\n                            't' =\u003e {\n                                content.push('\\t');\n                                self.advance_char();\n                            }\n                            '\\\\' =\u003e {\n                                content.push('\\\\');\n                                self.advance_char();\n                            }\n                            '\"' =\u003e {\n                                content.push('\"');\n                                self.advance_char();\n                            }\n                            'u' =\u003e {\n                                self.advance_char();\n                                match self.parse_unicode_escape(\n                                    start_offset,\n                                    start_line,\n                                    start_col,\n                                    \"string\",\n                                ) {\n                                    Ok(uc) =\u003e content.push(uc),\n                                    Err(token) =\u003e return token,\n                                }\n                            }\n                            _ =\u003e {\n                                let specific_error_lexeme = format!(\"\\\\{}\", next_ch);\n                                self.advance_char();\n                                let error_token_lexeme = self\n                                    .input\n                                    .get(start_offset..self.current_offset())\n                                    .unwrap_or(\"\")\n                                    .to_string();\n                                return Token {\n                                    kind: TokenKind::Error,\n                                    lexeme: error_token_lexeme,\n                                    literal: Some(LiteralValue::String(format!(\n                                        \"Invalid escape sequence in string literal: {}. Only valid escapes are \\\\n, \\\\t, \\\\\\\\, \\\\\\\" and \\\\u{{...}}.\",\n                                        specific_error_lexeme\n                                    ))),\n                                    span: Span {\n                                        start: Position { line: start_line, column: start_col, offset: start_offset },\n                                        end: Position { line: self.line, column: self.column, offset: self.current_offset() },\n                                    },\n                                };\n                            }\n                        }\n                    } else {\n                        // Unterminated escape sequence at EOF\n                        let current_lex_end_offset = self.current_offset();\n                        let current_lex_end_col = self.column;\n                        let current_lex_end_line = self.line;\n                        let lexeme = self\n                            .input\n                            .get(start_offset..current_lex_end_offset)\n                            .unwrap_or(\"\")\n                            .to_string();\n                        return Token {\n                            kind: TokenKind::Error,\n                            lexeme,\n                            literal: Some(LiteralValue::String(\n                                \"Unterminated escape sequence at end of string literal: expected character after \\\\\".to_string(),\n                            )),\n                            span: Span {\n                                start: Position { line: start_line, column: start_col, offset: start_offset },\n                                end: Position { line: current_lex_end_line, column: current_lex_end_col, offset: current_lex_end_offset },\n                            },\n                        };\n                    }\n                }\n                '\\n' =\u003e {\n                    // An unescaped newline character.\n                    // According to DESIGN_LEXER.md, string literals are single line unless escaped.\n                    // This signifies an unterminated string.\n                    // The newline character itself is NOT part of the string literal's lexeme or content.\n                    break;\n                }\n                _ =\u003e {\n                    content.push(ch);\n                    self.advance_char();\n                }\n            }\n        }\n\n        // current_offset() reflects the position *after* the last consumed character.\n        // If closed, it's after the closing quote. If not closed, it's where it stopped.\n        let current_lex_end_offset = self.current_offset();\n        let current_lex_end_col = self.column;\n        let current_lex_end_line = self.line;\n\n        if !closed {\n            return Token {\n                kind: TokenKind::Error,\n                lexeme: self.input.get(start_offset..current_lex_end_offset).unwrap_or(\"\").to_string(),\n                literal: Some(LiteralValue::String(\n                    r#\"Unterminated string literal: expected closing quote \" before end of line or file.\"#.to_string(),\n                )),\n                span: Span {\n                    start: Position { line: start_line, column: start_col, offset: start_offset },\n                    end: Position { line: current_lex_end_line, column: current_lex_end_col, offset: current_lex_end_offset },\n                },\n            };\n        }\n\n        Token {\n            kind: TokenKind::StringLiteral,\n            lexeme: self\n                .input\n                .get(start_offset..current_lex_end_offset)\n                .unwrap_or(\"\")\n                .to_string(),\n            literal: Some(LiteralValue::String(content)),\n            span: Span {\n                start: Position {\n                    line: start_line,\n                    column: start_col,\n                    offset: start_offset,\n                },\n                end: Position {\n                    line: current_lex_end_line,\n                    column: current_lex_end_col,\n                    offset: current_lex_end_offset,\n                },\n            },\n        }\n    }\n\n    fn lex_char_literal(\u0026mut self) -\u003e Token {\n        let start_offset = self.current_offset();\n        let start_line = self.line;\n        let start_col = self.column;\n\n        self.advance_char(); // consume the opening quote '\n\n        let mut char_val: Option\u003cchar\u003e = None;\n        let mut closed = false;\n        let mut error_msg: Option\u003cString\u003e = None;\n        let mut consumed_char_count = 0;\n\n        if let Some(\u0026(_idx, ch)) = self.chars.peek() {\n            match ch {\n                '\\'' =\u003e {\n                    // Empty char literal: ''\n                    error_msg = Some(\"Empty character literal \".to_string());\n                    self.advance_char(); // consume the closing quote\n                    closed = true;\n                }\n                '\\\\' =\u003e {\n                    // Escape sequence\n                    self.advance_char(); // consume backslash\n                    if let Some(\u0026(_escaped_idx, next_ch)) = self.chars.peek() {\n                        if next_ch == 'u' {\n                            self.advance_char(); // consume 'u'\n                            match self.parse_unicode_escape(\n                                start_offset,\n                                start_line,\n                                start_col,\n                                \"character\",\n                            ) {\n                                Ok(cv) =\u003e {\n                                    char_val = Some(cv);\n                                    consumed_char_count += 1;\n                                    // After a valid unicode escape, check for closing quote\n                                    if let Some(\u0026(_, ch)) = self.chars.peek() {\n                                        if ch == '\\'' {\n                                            self.advance_char(); // consume closing quote\n                                            let cv = char_val.unwrap();\n                                            let final_lexeme = self\n                                                .input\n                                                .get(start_offset..self.current_offset())\n                                                .unwrap_or(\"\");\n                                            return Token {\n                                                kind: TokenKind::CharacterLiteral,\n                                                lexeme: final_lexeme.to_string(),\n                                                literal: Some(LiteralValue::Char(cv)),\n                                                span: Span {\n                                                    start: Position {\n                                                        line: start_line,\n                                                        column: start_col,\n                                                        offset: start_offset,\n                                                    },\n                                                    end: Position {\n                                                        line: self.line,\n                                                        column: self.column,\n                                                        offset: self.current_offset(),\n                                                    },\n                                                },\n                                            };\n                                        } else {\n                                            // Not a closing quote: multi-character or unterminated\n                                            error_msg = Some(\"Multi-character literal or unterminated (in character literal)\".to_string());\n                                        }\n                                    } else {\n                                        // EOF before closing quote\n                                        error_msg = Some(\"Unterminated character literal (EOF before closing quote) (in character literal)\".to_string());\n                                    }\n                                }\n                                Err(token) =\u003e return token, // Return error token directly\n                            }\n                        } else {\n                            // Simple escape like \\n, \\t, etc.\n                            let current_char_res = match next_ch {\n                                'n' =\u003e Ok('\\n'),\n                                't' =\u003e Ok('\\t'),\n                                'r' =\u003e Ok('\\r'),\n                                '0' =\u003e Ok('\\0'),\n                                '\\\\' =\u003e Ok('\\\\'),\n                                '\\'' =\u003e Ok('\\''),\n                                _ =\u003e Err(format!(\n                                    \"Invalid escape sequence in char literal: \\\\{}\",\n                                    next_ch\n                                )),\n                            };\n                            self.advance_char(); // consume the character after backslash (e.g. 'n' in \\n)\n\n                            match current_char_res {\n                                Ok(cv) =\u003e {\n                                    char_val = Some(cv);\n                                    consumed_char_count += 1;\n                                }\n                                // Error message for char lit needs to be specific for invalid simple escape\n                                Err(msg_str) =\u003e {\n                                    error_msg = Some(format!(\"{} (in character literal)\", msg_str))\n                                }\n                            }\n                        }\n                    } else {\n                        // Unterminated: EOF after backslash (e.g. '\\')\n                        error_msg = Some(\n                            \"Unterminated character literal after backslash (in character literal)\"\n                                .to_string(),\n                        );\n                    }\n                }\n                '\\n' =\u003e {\n                    // Unescaped newline\n                    error_msg =\n                        Some(\"Unterminated character literal (newline encountered)\".to_string());\n                    // Do not consume newline, it's not part of the error lexeme for the char\n                }\n                _ =\u003e {\n                    // Regular character\n                    char_val = Some(ch);\n                    consumed_char_count += 1;\n                    self.advance_char(); // consume the character\n                }\n            }\n        } else {\n            // Unterminated: EOF immediately after opening '\n            error_msg = Some(\"Unterminated character literal (EOF)\".to_string());\n        }\n\n        if error_msg.is_none() \u0026\u0026 !closed {\n            // if no error so far, try to consume closing quote\n            if let Some(\u0026(_, ch)) = self.chars.peek() {\n                if ch == '\\'' {\n                    self.advance_char(); // consume closing quote\n                    closed = true;\n                    if consumed_char_count \u003e 1 {\n                        error_msg = Some(\"Multi-character literal \".to_string());\n                    } else if consumed_char_count == 0 \u0026\u0026 char_val.is_none() {\n                        error_msg = Some(\"Empty character literal \".to_string());\n                    }\n                } else {\n                    // Expected closing quote, found something else or too many chars\n                    if consumed_char_count \u003e= 1 {\n                        error_msg = Some(\"Multi-character literal or unterminated \".to_string());\n                    } else {\n                        error_msg = Some(\"Unterminated character literal \".to_string());\n                    }\n                }\n            } else {\n                // EOF before closing quote\n                error_msg =\n                    Some(\"Unterminated character literal (EOF before closing quote) \".to_string());\n            }\n        }\n\n        let current_lex_end_offset = self.current_offset();\n        let current_lex_end_col = self.column;\n        let current_lex_end_line = self.line;\n\n        let final_lexeme = self\n            .input\n            .get(start_offset..current_lex_end_offset)\n            .unwrap_or(\"\");\n\n        if let Some(mut msg) = error_msg {\n            if !msg.ends_with(\"(in character literal)\") {\n                if msg.ends_with(' ') {\n                    msg.push_str(\"(in character literal)\");\n                } else {\n                    msg.push_str(\" (in character literal)\");\n                }\n            }\n            return Token {\n                kind: TokenKind::Error,\n                lexeme: final_lexeme.to_string(),\n                literal: Some(LiteralValue::String(msg)),\n                span: Span {\n                    start: Position {\n                        line: start_line,\n                        column: start_col,\n                        offset: start_offset,\n                    },\n                    end: Position {\n                        line: current_lex_end_line,\n                        column: current_lex_end_col,\n                        offset: current_lex_end_offset,\n                    },\n                },\n            };\n        }\n        // If we have an error, return an Error token\n        if !closed {\n            return Token {\n                kind: TokenKind::Error,\n                lexeme: final_lexeme.to_string(),\n                literal: Some(LiteralValue::String(\n                    \"Unterminated character literal (in character literal)\".to_string(),\n                )),\n                span: Span {\n                    start: Position {\n                        line: start_line,\n                        column: start_col,\n                        offset: start_offset,\n                    },\n                    end: Position {\n                        line: current_lex_end_line,\n                        column: current_lex_end_col,\n                        offset: current_lex_end_offset,\n                    },\n                },\n            };\n        }\n\n        if let Some(cv) = char_val {\n            if consumed_char_count == 1 {\n                // Double check, though error_msg should catch multi-char or empty.\n                Token {\n                    kind: TokenKind::CharacterLiteral,\n                    lexeme: final_lexeme.to_string(),\n                    literal: Some(LiteralValue::Char(cv)),\n                    span: Span {\n                        start: Position {\n                            line: start_line,\n                            column: start_col,\n                            offset: start_offset,\n                        },\n                        end: Position {\n                            line: self.line,\n                            column: self.column,\n                            offset: self.current_offset(),\n                        },\n                    },\n                }\n            } else {\n                Token {\n                    kind: TokenKind::Error,\n                    lexeme: final_lexeme.to_string(),\n                    literal: Some(LiteralValue::String(\n                        \"Multi-character literal or unterminated (in character literal)\"\n                            .to_string(),\n                    )),\n                    span: Span {\n                        start: Position {\n                            line: start_line,\n                            column: start_col,\n                            offset: start_offset,\n                        },\n                        end: Position {\n                            line: current_lex_end_line,\n                            column: current_lex_end_col,\n                            offset: current_lex_end_offset,\n                        },\n                    },\n                }\n            }\n        } else {\n            Token {\n                kind: TokenKind::Error,\n                lexeme: final_lexeme.to_string(),\n                literal: Some(LiteralValue::String(\n                    \"Unterminated character literal (in character literal)\".to_string(),\n                )),\n                span: Span {\n                    start: Position {\n                        line: start_line,\n                        column: start_col,\n                        offset: start_offset,\n                    },\n                    end: Position {\n                        line: current_lex_end_line,\n                        column: current_lex_end_col,\n                        offset: current_lex_end_offset,\n                    },\n                },\n            }\n        }\n    }\n\n    fn lex_raw_string_literal(\u0026mut self, start_idx: usize) -\u003e Token {\n        let start_line = self.line;\n        let start_col = self.column;\n\n        self.advance_char(); // consume 'r'\n\n        // Count hash characters for delimiter\n        let mut hash_count = 0;\n        while let Some(\u0026(_, ch)) = self.chars.peek() {\n            if ch == '#' {\n                hash_count += 1;\n                self.advance_char();\n            } else {\n                break;\n            }\n        }\n\n        // Expect opening quote\n        if !matches!(self.chars.peek(), Some(\u0026(_, '\"'))) {\n            let end_offset = self.current_offset();\n            return Token {\n                kind: TokenKind::Error,\n                lexeme: self\n                    .input\n                    .get(start_idx..end_offset)\n                    .unwrap_or(\"\")\n                    .to_string(),\n                literal: Some(LiteralValue::String(\n                    \"Expected '\\\"' after 'r' and hash characters in raw string literal.\"\n                        .to_string(),\n                )),\n                span: Span {\n                    start: Position {\n                        line: start_line,\n                        column: start_col,\n                        offset: start_idx,\n                    },\n                    end: Position {\n                        line: self.line,\n                        column: self.column,\n                        offset: end_offset,\n                    },\n                },\n            };\n        }\n\n        self.advance_char(); // consume opening '\"'\n        let content_start_offset = self.current_offset();\n        let mut content = String::new();\n        let mut closed = false;\n\n        while let Some(\u0026(_i, ch)) = self.chars.peek() {\n            if ch == '\"' {\n                // Check if followed by the correct number of hashes\n                let mut temp_hash_count = 0;\n                let mut temp_offset = 1;\n\n                while let Some((_, temp_ch)) = self.peek_nth_char(temp_offset) {\n                    if temp_ch == '#' \u0026\u0026 temp_hash_count \u003c hash_count {\n                        temp_hash_count += 1;\n                        temp_offset += 1;\n                    } else {\n                        break;\n                    }\n                }\n\n                if temp_hash_count == hash_count {\n                    // Found the closing delimiter\n                    self.advance_char(); // consume closing '\"'\n                    for _ in 0..hash_count {\n                        self.advance_char(); // consume closing hashes\n                    }\n                    closed = true;\n                    break;\n                } else {\n                    // Not the closing delimiter, treat as content\n                    content.push(ch);\n                    self.advance_char();\n                }\n            } else {\n                // No escape processing for raw strings\n                content.push(ch);\n                self.advance_char();\n            }\n        }\n\n        let end_offset = self.current_offset();\n\n        let span = Span {\n            start: Position {\n                line: start_line,\n                column: start_col,\n                offset: start_idx,\n            },\n            end: Position {\n                line: self.line,\n                column: self.column,\n                offset: end_offset,\n            },\n        };\n\n        if !closed {\n            Token {\n                kind: TokenKind::Error,\n                lexeme: self.input.get(start_idx..end_offset).unwrap_or(\"\").to_string(),\n                literal: Some(LiteralValue::String(\"Unterminated raw string literal: expected closing quote and matching hash characters before end of file.\".to_string())),\n                span,\n            }\n        } else {\n            // Extract the content without the delimiters\n            let actual_content = self\n                .input\n                .get(\n                    content_start_offset\n                        ..(end_offset - '\"'.len_utf8() - hash_count * '#'.len_utf8()),\n                )\n                .unwrap_or(\"\");\n            Token {\n                kind: TokenKind::RawStringLiteral,\n                lexeme: self\n                    .input\n                    .get(start_idx..end_offset)\n                    .unwrap_or(\"\")\n                    .to_string(),\n                literal: Some(LiteralValue::String(actual_content.to_string())),\n                span,\n            }\n        }\n    }\n\n    fn lex_byte_literal(\u0026mut self, start_offset_param: usize) -\u003e Token {\n        let start_line = self.line;\n        let start_col = self.column;\n\n        self.advance_char(); // consume 'b'\n        let quote = self.advance_char().unwrap().1; // consume quote\n        let mut content = String::new();\n        let mut closed = false;\n        while let Some(\u0026(_, c)) = self.chars.peek() {\n            if c == quote {\n                self.advance_char();\n                closed = true;\n                break;\n            } else if c == '\\\\' {\n                // Basic escape handling for byte strings (e.g., b\"\\\\\", b\"\\'\", b\"\\\"\")\n                self.advance_char(); // consume backslash\n                if let Some(\u0026(_, esc_char)) = self.chars.peek() {\n                    match esc_char {\n                        'n' | 't' | 'r' | '0' | '\\\\' | '\\'' | '\"' =\u003e {\n                            // Common escapes, store as is\n                            content.push('\\\\');\n                            content.push(esc_char);\n                        }\n                        // Hex escapes like \\xHH could be added here if desired for byte strings\n                        _ =\u003e {\n                            // For byte strings, unknown escapes might be stored literally or be an error\n                            // Storing literally: \\ and the char\n                            content.push('\\\\');\n                            content.push(esc_char);\n                        }\n                    }\n                    self.advance_char(); // consume the escaped char\n                } else {\n                    break; // Unterminated escape at EOF\n                }\n            } else {\n                content.push(c);\n                self.advance_char();\n            }\n        }\n        let end_offset = self.current_offset();\n        let lexeme = self.input.get(start_offset_param..end_offset).unwrap_or(\"\");\n        let span = Span {\n            start: Position {\n                line: start_line,\n                column: start_col,\n                offset: start_offset_param,\n            },\n            end: Position {\n                line: self.line,\n                column: self.column,\n                offset: end_offset,\n            },\n        };\n\n        if !closed {\n            Token {\n                kind: TokenKind::Error,\n                lexeme: lexeme.to_string(),\n                literal: Some(LiteralValue::String(\n                    \"Unterminated byte literal\".to_string(),\n                )),\n                span,\n            }\n        } else if quote == '\\'' {\n            // Single-quoted byte literal, b'...'\n            // As per RFC-001 (implicitly, via char literal def), char/byte literals are single char/byte.\n            // For b'...', the `content` after escape processing must be a single byte representation.\n            // This requires more robust escape processing if e.g. b'\\n' is to become a single byte 10.\n            // Current simple escape stores \\ and n. For b'\\n', content is \"\\n\".len() = 2.\n            // For now, if it's b'c', content is \"c\". If b'\\\\ ', content is \"\\\\\".\n            // A simple check: if content contains \\, it's likely an escape not yet processed to a single byte.\n            // Or, if content.chars().count() != 1 for simple chars.\n            // Let's refine this: Ferra design implies byte literals are simple for now.\n            // b'a' -\u003e byte 'a'. b'\\'' -\u003e byte '''. b'\\\\' -\u003e byte '\\\\'.\n            // What about b'\\n'? The current escape logic makes `content` = \"\\n\".\n            // This is tricky for b'X'. For now, assume content should be 1 char unless it's a known single-byte escape.\n\n            if content.chars().count() == 1 {\n                Token {\n                    kind: TokenKind::ByteLiteral,\n                    lexeme: lexeme.to_string(),\n                    literal: Some(LiteralValue::Byte(content.as_bytes()[0])),\n                    span,\n                }\n            } else {\n                Token {\n                    kind: TokenKind::Error,\n                    lexeme: lexeme.to_string(),\n                    literal: Some(LiteralValue::String(\n                        \"Byte literal b'...' must represent a single byte after escapes.\"\n                            .to_string(),\n                    )),\n                    span,\n                }\n            }\n        } else {\n            Token {\n                kind: TokenKind::ByteLiteral,\n                lexeme: lexeme.to_string(),\n                literal: Some(LiteralValue::String(content)),\n                span,\n            }\n        }\n    }\n\n    fn lex_multiline_string_literal(\u0026mut self, start_idx: usize) -\u003e Token {\n        let start_line = self.line;\n        let start_col = self.column;\n\n        // Consume opening \"\"\"\n        self.advance_char(); // first \"\n        self.advance_char(); // second \"\n        self.advance_char(); // third \"\n\n        let mut content = String::new();\n        let mut closed = false;\n        let mut lines = Vec::new();\n        let mut current_line = String::new();\n\n        while let Some(\u0026(_idx, ch)) = self.chars.peek() {\n            if ch == '\"' {\n                // Check for closing \"\"\"\n                if self.peek_nth_char(1).is_some_and(|(_, c)| c == '\"')\n                    \u0026\u0026 self.peek_nth_char(2).is_some_and(|(_, c)| c == '\"')\n                {\n                    // Found closing delimiter\n                    self.advance_char(); // first \"\n                    self.advance_char(); // second \"\n                    self.advance_char(); // third \"\n                    closed = true;\n                    break;\n                } else {\n                    // Single quote, add to content\n                    current_line.push(ch);\n                    self.advance_char();\n                }\n            } else if ch == '\\n' {\n                // End of line\n                lines.push(current_line.clone());\n                current_line.clear();\n                content.push(ch);\n                self.advance_char();\n            } else {\n                // Regular character\n                current_line.push(ch);\n                content.push(ch);\n                self.advance_char();\n            }\n        }\n\n        // Add the last line if not empty\n        if !current_line.is_empty() {\n            lines.push(current_line);\n        }\n\n        let end_offset = self.current_offset();\n        let span = Span {\n            start: Position {\n                line: start_line,\n                column: start_col,\n                offset: start_idx,\n            },\n            end: Position {\n                line: self.line,\n                column: self.column,\n                offset: end_offset,\n            },\n        };\n\n        if !closed {\n            return Token {\n                kind: TokenKind::Error,\n                lexeme: self.input.get(start_idx..end_offset).unwrap_or(\"\").to_string(),\n                literal: Some(LiteralValue::String(\"Unterminated multiline string literal: expected closing \\\"\\\"\\\" before end of file.\".to_string())),\n                span,\n            };\n        }\n\n        // Apply indent stripping algorithm\n        let processed_content = self.strip_common_indentation(\u0026lines);\n\n        Token {\n            kind: TokenKind::MultiLineStringLiteral,\n            lexeme: self\n                .input\n                .get(start_idx..end_offset)\n                .unwrap_or(\"\")\n                .to_string(),\n            literal: Some(LiteralValue::String(processed_content)),\n            span,\n        }\n    }\n\n    // Helper function to strip common indentation from multiline strings\n    fn strip_common_indentation(\u0026self, lines: \u0026[String]) -\u003e String {\n        if lines.is_empty() {\n            return String::new();\n        }\n\n        // Check if first line has content\n        let first_line_has_content = !lines[0].trim().is_empty();\n\n        if first_line_has_content {\n            // If first line has content, don't strip indentation - just join lines\n            return lines.join(\"\\n\");\n        }\n\n        // Skip the first line if it's empty (common pattern with \"\"\")\n        let start_idx = 1;\n\n        if start_idx \u003e= lines.len() {\n            return String::new();\n        }\n\n        // Find the minimum indentation (ignoring empty lines)\n        let mut min_indent = usize::MAX;\n        for line in \u0026lines[start_idx..] {\n            if !line.trim().is_empty() {\n                let indent = line.len() - line.trim_start().len();\n                min_indent = min_indent.min(indent);\n            }\n        }\n\n        // If no non-empty lines found, return empty\n        if min_indent == usize::MAX {\n            return String::new();\n        }\n\n        // Strip the common indentation\n        let mut result = String::new();\n        let lines_to_process = \u0026lines[start_idx..];\n\n        for (i, line) in lines_to_process.iter().enumerate() {\n            if i \u003e 0 {\n                result.push('\\n');\n            }\n\n            if line.trim().is_empty() {\n                // Keep empty lines as empty (but preserve the newline)\n                // Don't add anything for empty lines (the newline is added above)\n            } else if line.len() \u003e= min_indent {\n                // Strip the common indentation\n                result.push_str(\u0026line[min_indent..]);\n            } else {\n                // Line has less indentation than expected, keep as-is\n                result.push_str(line);\n            }\n        }\n\n        result\n    }\n}\n","traces":[{"line":142,"address":[],"length":0,"stats":{"Line":959}},{"line":144,"address":[],"length":0,"stats":{"Line":959}},{"line":149,"address":[],"length":0,"stats":{"Line":959}},{"line":160,"address":[],"length":0,"stats":{"Line":959}},{"line":163,"address":[],"length":0,"stats":{"Line":959}},{"line":165,"address":[],"length":0,"stats":{"Line":959}},{"line":181,"address":[],"length":0,"stats":{"Line":957}},{"line":183,"address":[],"length":0,"stats":{"Line":1914}},{"line":184,"address":[],"length":0,"stats":{"Line":1}},{"line":185,"address":[],"length":0,"stats":{"Line":1}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":956}},{"line":193,"address":[],"length":0,"stats":{"Line":957}},{"line":196,"address":[],"length":0,"stats":{"Line":957}},{"line":202,"address":[],"length":0,"stats":{"Line":957}},{"line":203,"address":[],"length":0,"stats":{"Line":957}},{"line":204,"address":[],"length":0,"stats":{"Line":69977}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":7}},{"line":208,"address":[],"length":0,"stats":{"Line":7}},{"line":209,"address":[],"length":0,"stats":{"Line":7}},{"line":210,"address":[],"length":0,"stats":{"Line":7}},{"line":211,"address":[],"length":0,"stats":{"Line":7}},{"line":212,"address":[],"length":0,"stats":{"Line":7}},{"line":213,"address":[],"length":0,"stats":{"Line":7}},{"line":214,"address":[],"length":0,"stats":{"Line":7}},{"line":215,"address":[],"length":0,"stats":{"Line":7}},{"line":216,"address":[],"length":0,"stats":{"Line":7}},{"line":218,"address":[],"length":0,"stats":{"Line":7}},{"line":219,"address":[],"length":0,"stats":{"Line":7}},{"line":220,"address":[],"length":0,"stats":{"Line":7}},{"line":221,"address":[],"length":0,"stats":{"Line":7}},{"line":225,"address":[],"length":0,"stats":{"Line":7}},{"line":228,"address":[],"length":0,"stats":{"Line":34503}},{"line":229,"address":[],"length":0,"stats":{"Line":985}},{"line":230,"address":[],"length":0,"stats":{"Line":985}},{"line":231,"address":[],"length":0,"stats":{"Line":985}},{"line":232,"address":[],"length":0,"stats":{"Line":2955}},{"line":233,"address":[],"length":0,"stats":{"Line":985}},{"line":236,"address":[],"length":0,"stats":{"Line":2133}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":71}},{"line":239,"address":[],"length":0,"stats":{"Line":2}},{"line":241,"address":[],"length":0,"stats":{"Line":69}},{"line":242,"address":[],"length":0,"stats":{"Line":69}},{"line":243,"address":[],"length":0,"stats":{"Line":69}},{"line":244,"address":[],"length":0,"stats":{"Line":997}},{"line":245,"address":[],"length":0,"stats":{"Line":14}},{"line":246,"address":[],"length":0,"stats":{"Line":1}},{"line":248,"address":[],"length":0,"stats":{"Line":0}},{"line":249,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":984}},{"line":256,"address":[],"length":0,"stats":{"Line":985}},{"line":258,"address":[],"length":0,"stats":{"Line":3}},{"line":259,"address":[],"length":0,"stats":{"Line":6}},{"line":260,"address":[],"length":0,"stats":{"Line":3}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":3}},{"line":268,"address":[],"length":0,"stats":{"Line":3}},{"line":269,"address":[],"length":0,"stats":{"Line":3}},{"line":270,"address":[],"length":0,"stats":{"Line":3}},{"line":274,"address":[],"length":0,"stats":{"Line":3}},{"line":275,"address":[],"length":0,"stats":{"Line":3}},{"line":276,"address":[],"length":0,"stats":{"Line":3}},{"line":277,"address":[],"length":0,"stats":{"Line":3}},{"line":278,"address":[],"length":0,"stats":{"Line":3}},{"line":280,"address":[],"length":0,"stats":{"Line":3}},{"line":281,"address":[],"length":0,"stats":{"Line":3}},{"line":282,"address":[],"length":0,"stats":{"Line":3}},{"line":283,"address":[],"length":0,"stats":{"Line":3}},{"line":284,"address":[],"length":0,"stats":{"Line":3}},{"line":286,"address":[],"length":0,"stats":{"Line":3}},{"line":287,"address":[],"length":0,"stats":{"Line":3}},{"line":288,"address":[],"length":0,"stats":{"Line":3}},{"line":289,"address":[],"length":0,"stats":{"Line":3}},{"line":296,"address":[],"length":0,"stats":{"Line":3}},{"line":299,"address":[],"length":0,"stats":{"Line":1002}},{"line":300,"address":[],"length":0,"stats":{"Line":20}},{"line":301,"address":[],"length":0,"stats":{"Line":20}},{"line":302,"address":[],"length":0,"stats":{"Line":20}},{"line":303,"address":[],"length":0,"stats":{"Line":20}},{"line":304,"address":[],"length":0,"stats":{"Line":20}},{"line":305,"address":[],"length":0,"stats":{"Line":20}},{"line":306,"address":[],"length":0,"stats":{"Line":20}},{"line":307,"address":[],"length":0,"stats":{"Line":20}},{"line":308,"address":[],"length":0,"stats":{"Line":20}},{"line":309,"address":[],"length":0,"stats":{"Line":20}},{"line":311,"address":[],"length":0,"stats":{"Line":20}},{"line":312,"address":[],"length":0,"stats":{"Line":20}},{"line":313,"address":[],"length":0,"stats":{"Line":20}},{"line":314,"address":[],"length":0,"stats":{"Line":20}},{"line":318,"address":[],"length":0,"stats":{"Line":982}},{"line":319,"address":[],"length":0,"stats":{"Line":21}},{"line":320,"address":[],"length":0,"stats":{"Line":7}},{"line":321,"address":[],"length":0,"stats":{"Line":7}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":985}},{"line":331,"address":[],"length":0,"stats":{"Line":33518}},{"line":332,"address":[],"length":0,"stats":{"Line":32}},{"line":333,"address":[],"length":0,"stats":{"Line":32}},{"line":334,"address":[],"length":0,"stats":{"Line":32}},{"line":335,"address":[],"length":0,"stats":{"Line":32}},{"line":336,"address":[],"length":0,"stats":{"Line":32}},{"line":337,"address":[],"length":0,"stats":{"Line":32}},{"line":338,"address":[],"length":0,"stats":{"Line":32}},{"line":339,"address":[],"length":0,"stats":{"Line":32}},{"line":340,"address":[],"length":0,"stats":{"Line":32}},{"line":341,"address":[],"length":0,"stats":{"Line":32}},{"line":342,"address":[],"length":0,"stats":{"Line":32}},{"line":343,"address":[],"length":0,"stats":{"Line":32}},{"line":345,"address":[],"length":0,"stats":{"Line":32}},{"line":346,"address":[],"length":0,"stats":{"Line":32}},{"line":347,"address":[],"length":0,"stats":{"Line":32}},{"line":348,"address":[],"length":0,"stats":{"Line":32}},{"line":352,"address":[],"length":0,"stats":{"Line":32}},{"line":353,"address":[],"length":0,"stats":{"Line":32}},{"line":355,"address":[],"length":0,"stats":{"Line":33486}},{"line":356,"address":[],"length":0,"stats":{"Line":32870}},{"line":357,"address":[],"length":0,"stats":{"Line":611}},{"line":358,"address":[],"length":0,"stats":{"Line":611}},{"line":359,"address":[],"length":0,"stats":{"Line":1832}},{"line":361,"address":[],"length":0,"stats":{"Line":635}},{"line":362,"address":[],"length":0,"stats":{"Line":635}},{"line":366,"address":[],"length":0,"stats":{"Line":32851}},{"line":367,"address":[],"length":0,"stats":{"Line":2149}},{"line":369,"address":[],"length":0,"stats":{"Line":21}},{"line":370,"address":[],"length":0,"stats":{"Line":21}},{"line":371,"address":[],"length":0,"stats":{"Line":5695}},{"line":372,"address":[],"length":0,"stats":{"Line":0}},{"line":373,"address":[],"length":0,"stats":{"Line":4}},{"line":375,"address":[],"length":0,"stats":{"Line":2835}},{"line":377,"address":[],"length":0,"stats":{"Line":21}},{"line":378,"address":[],"length":0,"stats":{"Line":1390}},{"line":380,"address":[],"length":0,"stats":{"Line":24}},{"line":381,"address":[],"length":0,"stats":{"Line":24}},{"line":382,"address":[],"length":0,"stats":{"Line":24}},{"line":384,"address":[],"length":0,"stats":{"Line":24}},{"line":385,"address":[],"length":0,"stats":{"Line":24}},{"line":387,"address":[],"length":0,"stats":{"Line":24}},{"line":388,"address":[],"length":0,"stats":{"Line":24}},{"line":390,"address":[],"length":0,"stats":{"Line":7820}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":393,"address":[],"length":0,"stats":{"Line":144}},{"line":394,"address":[],"length":0,"stats":{"Line":3}},{"line":395,"address":[],"length":0,"stats":{"Line":3}},{"line":396,"address":[],"length":0,"stats":{"Line":3}},{"line":399,"address":[],"length":0,"stats":{"Line":3828}},{"line":400,"address":[],"length":0,"stats":{"Line":121}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":7}},{"line":403,"address":[],"length":0,"stats":{"Line":7}},{"line":404,"address":[],"length":0,"stats":{"Line":7}},{"line":405,"address":[],"length":0,"stats":{"Line":4}},{"line":406,"address":[],"length":0,"stats":{"Line":4}},{"line":413,"address":[],"length":0,"stats":{"Line":24}},{"line":414,"address":[],"length":0,"stats":{"Line":20}},{"line":415,"address":[],"length":0,"stats":{"Line":20}},{"line":416,"address":[],"length":0,"stats":{"Line":20}},{"line":419,"address":[],"length":0,"stats":{"Line":20}},{"line":420,"address":[],"length":0,"stats":{"Line":20}},{"line":422,"address":[],"length":0,"stats":{"Line":3890}},{"line":423,"address":[],"length":0,"stats":{"Line":3}},{"line":424,"address":[],"length":0,"stats":{"Line":3}},{"line":425,"address":[],"length":0,"stats":{"Line":3}},{"line":427,"address":[],"length":0,"stats":{"Line":3887}},{"line":431,"address":[],"length":0,"stats":{"Line":0}},{"line":432,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":24}},{"line":452,"address":[],"length":0,"stats":{"Line":24}},{"line":457,"address":[],"length":0,"stats":{"Line":32806}},{"line":459,"address":[],"length":0,"stats":{"Line":2155}},{"line":460,"address":[],"length":0,"stats":{"Line":2155}},{"line":464,"address":[],"length":0,"stats":{"Line":30651}},{"line":466,"address":[],"length":0,"stats":{"Line":3034}},{"line":467,"address":[],"length":0,"stats":{"Line":842}},{"line":469,"address":[],"length":0,"stats":{"Line":268}},{"line":471,"address":[],"length":0,"stats":{"Line":792}},{"line":473,"address":[],"length":0,"stats":{"Line":1060}},{"line":477,"address":[],"length":0,"stats":{"Line":29591}},{"line":478,"address":[],"length":0,"stats":{"Line":696}},{"line":479,"address":[],"length":0,"stats":{"Line":696}},{"line":483,"address":[],"length":0,"stats":{"Line":28895}},{"line":485,"address":[],"length":0,"stats":{"Line":111}},{"line":486,"address":[],"length":0,"stats":{"Line":47}},{"line":487,"address":[],"length":0,"stats":{"Line":46}},{"line":488,"address":[],"length":0,"stats":{"Line":46}},{"line":489,"address":[],"length":0,"stats":{"Line":46}},{"line":490,"address":[],"length":0,"stats":{"Line":46}},{"line":491,"address":[],"length":0,"stats":{"Line":46}},{"line":492,"address":[],"length":0,"stats":{"Line":46}},{"line":493,"address":[],"length":0,"stats":{"Line":46}},{"line":494,"address":[],"length":0,"stats":{"Line":46}},{"line":495,"address":[],"length":0,"stats":{"Line":46}},{"line":496,"address":[],"length":0,"stats":{"Line":46}},{"line":497,"address":[],"length":0,"stats":{"Line":46}},{"line":498,"address":[],"length":0,"stats":{"Line":46}},{"line":499,"address":[],"length":0,"stats":{"Line":46}},{"line":501,"address":[],"length":0,"stats":{"Line":46}},{"line":502,"address":[],"length":0,"stats":{"Line":46}},{"line":503,"address":[],"length":0,"stats":{"Line":46}},{"line":504,"address":[],"length":0,"stats":{"Line":46}},{"line":508,"address":[],"length":0,"stats":{"Line":46}},{"line":512,"address":[],"length":0,"stats":{"Line":1}},{"line":513,"address":[],"length":0,"stats":{"Line":1}},{"line":514,"address":[],"length":0,"stats":{"Line":1}},{"line":515,"address":[],"length":0,"stats":{"Line":1}},{"line":516,"address":[],"length":0,"stats":{"Line":1}},{"line":517,"address":[],"length":0,"stats":{"Line":1}},{"line":518,"address":[],"length":0,"stats":{"Line":1}},{"line":519,"address":[],"length":0,"stats":{"Line":1}},{"line":520,"address":[],"length":0,"stats":{"Line":1}},{"line":521,"address":[],"length":0,"stats":{"Line":1}},{"line":522,"address":[],"length":0,"stats":{"Line":1}},{"line":523,"address":[],"length":0,"stats":{"Line":1}},{"line":524,"address":[],"length":0,"stats":{"Line":1}},{"line":526,"address":[],"length":0,"stats":{"Line":1}},{"line":527,"address":[],"length":0,"stats":{"Line":1}},{"line":528,"address":[],"length":0,"stats":{"Line":1}},{"line":529,"address":[],"length":0,"stats":{"Line":1}},{"line":533,"address":[],"length":0,"stats":{"Line":1}},{"line":538,"address":[],"length":0,"stats":{"Line":28848}},{"line":539,"address":[],"length":0,"stats":{"Line":210}},{"line":540,"address":[],"length":0,"stats":{"Line":94}},{"line":541,"address":[],"length":0,"stats":{"Line":12}},{"line":542,"address":[],"length":0,"stats":{"Line":12}},{"line":548,"address":[],"length":0,"stats":{"Line":28836}},{"line":549,"address":[],"length":0,"stats":{"Line":694}},{"line":550,"address":[],"length":0,"stats":{"Line":289}},{"line":551,"address":[],"length":0,"stats":{"Line":280}},{"line":552,"address":[],"length":0,"stats":{"Line":280}},{"line":558,"address":[],"length":0,"stats":{"Line":28556}},{"line":560,"address":[],"length":0,"stats":{"Line":5814}},{"line":561,"address":[],"length":0,"stats":{"Line":5814}},{"line":562,"address":[],"length":0,"stats":{"Line":5814}},{"line":563,"address":[],"length":0,"stats":{"Line":5814}},{"line":564,"address":[],"length":0,"stats":{"Line":5814}},{"line":566,"address":[],"length":0,"stats":{"Line":15086}},{"line":567,"address":[],"length":0,"stats":{"Line":1760}},{"line":569,"address":[],"length":0,"stats":{"Line":1760}},{"line":570,"address":[],"length":0,"stats":{"Line":1760}},{"line":572,"address":[],"length":0,"stats":{"Line":5752}},{"line":575,"address":[],"length":0,"stats":{"Line":5814}},{"line":578,"address":[],"length":0,"stats":{"Line":5814}},{"line":580,"address":[],"length":0,"stats":{"Line":11628}},{"line":581,"address":[],"length":0,"stats":{"Line":5834}},{"line":582,"address":[],"length":0,"stats":{"Line":5795}},{"line":583,"address":[],"length":0,"stats":{"Line":5794}},{"line":584,"address":[],"length":0,"stats":{"Line":5793}},{"line":585,"address":[],"length":0,"stats":{"Line":5792}},{"line":586,"address":[],"length":0,"stats":{"Line":5791}},{"line":587,"address":[],"length":0,"stats":{"Line":5790}},{"line":588,"address":[],"length":0,"stats":{"Line":5789}},{"line":589,"address":[],"length":0,"stats":{"Line":5788}},{"line":590,"address":[],"length":0,"stats":{"Line":5787}},{"line":591,"address":[],"length":0,"stats":{"Line":5785}},{"line":594,"address":[],"length":0,"stats":{"Line":11628}},{"line":595,"address":[],"length":0,"stats":{"Line":1}},{"line":596,"address":[],"length":0,"stats":{"Line":1}},{"line":597,"address":[],"length":0,"stats":{"Line":5812}},{"line":600,"address":[],"length":0,"stats":{"Line":5814}},{"line":601,"address":[],"length":0,"stats":{"Line":5814}},{"line":602,"address":[],"length":0,"stats":{"Line":5814}},{"line":603,"address":[],"length":0,"stats":{"Line":5814}},{"line":604,"address":[],"length":0,"stats":{"Line":5814}},{"line":605,"address":[],"length":0,"stats":{"Line":5814}},{"line":606,"address":[],"length":0,"stats":{"Line":5814}},{"line":607,"address":[],"length":0,"stats":{"Line":5814}},{"line":608,"address":[],"length":0,"stats":{"Line":5814}},{"line":610,"address":[],"length":0,"stats":{"Line":5814}},{"line":611,"address":[],"length":0,"stats":{"Line":5814}},{"line":612,"address":[],"length":0,"stats":{"Line":5814}},{"line":613,"address":[],"length":0,"stats":{"Line":5814}},{"line":617,"address":[],"length":0,"stats":{"Line":5814}},{"line":621,"address":[],"length":0,"stats":{"Line":22742}},{"line":622,"address":[],"length":0,"stats":{"Line":22742}},{"line":623,"address":[],"length":0,"stats":{"Line":22742}},{"line":624,"address":[],"length":0,"stats":{"Line":22742}},{"line":625,"address":[],"length":0,"stats":{"Line":22742}},{"line":626,"address":[],"length":0,"stats":{"Line":22742}},{"line":627,"address":[],"length":0,"stats":{"Line":22742}},{"line":628,"address":[],"length":0,"stats":{"Line":22742}},{"line":629,"address":[],"length":0,"stats":{"Line":22742}},{"line":630,"address":[],"length":0,"stats":{"Line":22742}},{"line":631,"address":[],"length":0,"stats":{"Line":22742}},{"line":632,"address":[],"length":0,"stats":{"Line":22742}},{"line":633,"address":[],"length":0,"stats":{"Line":22742}},{"line":634,"address":[],"length":0,"stats":{"Line":22742}},{"line":635,"address":[],"length":0,"stats":{"Line":22742}},{"line":636,"address":[],"length":0,"stats":{"Line":22742}},{"line":637,"address":[],"length":0,"stats":{"Line":22742}},{"line":638,"address":[],"length":0,"stats":{"Line":22742}},{"line":639,"address":[],"length":0,"stats":{"Line":22742}},{"line":640,"address":[],"length":0,"stats":{"Line":22742}},{"line":641,"address":[],"length":0,"stats":{"Line":22742}},{"line":642,"address":[],"length":0,"stats":{"Line":22742}},{"line":643,"address":[],"length":0,"stats":{"Line":22742}},{"line":644,"address":[],"length":0,"stats":{"Line":22742}},{"line":645,"address":[],"length":0,"stats":{"Line":22742}},{"line":647,"address":[],"length":0,"stats":{"Line":22742}},{"line":648,"address":[],"length":0,"stats":{"Line":543621}},{"line":649,"address":[],"length":0,"stats":{"Line":543621}},{"line":650,"address":[],"length":0,"stats":{"Line":202}},{"line":651,"address":[],"length":0,"stats":{"Line":202}},{"line":652,"address":[],"length":0,"stats":{"Line":612}},{"line":653,"address":[],"length":0,"stats":{"Line":410}},{"line":655,"address":[],"length":0,"stats":{"Line":0}},{"line":656,"address":[],"length":0,"stats":{"Line":0}},{"line":657,"address":[],"length":0,"stats":{"Line":0}},{"line":658,"address":[],"length":0,"stats":{"Line":0}},{"line":659,"address":[],"length":0,"stats":{"Line":0}},{"line":660,"address":[],"length":0,"stats":{"Line":0}},{"line":661,"address":[],"length":0,"stats":{"Line":0}},{"line":662,"address":[],"length":0,"stats":{"Line":0}},{"line":663,"address":[],"length":0,"stats":{"Line":0}},{"line":664,"address":[],"length":0,"stats":{"Line":0}},{"line":666,"address":[],"length":0,"stats":{"Line":0}},{"line":667,"address":[],"length":0,"stats":{"Line":0}},{"line":668,"address":[],"length":0,"stats":{"Line":0}},{"line":669,"address":[],"length":0,"stats":{"Line":0}},{"line":673,"address":[],"length":0,"stats":{"Line":0}},{"line":674,"address":[],"length":0,"stats":{"Line":0}},{"line":677,"address":[],"length":0,"stats":{"Line":0}},{"line":678,"address":[],"length":0,"stats":{"Line":202}},{"line":682,"address":[],"length":0,"stats":{"Line":0}},{"line":683,"address":[],"length":0,"stats":{"Line":581}},{"line":684,"address":[],"length":0,"stats":{"Line":97}},{"line":685,"address":[],"length":0,"stats":{"Line":68}},{"line":686,"address":[],"length":0,"stats":{"Line":77}},{"line":687,"address":[],"length":0,"stats":{"Line":658}},{"line":688,"address":[],"length":0,"stats":{"Line":70}},{"line":689,"address":[],"length":0,"stats":{"Line":74}},{"line":690,"address":[],"length":0,"stats":{"Line":631}},{"line":691,"address":[],"length":0,"stats":{"Line":72}},{"line":692,"address":[],"length":0,"stats":{"Line":79}},{"line":693,"address":[],"length":0,"stats":{"Line":653}},{"line":694,"address":[],"length":0,"stats":{"Line":656}},{"line":695,"address":[],"length":0,"stats":{"Line":605}},{"line":696,"address":[],"length":0,"stats":{"Line":73}},{"line":697,"address":[],"length":0,"stats":{"Line":85}},{"line":698,"address":[],"length":0,"stats":{"Line":579}},{"line":699,"address":[],"length":0,"stats":{"Line":670}},{"line":700,"address":[],"length":0,"stats":{"Line":90}},{"line":701,"address":[],"length":0,"stats":{"Line":84}},{"line":702,"address":[],"length":0,"stats":{"Line":9}},{"line":703,"address":[],"length":0,"stats":{"Line":657}},{"line":704,"address":[],"length":0,"stats":{"Line":609}},{"line":705,"address":[],"length":0,"stats":{"Line":15363}},{"line":707,"address":[],"length":0,"stats":{"Line":0}},{"line":708,"address":[],"length":0,"stats":{"Line":0}},{"line":709,"address":[],"length":0,"stats":{"Line":0}},{"line":710,"address":[],"length":0,"stats":{"Line":0}},{"line":711,"address":[],"length":0,"stats":{"Line":0}},{"line":712,"address":[],"length":0,"stats":{"Line":0}},{"line":713,"address":[],"length":0,"stats":{"Line":0}},{"line":714,"address":[],"length":0,"stats":{"Line":0}},{"line":715,"address":[],"length":0,"stats":{"Line":0}},{"line":716,"address":[],"length":0,"stats":{"Line":0}},{"line":718,"address":[],"length":0,"stats":{"Line":0}},{"line":719,"address":[],"length":0,"stats":{"Line":0}},{"line":720,"address":[],"length":0,"stats":{"Line":0}},{"line":721,"address":[],"length":0,"stats":{"Line":0}},{"line":725,"address":[],"length":0,"stats":{"Line":0}},{"line":728,"address":[],"length":0,"stats":{"Line":12701}},{"line":729,"address":[],"length":0,"stats":{"Line":12995}},{"line":730,"address":[],"length":0,"stats":{"Line":12995}},{"line":731,"address":[],"length":0,"stats":{"Line":12995}},{"line":732,"address":[],"length":0,"stats":{"Line":12995}},{"line":733,"address":[],"length":0,"stats":{"Line":12995}},{"line":734,"address":[],"length":0,"stats":{"Line":12995}},{"line":735,"address":[],"length":0,"stats":{"Line":12995}},{"line":736,"address":[],"length":0,"stats":{"Line":12995}},{"line":737,"address":[],"length":0,"stats":{"Line":12995}},{"line":738,"address":[],"length":0,"stats":{"Line":12995}},{"line":739,"address":[],"length":0,"stats":{"Line":12995}},{"line":740,"address":[],"length":0,"stats":{"Line":12995}},{"line":741,"address":[],"length":0,"stats":{"Line":12995}},{"line":742,"address":[],"length":0,"stats":{"Line":12995}},{"line":743,"address":[],"length":0,"stats":{"Line":12995}},{"line":744,"address":[],"length":0,"stats":{"Line":12995}},{"line":745,"address":[],"length":0,"stats":{"Line":12995}},{"line":747,"address":[],"length":0,"stats":{"Line":12995}},{"line":748,"address":[],"length":0,"stats":{"Line":12995}},{"line":749,"address":[],"length":0,"stats":{"Line":12995}},{"line":750,"address":[],"length":0,"stats":{"Line":12995}},{"line":754,"address":[],"length":0,"stats":{"Line":12995}},{"line":758,"address":[],"length":0,"stats":{"Line":983}},{"line":759,"address":[],"length":0,"stats":{"Line":13}},{"line":760,"address":[],"length":0,"stats":{"Line":13}},{"line":761,"address":[],"length":0,"stats":{"Line":13}},{"line":762,"address":[],"length":0,"stats":{"Line":13}},{"line":763,"address":[],"length":0,"stats":{"Line":13}},{"line":764,"address":[],"length":0,"stats":{"Line":13}},{"line":765,"address":[],"length":0,"stats":{"Line":13}},{"line":766,"address":[],"length":0,"stats":{"Line":13}},{"line":767,"address":[],"length":0,"stats":{"Line":13}},{"line":768,"address":[],"length":0,"stats":{"Line":13}},{"line":770,"address":[],"length":0,"stats":{"Line":13}},{"line":771,"address":[],"length":0,"stats":{"Line":13}},{"line":772,"address":[],"length":0,"stats":{"Line":13}},{"line":773,"address":[],"length":0,"stats":{"Line":13}},{"line":778,"address":[],"length":0,"stats":{"Line":957}},{"line":779,"address":[],"length":0,"stats":{"Line":957}},{"line":782,"address":[],"length":0,"stats":{"Line":92835}},{"line":783,"address":[],"length":0,"stats":{"Line":92835}},{"line":784,"address":[],"length":0,"stats":{"Line":185621}},{"line":785,"address":[],"length":0,"stats":{"Line":449}},{"line":786,"address":[],"length":0,"stats":{"Line":449}},{"line":787,"address":[],"length":0,"stats":{"Line":449}},{"line":789,"address":[],"length":0,"stats":{"Line":92337}},{"line":792,"address":[],"length":0,"stats":{"Line":92835}},{"line":795,"address":[],"length":0,"stats":{"Line":5014}},{"line":796,"address":[],"length":0,"stats":{"Line":5014}},{"line":799,"address":[],"length":0,"stats":{"Line":23909}},{"line":800,"address":[],"length":0,"stats":{"Line":23909}},{"line":802,"address":[],"length":0,"stats":{"Line":70803}},{"line":803,"address":[],"length":0,"stats":{"Line":23909}},{"line":807,"address":[],"length":0,"stats":{"Line":635}},{"line":808,"address":[],"length":0,"stats":{"Line":635}},{"line":809,"address":[],"length":0,"stats":{"Line":635}},{"line":810,"address":[],"length":0,"stats":{"Line":635}},{"line":812,"address":[],"length":0,"stats":{"Line":635}},{"line":813,"address":[],"length":0,"stats":{"Line":635}},{"line":816,"address":[],"length":0,"stats":{"Line":1905}},{"line":817,"address":[],"length":0,"stats":{"Line":73}},{"line":818,"address":[],"length":0,"stats":{"Line":73}},{"line":819,"address":[],"length":0,"stats":{"Line":146}},{"line":820,"address":[],"length":0,"stats":{"Line":0}},{"line":821,"address":[],"length":0,"stats":{"Line":7}},{"line":822,"address":[],"length":0,"stats":{"Line":7}},{"line":823,"address":[],"length":0,"stats":{"Line":7}},{"line":824,"address":[],"length":0,"stats":{"Line":7}},{"line":826,"address":[],"length":0,"stats":{"Line":8}},{"line":827,"address":[],"length":0,"stats":{"Line":8}},{"line":828,"address":[],"length":0,"stats":{"Line":8}},{"line":829,"address":[],"length":0,"stats":{"Line":8}},{"line":831,"address":[],"length":0,"stats":{"Line":7}},{"line":832,"address":[],"length":0,"stats":{"Line":7}},{"line":833,"address":[],"length":0,"stats":{"Line":7}},{"line":834,"address":[],"length":0,"stats":{"Line":7}},{"line":836,"address":[],"length":0,"stats":{"Line":38}},{"line":837,"address":[],"length":0,"stats":{"Line":47}},{"line":842,"address":[],"length":0,"stats":{"Line":635}},{"line":843,"address":[],"length":0,"stats":{"Line":635}},{"line":846,"address":[],"length":0,"stats":{"Line":635}},{"line":847,"address":[],"length":0,"stats":{"Line":1839}},{"line":848,"address":[],"length":0,"stats":{"Line":21}},{"line":849,"address":[],"length":0,"stats":{"Line":21}},{"line":850,"address":[],"length":0,"stats":{"Line":63}},{"line":852,"address":[],"length":0,"stats":{"Line":21}},{"line":853,"address":[],"length":0,"stats":{"Line":21}},{"line":854,"address":[],"length":0,"stats":{"Line":21}},{"line":858,"address":[],"length":0,"stats":{"Line":2679}},{"line":859,"address":[],"length":0,"stats":{"Line":12}},{"line":860,"address":[],"length":0,"stats":{"Line":2452}},{"line":861,"address":[],"length":0,"stats":{"Line":663}},{"line":862,"address":[],"length":0,"stats":{"Line":663}},{"line":864,"address":[],"length":0,"stats":{"Line":691}},{"line":865,"address":[],"length":0,"stats":{"Line":6}},{"line":866,"address":[],"length":0,"stats":{"Line":6}},{"line":868,"address":[],"length":0,"stats":{"Line":0}},{"line":869,"address":[],"length":0,"stats":{"Line":20}},{"line":870,"address":[],"length":0,"stats":{"Line":52}},{"line":872,"address":[],"length":0,"stats":{"Line":20}},{"line":873,"address":[],"length":0,"stats":{"Line":20}},{"line":875,"address":[],"length":0,"stats":{"Line":0}},{"line":879,"address":[],"length":0,"stats":{"Line":86}},{"line":881,"address":[],"length":0,"stats":{"Line":28}},{"line":883,"address":[],"length":0,"stats":{"Line":55}},{"line":885,"address":[],"length":0,"stats":{"Line":16}},{"line":886,"address":[],"length":0,"stats":{"Line":16}},{"line":887,"address":[],"length":0,"stats":{"Line":16}},{"line":890,"address":[],"length":0,"stats":{"Line":12}},{"line":891,"address":[],"length":0,"stats":{"Line":12}},{"line":892,"address":[],"length":0,"stats":{"Line":12}},{"line":893,"address":[],"length":0,"stats":{"Line":12}},{"line":896,"address":[],"length":0,"stats":{"Line":24}},{"line":897,"address":[],"length":0,"stats":{"Line":14}},{"line":898,"address":[],"length":0,"stats":{"Line":14}},{"line":899,"address":[],"length":0,"stats":{"Line":14}},{"line":900,"address":[],"length":0,"stats":{"Line":14}},{"line":901,"address":[],"length":0,"stats":{"Line":13}},{"line":902,"address":[],"length":0,"stats":{"Line":19}},{"line":903,"address":[],"length":0,"stats":{"Line":7}},{"line":904,"address":[],"length":0,"stats":{"Line":7}},{"line":907,"address":[],"length":0,"stats":{"Line":12}},{"line":908,"address":[],"length":0,"stats":{"Line":4}},{"line":911,"address":[],"length":0,"stats":{"Line":598}},{"line":916,"address":[],"length":0,"stats":{"Line":642}},{"line":917,"address":[],"length":0,"stats":{"Line":641}},{"line":918,"address":[],"length":0,"stats":{"Line":637}},{"line":920,"address":[],"length":0,"stats":{"Line":7}},{"line":921,"address":[],"length":0,"stats":{"Line":7}},{"line":922,"address":[],"length":0,"stats":{"Line":7}},{"line":923,"address":[],"length":0,"stats":{"Line":7}},{"line":924,"address":[],"length":0,"stats":{"Line":7}},{"line":925,"address":[],"length":0,"stats":{"Line":7}},{"line":926,"address":[],"length":0,"stats":{"Line":7}},{"line":928,"address":[],"length":0,"stats":{"Line":7}},{"line":929,"address":[],"length":0,"stats":{"Line":7}},{"line":930,"address":[],"length":0,"stats":{"Line":7}},{"line":931,"address":[],"length":0,"stats":{"Line":7}},{"line":932,"address":[],"length":0,"stats":{"Line":7}},{"line":934,"address":[],"length":0,"stats":{"Line":7}},{"line":935,"address":[],"length":0,"stats":{"Line":7}},{"line":936,"address":[],"length":0,"stats":{"Line":7}},{"line":937,"address":[],"length":0,"stats":{"Line":7}},{"line":942,"address":[],"length":0,"stats":{"Line":628}},{"line":943,"address":[],"length":0,"stats":{"Line":4}},{"line":944,"address":[],"length":0,"stats":{"Line":4}},{"line":945,"address":[],"length":0,"stats":{"Line":4}},{"line":946,"address":[],"length":0,"stats":{"Line":4}},{"line":947,"address":[],"length":0,"stats":{"Line":4}},{"line":948,"address":[],"length":0,"stats":{"Line":4}},{"line":949,"address":[],"length":0,"stats":{"Line":4}},{"line":950,"address":[],"length":0,"stats":{"Line":4}},{"line":955,"address":[],"length":0,"stats":{"Line":624}},{"line":957,"address":[],"length":0,"stats":{"Line":624}},{"line":962,"address":[],"length":0,"stats":{"Line":624}},{"line":969,"address":[],"length":0,"stats":{"Line":1453}},{"line":971,"address":[],"length":0,"stats":{"Line":0}},{"line":972,"address":[],"length":0,"stats":{"Line":55}},{"line":975,"address":[],"length":0,"stats":{"Line":51}},{"line":976,"address":[],"length":0,"stats":{"Line":51}},{"line":981,"address":[],"length":0,"stats":{"Line":4}},{"line":982,"address":[],"length":0,"stats":{"Line":4}},{"line":987,"address":[],"length":0,"stats":{"Line":569}},{"line":988,"address":[],"length":0,"stats":{"Line":12}},{"line":989,"address":[],"length":0,"stats":{"Line":9}},{"line":990,"address":[],"length":0,"stats":{"Line":8}},{"line":991,"address":[],"length":0,"stats":{"Line":5}},{"line":992,"address":[],"length":0,"stats":{"Line":4}},{"line":993,"address":[],"length":0,"stats":{"Line":1}},{"line":995,"address":[],"length":0,"stats":{"Line":12}},{"line":997,"address":[],"length":0,"stats":{"Line":0}},{"line":1000,"address":[],"length":0,"stats":{"Line":557}},{"line":1003,"address":[],"length":0,"stats":{"Line":0}},{"line":1004,"address":[],"length":0,"stats":{"Line":0}},{"line":1005,"address":[],"length":0,"stats":{"Line":0}},{"line":1006,"address":[],"length":0,"stats":{"Line":0}},{"line":1007,"address":[],"length":0,"stats":{"Line":0}},{"line":1008,"address":[],"length":0,"stats":{"Line":0}},{"line":1011,"address":[],"length":0,"stats":{"Line":569}},{"line":1012,"address":[],"length":0,"stats":{"Line":0}},{"line":1013,"address":[],"length":0,"stats":{"Line":0}},{"line":1014,"address":[],"length":0,"stats":{"Line":0}},{"line":1015,"address":[],"length":0,"stats":{"Line":0}},{"line":1016,"address":[],"length":0,"stats":{"Line":0}},{"line":1020,"address":[],"length":0,"stats":{"Line":569}},{"line":1023,"address":[],"length":0,"stats":{"Line":569}},{"line":1024,"address":[],"length":0,"stats":{"Line":569}},{"line":1029,"address":[],"length":0,"stats":{"Line":0}},{"line":1030,"address":[],"length":0,"stats":{"Line":0}},{"line":1043,"address":[],"length":0,"stats":{"Line":13}},{"line":1051,"address":[],"length":0,"stats":{"Line":13}},{"line":1052,"address":[],"length":0,"stats":{"Line":13}},{"line":1053,"address":[],"length":0,"stats":{"Line":13}},{"line":1055,"address":[],"length":0,"stats":{"Line":52}},{"line":1056,"address":[],"length":0,"stats":{"Line":13}},{"line":1059,"address":[],"length":0,"stats":{"Line":0}},{"line":1060,"address":[],"length":0,"stats":{"Line":0}},{"line":1061,"address":[],"length":0,"stats":{"Line":0}},{"line":1064,"address":[],"length":0,"stats":{"Line":0}},{"line":1065,"address":[],"length":0,"stats":{"Line":0}},{"line":1066,"address":[],"length":0,"stats":{"Line":0}},{"line":1069,"address":[],"length":0,"stats":{"Line":0}},{"line":1070,"address":[],"length":0,"stats":{"Line":0}},{"line":1072,"address":[],"length":0,"stats":{"Line":0}},{"line":1073,"address":[],"length":0,"stats":{"Line":0}},{"line":1074,"address":[],"length":0,"stats":{"Line":0}},{"line":1075,"address":[],"length":0,"stats":{"Line":0}},{"line":1076,"address":[],"length":0,"stats":{"Line":0}},{"line":1077,"address":[],"length":0,"stats":{"Line":0}},{"line":1078,"address":[],"length":0,"stats":{"Line":0}},{"line":1079,"address":[],"length":0,"stats":{"Line":0}},{"line":1081,"address":[],"length":0,"stats":{"Line":0}},{"line":1082,"address":[],"length":0,"stats":{"Line":0}},{"line":1083,"address":[],"length":0,"stats":{"Line":0}},{"line":1084,"address":[],"length":0,"stats":{"Line":0}},{"line":1085,"address":[],"length":0,"stats":{"Line":0}},{"line":1086,"address":[],"length":0,"stats":{"Line":0}},{"line":1087,"address":[],"length":0,"stats":{"Line":0}},{"line":1092,"address":[],"length":0,"stats":{"Line":13}},{"line":1093,"address":[],"length":0,"stats":{"Line":13}},{"line":1094,"address":[],"length":0,"stats":{"Line":13}},{"line":1095,"address":[],"length":0,"stats":{"Line":13}},{"line":1097,"address":[],"length":0,"stats":{"Line":91}},{"line":1098,"address":[],"length":0,"stats":{"Line":0}},{"line":1099,"address":[],"length":0,"stats":{"Line":66}},{"line":1100,"address":[],"length":0,"stats":{"Line":33}},{"line":1101,"address":[],"length":0,"stats":{"Line":33}},{"line":1102,"address":[],"length":0,"stats":{"Line":33}},{"line":1105,"address":[],"length":0,"stats":{"Line":0}},{"line":1107,"address":[],"length":0,"stats":{"Line":0}},{"line":1108,"address":[],"length":0,"stats":{"Line":0}},{"line":1109,"address":[],"length":0,"stats":{"Line":0}},{"line":1111,"address":[],"length":0,"stats":{"Line":0}},{"line":1112,"address":[],"length":0,"stats":{"Line":0}},{"line":1113,"address":[],"length":0,"stats":{"Line":0}},{"line":1116,"address":[],"length":0,"stats":{"Line":0}},{"line":1117,"address":[],"length":0,"stats":{"Line":0}},{"line":1118,"address":[],"length":0,"stats":{"Line":0}},{"line":1119,"address":[],"length":0,"stats":{"Line":0}},{"line":1120,"address":[],"length":0,"stats":{"Line":0}},{"line":1123,"address":[],"length":0,"stats":{"Line":12}},{"line":1124,"address":[],"length":0,"stats":{"Line":10}},{"line":1128,"address":[],"length":0,"stats":{"Line":2}},{"line":1129,"address":[],"length":0,"stats":{"Line":2}},{"line":1130,"address":[],"length":0,"stats":{"Line":2}},{"line":1132,"address":[],"length":0,"stats":{"Line":2}},{"line":1133,"address":[],"length":0,"stats":{"Line":2}},{"line":1134,"address":[],"length":0,"stats":{"Line":2}},{"line":1137,"address":[],"length":0,"stats":{"Line":2}},{"line":1138,"address":[],"length":0,"stats":{"Line":2}},{"line":1139,"address":[],"length":0,"stats":{"Line":2}},{"line":1140,"address":[],"length":0,"stats":{"Line":2}},{"line":1141,"address":[],"length":0,"stats":{"Line":2}},{"line":1146,"address":[],"length":0,"stats":{"Line":21}},{"line":1149,"address":[],"length":0,"stats":{"Line":1}},{"line":1150,"address":[],"length":0,"stats":{"Line":1}},{"line":1151,"address":[],"length":0,"stats":{"Line":1}},{"line":1153,"address":[],"length":0,"stats":{"Line":1}},{"line":1154,"address":[],"length":0,"stats":{"Line":1}},{"line":1155,"address":[],"length":0,"stats":{"Line":1}},{"line":1158,"address":[],"length":0,"stats":{"Line":1}},{"line":1159,"address":[],"length":0,"stats":{"Line":1}},{"line":1160,"address":[],"length":0,"stats":{"Line":1}},{"line":1161,"address":[],"length":0,"stats":{"Line":1}},{"line":1162,"address":[],"length":0,"stats":{"Line":1}},{"line":1165,"address":[],"length":0,"stats":{"Line":10}},{"line":1167,"address":[],"length":0,"stats":{"Line":10}},{"line":1169,"address":[],"length":0,"stats":{"Line":2}},{"line":1170,"address":[],"length":0,"stats":{"Line":2}},{"line":1171,"address":[],"length":0,"stats":{"Line":2}},{"line":1173,"address":[],"length":0,"stats":{"Line":2}},{"line":1174,"address":[],"length":0,"stats":{"Line":2}},{"line":1175,"address":[],"length":0,"stats":{"Line":2}},{"line":1178,"address":[],"length":0,"stats":{"Line":2}},{"line":1179,"address":[],"length":0,"stats":{"Line":2}},{"line":1180,"address":[],"length":0,"stats":{"Line":2}},{"line":1181,"address":[],"length":0,"stats":{"Line":2}},{"line":1182,"address":[],"length":0,"stats":{"Line":2}},{"line":1183,"address":[],"length":0,"stats":{"Line":2}},{"line":1185,"address":[],"length":0,"stats":{"Line":2}},{"line":1186,"address":[],"length":0,"stats":{"Line":2}},{"line":1187,"address":[],"length":0,"stats":{"Line":2}},{"line":1188,"address":[],"length":0,"stats":{"Line":2}},{"line":1189,"address":[],"length":0,"stats":{"Line":2}},{"line":1191,"address":[],"length":0,"stats":{"Line":2}},{"line":1196,"address":[],"length":0,"stats":{"Line":8}},{"line":1197,"address":[],"length":0,"stats":{"Line":8}},{"line":1198,"address":[],"length":0,"stats":{"Line":6}},{"line":1199,"address":[],"length":0,"stats":{"Line":0}},{"line":1201,"address":[],"length":0,"stats":{"Line":2}},{"line":1202,"address":[],"length":0,"stats":{"Line":2}},{"line":1203,"address":[],"length":0,"stats":{"Line":2}},{"line":1205,"address":[],"length":0,"stats":{"Line":2}},{"line":1206,"address":[],"length":0,"stats":{"Line":2}},{"line":1207,"address":[],"length":0,"stats":{"Line":2}},{"line":1210,"address":[],"length":0,"stats":{"Line":2}},{"line":1211,"address":[],"length":0,"stats":{"Line":2}},{"line":1212,"address":[],"length":0,"stats":{"Line":2}},{"line":1213,"address":[],"length":0,"stats":{"Line":2}},{"line":1214,"address":[],"length":0,"stats":{"Line":2}},{"line":1218,"address":[],"length":0,"stats":{"Line":0}},{"line":1221,"address":[],"length":0,"stats":{"Line":0}},{"line":1222,"address":[],"length":0,"stats":{"Line":0}},{"line":1223,"address":[],"length":0,"stats":{"Line":0}},{"line":1225,"address":[],"length":0,"stats":{"Line":0}},{"line":1226,"address":[],"length":0,"stats":{"Line":0}},{"line":1227,"address":[],"length":0,"stats":{"Line":0}},{"line":1230,"address":[],"length":0,"stats":{"Line":0}},{"line":1231,"address":[],"length":0,"stats":{"Line":0}},{"line":1232,"address":[],"length":0,"stats":{"Line":0}},{"line":1233,"address":[],"length":0,"stats":{"Line":0}},{"line":1234,"address":[],"length":0,"stats":{"Line":0}},{"line":1235,"address":[],"length":0,"stats":{"Line":0}},{"line":1237,"address":[],"length":0,"stats":{"Line":0}},{"line":1238,"address":[],"length":0,"stats":{"Line":0}},{"line":1239,"address":[],"length":0,"stats":{"Line":0}},{"line":1240,"address":[],"length":0,"stats":{"Line":0}},{"line":1241,"address":[],"length":0,"stats":{"Line":0}},{"line":1243,"address":[],"length":0,"stats":{"Line":0}},{"line":1250,"address":[],"length":0,"stats":{"Line":792}},{"line":1251,"address":[],"length":0,"stats":{"Line":792}},{"line":1252,"address":[],"length":0,"stats":{"Line":792}},{"line":1253,"address":[],"length":0,"stats":{"Line":792}},{"line":1255,"address":[],"length":0,"stats":{"Line":792}},{"line":1257,"address":[],"length":0,"stats":{"Line":792}},{"line":1259,"address":[],"length":0,"stats":{"Line":792}},{"line":1260,"address":[],"length":0,"stats":{"Line":30722}},{"line":1261,"address":[],"length":0,"stats":{"Line":0}},{"line":1262,"address":[],"length":0,"stats":{"Line":0}},{"line":1263,"address":[],"length":0,"stats":{"Line":295}},{"line":1264,"address":[],"length":0,"stats":{"Line":295}},{"line":1265,"address":[],"length":0,"stats":{"Line":295}},{"line":1267,"address":[],"length":0,"stats":{"Line":0}},{"line":1268,"address":[],"length":0,"stats":{"Line":315}},{"line":1269,"address":[],"length":0,"stats":{"Line":628}},{"line":1270,"address":[],"length":0,"stats":{"Line":0}},{"line":1271,"address":[],"length":0,"stats":{"Line":7}},{"line":1272,"address":[],"length":0,"stats":{"Line":7}},{"line":1273,"address":[],"length":0,"stats":{"Line":7}},{"line":1275,"address":[],"length":0,"stats":{"Line":2}},{"line":1276,"address":[],"length":0,"stats":{"Line":2}},{"line":1277,"address":[],"length":0,"stats":{"Line":2}},{"line":1279,"address":[],"length":0,"stats":{"Line":3}},{"line":1280,"address":[],"length":0,"stats":{"Line":3}},{"line":1281,"address":[],"length":0,"stats":{"Line":3}},{"line":1283,"address":[],"length":0,"stats":{"Line":11}},{"line":1284,"address":[],"length":0,"stats":{"Line":11}},{"line":1285,"address":[],"length":0,"stats":{"Line":11}},{"line":1287,"address":[],"length":0,"stats":{"Line":0}},{"line":1288,"address":[],"length":0,"stats":{"Line":8}},{"line":1289,"address":[],"length":0,"stats":{"Line":8}},{"line":1290,"address":[],"length":0,"stats":{"Line":8}},{"line":1291,"address":[],"length":0,"stats":{"Line":8}},{"line":1292,"address":[],"length":0,"stats":{"Line":8}},{"line":1293,"address":[],"length":0,"stats":{"Line":8}},{"line":1295,"address":[],"length":0,"stats":{"Line":3}},{"line":1296,"address":[],"length":0,"stats":{"Line":5}},{"line":1299,"address":[],"length":0,"stats":{"Line":0}},{"line":1300,"address":[],"length":0,"stats":{"Line":282}},{"line":1301,"address":[],"length":0,"stats":{"Line":282}},{"line":1302,"address":[],"length":0,"stats":{"Line":282}},{"line":1303,"address":[],"length":0,"stats":{"Line":282}},{"line":1304,"address":[],"length":0,"stats":{"Line":282}},{"line":1307,"address":[],"length":0,"stats":{"Line":282}},{"line":1308,"address":[],"length":0,"stats":{"Line":282}},{"line":1309,"address":[],"length":0,"stats":{"Line":282}},{"line":1310,"address":[],"length":0,"stats":{"Line":282}},{"line":1311,"address":[],"length":0,"stats":{"Line":282}},{"line":1312,"address":[],"length":0,"stats":{"Line":282}},{"line":1314,"address":[],"length":0,"stats":{"Line":282}},{"line":1315,"address":[],"length":0,"stats":{"Line":282}},{"line":1316,"address":[],"length":0,"stats":{"Line":282}},{"line":1323,"address":[],"length":0,"stats":{"Line":2}},{"line":1324,"address":[],"length":0,"stats":{"Line":2}},{"line":1325,"address":[],"length":0,"stats":{"Line":2}},{"line":1326,"address":[],"length":0,"stats":{"Line":2}},{"line":1327,"address":[],"length":0,"stats":{"Line":2}},{"line":1328,"address":[],"length":0,"stats":{"Line":2}},{"line":1331,"address":[],"length":0,"stats":{"Line":2}},{"line":1332,"address":[],"length":0,"stats":{"Line":2}},{"line":1333,"address":[],"length":0,"stats":{"Line":2}},{"line":1334,"address":[],"length":0,"stats":{"Line":2}},{"line":1335,"address":[],"length":0,"stats":{"Line":2}},{"line":1337,"address":[],"length":0,"stats":{"Line":2}},{"line":1338,"address":[],"length":0,"stats":{"Line":2}},{"line":1339,"address":[],"length":0,"stats":{"Line":2}},{"line":1344,"address":[],"length":0,"stats":{"Line":0}},{"line":1349,"address":[],"length":0,"stats":{"Line":2}},{"line":1351,"address":[],"length":0,"stats":{"Line":14646}},{"line":1352,"address":[],"length":0,"stats":{"Line":14646}},{"line":1353,"address":[],"length":0,"stats":{"Line":14646}},{"line":1360,"address":[],"length":0,"stats":{"Line":503}},{"line":1361,"address":[],"length":0,"stats":{"Line":503}},{"line":1362,"address":[],"length":0,"stats":{"Line":503}},{"line":1364,"address":[],"length":0,"stats":{"Line":503}},{"line":1365,"address":[],"length":0,"stats":{"Line":208}},{"line":1366,"address":[],"length":0,"stats":{"Line":208}},{"line":1367,"address":[],"length":0,"stats":{"Line":208}},{"line":1368,"address":[],"length":0,"stats":{"Line":208}},{"line":1369,"address":[],"length":0,"stats":{"Line":208}},{"line":1371,"address":[],"length":0,"stats":{"Line":208}},{"line":1372,"address":[],"length":0,"stats":{"Line":208}},{"line":1373,"address":[],"length":0,"stats":{"Line":208}},{"line":1380,"address":[],"length":0,"stats":{"Line":295}},{"line":1385,"address":[],"length":0,"stats":{"Line":295}},{"line":1386,"address":[],"length":0,"stats":{"Line":295}},{"line":1401,"address":[],"length":0,"stats":{"Line":696}},{"line":1402,"address":[],"length":0,"stats":{"Line":696}},{"line":1403,"address":[],"length":0,"stats":{"Line":696}},{"line":1404,"address":[],"length":0,"stats":{"Line":696}},{"line":1406,"address":[],"length":0,"stats":{"Line":696}},{"line":1408,"address":[],"length":0,"stats":{"Line":696}},{"line":1409,"address":[],"length":0,"stats":{"Line":696}},{"line":1410,"address":[],"length":0,"stats":{"Line":696}},{"line":1411,"address":[],"length":0,"stats":{"Line":696}},{"line":1413,"address":[],"length":0,"stats":{"Line":1386}},{"line":1414,"address":[],"length":0,"stats":{"Line":0}},{"line":1415,"address":[],"length":0,"stats":{"Line":15}},{"line":1417,"address":[],"length":0,"stats":{"Line":15}},{"line":1418,"address":[],"length":0,"stats":{"Line":15}},{"line":1419,"address":[],"length":0,"stats":{"Line":15}},{"line":1421,"address":[],"length":0,"stats":{"Line":0}},{"line":1423,"address":[],"length":0,"stats":{"Line":23}},{"line":1424,"address":[],"length":0,"stats":{"Line":45}},{"line":1425,"address":[],"length":0,"stats":{"Line":0}},{"line":1426,"address":[],"length":0,"stats":{"Line":5}},{"line":1427,"address":[],"length":0,"stats":{"Line":5}},{"line":1428,"address":[],"length":0,"stats":{"Line":5}},{"line":1429,"address":[],"length":0,"stats":{"Line":5}},{"line":1430,"address":[],"length":0,"stats":{"Line":5}},{"line":1431,"address":[],"length":0,"stats":{"Line":5}},{"line":1433,"address":[],"length":0,"stats":{"Line":3}},{"line":1434,"address":[],"length":0,"stats":{"Line":3}},{"line":1435,"address":[],"length":0,"stats":{"Line":3}},{"line":1437,"address":[],"length":0,"stats":{"Line":3}},{"line":1438,"address":[],"length":0,"stats":{"Line":0}},{"line":1439,"address":[],"length":0,"stats":{"Line":2}},{"line":1440,"address":[],"length":0,"stats":{"Line":2}},{"line":1441,"address":[],"length":0,"stats":{"Line":2}},{"line":1442,"address":[],"length":0,"stats":{"Line":2}},{"line":1443,"address":[],"length":0,"stats":{"Line":2}},{"line":1445,"address":[],"length":0,"stats":{"Line":2}},{"line":1446,"address":[],"length":0,"stats":{"Line":2}},{"line":1447,"address":[],"length":0,"stats":{"Line":2}},{"line":1448,"address":[],"length":0,"stats":{"Line":2}},{"line":1449,"address":[],"length":0,"stats":{"Line":2}},{"line":1450,"address":[],"length":0,"stats":{"Line":2}},{"line":1451,"address":[],"length":0,"stats":{"Line":2}},{"line":1452,"address":[],"length":0,"stats":{"Line":2}},{"line":1453,"address":[],"length":0,"stats":{"Line":2}},{"line":1455,"address":[],"length":0,"stats":{"Line":2}},{"line":1456,"address":[],"length":0,"stats":{"Line":2}},{"line":1457,"address":[],"length":0,"stats":{"Line":2}},{"line":1458,"address":[],"length":0,"stats":{"Line":2}},{"line":1464,"address":[],"length":0,"stats":{"Line":1}},{"line":1468,"address":[],"length":0,"stats":{"Line":0}},{"line":1471,"address":[],"length":0,"stats":{"Line":2}},{"line":1475,"address":[],"length":0,"stats":{"Line":17}},{"line":1476,"address":[],"length":0,"stats":{"Line":1}},{"line":1477,"address":[],"length":0,"stats":{"Line":1}},{"line":1478,"address":[],"length":0,"stats":{"Line":1}},{"line":1479,"address":[],"length":0,"stats":{"Line":1}},{"line":1480,"address":[],"length":0,"stats":{"Line":1}},{"line":1481,"address":[],"length":0,"stats":{"Line":1}},{"line":1482,"address":[],"length":0,"stats":{"Line":11}},{"line":1483,"address":[],"length":0,"stats":{"Line":11}},{"line":1484,"address":[],"length":0,"stats":{"Line":11}},{"line":1487,"address":[],"length":0,"stats":{"Line":0}},{"line":1489,"address":[],"length":0,"stats":{"Line":0}},{"line":1490,"address":[],"length":0,"stats":{"Line":6}},{"line":1491,"address":[],"length":0,"stats":{"Line":6}},{"line":1492,"address":[],"length":0,"stats":{"Line":6}},{"line":1495,"address":[],"length":0,"stats":{"Line":11}},{"line":1496,"address":[],"length":0,"stats":{"Line":11}},{"line":1502,"address":[],"length":0,"stats":{"Line":1}},{"line":1503,"address":[],"length":0,"stats":{"Line":1}},{"line":1504,"address":[],"length":0,"stats":{"Line":1}},{"line":1508,"address":[],"length":0,"stats":{"Line":0}},{"line":1510,"address":[],"length":0,"stats":{"Line":0}},{"line":1511,"address":[],"length":0,"stats":{"Line":0}},{"line":1514,"address":[],"length":0,"stats":{"Line":652}},{"line":1516,"address":[],"length":0,"stats":{"Line":652}},{"line":1517,"address":[],"length":0,"stats":{"Line":652}},{"line":1518,"address":[],"length":0,"stats":{"Line":652}},{"line":1523,"address":[],"length":0,"stats":{"Line":6}},{"line":1526,"address":[],"length":0,"stats":{"Line":1350}},{"line":1528,"address":[],"length":0,"stats":{"Line":1314}},{"line":1529,"address":[],"length":0,"stats":{"Line":0}},{"line":1530,"address":[],"length":0,"stats":{"Line":19}},{"line":1531,"address":[],"length":0,"stats":{"Line":19}},{"line":1532,"address":[],"length":0,"stats":{"Line":19}},{"line":1533,"address":[],"length":0,"stats":{"Line":0}},{"line":1534,"address":[],"length":0,"stats":{"Line":19}},{"line":1535,"address":[],"length":0,"stats":{"Line":0}},{"line":1539,"address":[],"length":0,"stats":{"Line":1274}},{"line":1540,"address":[],"length":0,"stats":{"Line":637}},{"line":1542,"address":[],"length":0,"stats":{"Line":0}},{"line":1547,"address":[],"length":0,"stats":{"Line":2}},{"line":1548,"address":[],"length":0,"stats":{"Line":2}},{"line":1552,"address":[],"length":0,"stats":{"Line":0}},{"line":1553,"address":[],"length":0,"stats":{"Line":0}},{"line":1554,"address":[],"length":0,"stats":{"Line":0}},{"line":1556,"address":[],"length":0,"stats":{"Line":0}},{"line":1557,"address":[],"length":0,"stats":{"Line":0}},{"line":1558,"address":[],"length":0,"stats":{"Line":0}},{"line":1561,"address":[],"length":0,"stats":{"Line":673}},{"line":1562,"address":[],"length":0,"stats":{"Line":0}},{"line":1563,"address":[],"length":0,"stats":{"Line":1314}},{"line":1564,"address":[],"length":0,"stats":{"Line":654}},{"line":1566,"address":[],"length":0,"stats":{"Line":6}},{"line":1569,"address":[],"length":0,"stats":{"Line":0}},{"line":1570,"address":[],"length":0,"stats":{"Line":0}},{"line":1571,"address":[],"length":0,"stats":{"Line":0}},{"line":1572,"address":[],"length":0,"stats":{"Line":0}},{"line":1573,"address":[],"length":0,"stats":{"Line":0}},{"line":1574,"address":[],"length":0,"stats":{"Line":0}},{"line":1575,"address":[],"length":0,"stats":{"Line":0}},{"line":1576,"address":[],"length":0,"stats":{"Line":0}},{"line":1577,"address":[],"length":0,"stats":{"Line":0}},{"line":1579,"address":[],"length":0,"stats":{"Line":0}},{"line":1580,"address":[],"length":0,"stats":{"Line":0}},{"line":1581,"address":[],"length":0,"stats":{"Line":0}},{"line":1582,"address":[],"length":0,"stats":{"Line":0}},{"line":1588,"address":[],"length":0,"stats":{"Line":19}},{"line":1589,"address":[],"length":0,"stats":{"Line":0}},{"line":1590,"address":[],"length":0,"stats":{"Line":0}},{"line":1591,"address":[],"length":0,"stats":{"Line":0}},{"line":1592,"address":[],"length":0,"stats":{"Line":0}},{"line":1593,"address":[],"length":0,"stats":{"Line":0}},{"line":1595,"address":[],"length":0,"stats":{"Line":0}},{"line":1596,"address":[],"length":0,"stats":{"Line":0}},{"line":1597,"address":[],"length":0,"stats":{"Line":0}},{"line":1598,"address":[],"length":0,"stats":{"Line":0}},{"line":1599,"address":[],"length":0,"stats":{"Line":0}},{"line":1601,"address":[],"length":0,"stats":{"Line":0}},{"line":1602,"address":[],"length":0,"stats":{"Line":0}},{"line":1603,"address":[],"length":0,"stats":{"Line":0}},{"line":1604,"address":[],"length":0,"stats":{"Line":0}},{"line":1610,"address":[],"length":0,"stats":{"Line":38}},{"line":1611,"address":[],"length":0,"stats":{"Line":0}},{"line":1615,"address":[],"length":0,"stats":{"Line":19}},{"line":1616,"address":[],"length":0,"stats":{"Line":19}},{"line":1617,"address":[],"length":0,"stats":{"Line":19}},{"line":1633,"address":[],"length":0,"stats":{"Line":0}},{"line":1634,"address":[],"length":0,"stats":{"Line":0}},{"line":1638,"address":[],"length":0,"stats":{"Line":0}},{"line":1655,"address":[],"length":0,"stats":{"Line":0}},{"line":1656,"address":[],"length":0,"stats":{"Line":0}},{"line":1659,"address":[],"length":0,"stats":{"Line":0}},{"line":1675,"address":[],"length":0,"stats":{"Line":280}},{"line":1676,"address":[],"length":0,"stats":{"Line":280}},{"line":1677,"address":[],"length":0,"stats":{"Line":280}},{"line":1679,"address":[],"length":0,"stats":{"Line":280}},{"line":1682,"address":[],"length":0,"stats":{"Line":280}},{"line":1683,"address":[],"length":0,"stats":{"Line":1956}},{"line":1684,"address":[],"length":0,"stats":{"Line":698}},{"line":1685,"address":[],"length":0,"stats":{"Line":698}},{"line":1686,"address":[],"length":0,"stats":{"Line":698}},{"line":1688,"address":[],"length":0,"stats":{"Line":280}},{"line":1693,"address":[],"length":0,"stats":{"Line":281}},{"line":1694,"address":[],"length":0,"stats":{"Line":1}},{"line":1695,"address":[],"length":0,"stats":{"Line":1}},{"line":1696,"address":[],"length":0,"stats":{"Line":1}},{"line":1697,"address":[],"length":0,"stats":{"Line":1}},{"line":1698,"address":[],"length":0,"stats":{"Line":1}},{"line":1699,"address":[],"length":0,"stats":{"Line":1}},{"line":1700,"address":[],"length":0,"stats":{"Line":1}},{"line":1701,"address":[],"length":0,"stats":{"Line":1}},{"line":1702,"address":[],"length":0,"stats":{"Line":1}},{"line":1703,"address":[],"length":0,"stats":{"Line":1}},{"line":1704,"address":[],"length":0,"stats":{"Line":1}},{"line":1706,"address":[],"length":0,"stats":{"Line":1}},{"line":1707,"address":[],"length":0,"stats":{"Line":1}},{"line":1708,"address":[],"length":0,"stats":{"Line":1}},{"line":1709,"address":[],"length":0,"stats":{"Line":1}},{"line":1710,"address":[],"length":0,"stats":{"Line":1}},{"line":1712,"address":[],"length":0,"stats":{"Line":1}},{"line":1713,"address":[],"length":0,"stats":{"Line":1}},{"line":1714,"address":[],"length":0,"stats":{"Line":1}},{"line":1715,"address":[],"length":0,"stats":{"Line":1}},{"line":1721,"address":[],"length":0,"stats":{"Line":279}},{"line":1722,"address":[],"length":0,"stats":{"Line":279}},{"line":1723,"address":[],"length":0,"stats":{"Line":279}},{"line":1724,"address":[],"length":0,"stats":{"Line":279}},{"line":1726,"address":[],"length":0,"stats":{"Line":9544}},{"line":1727,"address":[],"length":0,"stats":{"Line":0}},{"line":1729,"address":[],"length":0,"stats":{"Line":287}},{"line":1730,"address":[],"length":0,"stats":{"Line":287}},{"line":1732,"address":[],"length":0,"stats":{"Line":1196}},{"line":1733,"address":[],"length":0,"stats":{"Line":758}},{"line":1734,"address":[],"length":0,"stats":{"Line":379}},{"line":1735,"address":[],"length":0,"stats":{"Line":379}},{"line":1737,"address":[],"length":0,"stats":{"Line":151}},{"line":1741,"address":[],"length":0,"stats":{"Line":287}},{"line":1743,"address":[],"length":0,"stats":{"Line":177}},{"line":1744,"address":[],"length":0,"stats":{"Line":555}},{"line":1745,"address":[],"length":0,"stats":{"Line":378}},{"line":1747,"address":[],"length":0,"stats":{"Line":0}},{"line":1748,"address":[],"length":0,"stats":{"Line":0}},{"line":1751,"address":[],"length":0,"stats":{"Line":110}},{"line":1752,"address":[],"length":0,"stats":{"Line":110}},{"line":1756,"address":[],"length":0,"stats":{"Line":4434}},{"line":1757,"address":[],"length":0,"stats":{"Line":4434}},{"line":1761,"address":[],"length":0,"stats":{"Line":279}},{"line":1764,"address":[],"length":0,"stats":{"Line":279}},{"line":1769,"address":[],"length":0,"stats":{"Line":279}},{"line":1776,"address":[],"length":0,"stats":{"Line":279}},{"line":1779,"address":[],"length":0,"stats":{"Line":102}},{"line":1780,"address":[],"length":0,"stats":{"Line":102}},{"line":1785,"address":[],"length":0,"stats":{"Line":177}},{"line":1786,"address":[],"length":0,"stats":{"Line":177}},{"line":1788,"address":[],"length":0,"stats":{"Line":177}},{"line":1789,"address":[],"length":0,"stats":{"Line":177}},{"line":1794,"address":[],"length":0,"stats":{"Line":177}},{"line":1799,"address":[],"length":0,"stats":{"Line":177}},{"line":1805,"address":[],"length":0,"stats":{"Line":12}},{"line":1806,"address":[],"length":0,"stats":{"Line":12}},{"line":1807,"address":[],"length":0,"stats":{"Line":12}},{"line":1809,"address":[],"length":0,"stats":{"Line":12}},{"line":1810,"address":[],"length":0,"stats":{"Line":12}},{"line":1811,"address":[],"length":0,"stats":{"Line":12}},{"line":1812,"address":[],"length":0,"stats":{"Line":12}},{"line":1813,"address":[],"length":0,"stats":{"Line":513}},{"line":1814,"address":[],"length":0,"stats":{"Line":0}},{"line":1815,"address":[],"length":0,"stats":{"Line":9}},{"line":1816,"address":[],"length":0,"stats":{"Line":9}},{"line":1817,"address":[],"length":0,"stats":{"Line":9}},{"line":1818,"address":[],"length":0,"stats":{"Line":246}},{"line":1820,"address":[],"length":0,"stats":{"Line":4}},{"line":1821,"address":[],"length":0,"stats":{"Line":8}},{"line":1822,"address":[],"length":0,"stats":{"Line":0}},{"line":1823,"address":[],"length":0,"stats":{"Line":1}},{"line":1825,"address":[],"length":0,"stats":{"Line":1}},{"line":1826,"address":[],"length":0,"stats":{"Line":1}},{"line":1829,"address":[],"length":0,"stats":{"Line":3}},{"line":1832,"address":[],"length":0,"stats":{"Line":3}},{"line":1833,"address":[],"length":0,"stats":{"Line":3}},{"line":1836,"address":[],"length":0,"stats":{"Line":0}},{"line":1838,"address":[],"length":0,"stats":{"Line":0}},{"line":1841,"address":[],"length":0,"stats":{"Line":242}},{"line":1842,"address":[],"length":0,"stats":{"Line":242}},{"line":1845,"address":[],"length":0,"stats":{"Line":12}},{"line":1846,"address":[],"length":0,"stats":{"Line":12}},{"line":1848,"address":[],"length":0,"stats":{"Line":12}},{"line":1853,"address":[],"length":0,"stats":{"Line":12}},{"line":1860,"address":[],"length":0,"stats":{"Line":12}},{"line":1863,"address":[],"length":0,"stats":{"Line":3}},{"line":1864,"address":[],"length":0,"stats":{"Line":3}},{"line":1869,"address":[],"length":0,"stats":{"Line":9}},{"line":1883,"address":[],"length":0,"stats":{"Line":7}},{"line":1886,"address":[],"length":0,"stats":{"Line":1}},{"line":1887,"address":[],"length":0,"stats":{"Line":1}},{"line":1893,"address":[],"length":0,"stats":{"Line":6}},{"line":1894,"address":[],"length":0,"stats":{"Line":6}},{"line":1904,"address":[],"length":0,"stats":{"Line":2}},{"line":1905,"address":[],"length":0,"stats":{"Line":2}},{"line":1911,"address":[],"length":0,"stats":{"Line":268}},{"line":1912,"address":[],"length":0,"stats":{"Line":268}},{"line":1913,"address":[],"length":0,"stats":{"Line":268}},{"line":1916,"address":[],"length":0,"stats":{"Line":268}},{"line":1917,"address":[],"length":0,"stats":{"Line":268}},{"line":1918,"address":[],"length":0,"stats":{"Line":268}},{"line":1920,"address":[],"length":0,"stats":{"Line":268}},{"line":1921,"address":[],"length":0,"stats":{"Line":268}},{"line":1922,"address":[],"length":0,"stats":{"Line":268}},{"line":1923,"address":[],"length":0,"stats":{"Line":268}},{"line":1925,"address":[],"length":0,"stats":{"Line":27552}},{"line":1926,"address":[],"length":0,"stats":{"Line":0}},{"line":1928,"address":[],"length":0,"stats":{"Line":704}},{"line":1929,"address":[],"length":0,"stats":{"Line":456}},{"line":1932,"address":[],"length":0,"stats":{"Line":152}},{"line":1933,"address":[],"length":0,"stats":{"Line":152}},{"line":1934,"address":[],"length":0,"stats":{"Line":152}},{"line":1935,"address":[],"length":0,"stats":{"Line":152}},{"line":1936,"address":[],"length":0,"stats":{"Line":152}},{"line":1939,"address":[],"length":0,"stats":{"Line":121}},{"line":1940,"address":[],"length":0,"stats":{"Line":121}},{"line":1942,"address":[],"length":0,"stats":{"Line":13760}},{"line":1944,"address":[],"length":0,"stats":{"Line":315}},{"line":1945,"address":[],"length":0,"stats":{"Line":315}},{"line":1946,"address":[],"length":0,"stats":{"Line":315}},{"line":1947,"address":[],"length":0,"stats":{"Line":315}},{"line":1950,"address":[],"length":0,"stats":{"Line":13130}},{"line":1951,"address":[],"length":0,"stats":{"Line":13130}},{"line":1952,"address":[],"length":0,"stats":{"Line":13130}},{"line":1957,"address":[],"length":0,"stats":{"Line":524}},{"line":1958,"address":[],"length":0,"stats":{"Line":256}},{"line":1961,"address":[],"length":0,"stats":{"Line":268}},{"line":1963,"address":[],"length":0,"stats":{"Line":268}},{"line":1968,"address":[],"length":0,"stats":{"Line":268}},{"line":1975,"address":[],"length":0,"stats":{"Line":268}},{"line":1976,"address":[],"length":0,"stats":{"Line":116}},{"line":1977,"address":[],"length":0,"stats":{"Line":116}},{"line":1978,"address":[],"length":0,"stats":{"Line":116}},{"line":1979,"address":[],"length":0,"stats":{"Line":116}},{"line":1980,"address":[],"length":0,"stats":{"Line":116}},{"line":1985,"address":[],"length":0,"stats":{"Line":152}},{"line":1989,"address":[],"length":0,"stats":{"Line":152}},{"line":1994,"address":[],"length":0,"stats":{"Line":152}},{"line":2000,"address":[],"length":0,"stats":{"Line":152}},{"line":2001,"address":[],"length":0,"stats":{"Line":152}},{"line":2002,"address":[],"length":0,"stats":{"Line":0}},{"line":2006,"address":[],"length":0,"stats":{"Line":152}},{"line":2008,"address":[],"length":0,"stats":{"Line":152}},{"line":2010,"address":[],"length":0,"stats":{"Line":139}},{"line":2014,"address":[],"length":0,"stats":{"Line":13}},{"line":2016,"address":[],"length":0,"stats":{"Line":13}},{"line":2017,"address":[],"length":0,"stats":{"Line":0}},{"line":2021,"address":[],"length":0,"stats":{"Line":13}},{"line":2022,"address":[],"length":0,"stats":{"Line":33}},{"line":2023,"address":[],"length":0,"stats":{"Line":32}},{"line":2024,"address":[],"length":0,"stats":{"Line":32}},{"line":2025,"address":[],"length":0,"stats":{"Line":32}},{"line":2030,"address":[],"length":0,"stats":{"Line":0}},{"line":2031,"address":[],"length":0,"stats":{"Line":0}},{"line":2035,"address":[],"length":0,"stats":{"Line":13}},{"line":2036,"address":[],"length":0,"stats":{"Line":13}},{"line":2038,"address":[],"length":0,"stats":{"Line":33}},{"line":2039,"address":[],"length":0,"stats":{"Line":20}},{"line":2040,"address":[],"length":0,"stats":{"Line":20}},{"line":2043,"address":[],"length":0,"stats":{"Line":1}},{"line":2046,"address":[],"length":0,"stats":{"Line":65}},{"line":2048,"address":[],"length":0,"stats":{"Line":32}},{"line":2051,"address":[],"length":0,"stats":{"Line":0}},{"line":2055,"address":[],"length":0,"stats":{"Line":0}}],"covered":893,"coverable":1103},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","tests","advanced_string_literals.rs"],"content":"use ferra_lexer::*;\n\nfn lex_all(input: \u0026str) -\u003e Vec\u003cToken\u003e {\n    Lexer::new(input).lex()\n}\n\n// Hash-delimited raw string tests\n#[test]\nfn test_raw_string_basic_no_hash() {\n    let input = r#\"r\"hello world\"\"#;\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens.len(), 2); // RawStringLiteral + EOF\n    assert_eq!(tokens[0].kind, TokenKind::RawStringLiteral);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"hello world\".to_string()))\n    );\n}\n\n#[test]\nfn test_raw_string_single_hash() {\n    let input = r##\"r#\"He said \"hello\" world\"#\"##;\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::RawStringLiteral);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(r#\"He said \"hello\" world\"#.to_string()))\n    );\n}\n\n#[test]\nfn test_raw_string_double_hash() {\n    let input = r###\"r##\"String with \"quotes\" and #hashes#\"##\"###;\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::RawStringLiteral);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\n            r#\"String with \"quotes\" and #hashes#\"#.to_string()\n        ))\n    );\n}\n\n#[test]\nfn test_raw_string_multiline_with_hash() {\n    let input = r##\"r#\"line 1\nline 2 with \"quotes\"\nline 3\"#\"##;\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::RawStringLiteral);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\n            \"line 1\\nline 2 with \\\"quotes\\\"\\nline 3\".to_string()\n        ))\n    );\n    assert_eq!(tokens[0].span.start.line, 1);\n    assert_eq!(tokens[0].span.end.line, 3);\n}\n\n#[test]\nfn test_raw_string_unterminated_with_hash() {\n    let input = r##\"r#\"unterminated\"##; // Missing closing #\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert!(matches!(\n        tokens[0].literal.as_ref().unwrap(),\n        LiteralValue::String(msg) if msg.contains(\"Unterminated raw string literal\")\n    ));\n}\n\n#[test]\nfn test_raw_string_hash_mismatch() {\n    let input = r###\"r##\"content\"#\"###; // Wrong number of closing hashes\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert!(matches!(\n        tokens[0].literal.as_ref().unwrap(),\n        LiteralValue::String(msg) if msg.contains(\"Unterminated raw string literal\")\n    ));\n}\n\n#[test]\nfn test_raw_string_invalid_no_quote() {\n    let input = \"r#hello\"; // Missing quote after hash\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert!(matches!(\n        tokens[0].literal.as_ref().unwrap(),\n        LiteralValue::String(msg) if msg.contains(\"Expected '\\\"' after 'r' and hash characters\")\n    ));\n}\n\n#[test]\nfn test_raw_string_no_escapes() {\n    // Verify that r\"\\n\" contains literal \\ and n, not a newline character\n    let input = r#\"r\"\\n\\t\\r\"\"#; // Changed to avoid quote termination issues\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::RawStringLiteral);\n    // Should contain literal backslashes, not escape sequences\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"\\\\n\\\\t\\\\r\".to_string()))\n    );\n\n    // Test with hash delimiters to include quotes\n    let input2 = r##\"r#\"\\n \"quotes\" \\t\\\"\"#\"##;\n    let tokens2 = lex_all(input2);\n\n    assert_eq!(tokens2[0].kind, TokenKind::RawStringLiteral);\n    assert_eq!(\n        tokens2[0].literal,\n        Some(LiteralValue::String(\"\\\\n \\\"quotes\\\" \\\\t\\\\\\\"\".to_string()))\n    );\n}\n\n// Multiline string tests\n#[test]\nfn test_multiline_string_basic() {\n    let input = \"\\\"\\\"\\\"\\nHello\\nWorld\\n\\\"\\\"\\\"\";\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::MultiLineStringLiteral);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"Hello\\nWorld\".to_string()))\n    );\n}\n\n#[test]\nfn test_multiline_string_with_indentation() {\n    let input = \"\\\"\\\"\\\"\\n    Line 1\\n    Line 2\\n        Indented line\\n    Line 3\\n\\\"\\\"\\\"\";\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::MultiLineStringLiteral);\n    // Common indentation (4 spaces) should be stripped\n    let expected = \"Line 1\\nLine 2\\n    Indented line\\nLine 3\";\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(expected.to_string()))\n    );\n}\n\n#[test]\nfn test_multiline_string_first_line_content() {\n    let input = \"\\\"\\\"\\\"Hello\\n    World\\n    !\\\"\\\"\\\"\";\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::MultiLineStringLiteral);\n    // First line has content, so indentation is preserved\n    let expected = \"Hello\\n    World\\n    !\";\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(expected.to_string()))\n    );\n}\n\n#[test]\nfn test_multiline_string_empty_lines() {\n    let input = \"\\\"\\\"\\\"\\n    Line 1\\n\\n    Line 3\\n\\\"\\\"\\\"\";\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::MultiLineStringLiteral);\n    let expected = \"Line 1\\n\\nLine 3\";\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(expected.to_string()))\n    );\n}\n\n#[test]\nfn test_multiline_string_quotes_inside() {\n    let input = \"\\\"\\\"\\\"\\nHe said \\\"hello\\\" and 'goodbye'\\nShe replied \\\"see you later\\\"\\n\\\"\\\"\\\"\";\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::MultiLineStringLiteral);\n    let expected = \"He said \\\"hello\\\" and 'goodbye'\\nShe replied \\\"see you later\\\"\";\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(expected.to_string()))\n    );\n}\n\n#[test]\nfn test_multiline_string_unterminated() {\n    let input = \"\\\"\\\"\\\"\\nUnterminated string\\nStill going...\";\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert!(matches!(\n        tokens[0].literal.as_ref().unwrap(),\n        LiteralValue::String(msg) if msg.contains(\"Unterminated multiline string literal\")\n    ));\n}\n\n#[test]\nfn test_multiline_string_single_quote_inside() {\n    let input = \"\\\"\\\"\\\"\\nThis has one \\\" quote\\nAnd another \\\" quote\\n\\\"\\\"\\\"\";\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::MultiLineStringLiteral);\n    let expected = \"This has one \\\" quote\\nAnd another \\\" quote\";\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(expected.to_string()))\n    );\n}\n\n#[test]\nfn test_multiline_string_precise_spans() {\n    let input = \"\\\"\\\"\\\"\\nline 1\\nline 2\\n\\\"\\\"\\\"\";\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].span.start.offset, 0);\n    assert_eq!(tokens[0].span.end.offset, input.len());\n    assert_eq!(tokens[0].span.start.line, 1);\n    assert_eq!(tokens[0].span.end.line, 4);\n}\n\n#[test]\nfn test_multiline_string_complex_indentation() {\n    let input = \"\\\"\\\"\\\"\\n        function example() {\\n            if (condition) {\\n                return value;\\n            }\\n        }\\n\\\"\\\"\\\"\";\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::MultiLineStringLiteral);\n    let expected = \"function example() {\\n    if (condition) {\\n        return value;\\n    }\\n}\";\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(expected.to_string()))\n    );\n}\n\n// Mixed usage tests\n#[test]\nfn test_mixed_string_types_advanced() {\n    let input = \"\\\"\\\"\\\"\\nmultiline\\ncontent\\n\\\"\\\"\\\" r#\\\"raw with \\\"quotes\\\"\\\"# \\\"regular\\\"\";\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens.len(), 4); // 3 strings + EOF\n\n    assert_eq!(tokens[0].kind, TokenKind::MultiLineStringLiteral);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"multiline\\ncontent\".to_string()))\n    );\n\n    assert_eq!(tokens[1].kind, TokenKind::RawStringLiteral);\n    assert_eq!(\n        tokens[1].literal,\n        Some(LiteralValue::String(\"raw with \\\"quotes\\\"\".to_string()))\n    );\n\n    assert_eq!(tokens[2].kind, TokenKind::StringLiteral);\n    assert_eq!(\n        tokens[2].literal,\n        Some(LiteralValue::String(\"regular\".to_string()))\n    );\n}\n\n#[test]\nfn test_multiline_string_indentation_interaction() {\n    // Test that multiline strings don't interfere with INDENT/DEDENT logic\n    let input = \"let x = \\\"\\\"\\\"\\n    inner content\\n    more content\\n\\\"\\\"\\\"\\nlet y = 5\";\n    let tokens = lex_all(input);\n\n    // Find the tokens we care about\n    let mut found_multiline = false;\n    let mut found_second_let = false;\n    let mut unexpected_indents = 0;\n\n    for token in tokens.iter() {\n        match \u0026token.kind {\n            TokenKind::MultiLineStringLiteral =\u003e {\n                found_multiline = true;\n                // Verify the content is properly processed\n                assert_eq!(\n                    token.literal,\n                    Some(LiteralValue::String(\n                        \"inner content\\nmore content\".to_string()\n                    ))\n                );\n            }\n            TokenKind::Let if found_multiline \u0026\u0026 !found_second_let =\u003e {\n                found_second_let = true;\n                // Should be the second 'let' statement\n            }\n            TokenKind::Indent | TokenKind::Dedent =\u003e {\n                // There should be no INDENT/DEDENT tokens in this example\n                // because the multiline string content doesn't affect the main indentation level\n                unexpected_indents += 1;\n            }\n            _ =\u003e {}\n        }\n    }\n\n    assert!(found_multiline, \"Should find multiline string\");\n    assert!(found_second_let, \"Should find second let statement\");\n    assert_eq!(\n        unexpected_indents, 0,\n        \"Should not have any INDENT/DEDENT tokens in this flat structure\"\n    );\n}\n","traces":[{"line":3,"address":[],"length":0,"stats":{"Line":20}},{"line":4,"address":[],"length":0,"stats":{"Line":20}}],"covered":2,"coverable":2},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","tests","char_literals.rs"],"content":"use ferra_lexer::*;\n\n// Helper function to lex the entire input string\nfn lex_all(input: \u0026str) -\u003e Vec\u003cToken\u003e {\n    Lexer::new(input).lex()\n}\n\n#[test]\nfn test_char_literal_simple() {\n    let tokens = lex_all(\"'a'\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::CharacterLiteral);\n    assert_eq!(tokens[0].lexeme, \"'a'\");\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Char('a')));\n    assert_eq!(tokens[0].span.end.offset, 3);\n}\n\n#[test]\nfn test_char_literal_escaped_newline() {\n    let tokens = lex_all(\"'\\\\n'\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::CharacterLiteral);\n    assert_eq!(tokens[0].lexeme, \"'\\\\n'\");\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Char('\\n')));\n}\n\n#[test]\nfn test_char_literal_escaped_tab() {\n    let tokens = lex_all(\"'\\\\t'\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::CharacterLiteral);\n    assert_eq!(tokens[0].lexeme, \"'\\\\t'\");\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Char('\\t')));\n}\n\n#[test]\nfn test_char_literal_escaped_carriage_return() {\n    let tokens = lex_all(\"'\\\\r'\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::CharacterLiteral);\n    assert_eq!(tokens[0].lexeme, \"'\\\\r'\");\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Char('\\r')));\n}\n\n#[test]\nfn test_char_literal_escaped_null() {\n    let tokens = lex_all(\"'\\\\0'\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::CharacterLiteral);\n    assert_eq!(tokens[0].lexeme, \"'\\\\0'\");\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Char('\\0')));\n}\n\n#[test]\nfn test_char_literal_escaped_backslash() {\n    let tokens = lex_all(\"'\\\\\\\\'\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::CharacterLiteral);\n    assert_eq!(tokens[0].lexeme, \"'\\\\\\\\'\");\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Char('\\\\')));\n}\n\n#[test]\nfn test_char_literal_escaped_single_quote() {\n    let tokens = lex_all(\"'\\\\\\''\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::CharacterLiteral);\n    assert_eq!(tokens[0].lexeme, \"'\\\\\\''\");\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Char('\\'')));\n}\n\n#[test]\nfn test_char_literal_empty() {\n    let tokens = lex_all(\"''\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert_eq!(tokens[0].lexeme, \"''\");\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\n            \"Empty character literal (in character literal)\".to_string()\n        ))\n    );\n}\n\n#[test]\nfn test_char_literal_multiple_chars() {\n    let tokens = lex_all(\"'ab'\");\n    // Based on current logic: Error('a), then main loop might process 'b' and then an error for '.\n    // This test focuses on the first error produced by lex_char_literal.\n    assert!(\n        tokens.len() \u003e= 2,\n        \"Expected at least an error token and EOF\"\n    );\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert_eq!(tokens[0].lexeme, \"'a\");\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\n            \"Multi-character literal or unterminated (in character literal)\".to_string()\n        ))\n    );\n}\n\n#[test]\nfn test_char_literal_unterminated_eof_after_opening() {\n    let tokens = lex_all(\"'\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert_eq!(tokens[0].lexeme, \"'\");\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\n            \"Unterminated character literal (EOF) (in character literal)\".to_string()\n        ))\n    );\n}\n\n#[test]\nfn test_char_literal_unterminated_eof_after_char() {\n    let tokens = lex_all(\"'a\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert_eq!(tokens[0].lexeme, \"'a\");\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\n            \"Unterminated character literal (EOF before closing quote) (in character literal)\"\n                .to_string()\n        ))\n    );\n}\n\n#[test]\nfn test_char_literal_unterminated_eof_after_backslash() {\n    let tokens = lex_all(\"'\\\\\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert_eq!(tokens[0].lexeme, \"'\\\\\");\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\n            \"Unterminated character literal after backslash (in character literal)\".to_string()\n        ))\n    );\n}\n\n#[test]\nfn test_char_literal_unterminated_by_newline() {\n    let tokens = lex_all(\"'a\\n\"); // 'a then newline\n                                  // Should produce an error token for unterminated char literal, then a Newline token, then EOF\n    assert!(tokens.len() \u003e= 2);\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert_eq!(tokens[0].lexeme, \"'a\"); // Consumes 'a, stops at \\n\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\n            \"Multi-character literal or unterminated (in character literal)\".to_string()\n        ))\n    );\n    // Optionally, check that the last token is EOF\n    assert_eq!(tokens.last().unwrap().kind, TokenKind::Eof);\n}\n\n#[test]\nfn test_char_literal_invalid_escape() {\n    let tokens = lex_all(\"'\\\\q'\");\n    // Should produce an error token for the invalid escape, then a token for the stray closing quote, then EOF\n    assert!(tokens.len() \u003e= 3);\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert_eq!(tokens[0].lexeme, \"'\\\\q\"); // Only up to the invalid escape\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\n            \"Invalid escape sequence in char literal: \\\\q (in character literal)\".to_string()\n        ))\n    );\n    // The next token should be the stray single quote\n    assert_eq!(tokens[1].kind, TokenKind::Error); // It will be an error token for the stray '\n    assert_eq!(tokens[1].lexeme, \"'\");\n    // Optionally, check that the last token is EOF\n    assert_eq!(tokens.last().unwrap().kind, TokenKind::Eof);\n}\n\n#[test]\nfn test_char_unicode_escapes() {\n    let src = \"'\\\\u{41}'\"; // 'A'\n    let tokens = lex_all(src);\n    assert_eq!(tokens[0].kind, TokenKind::CharacterLiteral);\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Char('A')));\n\n    let src_multichar_unicode = \"'\\\\u{1F600}'\"; // '😀'\n    let tokens_multi = lex_all(src_multichar_unicode);\n    assert_eq!(tokens_multi[0].kind, TokenKind::CharacterLiteral);\n    assert_eq!(tokens_multi[0].literal, Some(LiteralValue::Char('😀')));\n\n    let src_empty_braces = \"'\\\\u{}'\";\n    let tokens_empty = lex_all(src_empty_braces);\n    assert_eq!(tokens_empty[0].kind, TokenKind::Error);\n    assert!(\n        matches!(tokens_empty[0].literal.as_ref().unwrap(), LiteralValue::String(msg) if msg.contains(\"empty hex code \\\\u{}\"))\n    );\n\n    let src_unclosed_escape = \"'\\\\u{41\"; // unclosed, then EOF\n    let tokens_unclosed = lex_all(src_unclosed_escape);\n    assert_eq!(tokens_unclosed[0].kind, TokenKind::Error);\n    assert!(\n        matches!(tokens_unclosed[0].literal.as_ref().unwrap(), LiteralValue::String(msg) if msg.contains(\"unclosed \\\\u{41} sequence\"))\n    );\n\n    // Char literal specific: what if \\u{...} is followed by more chars before closing quote?\n    let src_unicode_plus_char = \"'\\\\u{41}b'\";\n    let tokens_unicode_plus = lex_all(src_unicode_plus_char);\n    assert_eq!(tokens_unicode_plus[0].kind, TokenKind::Error);\n    assert!(\n        matches!(tokens_unicode_plus[0].literal.as_ref().unwrap(), LiteralValue::String(msg) if msg.contains(\"Multi-character literal or unterminated (in character literal)\"))\n    );\n}\n","traces":[{"line":4,"address":[],"length":0,"stats":{"Line":19}},{"line":5,"address":[],"length":0,"stats":{"Line":19}}],"covered":2,"coverable":2},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","tests","comments.rs"],"content":"use ferra_lexer::{Lexer, TokenKind};\n\n#[test]\nfn test_line_comment() {\n    let src = \"let x = 5; // this is a comment\\nlet y = 10;\";\n    let tokens = Lexer::new(src).lex();\n    // Comments are consumed, not emitted as tokens\n    assert_eq!(tokens[0].kind, TokenKind::Let);\n    assert_eq!(tokens[1].kind, TokenKind::Identifier);\n    assert_eq!(tokens[2].kind, TokenKind::Equal);\n    assert_eq!(tokens[3].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[4].kind, TokenKind::Semicolon);\n    assert_eq!(tokens[5].kind, TokenKind::Newline);\n    assert_eq!(tokens[6].kind, TokenKind::Let);\n}\n\n#[test]\nfn test_block_comment() {\n    let src = \"let x = /* comment */ 5;\";\n    let tokens = Lexer::new(src).lex();\n    assert_eq!(tokens[0].kind, TokenKind::Let);\n    assert_eq!(tokens[1].kind, TokenKind::Identifier);\n    assert_eq!(tokens[2].kind, TokenKind::Equal);\n    assert_eq!(tokens[3].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[4].kind, TokenKind::Semicolon);\n}\n\n#[test]\nfn test_unterminated_block_comment() {\n    let src = \"let x = /* unterminated comment\";\n    let tokens = Lexer::new(src).lex();\n    assert_eq!(tokens[0].kind, TokenKind::Let);\n    assert_eq!(tokens[1].kind, TokenKind::Identifier);\n    assert_eq!(tokens[2].kind, TokenKind::Equal);\n    assert_eq!(tokens[3].kind, TokenKind::Error);\n    // Check error message\n    if let Some(ferra_lexer::LiteralValue::String(msg)) = \u0026tokens[3].literal {\n        assert!(msg.contains(\"Unterminated block comment\"));\n    }\n}\n\n#[test]\nfn test_unterminated_block_comment_eof() {\n    let src = \"/* comment without closing\";\n    let tokens = Lexer::new(src).lex();\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    if let Some(ferra_lexer::LiteralValue::String(msg)) = \u0026tokens[0].literal {\n        assert!(msg.contains(\"Unterminated block comment\"));\n    }\n}\n\n#[test]\nfn test_nested_block_comments() {\n    let src = \"let x = /* outer /* inner */ comment */ 5;\";\n    let tokens = Lexer::new(src).lex();\n    assert_eq!(tokens[0].kind, TokenKind::Let);\n    assert_eq!(tokens[1].kind, TokenKind::Identifier);\n    assert_eq!(tokens[2].kind, TokenKind::Equal);\n    assert_eq!(tokens[3].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[4].kind, TokenKind::Semicolon);\n}\n\n#[test]\nfn test_unterminated_nested_block_comment() {\n    let src = \"/* outer /* inner comment without proper closing */\";\n    let tokens = Lexer::new(src).lex();\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    if let Some(ferra_lexer::LiteralValue::String(msg)) = \u0026tokens[0].literal {\n        assert!(msg.contains(\"Unterminated block comment\"));\n    }\n}\n\n#[test]\nfn test_unterminated_inner_nested_block_comment() {\n    let src = \"/* outer /* inner */ still in outer comment\";\n    let tokens = Lexer::new(src).lex();\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    if let Some(ferra_lexer::LiteralValue::String(msg)) = \u0026tokens[0].literal {\n        assert!(msg.contains(\"Unterminated block comment\"));\n    }\n}\n\n#[test]\nfn test_multi_line_span_precision() {\n    // Test multi-line unterminated block comment span precision\n    let src = \"let x = /*\\nthis is a\\nmulti-line\\nunterminated comment\";\n    let tokens = Lexer::new(src).lex();\n\n    // Find the error token\n    let error_token = tokens.iter().find(|t| t.kind == TokenKind::Error).unwrap();\n\n    // Verify span boundaries\n    assert_eq!(error_token.span.start.line, 1); // starts on line 1\n    assert_eq!(error_token.span.start.column, 9); // after \"let x = \"\n    assert_eq!(error_token.span.start.offset, 8); // 8 characters in\n\n    // End should be at the end of the input\n    assert!(\n        error_token.span.end.line \u003e error_token.span.start.line,\n        \"Multi-line token should span multiple lines\"\n    );\n    assert_eq!(error_token.span.end.line, 4); // ends on line 4\n    assert_eq!(error_token.span.end.offset, src.len()); // should span to end of input\n\n    // Verify the lexeme contains the entire unterminated comment\n    assert!(error_token.lexeme.starts_with(\"/*\"));\n    assert!(error_token.lexeme.contains(\"multi-line\"));\n    assert_eq!(error_token.lexeme.len(), src.len() - 8); // everything after \"let x = \"\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","tests","float_literals.rs"],"content":"use ferra_lexer::{Lexer, LiteralValue, TokenKind};\n\n#[test]\n#[allow(clippy::approx_constant)]\nfn float_literals() {\n    let tokens = Lexer::new(\"3.14 2.0e10 1_000.5 42 1.0e-3 7. .5\").lex();\n    let kinds: Vec\u003c_\u003e = tokens.iter().map(|t| \u0026t.kind).collect();\n    assert_eq!(\n        kinds,\n        vec![\n            \u0026TokenKind::FloatLiteral,\n            \u0026TokenKind::FloatLiteral,\n            \u0026TokenKind::FloatLiteral,\n            \u0026TokenKind::IntegerLiteral,\n            \u0026TokenKind::FloatLiteral,\n            \u0026TokenKind::FloatLiteral,\n            \u0026TokenKind::FloatLiteral,\n            \u0026TokenKind::Eof\n        ]\n    );\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Float(3.14)));\n    assert_eq!(tokens[1].literal, Some(LiteralValue::Float(2.0e10)));\n    assert_eq!(tokens[2].literal, Some(LiteralValue::Float(1000.5)));\n    assert_eq!(tokens[4].literal, Some(LiteralValue::Float(1.0e-3)));\n    assert_eq!(tokens[5].literal, Some(LiteralValue::Float(7.0)));\n    assert_eq!(tokens[6].literal, Some(LiteralValue::Float(0.5)));\n}\n\n#[test]\n#[allow(clippy::approx_constant)]\nfn integration_float_literals() {\n    let tokens =\n        Lexer::new(\"x = 3.14; y = 2.0e10; z = 1_000.5; a = 42; b = 1.0e-3; c = 7.; d = .5;\").lex();\n    let kinds: Vec\u003c_\u003e = tokens.iter().map(|t| \u0026t.kind).collect();\n    assert_eq!(\n        kinds,\n        vec![\n            \u0026TokenKind::Identifier,\n            \u0026TokenKind::Equal,\n            \u0026TokenKind::FloatLiteral,\n            \u0026TokenKind::Semicolon,\n            \u0026TokenKind::Identifier,\n            \u0026TokenKind::Equal,\n            \u0026TokenKind::FloatLiteral,\n            \u0026TokenKind::Semicolon,\n            \u0026TokenKind::Identifier,\n            \u0026TokenKind::Equal,\n            \u0026TokenKind::FloatLiteral,\n            \u0026TokenKind::Semicolon,\n            \u0026TokenKind::Identifier,\n            \u0026TokenKind::Equal,\n            \u0026TokenKind::IntegerLiteral,\n            \u0026TokenKind::Semicolon,\n            \u0026TokenKind::Identifier,\n            \u0026TokenKind::Equal,\n            \u0026TokenKind::FloatLiteral,\n            \u0026TokenKind::Semicolon,\n            \u0026TokenKind::Identifier,\n            \u0026TokenKind::Equal,\n            \u0026TokenKind::FloatLiteral,\n            \u0026TokenKind::Semicolon,\n            \u0026TokenKind::Identifier,\n            \u0026TokenKind::Equal,\n            \u0026TokenKind::FloatLiteral,\n            \u0026TokenKind::Semicolon,\n            \u0026TokenKind::Eof\n        ]\n    );\n    // Spot check a value\n    let token_c = tokens.iter().find(|t| t.lexeme == \"7.\").unwrap();\n    assert_eq!(token_c.literal, Some(LiteralValue::Float(7.0)));\n    let token_d = tokens.iter().find(|t| t.lexeme == \".5\").unwrap();\n    assert_eq!(token_d.literal, Some(LiteralValue::Float(0.5)));\n    let float_token = tokens\n        .iter()\n        .find(|t| t.kind == TokenKind::FloatLiteral \u0026\u0026 t.lexeme == \"3.14\")\n        .unwrap();\n    assert_eq!(float_token.literal, Some(LiteralValue::Float(3.14)));\n}\n\n#[test]\n#[allow(clippy::approx_constant)]\nfn float_with_underscore_in_exponent() {\n    let tokens = Lexer::new(\"1.2e-3_4\").lex();\n    assert_eq!(tokens[0].kind, TokenKind::FloatLiteral);\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Float(1.2e-34)));\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","tests","fuzz.rs"],"content":"use ferra_lexer::Lexer;\nuse proptest::prelude::*;\n\nproptest! {\n    #[test]\n    fn lexer_never_panics_on_random_input(s in \".{0,512}\") {\n        let _ = Lexer::new(\u0026s).lex();\n    }\n\n    #[test]\n    fn lexer_handles_raw_string_fuzzing(\n        hash_count in 0usize..=5,\n        content in \"[^\\\"]*\", // Content without quotes to avoid early termination\n        malformed in prop::bool::ANY\n    ) {\n        // Generate raw string with variable hash count\n        let hashes = \"#\".repeat(hash_count);\n        let input = if malformed {\n            // Sometimes create malformed strings for error path testing\n            format!(\"r{}\\\"{}\\\"\", hashes, content)\n        } else {\n            format!(\"r{}\\\"{}\\\"{}\\\"\", hashes, content, hashes)\n        };\n\n        // Should never panic, regardless of input\n        let _ = Lexer::new(\u0026input).lex();\n    }\n\n    #[test]\n    fn lexer_handles_multiline_string_fuzzing(\n        content in \"[^\\\"]{0,100}\",\n        has_newlines in prop::bool::ANY,\n        malformed in prop::bool::ANY\n    ) {\n        let inner_content = if has_newlines {\n            content.replace(\"n\", \"\\n\") // Add some newlines\n        } else {\n            content\n        };\n\n        let input = if malformed {\n            format!(\"\\\"\\\"\\\"{}\\\"\", inner_content) // Missing closing quotes\n        } else {\n            format!(\"\\\"\\\"\\\"{}\\\"\\\"\\\"\", inner_content)\n        };\n\n        // Should never panic\n        let _ = Lexer::new(\u0026input).lex();\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","tests","general_lexing.rs"],"content":"use ferra_lexer::*;\n\n// Helper function to lex the entire input string\nfn lex_all(input: \u0026str) -\u003e Vec\u003cToken\u003e {\n    Lexer::new(input).lex()\n}\n\n#[test]\nfn test_empty_input() {\n    assert_eq!(lex_all(\"\"), vec![Token::eof_dummy()]);\n}\n\n#[test]\nfn test_indentation_with_whitespace() {\n    let tokens = lex_all(\"a\\n  \");\n    assert_eq!(tokens.len(), 5);\n    assert_eq!(tokens[0].kind, TokenKind::Identifier); // a\n    assert_eq!(tokens[1].kind, TokenKind::Newline);\n    assert_eq!(tokens[2].kind, TokenKind::Indent);\n    assert_eq!(tokens[3].kind, TokenKind::Dedent);\n    assert_eq!(tokens[4].kind, TokenKind::Eof);\n}\n\n#[test]\nfn test_unrecognized_character() {\n    let tokens = lex_all(\"$\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert_eq!(tokens[0].lexeme, \"$\".to_string());\n    assert_eq!(tokens[1].kind, TokenKind::Eof);\n}\n\n#[test]\nfn test_shebang_skipped() {\n    let src = \"#! /usr/bin/env ferra\\nlet x = 42;\";\n    let tokens = ferra_lexer::Lexer::new(src).lex();\n    let kinds: Vec\u003c_\u003e = tokens.iter().map(|t| \u0026t.kind).collect();\n    assert_eq!(\n        kinds,\n        vec![\n            \u0026ferra_lexer::TokenKind::Let,\n            \u0026ferra_lexer::TokenKind::Identifier,\n            \u0026ferra_lexer::TokenKind::Equal,\n            \u0026ferra_lexer::TokenKind::IntegerLiteral,\n            \u0026ferra_lexer::TokenKind::Semicolon,\n            \u0026ferra_lexer::TokenKind::Eof,\n        ]\n    );\n}\n","traces":[{"line":4,"address":[],"length":0,"stats":{"Line":3}},{"line":5,"address":[],"length":0,"stats":{"Line":3}}],"covered":2,"coverable":2},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","tests","keywords_identifiers.rs"],"content":"use ferra_lexer::*;\n\n// Helper function to lex the entire input string\nfn lex_all(input: \u0026str) -\u003e Vec\u003cToken\u003e {\n    Lexer::new(input).lex()\n}\n\n#[test]\nfn test_let_keyword() {\n    let tokens = lex_all(\"let\");\n    println!(\"TOKENS: {:?}\", tokens);\n    assert_eq!(tokens.len(), 2); // let, EOF\n    assert_eq!(tokens[0].kind, TokenKind::Let);\n    assert_eq!(tokens[0].lexeme, \"let\");\n    // Only check that the span covers the input\n    assert_eq!(tokens[0].span.start.offset, 0);\n    assert_eq!(tokens[0].span.end.offset, 3);\n    assert_eq!(tokens[1].kind, TokenKind::Eof);\n}\n\n#[test]\nfn test_identifier() {\n    let tokens = lex_all(\"my_var\");\n    println!(\"TOKENS: {:?}\", tokens);\n    assert_eq!(tokens.len(), 2); // identifier, EOF\n    assert_eq!(tokens[0].kind, TokenKind::Identifier);\n    assert_eq!(tokens[0].lexeme, \"my_var\");\n    assert_eq!(tokens[0].span.start.offset, 0);\n    assert_eq!(tokens[0].span.end.offset, 6);\n    assert_eq!(tokens[1].kind, TokenKind::Eof);\n}\n\n#[test]\nfn test_keywords_and_identifiers() {\n    let tokens = lex_all(\"let var fn async data match true false ident1 _ident2\");\n    // Filter out error tokens (which may be emitted for invalid UTF-8 boundaries or other robust handling)\n    let tokens: Vec\u003c_\u003e = tokens\n        .into_iter()\n        .filter(|t| t.kind != TokenKind::Error)\n        .collect();\n    println!(\"TOKENS: {:?}\", tokens);\n    let expected_kinds = [\n        TokenKind::Let,\n        TokenKind::Var,\n        TokenKind::Fn,\n        TokenKind::Async,\n        TokenKind::Data,\n        TokenKind::Match,\n        TokenKind::True,\n        TokenKind::False,\n        TokenKind::Identifier,\n        TokenKind::Underscore,\n        TokenKind::Identifier,\n        TokenKind::Eof,\n    ];\n    let expected_lexemes = [\n        \"let\", \"var\", \"fn\", \"async\", \"data\", \"match\", \"true\", \"false\", \"ident1\", \"_\", \"ident2\", \"\",\n    ];\n    let expected_literals = vec![\n        None,\n        None,\n        None,\n        None,\n        None,\n        None,\n        Some(LiteralValue::Boolean(true)),\n        Some(LiteralValue::Boolean(false)),\n        None,\n        None,\n        None,\n        None,\n    ];\n\n    assert_eq!(\n        tokens.len(),\n        expected_kinds.len(),\n        \"Mismatch in token count\"\n    );\n\n    for i in 0..tokens.len() - 1 {\n        // Exclude EOF for literal check simplicity here\n        assert_eq!(\n            tokens[i].kind, expected_kinds[i],\n            \"Mismatch in kind for {}\",\n            expected_lexemes[i]\n        );\n        assert_eq!(\n            tokens[i].lexeme, expected_lexemes[i],\n            \"Mismatch in lexeme for {}\",\n            expected_lexemes[i]\n        );\n        assert_eq!(\n            tokens[i].literal, expected_literals[i],\n            \"Mismatch in literal for {}\",\n            expected_lexemes[i]\n        );\n    }\n    assert_eq!(tokens.last().unwrap().kind, TokenKind::Eof);\n}\n\n#[test]\nfn test_and_or_keywords() {\n    let tokens = lex_all(\"and or\");\n    assert_eq!(tokens.len(), 3); // and, or, eof\n    assert_eq!(tokens[0].kind, TokenKind::LogicalAnd);\n    assert_eq!(tokens[0].lexeme, \"and\");\n    assert_eq!(tokens[1].kind, TokenKind::LogicalOr);\n    assert_eq!(tokens[1].lexeme, \"or\");\n    assert_eq!(tokens[2].kind, TokenKind::Eof);\n}\n\n#[test]\nfn test_unicode_identifiers() {\n    // Identifier with a non-ASCII character (Greek letter Alpha)\n    let tokens_alpha = lex_all(\"αβγ\");\n    let tokens_alpha: Vec\u003c_\u003e = tokens_alpha\n        .into_iter()\n        .filter(|t| t.kind != TokenKind::Error)\n        .collect();\n    println!(\"TOKENS_ALPHA: {:?}\", tokens_alpha);\n    assert_eq!(tokens_alpha.len(), 2);\n    assert_eq!(tokens_alpha[0].kind, TokenKind::Identifier);\n    assert_eq!(tokens_alpha[0].lexeme, \"αβγ\");\n    assert_eq!(tokens_alpha[1].kind, TokenKind::Eof);\n\n    // Identifier starting with underscore followed by Unicode\n    let tokens_underscore_unicode = lex_all(\"_Привет\"); // Russian \"Privet\" (Hello)\n    let tokens_underscore_unicode: Vec\u003c_\u003e = tokens_underscore_unicode\n        .into_iter()\n        .filter(|t| t.kind != TokenKind::Error)\n        .collect();\n    println!(\"TOKENS_UNDERSCORE_UNICODE: {:?}\", tokens_underscore_unicode);\n    assert_eq!(tokens_underscore_unicode.len(), 3);\n    assert_eq!(tokens_underscore_unicode[0].kind, TokenKind::Underscore);\n    assert_eq!(tokens_underscore_unicode[1].kind, TokenKind::Identifier);\n    assert_eq!(tokens_underscore_unicode[1].lexeme, \"Привет\");\n    assert_eq!(tokens_underscore_unicode[2].kind, TokenKind::Eof);\n\n    // Japanese Katakana identifier\n    let tokens_katakana = lex_all(\"変数名\"); // \"hensuumei\" (variable name)\n    let tokens_katakana: Vec\u003c_\u003e = tokens_katakana\n        .into_iter()\n        .filter(|t| t.kind != TokenKind::Error)\n        .collect();\n    println!(\"TOKENS_KATAKANA: {:?}\", tokens_katakana);\n    assert_eq!(tokens_katakana.len(), 2);\n    assert_eq!(tokens_katakana[0].kind, TokenKind::Identifier);\n    assert_eq!(tokens_katakana[0].lexeme, \"変数名\");\n    assert_eq!(tokens_katakana[1].kind, TokenKind::Eof);\n}\n\n#[test]\nfn test_nfc_normalization_identifiers() {\n    // U+006E (n) followed by U+0303 (combining tilde ~) -\u003e should normalize to U+00F1 (ñ)\n    let unnormalized_ntilde = \"n\\u{0303}ombre\"; // \"n~ombre\"\n    let normalized_ntilde = \"\\u{00F1}ombre\"; // \"ñombre\"\n\n    let tokens = lex_all(unnormalized_ntilde);\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::Identifier);\n    assert_eq!(\n        tokens[0].lexeme, normalized_ntilde,\n        \"Lexeme should be NFC normalized\"\n    );\n\n    // Test a keyword that might be typed with combining characters\n    // For example, \"l\" + \"e\" + \"◌̇\" (combining dot above) + \"t\"\n    // This is a bit contrived for `let`, as keywords are usually simple ASCII.\n    // The main point is that the *identifier* part of lexing normalizes.\n    // If \"le◌̇t\" were NOT a keyword, it would be normalized.\n    // If it *is* a keyword, it must match the exact keyword string post-normalization.\n    // Our keywords are simple ASCII so this won't make them match if typed weirdly.\n    // This test primarily ensures non-keyword identifiers are normalized.\n    let unnormalized_ident = \"vari\\u{0301}vel\"; // \"vari´vel\" (acute accent on i)\n    let normalized_ident = \"var\\u{00ED}vel\"; // \"varível\"\n    let tokens_complex = lex_all(unnormalized_ident);\n    assert_eq!(tokens_complex.len(), 2);\n    assert_eq!(tokens_complex[0].kind, TokenKind::Identifier);\n    assert_eq!(tokens_complex[0].lexeme, normalized_ident);\n}\n","traces":[{"line":4,"address":[],"length":0,"stats":{"Line":9}},{"line":5,"address":[],"length":0,"stats":{"Line":9}}],"covered":2,"coverable":2},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","tests","multi_char_ops.rs"],"content":"use ferra_lexer::{Lexer, TokenKind};\n\n#[test]\nfn multi_char_operators() {\n    let tokens = Lexer::new(\"a == b != c \u003c= d \u003e= e \u0026\u0026 f || g += h -= i *= j /= k %= l \u0026= m |= n ^= o \u003c\u003c= p \u003e\u003e= q -\u003e r =\u003e s .. t ..= u :: v ?? w\").lex();\n    let expected = [\n        TokenKind::Identifier,\n        TokenKind::EqualEqual,\n        TokenKind::Identifier,\n        TokenKind::NotEqual,\n        TokenKind::Identifier,\n        TokenKind::LessEqual,\n        TokenKind::Identifier,\n        TokenKind::GreaterEqual,\n        TokenKind::Identifier,\n        TokenKind::LogicalAnd,\n        TokenKind::Identifier,\n        TokenKind::LogicalOr,\n        TokenKind::Identifier,\n        TokenKind::PlusEqual,\n        TokenKind::Identifier,\n        TokenKind::MinusEqual,\n        TokenKind::Identifier,\n        TokenKind::StarEqual,\n        TokenKind::Identifier,\n        TokenKind::SlashEqual,\n        TokenKind::Identifier,\n        TokenKind::PercentEqual,\n        TokenKind::Identifier,\n        TokenKind::BitAndEqual,\n        TokenKind::Identifier,\n        TokenKind::BitOrEqual,\n        TokenKind::Identifier,\n        TokenKind::CaretEqual,\n        TokenKind::Identifier,\n        TokenKind::ShiftLeftEqual,\n        TokenKind::Identifier,\n        TokenKind::ShiftRightEqual,\n        TokenKind::Identifier,\n        TokenKind::Arrow,\n        TokenKind::Identifier,\n        TokenKind::FatArrow,\n        TokenKind::Identifier,\n        TokenKind::DotDot,\n        TokenKind::Identifier,\n        TokenKind::DotDotEqual,\n        TokenKind::Identifier,\n        TokenKind::PathSep,\n        TokenKind::Identifier,\n        TokenKind::Coalesce,\n        TokenKind::Identifier,\n        TokenKind::Eof,\n    ];\n    let kinds: Vec\u003cTokenKind\u003e = tokens.iter().map(|t| t.kind.clone()).collect();\n    assert_eq!(kinds, expected);\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","tests","multiline_and_raw_test.rs"],"content":"use ferra_lexer::*;\n\nfn lex_all(input: \u0026str) -\u003e Vec\u003cToken\u003e {\n    Lexer::new(input).lex()\n}\n\n#[test]\nfn test_raw_string_multiline() {\n    // Test that raw strings can contain newlines (multiline)\n    let input = r#\"r\"line 1\nline 2\nline 3\"\"#;\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens.len(), 2); // RawStringLiteral + EOF\n    assert_eq!(tokens[0].kind, TokenKind::RawStringLiteral);\n    assert_eq!(tokens[0].lexeme, input);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"line 1\\nline 2\\nline 3\".to_string()))\n    );\n\n    // Verify the span covers all lines\n    assert_eq!(tokens[0].span.start.line, 1);\n    assert_eq!(tokens[0].span.end.line, 3);\n}\n\n#[test]\nfn test_raw_string_with_backslashes() {\n    // Test raw strings preserve literal backslashes (no escape processing)\n    let input = r#\"r\"path\\to\\file and \\n stays literal\"\"#;\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::RawStringLiteral);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\n            r\"path\\to\\file and \\n stays literal\".to_string()\n        ))\n    );\n}\n\n#[test]\nfn test_regular_string_vs_raw_string_escapes() {\n    // Compare how regular strings process escapes vs raw strings\n    let regular_input = r#\"\"hello\\nworld\"\"#;\n    let raw_input = r#\"r\"hello\\nworld\"\"#;\n\n    let regular_tokens = lex_all(regular_input);\n    let raw_tokens = lex_all(raw_input);\n\n    // Regular string processes escapes\n    assert_eq!(regular_tokens[0].kind, TokenKind::StringLiteral);\n    assert_eq!(\n        regular_tokens[0].literal,\n        Some(LiteralValue::String(\"hello\\nworld\".to_string()))\n    );\n\n    // Raw string preserves literal backslashes\n    assert_eq!(raw_tokens[0].kind, TokenKind::RawStringLiteral);\n    assert_eq!(\n        raw_tokens[0].literal,\n        Some(LiteralValue::String(r\"hello\\nworld\".to_string()))\n    );\n}\n\n#[test]\nfn test_regular_string_multiline_behavior() {\n    // Regular strings should NOT span multiple lines (should error at newline)\n    let input = r#\"\"hello\nworld\"\"#;\n    let tokens = lex_all(input);\n\n    // Should produce an error token for unterminated string\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert_eq!(tokens[0].lexeme, \"\\\"hello\");\n    assert!(matches!(\n        tokens[0].literal.as_ref().unwrap(),\n        LiteralValue::String(msg) if msg.contains(\"Unterminated string literal\")\n    ));\n}\n\n#[test]\nfn test_raw_string_complex_multiline() {\n    // Test complex multiline raw string with various content\n    let input = r#\"r\"function example() {\n    if (x == 42) {\n        return template_var;\n    }\n    // Comment with \\backslash\n}\"\"#;\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::RawStringLiteral);\n    let expected_content = r#\"function example() {\n    if (x == 42) {\n        return template_var;\n    }\n    // Comment with \\backslash\n}\"#;\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(expected_content.to_string()))\n    );\n}\n\n#[test]\nfn test_raw_string_empty_lines() {\n    // Test raw string with empty lines\n    let input = r#\"r\"line 1\n\nline 3\"\"#;\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::RawStringLiteral);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"line 1\\n\\nline 3\".to_string()))\n    );\n}\n\n#[test]\nfn test_raw_string_precise_spans() {\n    // Test that spans are precise for multiline raw strings\n    let input = r#\"r\"a\nb\"\"#;\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].span.start.offset, 0);\n    assert_eq!(tokens[0].span.end.offset, input.len());\n    assert_eq!(tokens[0].span.start.line, 1);\n    assert_eq!(tokens[0].span.end.line, 2);\n    assert_eq!(tokens[0].span.start.column, 1);\n    assert_eq!(tokens[0].span.end.column, 3); // After the closing quote\n}\n\n#[test]\nfn test_mixed_string_types() {\n    // Test mixing different string types in one lexing session\n    let input = r#\"\"regular\" r\"raw\\string\" 'c'\"#;\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens.len(), 4); // 3 literals + EOF\n\n    assert_eq!(tokens[0].kind, TokenKind::StringLiteral);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"regular\".to_string()))\n    );\n\n    assert_eq!(tokens[1].kind, TokenKind::RawStringLiteral);\n    assert_eq!(\n        tokens[1].literal,\n        Some(LiteralValue::String(r\"raw\\string\".to_string()))\n    );\n\n    assert_eq!(tokens[2].kind, TokenKind::CharacterLiteral);\n    assert_eq!(tokens[2].literal, Some(LiteralValue::Char('c')));\n}\n\n#[test]\nfn test_raw_string_unterminated_multiline() {\n    // Test unterminated raw string across multiple lines\n    let input = r#\"r\"this is\nan unterminated\nraw string\"#; // Note: missing closing quote\n\n    let tokens = lex_all(input);\n\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert!(matches!(\n        tokens[0].literal.as_ref().unwrap(),\n        LiteralValue::String(msg) if msg.contains(\"Unterminated raw string literal\")\n    ));\n}\n","traces":[{"line":3,"address":[],"length":0,"stats":{"Line":10}},{"line":4,"address":[],"length":0,"stats":{"Line":10}}],"covered":2,"coverable":2},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","tests","numeric_literals.rs"],"content":"use ferra_lexer::*;\n\n// Helper function to lex the entire input string\nfn lex_all(input: \u0026str) -\u003e Vec\u003cToken\u003e {\n    Lexer::new(input).lex()\n}\n\n#[test]\nfn test_simple_integer() {\n    let tokens = lex_all(\"123\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[0].lexeme, \"123\");\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Integer(123)));\n    assert_eq!(tokens[0].span.start.offset, 0);\n    assert_eq!(tokens[0].span.end.offset, 3);\n}\n\n#[allow(clippy::approx_constant)]\n#[test]\nfn test_float_simple() {\n    let tokens = lex_all(\"3.14\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::FloatLiteral);\n    assert_eq!(tokens[0].lexeme, \"3.14\");\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Float(3.14)));\n    assert_eq!(tokens[0].span.start.offset, 0);\n    assert_eq!(tokens[0].span.end.offset, 4);\n\n    let tokens_leading_dot = lex_all(\".5\");\n    assert_eq!(tokens_leading_dot.len(), 2);\n    assert_eq!(tokens_leading_dot[0].kind, TokenKind::FloatLiteral);\n    assert_eq!(tokens_leading_dot[0].lexeme, \".5\");\n    assert_eq!(\n        tokens_leading_dot[0].literal,\n        Some(LiteralValue::Float(0.5))\n    );\n\n    let tokens_trailing_dot = lex_all(\"7.\");\n    assert_eq!(tokens_trailing_dot.len(), 2);\n    assert_eq!(tokens_trailing_dot[0].kind, TokenKind::FloatLiteral);\n    assert_eq!(tokens_trailing_dot[0].lexeme, \"7.\");\n    assert_eq!(\n        tokens_trailing_dot[0].literal,\n        Some(LiteralValue::Float(7.0))\n    );\n}\n\n#[test]\nfn test_float_with_exponent() {\n    let tokens = lex_all(\"1.2e3\");\n    assert_eq!(tokens[0].kind, TokenKind::FloatLiteral);\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Float(1200.0)));\n\n    let tokens_cap_e = lex_all(\"0.5E-2\");\n    assert_eq!(tokens_cap_e[0].kind, TokenKind::FloatLiteral);\n    assert_eq!(tokens_cap_e[0].literal, Some(LiteralValue::Float(0.005)));\n\n    let tokens_exp_pos = lex_all(\"5e+1\");\n    assert_eq!(tokens_exp_pos[0].kind, TokenKind::FloatLiteral);\n    assert_eq!(tokens_exp_pos[0].literal, Some(LiteralValue::Float(50.0)));\n}\n\n#[test]\nfn test_number_with_underscores() {\n    let tokens_int = lex_all(\"1_000_000\");\n    assert_eq!(tokens_int[0].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens_int[0].literal, Some(LiteralValue::Integer(1000000)));\n    assert_eq!(tokens_int[0].lexeme, \"1_000_000\");\n\n    let tokens_float = lex_all(\"3_0.1_4e-2\");\n    assert_eq!(tokens_float[0].kind, TokenKind::FloatLiteral);\n    assert_eq!(tokens_float[0].literal, Some(LiteralValue::Float(0.3014))); // 30.14e-2 = 0.3014\n    assert_eq!(tokens_float[0].lexeme, \"3_0.1_4e-2\");\n}\n\n#[test]\nfn test_invalid_numbers() {\n    let _tokens_double_dot = lex_all(\"1..2\"); // This should be DotDot, not a number error in lex_number\n                                              // The main lex loop handles DotDot before lex_number for such cases.\n                                              // So, a direct call to lex_number with \"1..2\" is not a valid test for lex_number itself.\n                                              // We test error cases that lex_number *would* produce if it got malformed numbers.\n\n    // lex_number itself would error if parsing fails, e.g.:\n    let tokens_bad_float = lex_all(\"3.14.15\");\n    assert_eq!(\n        tokens_bad_float[0].kind,\n        TokenKind::FloatLiteral,\n        \"Lexeme: {}\",\n        tokens_bad_float[0].lexeme\n    );\n    assert_eq!(tokens_bad_float[0].lexeme, \"3.14\");\n    assert_eq!(\n        tokens_bad_float[1].kind,\n        TokenKind::FloatLiteral,\n        \"Lexeme: {}\",\n        tokens_bad_float[1].lexeme\n    );\n    assert_eq!(tokens_bad_float[1].lexeme, \".15\");\n\n    let tokens_bad_exp = lex_all(\"1e\"); // Exponent without digits\n    assert_eq!(\n        tokens_bad_exp[0].kind,\n        TokenKind::Error,\n        \"Lexeme: {}\",\n        tokens_bad_exp[0].lexeme\n    );\n    assert_eq!(tokens_bad_exp[0].lexeme, \"1e\");\n\n    let tokens_bad_exp_sign = lex_all(\"1e-\");\n    assert_eq!(\n        tokens_bad_exp_sign[0].kind,\n        TokenKind::Error,\n        \"Lexeme: {}\",\n        tokens_bad_exp_sign[0].lexeme\n    );\n    assert_eq!(tokens_bad_exp_sign[0].lexeme, \"1e-\");\n}\n\n#[test]\nfn test_hex_literals() {\n    let tokens = lex_all(\"0x1A 0XFF 0x_a_B_0\");\n    assert_eq!(tokens[0].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Integer(26)));\n    assert_eq!(tokens[1].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[1].literal, Some(LiteralValue::Integer(255)));\n    assert_eq!(tokens[2].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[2].literal, Some(LiteralValue::Integer(0xAB0)));\n    let tokens_err = lex_all(\"0x 0x_ 0xG\");\n    assert_eq!(tokens_err[0].kind, TokenKind::Error); // No digits\n    assert_eq!(tokens_err[1].kind, TokenKind::Error); // Ends with underscore (or no digits after prefix)\n    assert_eq!(tokens_err[2].kind, TokenKind::Error); // Invalid digit\n}\n\n#[test]\nfn test_octal_literals() {\n    let tokens = lex_all(\"0o12 0O77 0o_1_0\");\n    assert_eq!(tokens[0].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Integer(10)));\n    assert_eq!(tokens[1].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[1].literal, Some(LiteralValue::Integer(63)));\n    assert_eq!(tokens[2].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[2].literal, Some(LiteralValue::Integer(0o10)));\n    let tokens_err = lex_all(\"0o 0o_ 0o8\");\n    assert_eq!(tokens_err[0].kind, TokenKind::Error); // No digits\n    assert_eq!(tokens_err[1].kind, TokenKind::Error); // Ends with underscore (or no digits after prefix)\n    assert_eq!(tokens_err[2].kind, TokenKind::Error); // Invalid digit\n}\n\n#[test]\nfn test_binary_literals() {\n    let tokens = lex_all(\"0b10 0B11 0b_1_0\");\n    assert_eq!(tokens[0].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Integer(2)));\n    assert_eq!(tokens[1].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[1].literal, Some(LiteralValue::Integer(3)));\n    assert_eq!(tokens[2].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[2].literal, Some(LiteralValue::Integer(0b10)));\n    let tokens_err = lex_all(\"0b 0b_ 0b2\");\n    assert_eq!(tokens_err[0].kind, TokenKind::Error); // No digits\n    assert_eq!(tokens_err[1].kind, TokenKind::Error); // Ends with underscore (or no digits after prefix)\n    assert_eq!(tokens_err[2].kind, TokenKind::Error); // Invalid digit\n}\n\n#[test]\nfn test_leading_zero_decimal() {\n    let tokens = lex_all(\"0123 007\");\n    assert_eq!(tokens[0].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Integer(123)));\n    assert_eq!(tokens[1].kind, TokenKind::IntegerLiteral);\n    assert_eq!(tokens[1].literal, Some(LiteralValue::Integer(7)));\n    let tokens_float = lex_all(\"0.5\");\n    assert_eq!(tokens_float[0].kind, TokenKind::FloatLiteral);\n    assert_eq!(tokens_float[0].literal, Some(LiteralValue::Float(0.5)));\n}\n","traces":[{"line":4,"address":[],"length":0,"stats":{"Line":21}},{"line":5,"address":[],"length":0,"stats":{"Line":21}}],"covered":2,"coverable":2},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","tests","operators_punctuation.rs"],"content":"use ferra_lexer::*;\n\n// Helper function to lex the entire input string\nfn lex_all(input: \u0026str) -\u003e Vec\u003cToken\u003e {\n    Lexer::new(input).lex()\n}\n\n#[test]\nfn test_single_char_operators() {\n    let ops = vec![\n        (\"+\", TokenKind::Plus),\n        (\"-\", TokenKind::Minus),\n        (\"*\", TokenKind::Star),\n        (\"/\", TokenKind::Slash),\n        (\"=\", TokenKind::Equal),\n        (\";\", TokenKind::Semicolon),\n        (\"(\", TokenKind::LParen),\n        (\")\", TokenKind::RParen),\n        (\"{\", TokenKind::LBrace),\n        (\"}\", TokenKind::RBrace),\n        (\",\", TokenKind::Comma),\n        (\":\", TokenKind::Colon),\n        // Add other single char ops as needed from TokenKind\n        (\"\u003c\", TokenKind::Less),\n        (\"\u003e\", TokenKind::Greater),\n        (\"\u0026\", TokenKind::BitAnd),\n        (\"|\", TokenKind::BitOr),\n        (\"^\", TokenKind::Caret),\n        (\"!\", TokenKind::Bang),\n        (\"?\", TokenKind::Question),\n        (\".\", TokenKind::Dot),\n        (\"_\", TokenKind::Underscore),\n        (\"%\", TokenKind::Percent),\n    ];\n\n    for (op_str, kind) in ops {\n        let tokens = lex_all(op_str);\n        assert_eq!(tokens.len(), 2, \"Failed for op: {}\", op_str);\n        assert_eq!(tokens[0].kind, kind, \"Mismatch in kind for {}\", op_str);\n        assert_eq!(\n            tokens[0].lexeme, op_str,\n            \"Mismatch in lexeme for {}\",\n            op_str\n        );\n    }\n}\n\n#[test]\nfn test_multi_char_operators() {\n    let ops = vec![\n        (\"==\", TokenKind::EqualEqual),\n        (\"!=\", TokenKind::NotEqual),\n        (\"\u003c=\", TokenKind::LessEqual),\n        (\"\u003e=\", TokenKind::GreaterEqual),\n        (\"\u0026\u0026\", TokenKind::LogicalAnd),\n        (\"||\", TokenKind::LogicalOr),\n        (\"+=\", TokenKind::PlusEqual),\n        (\"-=\", TokenKind::MinusEqual),\n        (\"*=\", TokenKind::StarEqual),\n        (\"/=\", TokenKind::SlashEqual),\n        (\"%=\", TokenKind::PercentEqual),\n        (\"\u0026=\", TokenKind::BitAndEqual),\n        (\"|=\", TokenKind::BitOrEqual),\n        (\"^=\", TokenKind::CaretEqual),\n        (\"\u003c\u003c=\", TokenKind::ShiftLeftEqual),\n        (\"\u003c\u003c\", TokenKind::ShiftLeft),\n        (\"\u003e\u003e=\", TokenKind::ShiftRightEqual),\n        (\"\u003e\u003e\", TokenKind::ShiftRight),\n        (\"-\u003e\", TokenKind::Arrow),\n        (\"=\u003e\", TokenKind::FatArrow),\n        (\"..=\", TokenKind::DotDotEqual),\n        (\"..\", TokenKind::DotDot),\n        (\"::\", TokenKind::PathSep),\n        (\"??\", TokenKind::Coalesce),\n    ];\n\n    for (op_str, kind) in ops {\n        let tokens = lex_all(op_str);\n        assert_eq!(tokens.len(), 2, \"Failed for op: {}\", op_str);\n        assert_eq!(tokens[0].kind, kind, \"Mismatch in kind for {}\", op_str);\n        assert_eq!(\n            tokens[0].lexeme, op_str,\n            \"Mismatch in lexeme for {}\",\n            op_str\n        );\n    }\n    // Specific test for \u003e\u003e because \u003e is also a token\n    let tokens_shr = lex_all(\"\u003e\u003e\");\n    assert_eq!(tokens_shr.len(), 2);\n    assert_eq!(tokens_shr[0].kind, TokenKind::ShiftRight);\n    assert_eq!(tokens_shr[0].lexeme, \"\u003e\u003e\");\n}\n\n#[test]\nfn test_mixed_operators_and_others() {\n    let input = \"let x = a + b == c \u0026\u0026 d - 1.0;\";\n    let kinds: Vec\u003cTokenKind\u003e = lex_all(input).into_iter().map(|t| t.kind).collect();\n    assert_eq!(\n        kinds,\n        vec![\n            TokenKind::Let,\n            TokenKind::Identifier, // x\n            TokenKind::Equal,\n            TokenKind::Identifier, // a\n            TokenKind::Plus,\n            TokenKind::Identifier, // b\n            TokenKind::EqualEqual,\n            TokenKind::Identifier, // c\n            TokenKind::LogicalAnd,\n            TokenKind::Identifier, // d\n            TokenKind::Minus,\n            TokenKind::FloatLiteral, // 1.0\n            TokenKind::Semicolon,\n            TokenKind::Eof,\n        ]\n    );\n}\n","traces":[{"line":4,"address":[],"length":0,"stats":{"Line":48}},{"line":5,"address":[],"length":0,"stats":{"Line":48}}],"covered":2,"coverable":2},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","tests","ragel_migration.rs"],"content":"use ferra_lexer::{Lexer, TokenKind};\n\n/// Test suite to ensure compatibility when migrating to Ragel DFA lexer\n/// These tests verify that the current hand-written lexer produces the expected\n/// token sequences that a Ragel-generated lexer should also produce.\n\n#[test]\nfn test_ragel_compatibility_basic_tokens() {\n    // Test basic token recognition that Ragel should handle identically\n    let src = \"let x = 42 + 3.14;\";\n    let tokens = Lexer::new(src).lex();\n\n    let expected_kinds = [\n        TokenKind::Let,\n        TokenKind::Identifier,\n        TokenKind::Equal,\n        TokenKind::IntegerLiteral,\n        TokenKind::Plus,\n        TokenKind::FloatLiteral,\n        TokenKind::Semicolon,\n        TokenKind::Eof,\n    ];\n\n    let actual_kinds: Vec\u003c_\u003e = tokens.iter().map(|t| \u0026t.kind).collect();\n    assert_eq!(actual_kinds, expected_kinds.iter().collect::\u003cVec\u003c_\u003e\u003e());\n}\n\n#[test]\nfn test_ragel_compatibility_complex_operators() {\n    // Test multi-character operators that Ragel DFA should handle efficiently\n    let src = \"x += y \u003c\u003c z \u003e\u003e w \u0026\u0026 a || b ?? c\";\n    let tokens = Lexer::new(src).lex();\n\n    let expected_kinds = [\n        TokenKind::Identifier, // x\n        TokenKind::PlusEqual,  // +=\n        TokenKind::Identifier, // y\n        TokenKind::ShiftLeft,  // \u003c\u003c\n        TokenKind::Identifier, // z\n        TokenKind::ShiftRight, // \u003e\u003e\n        TokenKind::Identifier, // w\n        TokenKind::LogicalAnd, // \u0026\u0026\n        TokenKind::Identifier, // a\n        TokenKind::LogicalOr,  // ||\n        TokenKind::Identifier, // b\n        TokenKind::Coalesce,   // ??\n        TokenKind::Identifier, // c\n        TokenKind::Eof,\n    ];\n\n    let actual_kinds: Vec\u003c_\u003e = tokens.iter().map(|t| \u0026t.kind).collect();\n    assert_eq!(actual_kinds, expected_kinds.iter().collect::\u003cVec\u003c_\u003e\u003e());\n}\n\n#[test]\nfn test_ragel_compatibility_unicode_identifiers() {\n    // Test Unicode identifier handling for Ragel compatibility\n    let src = \"let αβγ = δεζ + ηθι;\";\n    let tokens = Lexer::new(src).lex();\n\n    assert_eq!(tokens[0].kind, TokenKind::Let);\n    assert_eq!(tokens[1].kind, TokenKind::Identifier);\n    assert_eq!(tokens[1].lexeme, \"αβγ\");\n    assert_eq!(tokens[2].kind, TokenKind::Equal);\n    assert_eq!(tokens[3].kind, TokenKind::Identifier);\n    assert_eq!(tokens[3].lexeme, \"δεζ\");\n    assert_eq!(tokens[4].kind, TokenKind::Plus);\n    assert_eq!(tokens[5].kind, TokenKind::Identifier);\n    assert_eq!(tokens[5].lexeme, \"ηθι\");\n    assert_eq!(tokens[6].kind, TokenKind::Semicolon);\n}\n\n#[test]\nfn test_ragel_compatibility_indentation_handling() {\n    // Test indentation token generation for Ragel compatibility\n    let src = \"a\\n    b\\n        c\\n    d\\ne\";\n    let tokens = Lexer::new(src).lex();\n\n    let expected_kinds = [\n        TokenKind::Identifier, // a\n        TokenKind::Newline,\n        TokenKind::Indent,     // for b\n        TokenKind::Identifier, // b\n        TokenKind::Newline,\n        TokenKind::Indent,     // for c\n        TokenKind::Identifier, // c\n        TokenKind::Newline,\n        TokenKind::Dedent,     // back to d level\n        TokenKind::Identifier, // d\n        TokenKind::Newline,\n        TokenKind::Dedent,     // back to base level\n        TokenKind::Identifier, // e\n        TokenKind::Eof,\n    ];\n\n    let actual_kinds: Vec\u003c_\u003e = tokens.iter().map(|t| \u0026t.kind).collect();\n    assert_eq!(actual_kinds, expected_kinds.iter().collect::\u003cVec\u003c_\u003e\u003e());\n}\n\n#[test]\nfn test_ragel_compatibility_string_literals() {\n    // Test string literal parsing for Ragel compatibility\n    let src = r#\"\"hello\\nworld\" r\"raw\\string\" 'c'\"#;\n    let tokens = Lexer::new(src).lex();\n\n    assert_eq!(tokens[0].kind, TokenKind::StringLiteral);\n    assert_eq!(tokens[0].lexeme, r#\"\"hello\\nworld\"\"#);\n\n    assert_eq!(tokens[1].kind, TokenKind::RawStringLiteral);\n    assert_eq!(tokens[1].lexeme, r#\"r\"raw\\string\"\"#);\n\n    assert_eq!(tokens[2].kind, TokenKind::CharacterLiteral);\n    assert_eq!(tokens[2].lexeme, \"'c'\");\n}\n\n#[test]\nfn test_ragel_compatibility_numeric_literals() {\n    // Test numeric literal parsing for Ragel compatibility\n    let src = \"42 0x1A 0o77 0b1010 3.14 1e10 1_000_000\";\n    let tokens = Lexer::new(src).lex();\n\n    let expected_kinds = [\n        TokenKind::IntegerLiteral, // 42\n        TokenKind::IntegerLiteral, // 0x1A\n        TokenKind::IntegerLiteral, // 0o77\n        TokenKind::IntegerLiteral, // 0b1010\n        TokenKind::FloatLiteral,   // 3.14\n        TokenKind::FloatLiteral,   // 1e10\n        TokenKind::IntegerLiteral, // 1_000_000\n        TokenKind::Eof,\n    ];\n\n    let actual_kinds: Vec\u003c_\u003e = tokens.iter().map(|t| \u0026t.kind).collect();\n    assert_eq!(actual_kinds, expected_kinds.iter().collect::\u003cVec\u003c_\u003e\u003e());\n}\n\n#[test]\nfn test_ragel_compatibility_comments() {\n    // Test comment handling for Ragel compatibility\n    let src = \"let x = 5; // line comment\\nlet y = /* block */ 10;\";\n    let tokens = Lexer::new(src).lex();\n\n    // Comments should be consumed, not emitted as tokens\n    let expected_kinds = [\n        TokenKind::Let,\n        TokenKind::Identifier, // x\n        TokenKind::Equal,\n        TokenKind::IntegerLiteral, // 5\n        TokenKind::Semicolon,\n        TokenKind::Newline,\n        TokenKind::Let,\n        TokenKind::Identifier, // y\n        TokenKind::Equal,\n        TokenKind::IntegerLiteral, // 10\n        TokenKind::Semicolon,\n        TokenKind::Eof,\n    ];\n\n    let actual_kinds: Vec\u003c_\u003e = tokens.iter().map(|t| \u0026t.kind).collect();\n    assert_eq!(actual_kinds, expected_kinds.iter().collect::\u003cVec\u003c_\u003e\u003e());\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","tests","string_literals.rs"],"content":"use ferra_lexer::*;\n\n// Helper function to lex the entire input string\nfn lex_all(input: \u0026str) -\u003e Vec\u003cToken\u003e {\n    Lexer::new(input).lex()\n}\n\n#[test]\nfn test_string_literal_simple() {\n    let tokens = lex_all(\"\\\"hello\\\"\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::StringLiteral);\n    assert_eq!(tokens[0].lexeme, \"\\\"hello\\\"\");\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"hello\".to_string()))\n    );\n    assert_eq!(tokens[0].span.start.offset, 0);\n    assert_eq!(tokens[0].span.end.offset, 7);\n}\n\n#[test]\nfn test_string_literal_empty() {\n    let tokens = lex_all(\"\\\"\\\"\");\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::StringLiteral);\n    assert_eq!(tokens[0].lexeme, \"\\\"\\\"\");\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"\".to_string()))\n    );\n    assert_eq!(tokens[0].span.start.offset, 0);\n    assert_eq!(tokens[0].span.end.offset, 2);\n}\n\n#[test]\nfn test_string_literal_with_escapes() {\n    let input = \"\\\"a\\\\nb\\\\tc\\\\\\\"d\\\\\\\\e\\\"\"; // raw string: \"a\\nb\\tc\\\"d\\\\e\"\n    let tokens = lex_all(input);\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::StringLiteral);\n    assert_eq!(tokens[0].lexeme, input);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"a\\nb\\tc\\\"d\\\\e\".to_string()))\n    );\n    assert_eq!(tokens[0].span.start.offset, 0);\n    assert_eq!(tokens[0].span.end.offset, input.len());\n}\n\n#[test]\nfn test_string_literal_unterminated_eof() {\n    let input = \"\\\"hello\";\n    let tokens = lex_all(input);\n    assert_eq!(tokens.len(), 2); // Error token + EOF\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert_eq!(tokens[0].lexeme, input);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\n            \"Unterminated string literal: expected closing quote \\\" before end of line or file.\"\n                .to_string()\n        ))\n    );\n    assert_eq!(tokens[0].span.start.offset, 0);\n    assert_eq!(tokens[0].span.end.offset, input.len());\n}\n\n#[test]\nfn test_string_literal_unterminated_with_backslash_at_eof() {\n    let input = \"\\\"hello\\\\\";\n    let tokens = lex_all(input);\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert_eq!(tokens[0].lexeme, input);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\n            \"Unterminated escape sequence at end of string literal: expected character after \\\\\"\n                .to_string()\n        ))\n    );\n    assert_eq!(tokens[0].span.start.offset, 0);\n    assert_eq!(tokens[0].span.end.offset, input.len());\n}\n\n#[test]\nfn test_string_literal_unterminated_by_newline() {\n    let input = \"\\\"abc\\ndef\"; // Raw string: \"abc then newline then def\n    let tokens = lex_all(input);\n    // Expected: Error(\"abc\") then potentially Newline, then Identifier(def), then Eof.\n    // The exact number of tokens depends on whether Newline tokens are explicitly generated\n    // or if whitespace (including internal newlines) is just skipped by the main loop after an error.\n    // For now, checking the first error token is key.\n    assert!(\n        tokens.len() \u003e= 2,\n        \"Expected at least an error token and EOF\"\n    );\n\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert_eq!(tokens[0].lexeme, \"\\\"abc\");\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\n            \"Unterminated string literal: expected closing quote \\\" before end of line or file.\"\n                .to_string()\n        ))\n    );\n    assert_eq!(tokens[0].span.start.offset, 0);\n    assert_eq!(tokens[0].span.end.offset, \"\\\"abc\".len());\n}\n\n#[test]\nfn test_string_literal_invalid_escape_sequence() {\n    let input = \"\\\"invalid\\\\qescape\\\"\";\n    let tokens = lex_all(input);\n    assert_eq!(tokens.len(), 4);\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert_eq!(tokens[0].lexeme, input[..10].to_string()); // \"invalid\\q\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"Invalid escape sequence in string literal: \\\\q. Only valid escapes are \\\\n, \\\\t, \\\\\\\\, \\\\\\\" and \\\\u{...}.\".to_string()))\n    );\n    assert_eq!(tokens[1].kind, TokenKind::Identifier);\n    assert_eq!(tokens[1].lexeme, \"escape\");\n    assert_eq!(tokens[2].kind, TokenKind::Error); // stray quote\n    assert_eq!(tokens[2].lexeme, \"\\\"\");\n    assert_eq!(tokens[3].kind, TokenKind::Eof);\n}\n\n#[test]\nfn test_string_just_escaped_quote() {\n    let input = \"\\\"\\\\\\\"\\\"\"; // raw: \"\\\"\"\n    let tokens = lex_all(input);\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::StringLiteral);\n    assert_eq!(tokens[0].lexeme, input);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"\\\"\".to_string()))\n    );\n    assert_eq!(tokens[0].span.end.offset, input.len());\n}\n\n#[test]\nfn test_string_multiple_escapes_and_chars() {\n    let input = \"\\\"ab\\\\ncd\\\\t ef\\\\\\\\gh\\\\\\\"ij\\\"\"; // raw: \"ab\\ncd\\t ef\\\\gh\\\"ij\"\n    let tokens = lex_all(input);\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::StringLiteral);\n    assert_eq!(tokens[0].lexeme, input);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"ab\\ncd\\t ef\\\\gh\\\"ij\".to_string()))\n    );\n    assert_eq!(tokens[0].span.end.offset, input.len());\n}\n\n#[test]\nfn test_string_unicode_escapes() {\n    let src = \"\\\"\\\\u{41}\\\\u{DF}\\\\u{1F600}\\\"\"; // A, ß, 😀\n    let tokens = lex_all(src);\n    assert_eq!(tokens[0].kind, TokenKind::StringLiteral);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"Aß😀\".to_string()))\n    );\n\n    let src_empty_braces = \"\\\"\\\\u{}\\\"\";\n    let tokens_empty = lex_all(src_empty_braces);\n    assert_eq!(tokens_empty[0].kind, TokenKind::Error);\n    assert!(\n        matches!(tokens_empty[0].literal.as_ref().unwrap(), LiteralValue::String(msg) if msg.contains(\"empty hex code \\\\u{}\"))\n    );\n\n    let src_no_closing_brace = \"\\\"\\\\u{41\\\"\";\n    let tokens_no_close = lex_all(src_no_closing_brace);\n    assert_eq!(tokens_no_close[0].kind, TokenKind::Error);\n    assert!(\n        matches!(tokens_no_close[0].literal.as_ref().unwrap(), LiteralValue::String(msg) if msg.contains(\"unexpected character '\\\"' in \\\\u{41} sequence\"))\n    );\n\n    let src_too_many_digits = \"\\\"\\\\u{110000}\\\"\"; // Max is 10FFFF\n    let tokens_too_many = lex_all(src_too_many_digits);\n    assert_eq!(tokens_too_many[0].kind, TokenKind::Error);\n    // This might be caught as invalid codepoint rather than too many digits if 110000 is parsed first\n    assert!(\n        matches!(tokens_too_many[0].literal.as_ref().unwrap(), LiteralValue::String(msg) if msg.contains(\"not a valid Unicode codepoint\"))\n    );\n\n    let src_invalid_char_in_hex = \"\\\"\\\\u{4G}\\\"\";\n    let tokens_invalid_hex = lex_all(src_invalid_char_in_hex);\n    assert_eq!(tokens_invalid_hex[0].kind, TokenKind::Error);\n    assert!(\n        matches!(tokens_invalid_hex[0].literal.as_ref().unwrap(), LiteralValue::String(msg) if msg.contains(\"Invalid Unicode escape\"))\n    );\n\n    let src_surrogate = \"\\\"\\\\u{D800}\\\"\"; // Surrogate, invalid\n    let tokens_surrogate = lex_all(src_surrogate);\n    assert_eq!(tokens_surrogate[0].kind, TokenKind::Error);\n    assert!(\n        matches!(tokens_surrogate[0].literal.as_ref().unwrap(), LiteralValue::String(msg) if msg.contains(\"not a valid Unicode codepoint\"))\n    );\n}\n\n#[test]\nfn test_raw_string_literal_simple() {\n    let input = r#\"r\"hello\"\"#;\n    let tokens = lex_all(input);\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::RawStringLiteral);\n    assert_eq!(tokens[0].lexeme, input);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"hello\".to_string()))\n    );\n}\n\n#[test]\nfn test_raw_string_literal_with_escapes_and_quotes() {\n    let input = \"r\\\"a\\\\n\\\\tb\\\\\\\\c\\\"\"; // raw string: r\"a\\n\\tb\\\\c\"\n    let tokens = lex_all(input);\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::RawStringLiteral);\n    assert_eq!(tokens[0].lexeme, input);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"a\\\\n\\\\tb\\\\\\\\c\".to_string()))\n    );\n}\n\n#[test]\nfn test_raw_string_literal_empty() {\n    let input = r#\"r\"\"\"#;\n    let tokens = lex_all(input);\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::RawStringLiteral);\n    assert_eq!(tokens[0].lexeme, input);\n    assert_eq!(\n        tokens[0].literal,\n        Some(LiteralValue::String(\"\".to_string()))\n    );\n}\n\n#[test]\nfn test_raw_string_literal_unterminated() {\n    let input = r#\"r\"hello\"#; // Missing closing \"\n    let tokens = lex_all(input);\n    assert_eq!(tokens.len(), 2);\n    assert_eq!(tokens[0].kind, TokenKind::Error);\n    assert_eq!(tokens[0].lexeme, input);\n    assert!(\n        matches!(tokens[0].literal.as_ref().unwrap(), LiteralValue::String(msg) if msg.contains(\"Unterminated raw string literal\"))\n    );\n}\n","traces":[{"line":4,"address":[],"length":0,"stats":{"Line":19}},{"line":5,"address":[],"length":0,"stats":{"Line":19}}],"covered":2,"coverable":2},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_lexer","tests","unit_basic.rs"],"content":"use ferra_lexer::{Lexer, LiteralValue, Token, TokenKind};\n\n#[test]\nfn empty_source_emits_eof() {\n    let tokens = Lexer::new(\"\").lex();\n    assert_eq!(tokens, vec![Token::eof_dummy()]);\n}\n\n#[test]\nfn simple_let_statement() {\n    let tokens = Lexer::new(\"let x = 42;\").lex();\n    let kinds: Vec\u003c_\u003e = tokens.iter().map(|t| \u0026t.kind).collect();\n    assert_eq!(\n        kinds,\n        vec![\n            \u0026TokenKind::Let,\n            \u0026TokenKind::Identifier,\n            \u0026TokenKind::Equal,\n            \u0026TokenKind::IntegerLiteral,\n            \u0026TokenKind::Semicolon,\n            \u0026TokenKind::Eof,\n        ]\n    );\n}\n\n#[test]\nfn byte_literals() {\n    let tokens = Lexer::new(\"b'a' b\\\"foo\\\" b'' b'xy' b'\\\\q' b'a\").lex();\n    println!(\"TOKENS: {:?}\", tokens);\n    assert_eq!(tokens[0].kind, TokenKind::ByteLiteral);\n    assert_eq!(tokens[0].lexeme, \"b'a'\");\n    assert_eq!(tokens[0].literal, Some(LiteralValue::Byte(b'a')));\n    assert_eq!(tokens[1].kind, TokenKind::ByteLiteral);\n    assert_eq!(tokens[1].lexeme, \"b\\\"foo\\\"\");\n    assert_eq!(\n        tokens[1].literal,\n        Some(LiteralValue::String(\"foo\".to_string()))\n    );\n    assert_eq!(tokens[2].kind, TokenKind::Error); // empty\n    assert_eq!(tokens[3].kind, TokenKind::Error); // multi-char\n    assert_eq!(tokens[4].kind, TokenKind::Error); // invalid escape\n    assert_eq!(tokens[5].kind, TokenKind::Error); // unterminated\n}\n\n#[test]\nfn block_comment() {\n    let tokens = Lexer::new(\"let /* comment */ x\").lex();\n    assert_eq!(tokens[0].kind, TokenKind::Let);\n    assert_eq!(tokens[1].kind, TokenKind::Identifier);\n    assert_eq!(tokens[2].kind, TokenKind::Eof);\n    let tokens_unterminated = Lexer::new(\"let /* unterminated\").lex();\n    assert_eq!(tokens_unterminated[0].kind, TokenKind::Let);\n    assert_eq!(tokens_unterminated[1].kind, TokenKind::Error);\n}\n\n#[test]\nfn indentation_tokens() {\n    let src = \"a\\n    b\\n        c\\n    d\\ne\";\n    let tokens = Lexer::new(src).lex();\n    for t in \u0026tokens {\n        println!(\"{:?} '{}'\", t.kind, t.lexeme);\n    }\n    let kinds: Vec\u003c_\u003e = tokens.iter().map(|t| \u0026t.kind).collect();\n    // Updated to match the new correct behavior where all identifiers are preserved\n    assert_eq!(\n        kinds,\n        vec![\n            \u0026TokenKind::Identifier, // a\n            \u0026TokenKind::Newline,\n            \u0026TokenKind::Indent,     // for \"    b\"\n            \u0026TokenKind::Identifier, // b (now correctly preserved!)\n            \u0026TokenKind::Newline,    // after b\n            \u0026TokenKind::Indent,     // for \"        c\"\n            \u0026TokenKind::Identifier, // c (now correctly preserved!)\n            \u0026TokenKind::Newline,    // after c\n            \u0026TokenKind::Dedent,     // dedent for d\n            \u0026TokenKind::Identifier, // d (now correctly preserved!)\n            \u0026TokenKind::Newline,    // after d\n            \u0026TokenKind::Dedent,     // dedent to base level\n            \u0026TokenKind::Identifier, // e\n            \u0026TokenKind::Eof,\n        ]\n    );\n}\n\n#[test]\nfn error_token_for_unrecognized_input() {\n    let src = \"let x = \\u{1F600};\"; // \\u{1F600} is not valid in this lexer\n    let tokens = Lexer::new(src).lex();\n    assert!(tokens.iter().any(|t| t.kind == TokenKind::Error));\n}\n\n#[test]\nfn blank_and_comment_only_lines_indentation() {\n    let src = \"a\\n    \\n    // comment\\n    b\\nc\";\n    let tokens = Lexer::new(src).lex();\n    println!(\n        \"TOKENS: {:?}\",\n        tokens\n            .iter()\n            .map(|t| (t.kind.clone(), t.lexeme.clone()))\n            .collect::\u003cVec\u003c_\u003e\u003e()\n    );\n    let kinds: Vec\u003c_\u003e = tokens.iter().map(|t| t.kind.clone()).collect();\n    // Updated to match the new correct behavior where 'b' is properly preserved\n    assert_eq!(\n        kinds,\n        vec![\n            TokenKind::Identifier, // a\n            TokenKind::Newline,\n            TokenKind::Indent,\n            TokenKind::Newline,    // from blank line\n            TokenKind::Newline,    // from comment line\n            TokenKind::Identifier, // b (now correctly preserved!)\n            TokenKind::Newline,    // after b\n            TokenKind::Dedent,\n            TokenKind::Identifier, // c\n            TokenKind::Eof,\n        ]\n    );\n}\n\n#[test]\nfn test_mixed_indentation_error() {\n    // The lexer only processes indentation after newlines, not at file start\n    // So we need content before the newline for indentation to be processed\n\n    // Valid: only spaces after newline\n    let tokens_spaces = Lexer::new(\"x\\n  a\").lex();\n    assert_eq!(tokens_spaces.len(), 6); // x, newline, indent, a, dedent, eof\n    assert!(!tokens_spaces.iter().any(|t| t.kind == TokenKind::Error));\n    assert_eq!(tokens_spaces[2].kind, TokenKind::Indent);\n\n    // Valid: only tabs after newline (1 tab = 4 spaces)\n    let tokens_tabs = Lexer::new(\"x\\n\\ta\").lex();\n    assert_eq!(tokens_tabs.len(), 6); // x, newline, indent, a, dedent, eof\n    assert!(!tokens_tabs.iter().any(|t| t.kind == TokenKind::Error));\n    assert_eq!(tokens_tabs[2].kind, TokenKind::Indent);\n\n    // Invalid: space then tab after newline\n    let tokens_space_tab = Lexer::new(\"x\\n \\ta\").lex();\n    assert!(tokens_space_tab.iter().any(|t| t.kind == TokenKind::Error));\n    let error_token = tokens_space_tab\n        .iter()\n        .find(|t| t.kind == TokenKind::Error)\n        .unwrap();\n    assert_eq!(error_token.lexeme, \" \\t\");\n    if let Some(LiteralValue::String(msg)) = \u0026error_token.literal {\n        assert!(msg.contains(\"Mixed tabs and spaces\"));\n    }\n\n    // Invalid: tab then space after newline\n    let tokens_tab_space = Lexer::new(\"x\\n\\t a\").lex();\n    assert!(tokens_tab_space.iter().any(|t| t.kind == TokenKind::Error));\n    let error_token = tokens_tab_space\n        .iter()\n        .find(|t| t.kind == TokenKind::Error)\n        .unwrap();\n    assert_eq!(error_token.lexeme, \"\\t \");\n    if let Some(LiteralValue::String(msg)) = \u0026error_token.literal {\n        assert!(msg.contains(\"Mixed tabs and spaces\"));\n    }\n}\n\n#[test]\nfn test_mixed_tabs_spaces_in_indent() {\n    let input = \"x\\n\\t a\"; // Content, newline, then tab+space+content\n    let lexer = Lexer::new(input);\n    let tokens = lexer.lex();\n\n    // Should produce Identifier + Newline + Error + ... + EOF\n    // The exact count may vary but we should have an error\n    assert!(tokens.iter().any(|t| t.kind == TokenKind::Error));\n    let error_token = tokens.iter().find(|t| t.kind == TokenKind::Error).unwrap();\n    if let Some(LiteralValue::String(msg)) = \u0026error_token.literal {\n        assert!(msg.contains(\"Mixed tabs and spaces\"));\n    } else {\n        panic!(\"Expected error message\");\n    }\n}\n\n#[test]\nfn test_expansion_tabs_to_spaces() {\n    let input_tab_space = \"x\\n\\t\\ta\"; // Content, newline, then two tabs then 'a'\n    let lexer_ts = Lexer::new(input_tab_space);\n    let tokens_ts = lexer_ts.lex();\n\n    // Should produce some tokens including x and indent\n    // The exact sequence may vary due to the identifier consumption issue\n    assert!(tokens_ts.len() \u003e= 3);\n    assert_eq!(tokens_ts[0].kind, TokenKind::Identifier); // x\n    assert_eq!(tokens_ts[1].kind, TokenKind::Newline);\n    // Should have an indent token somewhere\n    assert!(tokens_ts.iter().any(|t| t.kind == TokenKind::Indent));\n}\n\n#[test]\nfn test_blank_comment_lines_preserve_identifiers() {\n    // This test explicitly checks for the bug where identifiers after blank/comment lines are dropped\n    let src = \"a\\n    \\n    // comment\\n    b\\nc\";\n    let tokens = Lexer::new(src).lex();\n\n    // Extract all identifiers to verify they're all present\n    let idents: Vec\u003c\u0026str\u003e = tokens\n        .iter()\n        .filter(|t| t.kind == TokenKind::Identifier)\n        .map(|t| t.lexeme.as_str())\n        .collect();\n\n    // CRITICAL: Should find all three identifiers: a, b, c\n    // Currently fails because 'b' is missing - this is the bug to fix\n    assert_eq!(\n        idents,\n        vec![\"a\", \"b\", \"c\"],\n        \"Expected all identifiers a, b, c but got: {:?}\",\n        idents\n    );\n}\n\n#[test]\nfn test_simple_dedent_case() {\n    // Simplified test: just a simple dedent case\n    let src = \"a\\n    b\\nc\";\n    let tokens = Lexer::new(src).lex();\n\n    println!(\n        \"All tokens: {:?}\",\n        tokens\n            .iter()\n            .map(|t| (t.kind.clone(), t.lexeme.clone()))\n            .collect::\u003cVec\u003c_\u003e\u003e()\n    );\n\n    // Extract all identifiers to verify they're all present\n    let idents: Vec\u003c\u0026str\u003e = tokens\n        .iter()\n        .filter(|t| t.kind == TokenKind::Identifier)\n        .map(|t| t.lexeme.as_str())\n        .collect();\n\n    assert_eq!(\n        idents,\n        vec![\"a\", \"b\", \"c\"],\n        \"Expected all identifiers a, b, c but got: {:?}\",\n        idents\n    );\n}\n\n#[test]\nfn test_minimal_indent_case() {\n    // Even simpler: just one space and one character\n    let src = \"a\\n b\";\n    let tokens = Lexer::new(src).lex();\n\n    println!(\n        \"Minimal tokens: {:?}\",\n        tokens\n            .iter()\n            .map(|t| (t.kind.clone(), t.lexeme.clone()))\n            .collect::\u003cVec\u003c_\u003e\u003e()\n    );\n\n    let idents: Vec\u003c\u0026str\u003e = tokens\n        .iter()\n        .filter(|t| t.kind == TokenKind::Identifier)\n        .map(|t| t.lexeme.as_str())\n        .collect();\n\n    assert_eq!(\n        idents,\n        vec![\"a\", \"b\"],\n        \"Expected identifiers a, b but got: {:?}\",\n        idents\n    );\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","benches","parser_bench.rs"],"content":"use criterion::{black_box, criterion_group, criterion_main, Criterion};\nuse ferra_parser::{\n    ast::Arena,\n    token::{TokenType, VecTokenStream},\n    Parser,\n};\n\nfn benchmark_token_stream_creation(c: \u0026mut Criterion) {\n    c.bench_function(\"token_stream_creation\", |b| {\n        b.iter(|| {\n            let tokens = vec![\n                TokenType::Let,\n                TokenType::Identifier(\"x\".to_string()),\n                TokenType::Equal,\n                TokenType::IntegerLiteral(42),\n                TokenType::Semicolon,\n                TokenType::Eof,\n            ];\n            black_box(VecTokenStream::from_token_types(tokens))\n        })\n    });\n}\n\nfn benchmark_parser_creation(c: \u0026mut Criterion) {\n    c.bench_function(\"parser_creation\", |b| {\n        let arena = Arena::new();\n        b.iter(|| {\n            let tokens = vec![\n                TokenType::Let,\n                TokenType::Identifier(\"x\".to_string()),\n                TokenType::Equal,\n                TokenType::IntegerLiteral(42),\n                TokenType::Eof,\n            ];\n            let stream = VecTokenStream::from_token_types(tokens);\n            black_box(Parser::new(\u0026arena, stream))\n        })\n    });\n}\n\n// TODO: Add more benchmarks as parsing functionality is implemented\n// fn benchmark_expression_parsing(c: \u0026mut Criterion) { ... }\n// fn benchmark_statement_parsing(c: \u0026mut Criterion) { ... }\n// fn benchmark_large_file_parsing(c: \u0026mut Criterion) { ... }\n\ncriterion_group!(\n    benches,\n    benchmark_token_stream_creation,\n    benchmark_parser_creation\n);\ncriterion_main!(benches);\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","ast","arena.rs"],"content":"//! Arena allocator for AST nodes\n//!\n//! Uses bumpalo for efficient allocation of AST nodes without individual deallocations\n\nuse bumpalo::Bump;\n\n/// Arena for allocating AST nodes efficiently\npub struct Arena {\n    bump: Bump,\n}\n\nimpl Arena {\n    /// Create a new arena\n    pub fn new() -\u003e Self {\n        Self { bump: Bump::new() }\n    }\n\n    /// Allocate a value in the arena and return a reference\n    pub fn alloc\u003cT\u003e(\u0026self, value: T) -\u003e \u0026T {\n        self.bump.alloc(value)\n    }\n\n    /// Allocate a slice in the arena\n    pub fn alloc_slice\u003cT\u003e(\u0026self, slice: \u0026[T]) -\u003e \u0026[T]\n    where\n        T: Clone,\n    {\n        self.bump.alloc_slice_clone(slice)\n    }\n\n    /// Allocate a vector in the arena\n    pub fn alloc_vec\u003cT\u003e(\u0026self, vec: Vec\u003cT\u003e) -\u003e \u0026[T]\n    where\n        T: Clone,\n    {\n        self.bump.alloc_slice_clone(\u0026vec)\n    }\n\n    /// Get the number of bytes allocated in this arena\n    pub fn allocated_bytes(\u0026self) -\u003e usize {\n        self.bump.allocated_bytes()\n    }\n\n    /// Reset the arena, deallocating all stored values\n    pub fn reset(\u0026mut self) {\n        self.bump.reset();\n    }\n}\n\nimpl Default for Arena {\n    fn default() -\u003e Self {\n        Self::new()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_arena_allocation() {\n        let arena = Arena::new();\n\n        let value = arena.alloc(42i32);\n        assert_eq!(*value, 42);\n\n        let string = arena.alloc(\"hello\".to_string());\n        assert_eq!(string, \"hello\");\n    }\n\n    #[test]\n    fn test_arena_slice_allocation() {\n        let arena = Arena::new();\n\n        let slice = arena.alloc_slice(\u0026[1, 2, 3, 4]);\n        assert_eq!(slice, \u0026[1, 2, 3, 4]);\n    }\n\n    #[test]\n    fn test_arena_reset() {\n        let mut arena = Arena::new();\n\n        // Allocate something\n        let _value = arena.alloc(100);\n        let _bytes_before = arena.allocated_bytes();\n\n        // Reset should clear allocations\n        arena.reset();\n        let _bytes_after = arena.allocated_bytes();\n\n        // After reset, we should be able to allocate again\n        // (bumpalo might keep capacity, so we just test functionality)\n        let value2 = arena.alloc(200);\n        assert_eq!(*value2, 200);\n    }\n}\n","traces":[{"line":14,"address":[],"length":0,"stats":{"Line":144}},{"line":15,"address":[],"length":0,"stats":{"Line":144}},{"line":19,"address":[],"length":0,"stats":{"Line":379}},{"line":20,"address":[],"length":0,"stats":{"Line":379}},{"line":24,"address":[],"length":0,"stats":{"Line":1}},{"line":28,"address":[],"length":0,"stats":{"Line":1}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":2}},{"line":41,"address":[],"length":0,"stats":{"Line":2}},{"line":45,"address":[],"length":0,"stats":{"Line":1}},{"line":46,"address":[],"length":0,"stats":{"Line":1}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}}],"covered":10,"coverable":14},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","ast","mod.rs"],"content":"//! Abstract Syntax Tree (AST) definitions and utilities\n//!\n//! This module defines the AST node types that represent the parsed structure\n//! of Ferra source code. Nodes are allocated in an arena for performance.\n\npub mod arena;\npub mod nodes;\npub mod visitor;\n\npub use arena::*;\npub use nodes::*;\npub use visitor::*;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","ast","nodes.rs"],"content":"//! AST node type definitions\n//!\n//! Defines the structure of AST nodes representing parsed Ferra code.\n//! Detailed implementation will be done during development phase.\n\nuse crate::token::{Span, Token};\n\n/// Top-level compilation unit (represents a complete source file)\n#[derive(Debug, Clone)]\npub struct CompilationUnit {\n    pub items: Vec\u003cItem\u003e,\n    pub span: Span,\n}\n\n/// Top-level items (declarations)\n#[derive(Debug, Clone)]\npub enum Item {\n    FunctionDecl(FunctionDecl),\n    VariableDecl(VariableDecl),\n    DataClassDecl(DataClassDecl),\n    ExternBlock(ExternBlock),\n}\n\n/// Function declaration\n#[derive(Debug, Clone)]\npub struct FunctionDecl {\n    pub name: String,\n    pub generics: Option\u003cGenericParams\u003e,\n    pub parameters: Vec\u003cParameter\u003e,\n    pub return_type: Option\u003cType\u003e,\n    pub body: Option\u003cBlock\u003e,\n    pub is_async: bool,\n    pub is_extern: bool,\n    pub abi: Option\u003cString\u003e,\n    pub modifiers: Modifiers,\n    pub attributes: Vec\u003cAttribute\u003e,\n    pub span: Span,\n}\n\n/// Function parameter\n#[derive(Debug, Clone)]\npub struct Parameter {\n    pub name: String,\n    pub param_type: Type,\n    pub attributes: Vec\u003cAttribute\u003e,\n    pub span: Span,\n}\n\n/// Variable declaration\n#[derive(Debug, Clone)]\npub struct VariableDecl {\n    pub name: String,\n    pub var_type: Option\u003cType\u003e,\n    pub initializer: Option\u003cExpression\u003e,\n    pub is_mutable: bool,\n    pub modifiers: Modifiers,\n    pub attributes: Vec\u003cAttribute\u003e,\n    pub span: Span,\n}\n\n/// Data class declaration\n#[derive(Debug, Clone)]\npub struct DataClassDecl {\n    pub name: String,\n    pub generics: Option\u003cGenericParams\u003e,\n    pub fields: Vec\u003cField\u003e,\n    pub attributes: Vec\u003cAttribute\u003e,\n    pub span: Span,\n}\n\n/// Data class field\n#[derive(Debug, Clone)]\npub struct Field {\n    pub name: String,\n    pub field_type: Type,\n    pub attributes: Vec\u003cAttribute\u003e,\n    pub span: Span,\n}\n\n/// External block for FFI\n#[derive(Debug, Clone)]\npub struct ExternBlock {\n    pub abi: String,\n    pub items: Vec\u003cExternItem\u003e,\n    pub span: Span,\n}\n\n/// External item (function or variable)\n#[derive(Debug, Clone)]\npub enum ExternItem {\n    Function(ExternFunction),\n    Variable(ExternVariable),\n}\n\n/// External function declaration\n#[derive(Debug, Clone)]\npub struct ExternFunction {\n    pub name: String,\n    pub parameters: Vec\u003cParameter\u003e,\n    pub return_type: Option\u003cType\u003e,\n    pub span: Span,\n}\n\n/// External variable declaration\n#[derive(Debug, Clone)]\npub struct ExternVariable {\n    pub name: String,\n    pub var_type: Type,\n    pub span: Span,\n}\n\n/// Statement types\n#[derive(Debug, Clone)]\npub enum Statement {\n    Expression(Expression),\n    VariableDecl(VariableDecl),\n    If(IfStatement),\n    While(WhileStatement),\n    For(ForStatement),\n    Return(ReturnStatement),\n    Break(BreakStatement),\n    Continue(ContinueStatement),\n    Block(Block),\n}\n\n/// If statement\n#[derive(Debug, Clone)]\npub struct IfStatement {\n    pub condition: Expression,\n    pub then_block: Block,\n    pub else_block: Option\u003cBlock\u003e,\n    pub span: Span,\n}\n\n/// While loop\n#[derive(Debug, Clone)]\npub struct WhileStatement {\n    pub condition: Expression,\n    pub body: Block,\n    pub span: Span,\n}\n\n/// For loop\n#[derive(Debug, Clone)]\npub struct ForStatement {\n    pub variable: String,\n    pub iterable: Expression,\n    pub body: Block,\n    pub span: Span,\n}\n\n/// Return statement\n#[derive(Debug, Clone)]\npub struct ReturnStatement {\n    pub value: Option\u003cExpression\u003e,\n    pub span: Span,\n}\n\n/// Break statement\n#[derive(Debug, Clone)]\npub struct BreakStatement {\n    pub span: Span,\n}\n\n/// Continue statement\n#[derive(Debug, Clone)]\npub struct ContinueStatement {\n    pub span: Span,\n}\n\n/// Block of statements\n#[derive(Debug, Clone)]\npub struct Block {\n    pub statements: Vec\u003cStatement\u003e,\n    pub is_braced: bool, // true for {}, false for indented\n    pub span: Span,\n    // Phase 2.4 enhancements\n    pub scope_depth: usize,\n    pub is_unsafe: bool,\n    pub is_async: bool,\n    pub is_try: bool,\n    pub label: Option\u003cString\u003e,\n}\n\nimpl Default for Block {\n    fn default() -\u003e Self {\n        Self {\n            statements: Vec::new(),\n            is_braced: true,\n            span: Span::dummy(),\n            scope_depth: 0,\n            is_unsafe: false,\n            is_async: false,\n            is_try: false,\n            label: None,\n        }\n    }\n}\n\n/// Expression types\n#[derive(Debug, Clone)]\npub enum Expression {\n    Literal(Literal),\n    Identifier(String),\n    QualifiedIdentifier(QualifiedIdentifier),\n    Binary(BinaryExpression),\n    Unary(UnaryExpression),\n    Call(CallExpression),\n    MemberAccess(MemberAccessExpression),\n    Index(IndexExpression),\n    Await(AwaitExpression),\n    Array(ArrayLiteral),\n    Tuple(TupleLiteral),\n    If(IfExpression),\n    Match(MatchExpression),\n    Grouped(Box\u003cExpression\u003e),\n    Block(BlockExpression), // Phase 2.4 addition\n    Macro(MacroInvocation), // Phase 2.8.4: Macro invocations\n}\n\n/// Literal values\n#[derive(Debug, Clone)]\npub enum Literal {\n    String(String),\n    Integer(i64),\n    Float(f64),\n    Boolean(bool),\n}\n\n/// Qualified identifier (e.g., module.function)\n#[derive(Debug, Clone)]\npub struct QualifiedIdentifier {\n    pub parts: Vec\u003cString\u003e,\n    pub span: Span,\n}\n\n/// Binary expression\n#[derive(Debug, Clone)]\npub struct BinaryExpression {\n    pub left: Box\u003cExpression\u003e,\n    pub operator: BinaryOperator,\n    pub right: Box\u003cExpression\u003e,\n    pub span: Span,\n}\n\n/// Binary operators\n#[derive(Debug, Clone)]\npub enum BinaryOperator {\n    Add,\n    Sub,\n    Mul,\n    Div,\n    Mod,\n    Equal,\n    NotEqual,\n    Less,\n    LessEqual,\n    Greater,\n    GreaterEqual,\n    And,\n    Or,\n    NullCoalesce,\n    Assign,\n    AddAssign,\n    SubAssign,\n    MulAssign,\n    DivAssign,\n}\n\n/// Unary expression\n#[derive(Debug, Clone)]\npub struct UnaryExpression {\n    pub operator: UnaryOperator,\n    pub operand: Box\u003cExpression\u003e,\n    pub span: Span,\n}\n\n/// Unary operators\n#[derive(Debug, Clone)]\npub enum UnaryOperator {\n    Not,\n    Minus,\n    Plus,\n}\n\n/// Function call expression\n#[derive(Debug, Clone)]\npub struct CallExpression {\n    pub callee: Box\u003cExpression\u003e,\n    pub arguments: Vec\u003cExpression\u003e,\n    pub span: Span,\n}\n\n/// Member access expression\n#[derive(Debug, Clone)]\npub struct MemberAccessExpression {\n    pub object: Box\u003cExpression\u003e,\n    pub member: String,\n    pub span: Span,\n}\n\n/// If expression\n#[derive(Debug, Clone)]\npub struct IfExpression {\n    pub condition: Box\u003cExpression\u003e,\n    pub then_expr: Box\u003cExpression\u003e,\n    pub else_expr: Option\u003cBox\u003cExpression\u003e\u003e,\n    pub span: Span,\n}\n\n/// Match expression\n#[derive(Debug, Clone)]\npub struct MatchExpression {\n    pub scrutinee: Box\u003cExpression\u003e,\n    pub arms: Vec\u003cMatchArm\u003e,\n    pub span: Span,\n}\n\n/// Match arm\n#[derive(Debug, Clone)]\npub struct MatchArm {\n    pub pattern: Pattern,\n    pub expression: Expression,\n    pub span: Span,\n}\n\n/// Pattern types for match expressions\n#[derive(Debug, Clone)]\npub enum Pattern {\n    Literal(Literal),\n    Identifier(String),\n    Wildcard,\n    DataClass(DataClassPattern),\n    Range(RangePattern),     // Phase 2.8.3: Range patterns (1..=10)\n    Slice(SlicePattern),     // Phase 2.8.3: Slice patterns ([head, tail @ ..])\n    Or(OrPattern),           // Phase 2.8.3: Or patterns (Some(x) | None)\n    Guard(GuardPattern),     // Phase 2.8.3: Guard patterns (x if x \u003e 0)\n    Binding(BindingPattern), // Phase 2.8.3: Binding patterns (name @ pattern)\n}\n\n/// Data class pattern\n#[derive(Debug, Clone)]\npub struct DataClassPattern {\n    pub name: String,\n    pub fields: Vec\u003cFieldPattern\u003e,\n    pub has_rest: bool,\n    pub span: Span,\n}\n\n/// Field pattern in data class destructuring\n#[derive(Debug, Clone)]\npub struct FieldPattern {\n    pub name: String,\n    pub pattern: Option\u003cPattern\u003e,\n    pub span: Span,\n}\n\n/// Range pattern for numeric ranges\n#[derive(Debug, Clone)]\npub struct RangePattern {\n    pub start: Option\u003cBox\u003cPattern\u003e\u003e, // None for open ranges like ..=5\n    pub end: Option\u003cBox\u003cPattern\u003e\u003e,   // None for open ranges like 5..\n    pub inclusive: bool,             // true for ..=, false for ..\n    pub span: Span,\n}\n\n/// Slice pattern for array destructuring\n#[derive(Debug, Clone)]\npub struct SlicePattern {\n    pub prefix: Vec\u003cPattern\u003e, // Patterns before the rest element\n    pub rest: Option\u003cString\u003e, // Variable name for rest element (tail @ ..)\n    pub suffix: Vec\u003cPattern\u003e, // Patterns after the rest element\n    pub span: Span,\n}\n\n/// Or pattern for matching multiple patterns\n#[derive(Debug, Clone)]\npub struct OrPattern {\n    pub patterns: Vec\u003cPattern\u003e, // List of alternative patterns\n    pub span: Span,\n}\n\n/// Guard pattern with conditional expression\n#[derive(Debug, Clone)]\npub struct GuardPattern {\n    pub pattern: Box\u003cPattern\u003e, // Base pattern to match\n    pub guard: Expression,     // Guard condition\n    pub span: Span,\n}\n\n/// Binding pattern for named pattern matching\n#[derive(Debug, Clone)]\npub struct BindingPattern {\n    pub name: String,          // Variable name to bind to\n    pub pattern: Box\u003cPattern\u003e, // Pattern to match\n    pub span: Span,\n}\n\n/// Type expressions\n#[derive(Debug, Clone)]\npub enum Type {\n    Identifier(String),\n    Generic(GenericType),\n    Tuple(Vec\u003cType\u003e),\n    Array(Box\u003cType\u003e),\n    Function(FunctionType),\n    Pointer(PointerType),\n}\n\n/// Generic type with type parameters (e.g., Vec\u003cT\u003e, HashMap\u003cK, V\u003e)\n#[derive(Debug, Clone)]\npub struct GenericType {\n    pub base: String,\n    pub args: Vec\u003cType\u003e,\n    pub span: Span,\n}\n\n/// Function type\n#[derive(Debug, Clone)]\npub struct FunctionType {\n    pub parameters: Vec\u003cType\u003e,\n    pub return_type: Box\u003cType\u003e,\n    pub is_extern: bool,\n    pub abi: Option\u003cString\u003e,\n}\n\n/// Pointer type\n#[derive(Debug, Clone)]\npub struct PointerType {\n    pub target: Box\u003cType\u003e,\n    pub is_mutable: bool,\n}\n\n/// Modifiers for declarations\n#[derive(Debug, Clone, Default)]\npub struct Modifiers {\n    pub is_public: bool,\n    pub is_unsafe: bool,\n}\n\n/// Attribute for declarations and expressions\n#[derive(Debug, Clone)]\npub struct Attribute {\n    pub name: String,\n    pub arguments: Vec\u003cString\u003e,\n    pub span: Span,\n}\n\n/// Index expression (arr[index])\n#[derive(Debug, Clone)]\npub struct IndexExpression {\n    pub object: Box\u003cExpression\u003e,\n    pub index: Box\u003cExpression\u003e,\n    pub span: Span,\n}\n\n/// Await expression (expr.await)\n#[derive(Debug, Clone)]\npub struct AwaitExpression {\n    pub expression: Box\u003cExpression\u003e,\n    pub span: Span,\n}\n\n/// Array literal ([1, 2, 3])\n#[derive(Debug, Clone)]\npub struct ArrayLiteral {\n    pub elements: Vec\u003cExpression\u003e,\n    pub span: Span,\n}\n\n/// Tuple literal ((1, 2, 3))\n#[derive(Debug, Clone)]\npub struct TupleLiteral {\n    pub elements: Vec\u003cExpression\u003e,\n    pub span: Span,\n}\n\n/// Block expression (Phase 2.4)\n#[derive(Debug, Clone)]\npub struct BlockExpression {\n    pub block: Block,\n    pub value: Option\u003cBox\u003cExpression\u003e\u003e,\n    pub span: Span,\n}\n\n/// Generic type parameter\n#[derive(Debug, Clone)]\npub struct GenericParam {\n    pub name: String,\n    pub bounds: Vec\u003cTypeBound\u003e,\n    pub default: Option\u003cType\u003e,\n    pub is_lifetime: bool,\n    pub span: Span,\n}\n\n/// Type bound for generic constraints (T: Clone + Debug)\n#[derive(Debug, Clone)]\npub struct TypeBound {\n    pub trait_name: String,\n    pub span: Span,\n}\n\n/// Where clause for complex generic constraints\n#[derive(Debug, Clone)]\npub struct WhereClause {\n    pub constraints: Vec\u003cWhereConstraint\u003e,\n    pub span: Span,\n}\n\n/// Individual constraint in where clause\n#[derive(Debug, Clone)]\npub struct WhereConstraint {\n    pub type_name: String,\n    pub bounds: Vec\u003cTypeBound\u003e,\n    pub span: Span,\n}\n\n/// Generic parameters collection\n#[derive(Debug, Clone)]\npub struct GenericParams {\n    pub params: Vec\u003cGenericParam\u003e,\n    pub where_clause: Option\u003cWhereClause\u003e,\n    pub span: Span,\n}\n\n/// Macro invocation expression\n#[derive(Debug, Clone)]\npub struct MacroInvocation {\n    pub name: String,\n    pub arguments: Vec\u003cTokenTree\u003e,\n    pub span: Span,\n}\n\n/// Token tree for macro arguments\n#[derive(Debug, Clone)]\npub enum TokenTree {\n    Token(Token),\n    Group(TokenGroup),\n}\n\n/// Grouped tokens in macro arguments\n#[derive(Debug, Clone)]\npub struct TokenGroup {\n    pub delimiter: GroupDelimiter,\n    pub tokens: Vec\u003cTokenTree\u003e,\n    pub span: Span,\n}\n\n/// Delimiters for token groups\n#[derive(Debug, Clone)]\npub enum GroupDelimiter {\n    Parentheses, // ()\n    Brackets,    // []\n    Braces,      // {}\n}\n\n/// Macro definition (basic framework)\n#[derive(Debug, Clone)]\npub struct MacroDefinition {\n    pub name: String,\n    pub rules: Vec\u003cMacroRule\u003e,\n    pub span: Span,\n}\n\n/// Macro rule for pattern matching\n#[derive(Debug, Clone)]\npub struct MacroRule {\n    pub pattern: Vec\u003cTokenTree\u003e,\n    pub replacement: Vec\u003cTokenTree\u003e,\n    pub span: Span,\n}\n\nimpl Statement {\n    /// Get the span of this statement\n    pub fn span(\u0026self) -\u003e Span {\n        match self {\n            Statement::Expression(expr) =\u003e expr.span(),\n            Statement::VariableDecl(var_decl) =\u003e var_decl.span.clone(),\n            Statement::If(if_stmt) =\u003e if_stmt.span.clone(),\n            Statement::While(while_stmt) =\u003e while_stmt.span.clone(),\n            Statement::For(for_stmt) =\u003e for_stmt.span.clone(),\n            Statement::Return(return_stmt) =\u003e return_stmt.span.clone(),\n            Statement::Break(break_stmt) =\u003e break_stmt.span.clone(),\n            Statement::Continue(continue_stmt) =\u003e continue_stmt.span.clone(),\n            Statement::Block(block) =\u003e block.span.clone(),\n        }\n    }\n}\n\nimpl Expression {\n    /// Get the span of this expression\n    pub fn span(\u0026self) -\u003e Span {\n        match self {\n            Expression::Literal(_) =\u003e Span::dummy(), // Literals would have their own spans\n            Expression::Identifier(_) =\u003e Span::dummy(),\n            Expression::QualifiedIdentifier(qi) =\u003e qi.span.clone(),\n            Expression::Binary(binary) =\u003e binary.span.clone(),\n            Expression::Unary(unary) =\u003e unary.span.clone(),\n            Expression::Call(call) =\u003e call.span.clone(),\n            Expression::MemberAccess(member) =\u003e member.span.clone(),\n            Expression::Index(index) =\u003e index.span.clone(),\n            Expression::Await(await_expr) =\u003e await_expr.span.clone(),\n            Expression::Array(array) =\u003e array.span.clone(),\n            Expression::Tuple(tuple) =\u003e tuple.span.clone(),\n            Expression::If(if_expr) =\u003e if_expr.span.clone(),\n            Expression::Match(match_expr) =\u003e match_expr.span.clone(),\n            Expression::Grouped(_) =\u003e Span::dummy(),\n            Expression::Block(block_expr) =\u003e block_expr.span.clone(),\n            Expression::Macro(macro_invocation) =\u003e macro_invocation.span.clone(),\n        }\n    }\n}\n\nimpl Pattern {\n    /// Get the span for this pattern\n    pub fn span(\u0026self) -\u003e Span {\n        match self {\n            Pattern::Literal(literal) =\u003e match literal {\n                Literal::String(_)\n                | Literal::Integer(_)\n                | Literal::Float(_)\n                | Literal::Boolean(_) =\u003e {\n                    // For literals, we'd need to track spans better - for now return dummy\n                    Span::dummy()\n                }\n            },\n            Pattern::Identifier(_) =\u003e Span::dummy(), // Would need proper span tracking\n            Pattern::Wildcard =\u003e Span::dummy(),\n            Pattern::DataClass(dc) =\u003e dc.span.clone(),\n            Pattern::Range(r) =\u003e r.span.clone(),\n            Pattern::Slice(s) =\u003e s.span.clone(),\n            Pattern::Or(o) =\u003e o.span.clone(),\n            Pattern::Guard(g) =\u003e g.span.clone(),\n            Pattern::Binding(b) =\u003e b.span.clone(),\n        }\n    }\n}\n","traces":[{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":575,"address":[],"length":0,"stats":{"Line":1}},{"line":576,"address":[],"length":0,"stats":{"Line":1}},{"line":577,"address":[],"length":0,"stats":{"Line":0}},{"line":578,"address":[],"length":0,"stats":{"Line":1}},{"line":579,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":0}},{"line":581,"address":[],"length":0,"stats":{"Line":0}},{"line":582,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":0}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":585,"address":[],"length":0,"stats":{"Line":0}},{"line":592,"address":[],"length":0,"stats":{"Line":8}},{"line":593,"address":[],"length":0,"stats":{"Line":8}},{"line":594,"address":[],"length":0,"stats":{"Line":4}},{"line":595,"address":[],"length":0,"stats":{"Line":1}},{"line":596,"address":[],"length":0,"stats":{"Line":0}},{"line":597,"address":[],"length":0,"stats":{"Line":1}},{"line":598,"address":[],"length":0,"stats":{"Line":2}},{"line":599,"address":[],"length":0,"stats":{"Line":0}},{"line":600,"address":[],"length":0,"stats":{"Line":0}},{"line":601,"address":[],"length":0,"stats":{"Line":0}},{"line":602,"address":[],"length":0,"stats":{"Line":0}},{"line":603,"address":[],"length":0,"stats":{"Line":0}},{"line":604,"address":[],"length":0,"stats":{"Line":0}},{"line":605,"address":[],"length":0,"stats":{"Line":0}},{"line":606,"address":[],"length":0,"stats":{"Line":0}},{"line":607,"address":[],"length":0,"stats":{"Line":0}},{"line":608,"address":[],"length":0,"stats":{"Line":0}},{"line":609,"address":[],"length":0,"stats":{"Line":0}},{"line":616,"address":[],"length":0,"stats":{"Line":8}},{"line":617,"address":[],"length":0,"stats":{"Line":8}},{"line":618,"address":[],"length":0,"stats":{"Line":3}},{"line":624,"address":[],"length":0,"stats":{"Line":0}},{"line":627,"address":[],"length":0,"stats":{"Line":4}},{"line":628,"address":[],"length":0,"stats":{"Line":0}},{"line":629,"address":[],"length":0,"stats":{"Line":0}},{"line":630,"address":[],"length":0,"stats":{"Line":0}},{"line":631,"address":[],"length":0,"stats":{"Line":0}},{"line":632,"address":[],"length":0,"stats":{"Line":1}},{"line":633,"address":[],"length":0,"stats":{"Line":0}},{"line":634,"address":[],"length":0,"stats":{"Line":0}}],"covered":14,"coverable":44},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","ast","visitor.rs"],"content":"//! AST visitor patterns for traversal and transformation\n//!\n//! Implementation will be completed during development phase\n\nuse super::*;\n\n/// Trait for visiting AST nodes\npub trait Visitor\u003cT\u003e {\n    fn visit_compilation_unit(\u0026mut self, node: \u0026CompilationUnit) -\u003e T;\n    fn visit_expression(\u0026mut self, node: \u0026Expression) -\u003e T;\n    fn visit_statement(\u0026mut self, node: \u0026Statement) -\u003e T;\n    fn visit_type(\u0026mut self, node: \u0026Type) -\u003e T;\n\n    // Default implementations can delegate to more specific methods\n}\n\n/// Mutable visitor trait for transforming AST nodes\npub trait MutVisitor\u003cT\u003e {\n    fn visit_compilation_unit_mut(\u0026mut self, node: \u0026mut CompilationUnit) -\u003e T;\n    fn visit_expression_mut(\u0026mut self, node: \u0026mut Expression) -\u003e T;\n    fn visit_statement_mut(\u0026mut self, node: \u0026mut Statement) -\u003e T;\n    fn visit_type_mut(\u0026mut self, node: \u0026mut Type) -\u003e T;\n}\n\n// Implementation will be completed during development phase\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","attribute","mod.rs"],"content":"//! Attribute parsing for Phase 2.8.1\n//!\n//! Implements parsing for Ferra attribute syntax including:\n//! - Standard attributes: #[derive(Debug, Clone)]\n//! - Simple attributes: #[inline]\n//! - Alternative syntax: @inline (future)\n\npub mod parser;\n\npub use parser::*;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","attribute","parser.rs"],"content":"//! Attribute parser implementation for Phase 2.8.1\n//!\n//! Supports parsing of Ferra attribute syntax:\n//! - #[derive(Debug, Clone)] - standard attributes with arguments\n//! - #[inline] - simple attributes without arguments\n//! - #[cfg(feature = \"std\")] - configuration attributes\n//! - @inline - alternative syntax (future support)\n\nuse crate::{\n    ast::Attribute,\n    error::{ParseError, ParseResult},\n    token::{Span, TokenStream, TokenType},\n};\n\n/// Parse a list of attributes from token stream\npub fn parse_attributes\u003cT: TokenStream\u003e(tokens: \u0026mut T) -\u003e ParseResult\u003cVec\u003cAttribute\u003e\u003e {\n    let mut parser = AttributeParser::new(tokens);\n    parser.parse_attribute_list()\n}\n\n/// Parse a single attribute from token stream\npub fn parse_attribute\u003cT: TokenStream\u003e(tokens: \u0026mut T) -\u003e ParseResult\u003cAttribute\u003e {\n    let mut parser = AttributeParser::new(tokens);\n    parser.parse_attribute()\n}\n\n/// Comprehensive attribute parser for Phase 2.8.1\nstruct AttributeParser\u003c'a, T: TokenStream\u003e {\n    tokens: \u0026'a mut T,\n}\n\nimpl\u003c'a, T: TokenStream\u003e AttributeParser\u003c'a, T\u003e {\n    fn new(tokens: \u0026'a mut T) -\u003e Self {\n        Self { tokens }\n    }\n\n    /// Parse a list of consecutive attributes\n    fn parse_attribute_list(\u0026mut self) -\u003e ParseResult\u003cVec\u003cAttribute\u003e\u003e {\n        let mut attributes = Vec::new();\n\n        // Parse consecutive attributes\n        while matches!(self.tokens.peek().token_type, TokenType::Hash) {\n            let attribute = self.parse_attribute()?;\n            attributes.push(attribute);\n        }\n\n        Ok(attributes)\n    }\n\n    /// Parse a single attribute: #[name] or #[name(args)]\n    fn parse_attribute(\u0026mut self) -\u003e ParseResult\u003cAttribute\u003e {\n        let start_span = self.current_span();\n\n        // Consume '#'\n        let hash_token = self.tokens.consume();\n        if !matches!(hash_token.token_type, TokenType::Hash) {\n            return Err(ParseError::unexpected_token(\"'#'\", \u0026hash_token));\n        }\n\n        // Consume '['\n        let open_bracket = self.tokens.consume();\n        if !matches!(open_bracket.token_type, TokenType::LeftBracket) {\n            return Err(ParseError::unexpected_token(\"'['\", \u0026open_bracket));\n        }\n\n        // Parse attribute name\n        let name_token = self.tokens.consume();\n        let name = match name_token.token_type {\n            TokenType::Identifier(name) =\u003e name,\n            _ =\u003e return Err(ParseError::unexpected_token(\"attribute name\", \u0026name_token)),\n        };\n\n        // Parse optional arguments\n        let arguments = if matches!(self.tokens.peek().token_type, TokenType::LeftParen) {\n            self.parse_attribute_arguments()?\n        } else {\n            Vec::new()\n        };\n\n        // Consume ']'\n        let close_bracket = self.tokens.consume();\n        if !matches!(close_bracket.token_type, TokenType::RightBracket) {\n            return Err(ParseError::unexpected_token(\"']'\", \u0026close_bracket));\n        }\n\n        Ok(Attribute {\n            name,\n            arguments,\n            span: start_span,\n        })\n    }\n\n    /// Parse attribute arguments: (arg1, arg2, ...)\n    fn parse_attribute_arguments(\u0026mut self) -\u003e ParseResult\u003cVec\u003cString\u003e\u003e {\n        // Consume '('\n        let open_paren = self.tokens.consume();\n        if !matches!(open_paren.token_type, TokenType::LeftParen) {\n            return Err(ParseError::unexpected_token(\"'('\", \u0026open_paren));\n        }\n\n        let mut arguments = Vec::new();\n\n        // Handle empty argument list\n        if matches!(self.tokens.peek().token_type, TokenType::RightParen) {\n            self.tokens.consume(); // consume ')'\n            return Ok(arguments);\n        }\n\n        // Parse argument list\n        loop {\n            let arg = self.parse_attribute_argument()?;\n            arguments.push(arg);\n\n            match self.tokens.peek().token_type {\n                TokenType::Comma =\u003e {\n                    self.tokens.consume(); // consume ','\n                                           // Allow trailing comma\n                    if matches!(self.tokens.peek().token_type, TokenType::RightParen) {\n                        break;\n                    }\n                }\n                TokenType::RightParen =\u003e break,\n                _ =\u003e {\n                    return Err(ParseError::unexpected_token(\n                        \"',' or ')'\",\n                        self.tokens.peek(),\n                    ))\n                }\n            }\n        }\n\n        // Consume ')'\n        let close_paren = self.tokens.consume();\n        if !matches!(close_paren.token_type, TokenType::RightParen) {\n            return Err(ParseError::unexpected_token(\"')'\", \u0026close_paren));\n        }\n\n        Ok(arguments)\n    }\n\n    /// Parse a single attribute argument (identifier, string, or simple expression)\n    fn parse_attribute_argument(\u0026mut self) -\u003e ParseResult\u003cString\u003e {\n        let token = self.tokens.consume();\n\n        match token.token_type {\n            TokenType::Identifier(name) =\u003e Ok(name),\n            TokenType::StringLiteral(s) =\u003e Ok(format!(\"\\\"{}\\\"\", s)),\n            TokenType::IntegerLiteral(i) =\u003e Ok(i.to_string()),\n            TokenType::BooleanLiteral(b) =\u003e Ok(b.to_string()),\n            _ =\u003e {\n                // For more complex expressions, we'll represent them as strings for now\n                // In future phases, we might want to parse full expressions\n                match \u0026token.token_type {\n                    TokenType::Identifier(name) =\u003e Ok(name.clone()),\n                    _ =\u003e Err(ParseError::unexpected_token(\"attribute argument\", \u0026token)),\n                }\n            }\n        }\n    }\n\n    /// Get current token span\n    fn current_span(\u0026self) -\u003e Span {\n        self.tokens.peek().span.clone()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::token::VecTokenStream;\n\n    fn create_token_stream(token_types: Vec\u003cTokenType\u003e) -\u003e VecTokenStream {\n        VecTokenStream::from_token_types(token_types)\n    }\n\n    #[test]\n    fn test_simple_attribute() {\n        // #[inline]\n        let mut tokens = create_token_stream(vec![\n            TokenType::Hash,\n            TokenType::LeftBracket,\n            TokenType::Identifier(\"inline\".to_string()),\n            TokenType::RightBracket,\n        ]);\n\n        let result = parse_attribute(\u0026mut tokens).unwrap();\n        assert_eq!(result.name, \"inline\");\n        assert_eq!(result.arguments.len(), 0);\n    }\n\n    #[test]\n    fn test_attribute_with_single_argument() {\n        // #[cfg(test)]\n        let mut tokens = create_token_stream(vec![\n            TokenType::Hash,\n            TokenType::LeftBracket,\n            TokenType::Identifier(\"cfg\".to_string()),\n            TokenType::LeftParen,\n            TokenType::Identifier(\"test\".to_string()),\n            TokenType::RightParen,\n            TokenType::RightBracket,\n        ]);\n\n        let result = parse_attribute(\u0026mut tokens).unwrap();\n        assert_eq!(result.name, \"cfg\");\n        assert_eq!(result.arguments.len(), 1);\n        assert_eq!(result.arguments[0], \"test\");\n    }\n\n    #[test]\n    fn test_attribute_with_multiple_arguments() {\n        // #[derive(Debug, Clone)]\n        let mut tokens = create_token_stream(vec![\n            TokenType::Hash,\n            TokenType::LeftBracket,\n            TokenType::Identifier(\"derive\".to_string()),\n            TokenType::LeftParen,\n            TokenType::Identifier(\"Debug\".to_string()),\n            TokenType::Comma,\n            TokenType::Identifier(\"Clone\".to_string()),\n            TokenType::RightParen,\n            TokenType::RightBracket,\n        ]);\n\n        let result = parse_attribute(\u0026mut tokens).unwrap();\n        assert_eq!(result.name, \"derive\");\n        assert_eq!(result.arguments.len(), 2);\n        assert_eq!(result.arguments[0], \"Debug\");\n        assert_eq!(result.arguments[1], \"Clone\");\n    }\n\n    #[test]\n    fn test_attribute_with_trailing_comma() {\n        // #[derive(Debug, Clone,)]\n        let mut tokens = create_token_stream(vec![\n            TokenType::Hash,\n            TokenType::LeftBracket,\n            TokenType::Identifier(\"derive\".to_string()),\n            TokenType::LeftParen,\n            TokenType::Identifier(\"Debug\".to_string()),\n            TokenType::Comma,\n            TokenType::Identifier(\"Clone\".to_string()),\n            TokenType::Comma,\n            TokenType::RightParen,\n            TokenType::RightBracket,\n        ]);\n\n        let result = parse_attribute(\u0026mut tokens).unwrap();\n        assert_eq!(result.name, \"derive\");\n        assert_eq!(result.arguments.len(), 2);\n        assert_eq!(result.arguments[0], \"Debug\");\n        assert_eq!(result.arguments[1], \"Clone\");\n    }\n\n    #[test]\n    fn test_attribute_with_string_argument() {\n        // #[doc(\"This is documentation\")]\n        let mut tokens = create_token_stream(vec![\n            TokenType::Hash,\n            TokenType::LeftBracket,\n            TokenType::Identifier(\"doc\".to_string()),\n            TokenType::LeftParen,\n            TokenType::StringLiteral(\"This is documentation\".to_string()),\n            TokenType::RightParen,\n            TokenType::RightBracket,\n        ]);\n\n        let result = parse_attribute(\u0026mut tokens).unwrap();\n        assert_eq!(result.name, \"doc\");\n        assert_eq!(result.arguments.len(), 1);\n        assert_eq!(result.arguments[0], \"\\\"This is documentation\\\"\");\n    }\n\n    #[test]\n    fn test_attribute_with_mixed_arguments() {\n        // #[test_attr(\"string\", 42, true)]\n        let mut tokens = create_token_stream(vec![\n            TokenType::Hash,\n            TokenType::LeftBracket,\n            TokenType::Identifier(\"test_attr\".to_string()),\n            TokenType::LeftParen,\n            TokenType::StringLiteral(\"string\".to_string()),\n            TokenType::Comma,\n            TokenType::IntegerLiteral(42),\n            TokenType::Comma,\n            TokenType::BooleanLiteral(true),\n            TokenType::RightParen,\n            TokenType::RightBracket,\n        ]);\n\n        let result = parse_attribute(\u0026mut tokens).unwrap();\n        assert_eq!(result.name, \"test_attr\");\n        assert_eq!(result.arguments.len(), 3);\n        assert_eq!(result.arguments[0], \"\\\"string\\\"\");\n        assert_eq!(result.arguments[1], \"42\");\n        assert_eq!(result.arguments[2], \"true\");\n    }\n\n    #[test]\n    fn test_multiple_attributes() {\n        // #[inline] #[derive(Debug)]\n        let mut tokens = create_token_stream(vec![\n            TokenType::Hash,\n            TokenType::LeftBracket,\n            TokenType::Identifier(\"inline\".to_string()),\n            TokenType::RightBracket,\n            TokenType::Hash,\n            TokenType::LeftBracket,\n            TokenType::Identifier(\"derive\".to_string()),\n            TokenType::LeftParen,\n            TokenType::Identifier(\"Debug\".to_string()),\n            TokenType::RightParen,\n            TokenType::RightBracket,\n        ]);\n\n        let result = parse_attributes(\u0026mut tokens).unwrap();\n        assert_eq!(result.len(), 2);\n        assert_eq!(result[0].name, \"inline\");\n        assert_eq!(result[0].arguments.len(), 0);\n        assert_eq!(result[1].name, \"derive\");\n        assert_eq!(result[1].arguments.len(), 1);\n        assert_eq!(result[1].arguments[0], \"Debug\");\n    }\n\n    #[test]\n    fn test_empty_attribute_list() {\n        // No attributes, just some other token\n        let mut tokens = create_token_stream(vec![TokenType::Identifier(\"something\".to_string())]);\n\n        let result = parse_attributes(\u0026mut tokens).unwrap();\n        assert_eq!(result.len(), 0);\n    }\n\n    #[test]\n    fn test_attribute_parsing_errors() {\n        // Missing opening bracket: #identifier\n        let mut tokens = create_token_stream(vec![\n            TokenType::Hash,\n            TokenType::Identifier(\"inline\".to_string()),\n        ]);\n\n        let result = parse_attribute(\u0026mut tokens);\n        assert!(result.is_err());\n\n        // Missing closing bracket: #[inline\n        let mut tokens = create_token_stream(vec![\n            TokenType::Hash,\n            TokenType::LeftBracket,\n            TokenType::Identifier(\"inline\".to_string()),\n        ]);\n\n        let result = parse_attribute(\u0026mut tokens);\n        assert!(result.is_err());\n\n        // Invalid attribute name: #[123]\n        let mut tokens = create_token_stream(vec![\n            TokenType::Hash,\n            TokenType::LeftBracket,\n            TokenType::IntegerLiteral(123),\n            TokenType::RightBracket,\n        ]);\n\n        let result = parse_attribute(\u0026mut tokens);\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_complex_derive_attribute() {\n        // #[derive(Debug, Clone, PartialEq, Eq)]\n        let mut tokens = create_token_stream(vec![\n            TokenType::Hash,\n            TokenType::LeftBracket,\n            TokenType::Identifier(\"derive\".to_string()),\n            TokenType::LeftParen,\n            TokenType::Identifier(\"Debug\".to_string()),\n            TokenType::Comma,\n            TokenType::Identifier(\"Clone\".to_string()),\n            TokenType::Comma,\n            TokenType::Identifier(\"PartialEq\".to_string()),\n            TokenType::Comma,\n            TokenType::Identifier(\"Eq\".to_string()),\n            TokenType::RightParen,\n            TokenType::RightBracket,\n        ]);\n\n        let result = parse_attribute(\u0026mut tokens).unwrap();\n        assert_eq!(result.name, \"derive\");\n        assert_eq!(result.arguments.len(), 4);\n        assert_eq!(result.arguments[0], \"Debug\");\n        assert_eq!(result.arguments[1], \"Clone\");\n        assert_eq!(result.arguments[2], \"PartialEq\");\n        assert_eq!(result.arguments[3], \"Eq\");\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":59}},{"line":17,"address":[],"length":0,"stats":{"Line":59}},{"line":18,"address":[],"length":0,"stats":{"Line":59}},{"line":22,"address":[],"length":0,"stats":{"Line":19}},{"line":23,"address":[],"length":0,"stats":{"Line":19}},{"line":24,"address":[],"length":0,"stats":{"Line":19}},{"line":33,"address":[],"length":0,"stats":{"Line":78}},{"line":38,"address":[],"length":0,"stats":{"Line":59}},{"line":39,"address":[],"length":0,"stats":{"Line":59}},{"line":42,"address":[],"length":0,"stats":{"Line":131}},{"line":43,"address":[],"length":0,"stats":{"Line":26}},{"line":44,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":59}},{"line":51,"address":[],"length":0,"stats":{"Line":32}},{"line":52,"address":[],"length":0,"stats":{"Line":32}},{"line":55,"address":[],"length":0,"stats":{"Line":32}},{"line":56,"address":[],"length":0,"stats":{"Line":32}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":32}},{"line":62,"address":[],"length":0,"stats":{"Line":34}},{"line":63,"address":[],"length":0,"stats":{"Line":2}},{"line":67,"address":[],"length":0,"stats":{"Line":30}},{"line":68,"address":[],"length":0,"stats":{"Line":58}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":2}},{"line":74,"address":[],"length":0,"stats":{"Line":37}},{"line":75,"address":[],"length":0,"stats":{"Line":19}},{"line":77,"address":[],"length":0,"stats":{"Line":9}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":2}},{"line":83,"address":[],"length":0,"stats":{"Line":2}},{"line":86,"address":[],"length":0,"stats":{"Line":26}},{"line":87,"address":[],"length":0,"stats":{"Line":26}},{"line":88,"address":[],"length":0,"stats":{"Line":26}},{"line":89,"address":[],"length":0,"stats":{"Line":26}},{"line":94,"address":[],"length":0,"stats":{"Line":19}},{"line":96,"address":[],"length":0,"stats":{"Line":19}},{"line":97,"address":[],"length":0,"stats":{"Line":19}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":19}},{"line":104,"address":[],"length":0,"stats":{"Line":38}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":68}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":17}},{"line":118,"address":[],"length":0,"stats":{"Line":32}},{"line":119,"address":[],"length":0,"stats":{"Line":2}},{"line":122,"address":[],"length":0,"stats":{"Line":17}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":133,"address":[],"length":0,"stats":{"Line":19}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":19}},{"line":142,"address":[],"length":0,"stats":{"Line":34}},{"line":143,"address":[],"length":0,"stats":{"Line":34}},{"line":145,"address":[],"length":0,"stats":{"Line":34}},{"line":146,"address":[],"length":0,"stats":{"Line":25}},{"line":147,"address":[],"length":0,"stats":{"Line":5}},{"line":148,"address":[],"length":0,"stats":{"Line":2}},{"line":149,"address":[],"length":0,"stats":{"Line":2}},{"line":150,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":32}},{"line":163,"address":[],"length":0,"stats":{"Line":32}}],"covered":52,"coverable":73},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","block","mod.rs"],"content":"//! Block structure parsing\n//!\n//! Handles both brace-style and indentation-style blocks\n\npub mod parser;\n\npub use parser::*;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","block","parser.rs"],"content":"//! Block parsing implementation for Phase 2.4\n//!\n//! Handles all block types: braced, indented, and advanced block features\n\nuse crate::{\n    ast::{\n        Arena, Block, BreakStatement, ContinueStatement, Expression, Literal, Modifiers,\n        ReturnStatement, Statement, Type, VariableDecl,\n    },\n    error::{ParseError, ParseResult},\n    pratt::parser::PrattParser,\n    token::{Span, Token, TokenStream, TokenType},\n};\n\n/// Block style enumeration for consistency\n#[derive(Debug, Clone, Copy, PartialEq)]\npub enum BlockStyle {\n    Braced,\n    Indented,\n}\n\n/// Scope information for variable tracking\n#[derive(Debug, Clone)]\npub struct ScopeInfo {\n    pub depth: usize,\n    pub variables: Vec\u003cString\u003e,\n    pub is_unsafe: bool,\n    pub is_async: bool,\n    pub label: Option\u003cString\u003e,\n}\n\n/// Block parser with comprehensive scope and style management\npub struct BlockParser\u003c'arena\u003e {\n    arena: \u0026'arena Arena,\n    current_scope_depth: usize,\n    _current_indentation: usize, // For future indentation tracking\n    block_style: Option\u003cBlockStyle\u003e,\n}\n\nimpl\u003c'arena\u003e BlockParser\u003c'arena\u003e {\n    /// Create a new block parser\n    pub fn new(arena: \u0026'arena Arena) -\u003e Self {\n        Self {\n            arena,\n            current_scope_depth: 0,\n            _current_indentation: 0,\n            block_style: None,\n        }\n    }\n\n    /// Parse a block, automatically detecting style\n    pub fn parse_block\u003cT: TokenStream\u003e(\u0026mut self, tokens: \u0026mut T) -\u003e ParseResult\u003c\u0026'arena Block\u003e {\n        let current = tokens.peek();\n\n        match current.token_type {\n            TokenType::LeftBrace =\u003e self.parse_braced_block(tokens),\n            TokenType::Colon =\u003e self.parse_indented_block(tokens),\n            _ =\u003e Err(ParseError::expected_block(current.span.clone())),\n        }\n    }\n\n    /// Parse a braced block { statements... }\n    pub fn parse_braced_block\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        tokens: \u0026mut T,\n    ) -\u003e ParseResult\u003c\u0026'arena Block\u003e {\n        let start_span = tokens.peek().span.clone();\n\n        // Consume opening brace\n        self.expect_token(tokens, TokenType::LeftBrace)?;\n\n        // Set block style for consistency checking\n        match self.block_style {\n            None =\u003e self.block_style = Some(BlockStyle::Braced),\n            Some(BlockStyle::Indented) =\u003e {\n                return Err(ParseError::mixed_block_styles(start_span));\n            }\n            Some(BlockStyle::Braced) =\u003e {} // OK, consistent\n        }\n\n        let mut statements = Vec::new();\n        self.current_scope_depth += 1;\n\n        // Parse statements until closing brace\n        while !tokens.is_at_end() \u0026\u0026 !matches!(tokens.peek().token_type, TokenType::RightBrace) {\n            let statement = self.parse_statement_in_block(tokens)?;\n            statements.push(statement.clone());\n        }\n\n        let end_span = tokens.peek().span.clone();\n        self.expect_token(tokens, TokenType::RightBrace)?;\n\n        self.current_scope_depth -= 1;\n\n        let block = self.arena.alloc(Block {\n            statements,\n            is_braced: true,\n            scope_depth: self.current_scope_depth,\n            span: start_span.combine(end_span),\n            is_unsafe: false,\n            is_async: false,\n            is_try: false,\n            label: None,\n        });\n\n        Ok(block)\n    }\n\n    /// Parse an indented block : \\n statements...\n    pub fn parse_indented_block\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        tokens: \u0026mut T,\n    ) -\u003e ParseResult\u003c\u0026'arena Block\u003e {\n        let start_span = tokens.peek().span.clone();\n\n        // Consume colon\n        self.expect_token(tokens, TokenType::Colon)?;\n\n        // Expect newline\n        self.expect_token(tokens, TokenType::Newline)?;\n\n        // Set block style for consistency checking\n        match self.block_style {\n            None =\u003e self.block_style = Some(BlockStyle::Indented),\n            Some(BlockStyle::Braced) =\u003e {\n                return Err(ParseError::mixed_block_styles(start_span));\n            }\n            Some(BlockStyle::Indented) =\u003e {} // OK, consistent\n        }\n\n        let mut statements = Vec::new();\n        self.current_scope_depth += 1;\n\n        // Parse indented statements (simplified - just parse until we see dedent)\n        while !tokens.is_at_end() {\n            // Check if we've reached the end of the indented block\n            if matches!(\n                tokens.peek().token_type,\n                TokenType::Eof | TokenType::RightBrace\n            ) {\n                break;\n            }\n\n            let statement = self.parse_statement_in_block(tokens)?;\n            statements.push(statement.clone());\n        }\n\n        self.current_scope_depth -= 1;\n\n        let end_span = if let Some(last_stmt) = statements.last() {\n            last_stmt.span()\n        } else {\n            start_span.clone()\n        };\n\n        let block = self.arena.alloc(Block {\n            statements,\n            is_braced: false,\n            scope_depth: self.current_scope_depth,\n            span: start_span.combine(end_span),\n            is_unsafe: false,\n            is_async: false,\n            is_try: false,\n            label: None,\n        });\n\n        Ok(block)\n    }\n\n    /// Parse a statement within a block context\n    fn parse_statement_in_block\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        tokens: \u0026mut T,\n    ) -\u003e ParseResult\u003c\u0026'arena Statement\u003e {\n        // Create a temporary token stream for the statement parser\n        // We'll parse one statement at a time\n        let token = tokens.peek();\n\n        match \u0026token.token_type {\n            // Variable declarations\n            TokenType::Let | TokenType::Var =\u003e self.parse_variable_statement(tokens),\n            // Control flow\n            TokenType::If =\u003e self.parse_if_statement(tokens),\n            TokenType::While =\u003e self.parse_while_statement(tokens),\n            TokenType::For =\u003e self.parse_for_statement(tokens),\n            TokenType::Return =\u003e self.parse_return_statement(tokens),\n            TokenType::Break =\u003e self.parse_break_statement(tokens),\n            TokenType::Continue =\u003e self.parse_continue_statement(tokens),\n            // Block statements\n            TokenType::LeftBrace =\u003e {\n                let block = self.parse_braced_block(tokens)?;\n                Ok(self.arena.alloc(Statement::Block(block.clone())))\n            }\n            // Expression statements (fallback)\n            _ =\u003e self.parse_expression_statement(tokens),\n        }\n    }\n\n    /// Parse a variable declaration statement\n    fn parse_variable_statement\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        tokens: \u0026mut T,\n    ) -\u003e ParseResult\u003c\u0026'arena Statement\u003e {\n        let start_token = tokens.consume(); // let or var\n        let is_mutable = matches!(start_token.token_type, TokenType::Var);\n\n        let name_token = tokens.consume();\n        let name = match name_token.token_type {\n            TokenType::Identifier(name) =\u003e name,\n            _ =\u003e return Err(ParseError::unexpected_token(\"identifier\", \u0026name_token)),\n        };\n\n        // Optional type annotation\n        let var_type = if matches!(tokens.peek().token_type, TokenType::Colon) {\n            tokens.consume(); // consume ':'\n            Some(Type::Identifier(\"i32\".to_string())) // Simplified for now\n        } else {\n            None\n        };\n\n        // Optional initializer\n        let initializer = if matches!(tokens.peek().token_type, TokenType::Equal) {\n            tokens.consume(); // consume '='\n            Some(self.parse_expression(tokens)?)\n        } else {\n            None\n        };\n\n        // Consume optional semicolon\n        if matches!(tokens.peek().token_type, TokenType::Semicolon) {\n            tokens.consume();\n        }\n\n        let var_decl = VariableDecl {\n            name,\n            var_type,\n            initializer: initializer.cloned(),\n            is_mutable,\n            modifiers: Modifiers {\n                is_public: false,\n                is_unsafe: false,\n            },\n            attributes: Vec::new(),\n            span: start_token.span,\n        };\n\n        Ok(self.arena.alloc(Statement::VariableDecl(var_decl)))\n    }\n\n    #[allow(dead_code)]\n    fn parse_expression_statement\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        tokens: \u0026mut T,\n    ) -\u003e ParseResult\u003c\u0026'arena Statement\u003e {\n        let expr = self.parse_expression(tokens)?;\n\n        // Consume optional semicolon\n        if matches!(tokens.peek().token_type, TokenType::Semicolon) {\n            tokens.consume();\n        }\n\n        Ok(self.arena.alloc(Statement::Expression(expr.clone())))\n    }\n\n    /// Parse a complex expression using the PrattParser\n    fn parse_expression\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        tokens: \u0026mut T,\n    ) -\u003e ParseResult\u003c\u0026'arena Expression\u003e {\n        // Collect tokens into a vector for PrattParser consumption\n        let mut collected_tokens = Vec::new();\n        let mut paren_depth = 0;\n        let mut bracket_depth = 0;\n        let mut brace_depth = 0;\n\n        // Collect tokens until we find a statement terminator\n        loop {\n            let token = tokens.peek();\n            match token.token_type {\n                TokenType::LeftParen =\u003e paren_depth += 1,\n                TokenType::RightParen =\u003e {\n                    if paren_depth == 0 {\n                        break;\n                    }\n                    paren_depth -= 1;\n                }\n                TokenType::LeftBracket =\u003e bracket_depth += 1,\n                TokenType::RightBracket =\u003e {\n                    if bracket_depth == 0 {\n                        break;\n                    }\n                    bracket_depth -= 1;\n                }\n                TokenType::LeftBrace =\u003e brace_depth += 1,\n                TokenType::RightBrace =\u003e {\n                    if brace_depth == 0 {\n                        break;\n                    }\n                    brace_depth -= 1;\n                }\n                TokenType::Semicolon | TokenType::Newline =\u003e {\n                    if paren_depth == 0 \u0026\u0026 bracket_depth == 0 \u0026\u0026 brace_depth == 0 {\n                        break;\n                    }\n                }\n                // Statement keywords should terminate expression parsing\n                TokenType::Let\n                | TokenType::Var\n                | TokenType::If\n                | TokenType::While\n                | TokenType::For\n                | TokenType::Return\n                | TokenType::Break\n                | TokenType::Continue =\u003e {\n                    if paren_depth == 0 \u0026\u0026 bracket_depth == 0 \u0026\u0026 brace_depth == 0 {\n                        break;\n                    }\n                }\n                TokenType::Eof =\u003e break,\n                _ =\u003e {}\n            }\n\n            collected_tokens.push(tokens.consume());\n        }\n\n        // Add EOF token\n        collected_tokens.push(Token {\n            token_type: TokenType::Eof,\n            span: tokens.peek().span.clone(),\n        });\n\n        // Create a VecTokenStream and parse with PrattParser\n        let token_stream = crate::token::VecTokenStream::new(collected_tokens);\n        let mut pratt_parser = PrattParser::new(self.arena, token_stream);\n        pratt_parser.parse_expression(0)\n    }\n\n    /// Parse other statement types (simplified implementations)\n    fn parse_if_statement\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        _tokens: \u0026mut T,\n    ) -\u003e ParseResult\u003c\u0026'arena Statement\u003e {\n        // Simplified - just return a dummy statement for now\n        Ok(self.arena.alloc(Statement::Expression(\n            self.arena\n                .alloc(Expression::Literal(Literal::Boolean(true)))\n                .clone(),\n        )))\n    }\n\n    fn parse_while_statement\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        _tokens: \u0026mut T,\n    ) -\u003e ParseResult\u003c\u0026'arena Statement\u003e {\n        // Simplified - just return a dummy statement for now\n        Ok(self.arena.alloc(Statement::Expression(\n            self.arena\n                .alloc(Expression::Literal(Literal::Boolean(true)))\n                .clone(),\n        )))\n    }\n\n    fn parse_for_statement\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        _tokens: \u0026mut T,\n    ) -\u003e ParseResult\u003c\u0026'arena Statement\u003e {\n        // Simplified - just return a dummy statement for now\n        Ok(self.arena.alloc(Statement::Expression(\n            self.arena\n                .alloc(Expression::Literal(Literal::Boolean(true)))\n                .clone(),\n        )))\n    }\n\n    fn parse_return_statement\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        tokens: \u0026mut T,\n    ) -\u003e ParseResult\u003c\u0026'arena Statement\u003e {\n        tokens.consume(); // consume 'return'\n\n        // Optional return value\n        let value = if matches!(\n            tokens.peek().token_type,\n            TokenType::Semicolon | TokenType::Eof | TokenType::RightBrace\n        ) {\n            None\n        } else {\n            let expr_token = tokens.consume();\n            match expr_token.token_type {\n                TokenType::IntegerLiteral(value) =\u003e Some(\n                    self.arena\n                        .alloc(Expression::Literal(Literal::Integer(value))),\n                ),\n                TokenType::Identifier(name) =\u003e Some(self.arena.alloc(Expression::Identifier(name))),\n                _ =\u003e return Err(ParseError::unexpected_token(\"expression\", \u0026expr_token)),\n            }\n        };\n\n        // Consume optional semicolon\n        if matches!(tokens.peek().token_type, TokenType::Semicolon) {\n            tokens.consume();\n        }\n\n        let return_stmt = ReturnStatement {\n            value: value.cloned(),\n            span: tokens.peek().span.clone(),\n        };\n\n        Ok(self.arena.alloc(Statement::Return(return_stmt)))\n    }\n\n    fn parse_break_statement\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        tokens: \u0026mut T,\n    ) -\u003e ParseResult\u003c\u0026'arena Statement\u003e {\n        let break_token = tokens.consume(); // consume 'break'\n\n        // Consume optional semicolon\n        if matches!(tokens.peek().token_type, TokenType::Semicolon) {\n            tokens.consume();\n        }\n\n        let break_stmt = BreakStatement {\n            span: break_token.span,\n        };\n\n        Ok(self.arena.alloc(Statement::Break(break_stmt)))\n    }\n\n    fn parse_continue_statement\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        tokens: \u0026mut T,\n    ) -\u003e ParseResult\u003c\u0026'arena Statement\u003e {\n        let continue_token = tokens.consume(); // consume 'continue'\n\n        // Consume optional semicolon\n        if matches!(tokens.peek().token_type, TokenType::Semicolon) {\n            tokens.consume();\n        }\n\n        let continue_stmt = ContinueStatement {\n            span: continue_token.span,\n        };\n\n        Ok(self.arena.alloc(Statement::Continue(continue_stmt)))\n    }\n\n    /// Parse a labeled block (for break/continue)\n    pub fn parse_labeled_block\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        tokens: \u0026mut T,\n        label: String,\n    ) -\u003e ParseResult\u003c\u0026'arena Block\u003e {\n        let block = self.parse_block(tokens)?.clone();\n\n        // Create new block with label\n        let labeled_block = self.arena.alloc(Block {\n            statements: block.statements,\n            is_braced: block.is_braced,\n            scope_depth: block.scope_depth,\n            span: block.span,\n            is_unsafe: block.is_unsafe,\n            is_async: block.is_async,\n            is_try: block.is_try,\n            label: Some(label),\n        });\n\n        Ok(labeled_block)\n    }\n\n    /// Parse an unsafe block\n    pub fn parse_unsafe_block\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        tokens: \u0026mut T,\n    ) -\u003e ParseResult\u003c\u0026'arena Block\u003e {\n        let start_span = tokens.peek().span.clone();\n\n        // Consume 'unsafe' keyword\n        self.expect_token(tokens, TokenType::Unsafe)?;\n\n        let block = self.parse_braced_block(tokens)?.clone();\n\n        // Create new block marked as unsafe\n        let unsafe_block = self.arena.alloc(Block {\n            statements: block.statements,\n            is_braced: true,\n            scope_depth: block.scope_depth,\n            span: start_span.combine(block.span),\n            is_unsafe: true,\n            is_async: block.is_async,\n            is_try: block.is_try,\n            label: block.label,\n        });\n\n        Ok(unsafe_block)\n    }\n\n    /// Parse an async block\n    pub fn parse_async_block\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        tokens: \u0026mut T,\n    ) -\u003e ParseResult\u003c\u0026'arena Block\u003e {\n        let start_span = tokens.peek().span.clone();\n\n        // Consume 'async' keyword\n        self.expect_token(tokens, TokenType::Async)?;\n\n        let block = self.parse_braced_block(tokens)?.clone();\n\n        // Create new block marked as async\n        let async_block = self.arena.alloc(Block {\n            statements: block.statements,\n            is_braced: true,\n            scope_depth: block.scope_depth,\n            span: start_span.combine(block.span),\n            is_unsafe: block.is_unsafe,\n            is_async: true,\n            is_try: block.is_try,\n            label: block.label,\n        });\n\n        Ok(async_block)\n    }\n\n    /// Validate scope consistency and variable shadowing\n    pub fn validate_scope(\u0026self, scope: \u0026ScopeInfo) -\u003e ParseResult\u003c()\u003e {\n        // Check for variable redefinition within same scope\n        let mut seen_vars = std::collections::HashSet::new();\n        for var in \u0026scope.variables {\n            if seen_vars.contains(var) {\n                return Err(ParseError::variable_redefinition(\n                    var,\n                    Span::dummy(), // Would need actual span tracking\n                ));\n            }\n            seen_vars.insert(var.clone());\n        }\n\n        Ok(())\n    }\n\n    /// Expect a specific token type\n    fn expect_token\u003cT: TokenStream\u003e(\n        \u0026mut self,\n        tokens: \u0026mut T,\n        expected: TokenType,\n    ) -\u003e ParseResult\u003cToken\u003e {\n        let current = tokens.peek();\n        if std::mem::discriminant(\u0026current.token_type) == std::mem::discriminant(\u0026expected) {\n            let token = current.clone();\n            tokens.consume();\n            Ok(token)\n        } else {\n            Err(ParseError::unexpected_token(\n                \u0026format!(\"{:?}\", expected),\n                current,\n            ))\n        }\n    }\n}\n\n/// Convenience functions for block parsing\npub fn parse_block\u003cT: TokenStream\u003e(arena: \u0026Arena, tokens: \u0026mut T) -\u003e ParseResult\u003cBlock\u003e {\n    let mut parser = BlockParser::new(arena);\n    let block_ref = parser.parse_block(tokens)?;\n    Ok(block_ref.clone())\n}\n\npub fn parse_braced_block\u003cT: TokenStream\u003e(arena: \u0026Arena, tokens: \u0026mut T) -\u003e ParseResult\u003cBlock\u003e {\n    let mut parser = BlockParser::new(arena);\n    let block_ref = parser.parse_braced_block(tokens)?;\n    Ok(block_ref.clone())\n}\n\npub fn parse_indented_block\u003cT: TokenStream\u003e(arena: \u0026Arena, tokens: \u0026mut T) -\u003e ParseResult\u003cBlock\u003e {\n    let mut parser = BlockParser::new(arena);\n    let block_ref = parser.parse_indented_block(tokens)?;\n    Ok(block_ref.clone())\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_block_parser_creation() {\n        let arena = Arena::new();\n        let _parser = BlockParser::new(\u0026arena);\n    }\n\n    #[test]\n    fn test_block_style_consistency() {\n        // Test that mixing block styles is detected as an error\n        assert_eq!(BlockStyle::Braced, BlockStyle::Braced);\n        assert_ne!(BlockStyle::Braced, BlockStyle::Indented);\n    }\n}\n","traces":[{"line":42,"address":[],"length":0,"stats":{"Line":26}},{"line":52,"address":[],"length":0,"stats":{"Line":4}},{"line":53,"address":[],"length":0,"stats":{"Line":4}},{"line":55,"address":[],"length":0,"stats":{"Line":4}},{"line":56,"address":[],"length":0,"stats":{"Line":2}},{"line":57,"address":[],"length":0,"stats":{"Line":1}},{"line":58,"address":[],"length":0,"stats":{"Line":1}},{"line":63,"address":[],"length":0,"stats":{"Line":17}},{"line":67,"address":[],"length":0,"stats":{"Line":17}},{"line":70,"address":[],"length":0,"stats":{"Line":17}},{"line":73,"address":[],"length":0,"stats":{"Line":1}},{"line":74,"address":[],"length":0,"stats":{"Line":16}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":1}},{"line":81,"address":[],"length":0,"stats":{"Line":17}},{"line":82,"address":[],"length":0,"stats":{"Line":17}},{"line":85,"address":[],"length":0,"stats":{"Line":82}},{"line":86,"address":[],"length":0,"stats":{"Line":32}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":17}},{"line":91,"address":[],"length":0,"stats":{"Line":17}},{"line":93,"address":[],"length":0,"stats":{"Line":17}},{"line":95,"address":[],"length":0,"stats":{"Line":17}},{"line":96,"address":[],"length":0,"stats":{"Line":17}},{"line":97,"address":[],"length":0,"stats":{"Line":17}},{"line":98,"address":[],"length":0,"stats":{"Line":17}},{"line":99,"address":[],"length":0,"stats":{"Line":17}},{"line":100,"address":[],"length":0,"stats":{"Line":17}},{"line":101,"address":[],"length":0,"stats":{"Line":17}},{"line":102,"address":[],"length":0,"stats":{"Line":17}},{"line":103,"address":[],"length":0,"stats":{"Line":17}},{"line":106,"address":[],"length":0,"stats":{"Line":17}},{"line":110,"address":[],"length":0,"stats":{"Line":5}},{"line":114,"address":[],"length":0,"stats":{"Line":5}},{"line":117,"address":[],"length":0,"stats":{"Line":5}},{"line":120,"address":[],"length":0,"stats":{"Line":5}},{"line":123,"address":[],"length":0,"stats":{"Line":1}},{"line":124,"address":[],"length":0,"stats":{"Line":4}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":1}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":4}},{"line":132,"address":[],"length":0,"stats":{"Line":4}},{"line":135,"address":[],"length":0,"stats":{"Line":5}},{"line":137,"address":[],"length":0,"stats":{"Line":1}},{"line":138,"address":[],"length":0,"stats":{"Line":1}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":1}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":4}},{"line":150,"address":[],"length":0,"stats":{"Line":1}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":3}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":17}},{"line":177,"address":[],"length":0,"stats":{"Line":17}},{"line":179,"address":[],"length":0,"stats":{"Line":17}},{"line":181,"address":[],"length":0,"stats":{"Line":12}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":1}},{"line":187,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":2}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":3}},{"line":200,"address":[],"length":0,"stats":{"Line":12}},{"line":204,"address":[],"length":0,"stats":{"Line":12}},{"line":205,"address":[],"length":0,"stats":{"Line":36}},{"line":207,"address":[],"length":0,"stats":{"Line":12}},{"line":208,"address":[],"length":0,"stats":{"Line":24}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":12}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":12}},{"line":222,"address":[],"length":0,"stats":{"Line":12}},{"line":223,"address":[],"length":0,"stats":{"Line":12}},{"line":224,"address":[],"length":0,"stats":{"Line":12}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":12}},{"line":231,"address":[],"length":0,"stats":{"Line":12}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":3}},{"line":255,"address":[],"length":0,"stats":{"Line":6}},{"line":258,"address":[],"length":0,"stats":{"Line":3}},{"line":259,"address":[],"length":0,"stats":{"Line":3}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":15}},{"line":271,"address":[],"length":0,"stats":{"Line":15}},{"line":272,"address":[],"length":0,"stats":{"Line":15}},{"line":273,"address":[],"length":0,"stats":{"Line":15}},{"line":274,"address":[],"length":0,"stats":{"Line":15}},{"line":277,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":56}},{"line":279,"address":[],"length":0,"stats":{"Line":56}},{"line":280,"address":[],"length":0,"stats":{"Line":2}},{"line":281,"address":[],"length":0,"stats":{"Line":0}},{"line":282,"address":[],"length":0,"stats":{"Line":2}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":285,"address":[],"length":0,"stats":{"Line":2}},{"line":287,"address":[],"length":0,"stats":{"Line":2}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":2}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":2}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":45}},{"line":303,"address":[],"length":0,"stats":{"Line":15}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":33}},{"line":323,"address":[],"length":0,"stats":{"Line":41}},{"line":327,"address":[],"length":0,"stats":{"Line":15}},{"line":328,"address":[],"length":0,"stats":{"Line":15}},{"line":329,"address":[],"length":0,"stats":{"Line":15}},{"line":333,"address":[],"length":0,"stats":{"Line":15}},{"line":334,"address":[],"length":0,"stats":{"Line":15}},{"line":335,"address":[],"length":0,"stats":{"Line":15}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":346,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":0}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":1}},{"line":379,"address":[],"length":0,"stats":{"Line":1}},{"line":382,"address":[],"length":0,"stats":{"Line":2}},{"line":383,"address":[],"length":0,"stats":{"Line":1}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":1}},{"line":389,"address":[],"length":0,"stats":{"Line":1}},{"line":391,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":1}},{"line":395,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":1}},{"line":401,"address":[],"length":0,"stats":{"Line":1}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":412,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":419,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":424,"address":[],"length":0,"stats":{"Line":0}},{"line":427,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":1}},{"line":454,"address":[],"length":0,"stats":{"Line":2}},{"line":457,"address":[],"length":0,"stats":{"Line":0}},{"line":458,"address":[],"length":0,"stats":{"Line":0}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":461,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":0}},{"line":463,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":0}},{"line":465,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":1}},{"line":476,"address":[],"length":0,"stats":{"Line":1}},{"line":479,"address":[],"length":0,"stats":{"Line":1}},{"line":481,"address":[],"length":0,"stats":{"Line":2}},{"line":484,"address":[],"length":0,"stats":{"Line":0}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":0}},{"line":487,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":489,"address":[],"length":0,"stats":{"Line":0}},{"line":490,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":492,"address":[],"length":0,"stats":{"Line":0}},{"line":495,"address":[],"length":0,"stats":{"Line":0}},{"line":499,"address":[],"length":0,"stats":{"Line":1}},{"line":503,"address":[],"length":0,"stats":{"Line":1}},{"line":506,"address":[],"length":0,"stats":{"Line":1}},{"line":508,"address":[],"length":0,"stats":{"Line":2}},{"line":511,"address":[],"length":0,"stats":{"Line":0}},{"line":512,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":0}},{"line":514,"address":[],"length":0,"stats":{"Line":0}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":0}},{"line":517,"address":[],"length":0,"stats":{"Line":0}},{"line":518,"address":[],"length":0,"stats":{"Line":0}},{"line":519,"address":[],"length":0,"stats":{"Line":0}},{"line":522,"address":[],"length":0,"stats":{"Line":0}},{"line":526,"address":[],"length":0,"stats":{"Line":2}},{"line":528,"address":[],"length":0,"stats":{"Line":2}},{"line":529,"address":[],"length":0,"stats":{"Line":11}},{"line":530,"address":[],"length":0,"stats":{"Line":5}},{"line":531,"address":[],"length":0,"stats":{"Line":1}},{"line":532,"address":[],"length":0,"stats":{"Line":1}},{"line":533,"address":[],"length":0,"stats":{"Line":1}},{"line":536,"address":[],"length":0,"stats":{"Line":4}},{"line":539,"address":[],"length":0,"stats":{"Line":1}},{"line":543,"address":[],"length":0,"stats":{"Line":46}},{"line":548,"address":[],"length":0,"stats":{"Line":46}},{"line":549,"address":[],"length":0,"stats":{"Line":46}},{"line":550,"address":[],"length":0,"stats":{"Line":46}},{"line":551,"address":[],"length":0,"stats":{"Line":46}},{"line":552,"address":[],"length":0,"stats":{"Line":46}},{"line":554,"address":[],"length":0,"stats":{"Line":0}},{"line":555,"address":[],"length":0,"stats":{"Line":0}},{"line":556,"address":[],"length":0,"stats":{"Line":0}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":564,"address":[],"length":0,"stats":{"Line":0}},{"line":565,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":1}},{"line":570,"address":[],"length":0,"stats":{"Line":1}},{"line":571,"address":[],"length":0,"stats":{"Line":2}},{"line":572,"address":[],"length":0,"stats":{"Line":0}},{"line":575,"address":[],"length":0,"stats":{"Line":1}},{"line":576,"address":[],"length":0,"stats":{"Line":1}},{"line":577,"address":[],"length":0,"stats":{"Line":2}},{"line":578,"address":[],"length":0,"stats":{"Line":0}}],"covered":132,"coverable":265},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","error","mod.rs"],"content":"//! Error handling and diagnostics for the parser\n//!\n//! Implements \"positive-first\" error messaging and recovery strategies\n\npub mod parse_error;\npub mod recovery;\n\npub use parse_error::*;\npub use recovery::*;\n\n/// Result type for parser operations\npub type ParseResult\u003cT\u003e = Result\u003cT, ParseError\u003e;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","error","parse_error.rs"],"content":"//! Parse error types and positive-first error messaging\n\nuse crate::token::{Span, Token};\nuse thiserror::Error;\n\n/// Error severity levels for better diagnostics\n#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]\npub enum ErrorSeverity {\n    /// Warning: non-blocking issues that should be addressed\n    Warning,\n    /// Error: blocking issues that prevent successful parsing\n    Error,\n    /// Fatal: critical issues that stop all parsing\n    Fatal,\n}\n\nimpl std::fmt::Display for ErrorSeverity {\n    fn fmt(\u0026self, f: \u0026mut std::fmt::Formatter\u003c'_\u003e) -\u003e std::fmt::Result {\n        match self {\n            ErrorSeverity::Warning =\u003e write!(f, \"warning\"),\n            ErrorSeverity::Error =\u003e write!(f, \"error\"),\n            ErrorSeverity::Fatal =\u003e write!(f, \"fatal\"),\n        }\n    }\n}\n\n/// Parse errors with location information and positive-first messaging\n#[derive(Error, Debug, Clone)]\npub enum ParseError {\n    #[error(\"Expected {expected}, but found {found}\")]\n    UnexpectedToken {\n        expected: String,\n        found: String,\n        span: Span,\n        suggestion: Option\u003cString\u003e,\n        severity: ErrorSeverity,\n        error_code: Option\u003c\u0026'static str\u003e,\n    },\n\n    #[error(\"Expected expression\")]\n    ExpectedExpression {\n        span: Span,\n        suggestion: Option\u003cString\u003e,\n        severity: ErrorSeverity,\n        error_code: Option\u003c\u0026'static str\u003e,\n    },\n\n    #[error(\"Expected statement\")]\n    ExpectedStatement {\n        span: Span,\n        suggestion: Option\u003cString\u003e,\n        severity: ErrorSeverity,\n        error_code: Option\u003c\u0026'static str\u003e,\n    },\n\n    #[error(\"Expected type expression\")]\n    ExpectedType {\n        span: Span,\n        suggestion: Option\u003cString\u003e,\n        severity: ErrorSeverity,\n        error_code: Option\u003c\u0026'static str\u003e,\n    },\n\n    #[error(\"Invalid block structure: {message}\")]\n    InvalidBlock {\n        message: String,\n        span: Span,\n        suggestion: Option\u003cString\u003e,\n        severity: ErrorSeverity,\n        error_code: Option\u003c\u0026'static str\u003e,\n    },\n\n    #[error(\"Mixed block styles are not allowed in the same block\")]\n    MixedBlockStyles {\n        span: Span,\n        suggestion: Option\u003cString\u003e,\n        severity: ErrorSeverity,\n        error_code: Option\u003c\u0026'static str\u003e,\n    },\n\n    #[error(\"Inconsistent indentation\")]\n    InconsistentIndentation {\n        span: Span,\n        expected_level: usize,\n        found_level: usize,\n        suggestion: Option\u003cString\u003e,\n        severity: ErrorSeverity,\n        error_code: Option\u003c\u0026'static str\u003e,\n    },\n\n    #[error(\"Expected block (either braced or indented)\")]\n    ExpectedBlock {\n        span: Span,\n        suggestion: Option\u003cString\u003e,\n        severity: ErrorSeverity,\n        error_code: Option\u003c\u0026'static str\u003e,\n    },\n\n    #[error(\"Invalid indentation level\")]\n    InvalidIndentation {\n        span: Span,\n        suggestion: Option\u003cString\u003e,\n        severity: ErrorSeverity,\n        error_code: Option\u003c\u0026'static str\u003e,\n    },\n\n    #[error(\"Variable '{variable}' is already defined in this scope\")]\n    VariableRedefinition {\n        variable: String,\n        span: Span,\n        suggestion: Option\u003cString\u003e,\n        severity: ErrorSeverity,\n        error_code: Option\u003c\u0026'static str\u003e,\n    },\n\n    #[error(\"Unexpected end of file\")]\n    UnexpectedEof {\n        expected: String,\n        span: Span,\n        severity: ErrorSeverity,\n        error_code: Option\u003c\u0026'static str\u003e,\n    },\n\n    #[error(\"Internal parser error: {message}\")]\n    Internal {\n        message: String,\n        span: Span,\n        severity: ErrorSeverity,\n        error_code: Option\u003c\u0026'static str\u003e,\n    },\n\n    #[error(\"Syntax error: {message}\")]\n    SyntaxError {\n        message: String,\n        span: Span,\n        suggestion: Option\u003cString\u003e,\n        severity: ErrorSeverity,\n        error_code: Option\u003c\u0026'static str\u003e,\n    },\n\n    #[error(\"Recovery error: {message}\")]\n    RecoveryError {\n        message: String,\n        span: Span,\n        original_error: Box\u003cParseError\u003e,\n        severity: ErrorSeverity,\n        error_code: Option\u003c\u0026'static str\u003e,\n    },\n}\n\nimpl ParseError {\n    /// Create an unexpected token error with positive-first messaging\n    pub fn unexpected_token(expected: \u0026str, found: \u0026Token) -\u003e Self {\n        let found_str = format!(\"{:?}\", found.token_type);\n        Self::UnexpectedToken {\n            expected: expected.to_string(),\n            found: found_str,\n            span: found.span.clone(),\n            suggestion: None,\n            severity: ErrorSeverity::Error,\n            error_code: None,\n        }\n    }\n\n    /// Create an unexpected token error with suggestion\n    pub fn unexpected_token_with_suggestion(\n        expected: \u0026str,\n        found: \u0026Token,\n        suggestion: \u0026str,\n    ) -\u003e Self {\n        let found_str = format!(\"{:?}\", found.token_type);\n        Self::UnexpectedToken {\n            expected: expected.to_string(),\n            found: found_str,\n            span: found.span.clone(),\n            suggestion: Some(suggestion.to_string()),\n            severity: ErrorSeverity::Error,\n            error_code: None,\n        }\n    }\n\n    /// Create an expected expression error\n    pub fn expected_expression(span: Span) -\u003e Self {\n        Self::ExpectedExpression {\n            span,\n            suggestion: Some(\n                \"Consider adding a literal, identifier, or parenthesized expression\".to_string(),\n            ),\n            severity: ErrorSeverity::Error,\n            error_code: None,\n        }\n    }\n\n    /// Create an expected statement error\n    pub fn expected_statement(span: Span) -\u003e Self {\n        Self::ExpectedStatement {\n            span,\n            suggestion: Some(\n                \"Statements can be declarations (let, var, fn, data) or expressions\".to_string(),\n            ),\n            severity: ErrorSeverity::Error,\n            error_code: None,\n        }\n    }\n\n    /// Create an expected type error\n    pub fn expected_type(span: Span) -\u003e Self {\n        Self::ExpectedType {\n            span,\n            suggestion: Some(\n                \"Type expressions include identifiers, tuples, arrays, and function types\"\n                    .to_string(),\n            ),\n            severity: ErrorSeverity::Error,\n            error_code: None,\n        }\n    }\n\n    /// Create a mixed block styles error\n    pub fn mixed_block_styles(span: Span) -\u003e Self {\n        Self::MixedBlockStyles {\n            span,\n            suggestion: Some(\n                \"Use either braces {...} OR indentation consistently within a single block\"\n                    .to_string(),\n            ),\n            severity: ErrorSeverity::Error,\n            error_code: None,\n        }\n    }\n\n    /// Create an inconsistent indentation error\n    pub fn inconsistent_indentation(span: Span, expected: usize, found: usize) -\u003e Self {\n        Self::InconsistentIndentation {\n            span,\n            expected_level: expected,\n            found_level: found,\n            suggestion: Some(format!(\"All statements in an indented block must be at the same level (expected {} spaces)\", expected)),\n            severity: ErrorSeverity::Error,\n            error_code: None,\n        }\n    }\n\n    /// Create an expected block error\n    pub fn expected_block(span: Span) -\u003e Self {\n        Self::ExpectedBlock {\n            span,\n            suggestion: Some(\"Consider adding a block (either braced or indented)\".to_string()),\n            severity: ErrorSeverity::Error,\n            error_code: None,\n        }\n    }\n\n    /// Create an invalid indentation error\n    pub fn invalid_indentation(span: Span) -\u003e Self {\n        Self::InvalidIndentation {\n            span,\n            suggestion: Some(\"Check the indentation level of the block\".to_string()),\n            severity: ErrorSeverity::Error,\n            error_code: None,\n        }\n    }\n\n    /// Create a variable redefinition error\n    pub fn variable_redefinition(variable: \u0026str, span: Span) -\u003e Self {\n        Self::VariableRedefinition {\n            variable: variable.to_string(),\n            span: span.clone(),\n            suggestion: None,\n            severity: ErrorSeverity::Error,\n            error_code: None,\n        }\n    }\n\n    /// Create an unexpected EOF error\n    pub fn unexpected_eof(expected: \u0026str, span: Span) -\u003e Self {\n        Self::UnexpectedEof {\n            expected: expected.to_string(),\n            span,\n            severity: ErrorSeverity::Error,\n            error_code: None,\n        }\n    }\n\n    /// Get the span of this error\n    pub fn span(\u0026self) -\u003e \u0026Span {\n        match self {\n            Self::UnexpectedToken { span, .. } =\u003e span,\n            Self::ExpectedExpression { span, .. } =\u003e span,\n            Self::ExpectedStatement { span, .. } =\u003e span,\n            Self::ExpectedType { span, .. } =\u003e span,\n            Self::InvalidBlock { span, .. } =\u003e span,\n            Self::MixedBlockStyles { span, .. } =\u003e span,\n            Self::InconsistentIndentation { span, .. } =\u003e span,\n            Self::ExpectedBlock { span, .. } =\u003e span,\n            Self::InvalidIndentation { span, .. } =\u003e span,\n            Self::VariableRedefinition { span, .. } =\u003e span,\n            Self::UnexpectedEof { span, .. } =\u003e span,\n            Self::Internal { span, .. } =\u003e span,\n            Self::SyntaxError { span, .. } =\u003e span,\n            Self::RecoveryError { span, .. } =\u003e span,\n        }\n    }\n\n    /// Get the suggestion for this error, if any\n    pub fn suggestion(\u0026self) -\u003e Option\u003c\u0026str\u003e {\n        match self {\n            Self::UnexpectedToken { suggestion, .. } =\u003e suggestion.as_deref(),\n            Self::ExpectedExpression { suggestion, .. } =\u003e suggestion.as_deref(),\n            Self::ExpectedStatement { suggestion, .. } =\u003e suggestion.as_deref(),\n            Self::ExpectedType { suggestion, .. } =\u003e suggestion.as_deref(),\n            Self::InvalidBlock { suggestion, .. } =\u003e suggestion.as_deref(),\n            Self::MixedBlockStyles { suggestion, .. } =\u003e suggestion.as_deref(),\n            Self::InconsistentIndentation { suggestion, .. } =\u003e suggestion.as_deref(),\n            Self::ExpectedBlock { suggestion, .. } =\u003e suggestion.as_deref(),\n            Self::InvalidIndentation { suggestion, .. } =\u003e suggestion.as_deref(),\n            Self::VariableRedefinition { suggestion, .. } =\u003e suggestion.as_deref(),\n            Self::UnexpectedEof { .. } =\u003e None,\n            Self::Internal { .. } =\u003e None,\n            Self::SyntaxError { suggestion, .. } =\u003e suggestion.as_deref(),\n            Self::RecoveryError { .. } =\u003e None,\n        }\n    }\n\n    /// Get the severity of this error\n    pub fn severity(\u0026self) -\u003e ErrorSeverity {\n        match self {\n            Self::UnexpectedToken { severity, .. } =\u003e *severity,\n            Self::ExpectedExpression { severity, .. } =\u003e *severity,\n            Self::ExpectedStatement { severity, .. } =\u003e *severity,\n            Self::ExpectedType { severity, .. } =\u003e *severity,\n            Self::InvalidBlock { severity, .. } =\u003e *severity,\n            Self::MixedBlockStyles { severity, .. } =\u003e *severity,\n            Self::InconsistentIndentation { severity, .. } =\u003e *severity,\n            Self::ExpectedBlock { severity, .. } =\u003e *severity,\n            Self::InvalidIndentation { severity, .. } =\u003e *severity,\n            Self::VariableRedefinition { severity, .. } =\u003e *severity,\n            Self::UnexpectedEof { severity, .. } =\u003e *severity,\n            Self::Internal { severity, .. } =\u003e *severity,\n            Self::SyntaxError { severity, .. } =\u003e *severity,\n            Self::RecoveryError { severity, .. } =\u003e *severity,\n        }\n    }\n\n    /// Get the error code, if any\n    pub fn error_code(\u0026self) -\u003e Option\u003c\u0026'static str\u003e {\n        match self {\n            Self::UnexpectedToken { error_code, .. } =\u003e *error_code,\n            Self::ExpectedExpression { error_code, .. } =\u003e *error_code,\n            Self::ExpectedStatement { error_code, .. } =\u003e *error_code,\n            Self::ExpectedType { error_code, .. } =\u003e *error_code,\n            Self::InvalidBlock { error_code, .. } =\u003e *error_code,\n            Self::MixedBlockStyles { error_code, .. } =\u003e *error_code,\n            Self::InconsistentIndentation { error_code, .. } =\u003e *error_code,\n            Self::ExpectedBlock { error_code, .. } =\u003e *error_code,\n            Self::InvalidIndentation { error_code, .. } =\u003e *error_code,\n            Self::VariableRedefinition { error_code, .. } =\u003e *error_code,\n            Self::UnexpectedEof { error_code, .. } =\u003e *error_code,\n            Self::Internal { error_code, .. } =\u003e *error_code,\n            Self::SyntaxError { error_code, .. } =\u003e *error_code,\n            Self::RecoveryError { error_code, .. } =\u003e *error_code,\n        }\n    }\n\n    /// Create a syntax error with custom message\n    pub fn syntax_error(message: \u0026str, span: Span) -\u003e Self {\n        Self::SyntaxError {\n            message: message.to_string(),\n            span,\n            suggestion: None,\n            severity: ErrorSeverity::Error,\n            error_code: Some(\"E001\"),\n        }\n    }\n\n    /// Create a syntax error with suggestion\n    pub fn syntax_error_with_suggestion(message: \u0026str, span: Span, suggestion: \u0026str) -\u003e Self {\n        Self::SyntaxError {\n            message: message.to_string(),\n            span,\n            suggestion: Some(suggestion.to_string()),\n            severity: ErrorSeverity::Error,\n            error_code: Some(\"E001\"),\n        }\n    }\n\n    /// Create a recovery error that wraps another error\n    pub fn recovery_error(message: \u0026str, span: Span, original: ParseError) -\u003e Self {\n        Self::RecoveryError {\n            message: message.to_string(),\n            span,\n            original_error: Box::new(original),\n            severity: ErrorSeverity::Warning,\n            error_code: Some(\"R001\"),\n        }\n    }\n\n    /// Create an internal error (fatal)\n    pub fn internal(message: \u0026str, span: Span) -\u003e Self {\n        Self::Internal {\n            message: message.to_string(),\n            span,\n            severity: ErrorSeverity::Fatal,\n            error_code: Some(\"I001\"),\n        }\n    }\n\n    /// Set the severity of this error\n    pub fn with_severity(mut self, severity: ErrorSeverity) -\u003e Self {\n        match \u0026mut self {\n            Self::UnexpectedToken { severity: s, .. } =\u003e *s = severity,\n            Self::ExpectedExpression { severity: s, .. } =\u003e *s = severity,\n            Self::ExpectedStatement { severity: s, .. } =\u003e *s = severity,\n            Self::ExpectedType { severity: s, .. } =\u003e *s = severity,\n            Self::InvalidBlock { severity: s, .. } =\u003e *s = severity,\n            Self::MixedBlockStyles { severity: s, .. } =\u003e *s = severity,\n            Self::InconsistentIndentation { severity: s, .. } =\u003e *s = severity,\n            Self::ExpectedBlock { severity: s, .. } =\u003e *s = severity,\n            Self::InvalidIndentation { severity: s, .. } =\u003e *s = severity,\n            Self::VariableRedefinition { severity: s, .. } =\u003e *s = severity,\n            Self::UnexpectedEof { severity: s, .. } =\u003e *s = severity,\n            Self::Internal { severity: s, .. } =\u003e *s = severity,\n            Self::SyntaxError { severity: s, .. } =\u003e *s = severity,\n            Self::RecoveryError { severity: s, .. } =\u003e *s = severity,\n        }\n        self\n    }\n\n    /// Set the error code of this error\n    pub fn with_error_code(mut self, code: \u0026'static str) -\u003e Self {\n        match \u0026mut self {\n            Self::UnexpectedToken { error_code, .. } =\u003e *error_code = Some(code),\n            Self::ExpectedExpression { error_code, .. } =\u003e *error_code = Some(code),\n            Self::ExpectedStatement { error_code, .. } =\u003e *error_code = Some(code),\n            Self::ExpectedType { error_code, .. } =\u003e *error_code = Some(code),\n            Self::InvalidBlock { error_code, .. } =\u003e *error_code = Some(code),\n            Self::MixedBlockStyles { error_code, .. } =\u003e *error_code = Some(code),\n            Self::InconsistentIndentation { error_code, .. } =\u003e *error_code = Some(code),\n            Self::ExpectedBlock { error_code, .. } =\u003e *error_code = Some(code),\n            Self::InvalidIndentation { error_code, .. } =\u003e *error_code = Some(code),\n            Self::VariableRedefinition { error_code, .. } =\u003e *error_code = Some(code),\n            Self::UnexpectedEof { error_code, .. } =\u003e *error_code = Some(code),\n            Self::Internal { error_code, .. } =\u003e *error_code = Some(code),\n            Self::SyntaxError { error_code, .. } =\u003e *error_code = Some(code),\n            Self::RecoveryError { error_code, .. } =\u003e *error_code = Some(code),\n        }\n        self\n    }\n\n    /// Format the error with enhanced diagnostics\n    pub fn format_diagnostic(\u0026self, source_name: Option\u003c\u0026str\u003e) -\u003e String {\n        let severity = self.severity();\n        let span = self.span();\n        let error_code = self.error_code().unwrap_or(\"E000\");\n\n        let mut output = format!(\"{}: [{}] {}\", severity, error_code, self);\n\n        if let Some(source) = source_name {\n            output.push('\\n');\n            output.push_str(\u0026format!(\"  --\u003e {}:{}:{}\", source, span.line, span.column));\n        } else {\n            output.push('\\n');\n            output.push_str(\u0026format!(\"  --\u003e line {}:{}\", span.line, span.column));\n        }\n\n        if let Some(suggestion) = self.suggestion() {\n            output.push('\\n');\n            output.push_str(\u0026format!(\"  help: {}\", suggestion));\n        }\n\n        if let Self::RecoveryError { original_error, .. } = self {\n            output.push('\\n');\n            output.push_str(\u0026format!(\"  caused by: {}\", original_error));\n        }\n\n        output\n    }\n\n    /// Check if this error should stop parsing\n    pub fn should_stop_parsing(\u0026self) -\u003e bool {\n        self.severity() == ErrorSeverity::Fatal\n    }\n\n    /// Check if this error can be recovered from\n    pub fn is_recoverable(\u0026self) -\u003e bool {\n        self.severity() != ErrorSeverity::Fatal\n    }\n}\n\n/// Multi-error diagnostic report\n#[derive(Debug, Clone)]\npub struct DiagnosticReport {\n    /// All collected errors\n    pub errors: Vec\u003cParseError\u003e,\n    /// Source file name (optional)\n    pub source_name: Option\u003cString\u003e,\n    /// Whether parsing was successful despite errors\n    pub success: bool,\n}\n\nimpl DiagnosticReport {\n    /// Create a new diagnostic report\n    pub fn new(source_name: Option\u003cString\u003e) -\u003e Self {\n        Self {\n            errors: Vec::new(),\n            source_name,\n            success: true,\n        }\n    }\n\n    /// Add an error to the report\n    pub fn add_error(\u0026mut self, error: ParseError) {\n        if error.should_stop_parsing() {\n            self.success = false;\n        }\n        self.errors.push(error);\n    }\n\n    /// Add multiple errors to the report\n    pub fn add_errors(\u0026mut self, errors: Vec\u003cParseError\u003e) {\n        for error in errors {\n            self.add_error(error);\n        }\n    }\n\n    /// Check if the report has any errors\n    pub fn has_errors(\u0026self) -\u003e bool {\n        !self.errors.is_empty()\n    }\n\n    /// Get all errors of a specific severity\n    pub fn errors_with_severity(\u0026self, severity: ErrorSeverity) -\u003e Vec\u003c\u0026ParseError\u003e {\n        self.errors\n            .iter()\n            .filter(|e| e.severity() == severity)\n            .collect()\n    }\n\n    /// Get error count by severity\n    pub fn error_count_by_severity(\u0026self, severity: ErrorSeverity) -\u003e usize {\n        self.errors\n            .iter()\n            .filter(|e| e.severity() == severity)\n            .count()\n    }\n\n    /// Format the entire diagnostic report\n    pub fn format_report(\u0026self) -\u003e String {\n        if self.errors.is_empty() {\n            return \"No errors found.\".to_string();\n        }\n\n        let mut output = String::new();\n\n        // Summary\n        let fatal_count = self.error_count_by_severity(ErrorSeverity::Fatal);\n        let error_count = self.error_count_by_severity(ErrorSeverity::Error);\n        let warning_count = self.error_count_by_severity(ErrorSeverity::Warning);\n\n        output.push_str(\u0026format!(\n            \"Parse result: {} ({} errors, {} warnings, {} fatal)\\n\\n\",\n            if self.success { \"success\" } else { \"failed\" },\n            error_count,\n            warning_count,\n            fatal_count\n        ));\n\n        // Individual errors\n        for (i, error) in self.errors.iter().enumerate() {\n            if i \u003e 0 {\n                output.push('\\n');\n            }\n            output.push_str(\u0026error.format_diagnostic(self.source_name.as_deref()));\n        }\n\n        output\n    }\n\n    /// Check if parsing should continue based on error severity\n    pub fn should_continue_parsing(\u0026self) -\u003e bool {\n        self.success \u0026\u0026 !self.errors.iter().any(|e| e.should_stop_parsing())\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::token::TokenType;\n\n    #[test]\n    fn test_unexpected_token_error() {\n        let token = Token::dummy(TokenType::Plus);\n        let error = ParseError::unexpected_token(\"identifier\", \u0026token);\n\n        assert!(error.to_string().contains(\"Expected identifier\"));\n        assert!(error.to_string().contains(\"found Plus\"));\n    }\n\n    #[test]\n    fn test_error_with_suggestion() {\n        let token = Token::dummy(TokenType::LeftBrace);\n        let error = ParseError::unexpected_token_with_suggestion(\n            \"semicolon\",\n            \u0026token,\n            \"Try adding a ';' to end the statement\",\n        );\n\n        assert_eq!(\n            error.suggestion(),\n            Some(\"Try adding a ';' to end the statement\")\n        );\n    }\n}\n","traces":[{"line":18,"address":[],"length":0,"stats":{"Line":4}},{"line":19,"address":[],"length":0,"stats":{"Line":4}},{"line":20,"address":[],"length":0,"stats":{"Line":2}},{"line":21,"address":[],"length":0,"stats":{"Line":2}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":25}},{"line":154,"address":[],"length":0,"stats":{"Line":25}},{"line":156,"address":[],"length":0,"stats":{"Line":25}},{"line":158,"address":[],"length":0,"stats":{"Line":25}},{"line":166,"address":[],"length":0,"stats":{"Line":8}},{"line":171,"address":[],"length":0,"stats":{"Line":8}},{"line":173,"address":[],"length":0,"stats":{"Line":8}},{"line":175,"address":[],"length":0,"stats":{"Line":8}},{"line":176,"address":[],"length":0,"stats":{"Line":8}},{"line":183,"address":[],"length":0,"stats":{"Line":1}},{"line":186,"address":[],"length":0,"stats":{"Line":1}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":3}},{"line":223,"address":[],"length":0,"stats":{"Line":3}},{"line":233,"address":[],"length":0,"stats":{"Line":1}},{"line":238,"address":[],"length":0,"stats":{"Line":1}},{"line":245,"address":[],"length":0,"stats":{"Line":1}},{"line":248,"address":[],"length":0,"stats":{"Line":1}},{"line":255,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":1}},{"line":267,"address":[],"length":0,"stats":{"Line":1}},{"line":268,"address":[],"length":0,"stats":{"Line":1}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":4}},{"line":287,"address":[],"length":0,"stats":{"Line":4}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":289,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":3}},{"line":301,"address":[],"length":0,"stats":{"Line":1}},{"line":306,"address":[],"length":0,"stats":{"Line":9}},{"line":307,"address":[],"length":0,"stats":{"Line":9}},{"line":308,"address":[],"length":0,"stats":{"Line":4}},{"line":309,"address":[],"length":0,"stats":{"Line":1}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":316,"address":[],"length":0,"stats":{"Line":0}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":0}},{"line":320,"address":[],"length":0,"stats":{"Line":3}},{"line":321,"address":[],"length":0,"stats":{"Line":1}},{"line":326,"address":[],"length":0,"stats":{"Line":34}},{"line":327,"address":[],"length":0,"stats":{"Line":34}},{"line":328,"address":[],"length":0,"stats":{"Line":1}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":32}},{"line":341,"address":[],"length":0,"stats":{"Line":1}},{"line":346,"address":[],"length":0,"stats":{"Line":8}},{"line":347,"address":[],"length":0,"stats":{"Line":8}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":1}},{"line":360,"address":[],"length":0,"stats":{"Line":5}},{"line":361,"address":[],"length":0,"stats":{"Line":2}},{"line":366,"address":[],"length":0,"stats":{"Line":15}},{"line":368,"address":[],"length":0,"stats":{"Line":15}},{"line":372,"address":[],"length":0,"stats":{"Line":15}},{"line":377,"address":[],"length":0,"stats":{"Line":1}},{"line":379,"address":[],"length":0,"stats":{"Line":1}},{"line":381,"address":[],"length":0,"stats":{"Line":1}},{"line":383,"address":[],"length":0,"stats":{"Line":1}},{"line":388,"address":[],"length":0,"stats":{"Line":2}},{"line":390,"address":[],"length":0,"stats":{"Line":2}},{"line":392,"address":[],"length":0,"stats":{"Line":2}},{"line":394,"address":[],"length":0,"stats":{"Line":2}},{"line":399,"address":[],"length":0,"stats":{"Line":1}},{"line":401,"address":[],"length":0,"stats":{"Line":1}},{"line":404,"address":[],"length":0,"stats":{"Line":1}},{"line":409,"address":[],"length":0,"stats":{"Line":7}},{"line":410,"address":[],"length":0,"stats":{"Line":7}},{"line":411,"address":[],"length":0,"stats":{"Line":0}},{"line":412,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":418,"address":[],"length":0,"stats":{"Line":0}},{"line":419,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":421,"address":[],"length":0,"stats":{"Line":0}},{"line":422,"address":[],"length":0,"stats":{"Line":0}},{"line":423,"address":[],"length":0,"stats":{"Line":7}},{"line":424,"address":[],"length":0,"stats":{"Line":0}},{"line":426,"address":[],"length":0,"stats":{"Line":7}},{"line":430,"address":[],"length":0,"stats":{"Line":1}},{"line":431,"address":[],"length":0,"stats":{"Line":1}},{"line":432,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":0}},{"line":434,"address":[],"length":0,"stats":{"Line":0}},{"line":435,"address":[],"length":0,"stats":{"Line":0}},{"line":436,"address":[],"length":0,"stats":{"Line":0}},{"line":437,"address":[],"length":0,"stats":{"Line":0}},{"line":438,"address":[],"length":0,"stats":{"Line":0}},{"line":439,"address":[],"length":0,"stats":{"Line":0}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":441,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":1}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":1}},{"line":451,"address":[],"length":0,"stats":{"Line":4}},{"line":452,"address":[],"length":0,"stats":{"Line":4}},{"line":453,"address":[],"length":0,"stats":{"Line":4}},{"line":454,"address":[],"length":0,"stats":{"Line":4}},{"line":456,"address":[],"length":0,"stats":{"Line":4}},{"line":458,"address":[],"length":0,"stats":{"Line":7}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":462,"address":[],"length":0,"stats":{"Line":1}},{"line":463,"address":[],"length":0,"stats":{"Line":1}},{"line":466,"address":[],"length":0,"stats":{"Line":5}},{"line":467,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":471,"address":[],"length":0,"stats":{"Line":5}},{"line":472,"address":[],"length":0,"stats":{"Line":0}},{"line":473,"address":[],"length":0,"stats":{"Line":0}},{"line":476,"address":[],"length":0,"stats":{"Line":4}},{"line":480,"address":[],"length":0,"stats":{"Line":11}},{"line":481,"address":[],"length":0,"stats":{"Line":11}},{"line":485,"address":[],"length":0,"stats":{"Line":3}},{"line":486,"address":[],"length":0,"stats":{"Line":3}},{"line":503,"address":[],"length":0,"stats":{"Line":4}},{"line":505,"address":[],"length":0,"stats":{"Line":4}},{"line":512,"address":[],"length":0,"stats":{"Line":5}},{"line":513,"address":[],"length":0,"stats":{"Line":6}},{"line":514,"address":[],"length":0,"stats":{"Line":1}},{"line":516,"address":[],"length":0,"stats":{"Line":5}},{"line":520,"address":[],"length":0,"stats":{"Line":0}},{"line":521,"address":[],"length":0,"stats":{"Line":0}},{"line":527,"address":[],"length":0,"stats":{"Line":4}},{"line":528,"address":[],"length":0,"stats":{"Line":4}},{"line":532,"address":[],"length":0,"stats":{"Line":0}},{"line":533,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":540,"address":[],"length":0,"stats":{"Line":6}},{"line":541,"address":[],"length":0,"stats":{"Line":6}},{"line":543,"address":[],"length":0,"stats":{"Line":24}},{"line":548,"address":[],"length":0,"stats":{"Line":1}},{"line":549,"address":[],"length":0,"stats":{"Line":1}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":1}},{"line":556,"address":[],"length":0,"stats":{"Line":1}},{"line":557,"address":[],"length":0,"stats":{"Line":1}},{"line":558,"address":[],"length":0,"stats":{"Line":1}},{"line":560,"address":[],"length":0,"stats":{"Line":1}},{"line":561,"address":[],"length":0,"stats":{"Line":0}},{"line":562,"address":[],"length":0,"stats":{"Line":1}},{"line":569,"address":[],"length":0,"stats":{"Line":2}},{"line":570,"address":[],"length":0,"stats":{"Line":1}},{"line":571,"address":[],"length":0,"stats":{"Line":1}},{"line":573,"address":[],"length":0,"stats":{"Line":0}},{"line":576,"address":[],"length":0,"stats":{"Line":0}},{"line":580,"address":[],"length":0,"stats":{"Line":4}},{"line":581,"address":[],"length":0,"stats":{"Line":13}}],"covered":105,"coverable":199},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","error","recovery.rs"],"content":"//! Error recovery strategies for continuing parsing after errors\n\nuse crate::error::ParseError;\nuse crate::token::{Token, TokenStream, TokenType};\n\n/// Tokens that can be used for synchronization during error recovery\n#[derive(Debug, Clone, PartialEq)]\npub enum SyncToken {\n    StatementStart,\n    DeclarationStart,\n    BlockEnd,\n    StatementTerminator,\n    ExpressionStart,\n    ExpressionTerminator,\n}\n\nimpl SyncToken {\n    /// Check if a token can be used for synchronization\n    pub fn matches(\u0026self, token: \u0026Token) -\u003e bool {\n        match self {\n            SyncToken::StatementStart =\u003e matches!(\n                token.token_type,\n                TokenType::Let\n                    | TokenType::Var\n                    | TokenType::If\n                    | TokenType::While\n                    | TokenType::For\n                    | TokenType::Return\n                    | TokenType::Break\n                    | TokenType::Continue\n                    | TokenType::Match\n            ),\n            SyncToken::DeclarationStart =\u003e matches!(\n                token.token_type,\n                TokenType::Let\n                    | TokenType::Var\n                    | TokenType::Fn\n                    | TokenType::Data\n                    | TokenType::Extern\n            ),\n            SyncToken::BlockEnd =\u003e {\n                matches!(token.token_type, TokenType::RightBrace | TokenType::Dedent)\n            }\n            SyncToken::StatementTerminator =\u003e matches!(\n                token.token_type,\n                TokenType::Semicolon\n                    | TokenType::Newline\n                    | TokenType::RightBrace\n                    | TokenType::Dedent\n                    | TokenType::Eof\n            ),\n            SyncToken::ExpressionStart =\u003e matches!(\n                token.token_type,\n                TokenType::Identifier(_)\n                    | TokenType::IntegerLiteral(_)\n                    | TokenType::FloatLiteral(_)\n                    | TokenType::StringLiteral(_)\n                    | TokenType::BooleanLiteral(_)\n                    | TokenType::LeftParen\n                    | TokenType::LeftBracket\n                    | TokenType::Minus\n                    | TokenType::Bang\n            ),\n            SyncToken::ExpressionTerminator =\u003e matches!(\n                token.token_type,\n                TokenType::Semicolon\n                    | TokenType::Comma\n                    | TokenType::RightParen\n                    | TokenType::RightBracket\n                    | TokenType::RightBrace\n                    | TokenType::Newline\n                    | TokenType::Eof\n            ),\n        }\n    }\n}\n\n/// Error production rules for handling common syntax errors\n#[derive(Debug, Clone, PartialEq)]\npub enum ErrorProduction {\n    /// Missing semicolon after statement\n    MissingSemicolon,\n    /// Missing opening parenthesis in function call\n    MissingOpenParen,\n    /// Missing closing parenthesis in function call\n    MissingCloseParen,\n    /// Missing opening brace in block\n    MissingOpenBrace,\n    /// Missing closing brace in block\n    MissingCloseBrace,\n    /// Unmatched delimiter\n    UnmatchedDelimiter,\n    /// Incomplete expression\n    IncompleteExpression,\n    /// Invalid operator usage\n    InvalidOperator,\n}\n\nimpl ErrorProduction {\n    /// Check if this error production applies to the current parsing context\n    pub fn applies_to_context\u003cT: TokenStream\u003e(\n        \u0026self,\n        tokens: \u0026T,\n        context: \u0026str,\n    ) -\u003e Option\u003cParseError\u003e {\n        let current = tokens.peek();\n\n        match self {\n            ErrorProduction::MissingSemicolon =\u003e {\n                if context.contains(\"statement\")\n                    \u0026\u0026 !matches!(\n                        current.token_type,\n                        TokenType::Semicolon\n                            | TokenType::RightBrace\n                            | TokenType::Dedent\n                            | TokenType::Eof\n                    )\n                {\n                    Some(ParseError::unexpected_token_with_suggestion(\n                        \"semicolon or newline\",\n                        current,\n                        \"Try adding ';' at the end of the statement\",\n                    ))\n                } else {\n                    None\n                }\n            }\n            ErrorProduction::MissingOpenParen =\u003e {\n                if context.contains(\"function_call\")\n                    \u0026\u0026 !matches!(current.token_type, TokenType::LeftParen)\n                {\n                    Some(ParseError::unexpected_token_with_suggestion(\n                        \"opening parenthesis\",\n                        current,\n                        \"Function calls require parentheses: func(args)\",\n                    ))\n                } else {\n                    None\n                }\n            }\n            ErrorProduction::MissingCloseParen =\u003e {\n                if context.contains(\"parenthesized\")\n                    \u0026\u0026 !matches!(current.token_type, TokenType::RightParen)\n                {\n                    Some(ParseError::unexpected_token_with_suggestion(\n                        \"closing parenthesis\",\n                        current,\n                        \"Check for matching parentheses\",\n                    ))\n                } else {\n                    None\n                }\n            }\n            ErrorProduction::MissingOpenBrace =\u003e {\n                if context.contains(\"block\")\n                    \u0026\u0026 !matches!(current.token_type, TokenType::LeftBrace | TokenType::Colon)\n                {\n                    Some(ParseError::expected_block(current.span.clone()))\n                } else {\n                    None\n                }\n            }\n            ErrorProduction::MissingCloseBrace =\u003e {\n                if context.contains(\"braced_block\")\n                    \u0026\u0026 !matches!(current.token_type, TokenType::RightBrace)\n                {\n                    Some(ParseError::unexpected_token_with_suggestion(\n                        \"closing brace\",\n                        current,\n                        \"Check for matching braces in blocks\",\n                    ))\n                } else {\n                    None\n                }\n            }\n            ErrorProduction::UnmatchedDelimiter =\u003e match current.token_type {\n                TokenType::RightParen | TokenType::RightBracket | TokenType::RightBrace =\u003e {\n                    Some(ParseError::unexpected_token_with_suggestion(\n                        \"matching opening delimiter\",\n                        current,\n                        \"Check that all delimiters are properly matched\",\n                    ))\n                }\n                _ =\u003e None,\n            },\n            ErrorProduction::IncompleteExpression =\u003e {\n                if context.contains(\"expression\")\n                    \u0026\u0026 matches!(\n                        current.token_type,\n                        TokenType::Plus\n                            | TokenType::Minus\n                            | TokenType::Star\n                            | TokenType::Slash\n                            | TokenType::Equal\n                            | TokenType::EqualEqual\n                            | TokenType::BangEqual\n                            | TokenType::Less\n                            | TokenType::Greater\n                            | TokenType::LessEqual\n                            | TokenType::GreaterEqual\n                    )\n                {\n                    Some(ParseError::expected_expression(current.span.clone()))\n                } else {\n                    None\n                }\n            }\n            ErrorProduction::InvalidOperator =\u003e {\n                if context.contains(\"operator\") {\n                    Some(ParseError::unexpected_token_with_suggestion(\n                        \"valid operator\",\n                        current,\n                        \"Check operator precedence and usage\",\n                    ))\n                } else {\n                    None\n                }\n            }\n        }\n    }\n\n    /// Get a suggested fix for this error production\n    pub fn get_suggestion(\u0026self) -\u003e \u0026'static str {\n        match self {\n            ErrorProduction::MissingSemicolon =\u003e \"Add ';' at the end of the statement\",\n            ErrorProduction::MissingOpenParen =\u003e \"Add '(' before function arguments\",\n            ErrorProduction::MissingCloseParen =\u003e \"Add ')' to close the parentheses\",\n            ErrorProduction::MissingOpenBrace =\u003e {\n                \"Add '{' to start a block or ':' for indented block\"\n            }\n            ErrorProduction::MissingCloseBrace =\u003e \"Add '}' to close the block\",\n            ErrorProduction::UnmatchedDelimiter =\u003e \"Check that all delimiters are properly matched\",\n            ErrorProduction::IncompleteExpression =\u003e {\n                \"Complete the expression with a value or identifier\"\n            }\n            ErrorProduction::InvalidOperator =\u003e \"Use a valid operator for this context\",\n        }\n    }\n}\n\n/// Recovery strategy for building partial AST nodes\n#[derive(Debug, Clone)]\npub struct PartialRecovery {\n    /// Whether to create placeholder nodes for missing elements\n    pub create_placeholders: bool,\n    /// Maximum number of errors to collect before giving up\n    pub max_errors: usize,\n    /// Whether to attempt expression completion\n    pub attempt_expression_completion: bool,\n}\n\nimpl Default for PartialRecovery {\n    fn default() -\u003e Self {\n        Self {\n            create_placeholders: true,\n            max_errors: 50,\n            attempt_expression_completion: true,\n        }\n    }\n}\n\n/// Multi-error collector for gathering multiple parse errors\n#[derive(Debug, Clone)]\npub struct ErrorCollector {\n    /// Collected errors\n    pub errors: Vec\u003cParseError\u003e,\n    /// Maximum errors to collect\n    pub max_errors: usize,\n    /// Whether to continue parsing after errors\n    pub continue_on_error: bool,\n}\n\nimpl ErrorCollector {\n    /// Create a new error collector\n    pub fn new(max_errors: usize) -\u003e Self {\n        Self {\n            errors: Vec::new(),\n            max_errors,\n            continue_on_error: true,\n        }\n    }\n\n    /// Add an error to the collection\n    pub fn add_error(\u0026mut self, error: ParseError) {\n        if self.errors.len() \u003c self.max_errors {\n            self.errors.push(error);\n        }\n\n        if self.errors.len() \u003e= self.max_errors {\n            self.continue_on_error = false;\n        }\n    }\n\n    /// Check if we should continue parsing\n    pub fn should_continue(\u0026self) -\u003e bool {\n        self.continue_on_error \u0026\u0026 self.errors.len() \u003c self.max_errors\n    }\n\n    /// Get all collected errors\n    pub fn get_errors(\u0026self) -\u003e \u0026[ParseError] {\n        \u0026self.errors\n    }\n\n    /// Check if any errors were collected\n    pub fn has_errors(\u0026self) -\u003e bool {\n        !self.errors.is_empty()\n    }\n\n    /// Get the most recent error\n    pub fn last_error(\u0026self) -\u003e Option\u003c\u0026ParseError\u003e {\n        self.errors.last()\n    }\n\n    /// Clear all errors\n    pub fn clear(\u0026mut self) {\n        self.errors.clear();\n        self.continue_on_error = true;\n    }\n}\n\n/// Enhanced error recovery strategies\npub struct ErrorRecovery;\n\nimpl ErrorRecovery {\n    /// Panic mode recovery: skip tokens until a synchronizing token is found\n    pub fn panic_mode_recovery\u003cT: TokenStream\u003e(\n        tokens: \u0026mut T,\n        sync_tokens: \u0026[SyncToken],\n    ) -\u003e Option\u003cToken\u003e {\n        while !tokens.is_at_end() {\n            let current = tokens.peek();\n\n            // Check if current token is a synchronizing token\n            for sync_token in sync_tokens {\n                if sync_token.matches(current) {\n                    return Some(current.clone());\n                }\n            }\n\n            // Skip the current token\n            tokens.consume();\n        }\n\n        None\n    }\n\n    /// Recover to the next statement boundary\n    pub fn recover_to_statement\u003cT: TokenStream\u003e(tokens: \u0026mut T) -\u003e Option\u003cToken\u003e {\n        Self::panic_mode_recovery(\n            tokens,\n            \u0026[SyncToken::StatementStart, SyncToken::StatementTerminator],\n        )\n    }\n\n    /// Recover to the next declaration boundary\n    pub fn recover_to_declaration\u003cT: TokenStream\u003e(tokens: \u0026mut T) -\u003e Option\u003cToken\u003e {\n        Self::panic_mode_recovery(tokens, \u0026[SyncToken::DeclarationStart])\n    }\n\n    /// Recover to the end of a block\n    pub fn recover_to_block_end\u003cT: TokenStream\u003e(tokens: \u0026mut T) -\u003e Option\u003cToken\u003e {\n        Self::panic_mode_recovery(tokens, \u0026[SyncToken::BlockEnd])\n    }\n\n    /// Recover to the next expression boundary\n    pub fn recover_to_expression\u003cT: TokenStream\u003e(tokens: \u0026mut T) -\u003e Option\u003cToken\u003e {\n        Self::panic_mode_recovery(\n            tokens,\n            \u0026[SyncToken::ExpressionStart, SyncToken::ExpressionTerminator],\n        )\n    }\n\n    /// Advanced recovery with error production rules\n    pub fn recover_with_productions\u003cT: TokenStream\u003e(\n        tokens: \u0026mut T,\n        context: \u0026str,\n        collector: \u0026mut ErrorCollector,\n    ) -\u003e Option\u003cToken\u003e {\n        let productions = [\n            ErrorProduction::MissingSemicolon,\n            ErrorProduction::MissingOpenParen,\n            ErrorProduction::MissingCloseParen,\n            ErrorProduction::MissingOpenBrace,\n            ErrorProduction::MissingCloseBrace,\n            ErrorProduction::UnmatchedDelimiter,\n            ErrorProduction::IncompleteExpression,\n            ErrorProduction::InvalidOperator,\n        ];\n\n        for production in \u0026productions {\n            if let Some(error) = production.applies_to_context(tokens, context) {\n                collector.add_error(error);\n\n                // Try to insert missing token or skip problematic token\n                match production {\n                    ErrorProduction::MissingSemicolon =\u003e {\n                        // Continue parsing, assuming semicolon is optional\n                        return Some(tokens.peek().clone());\n                    }\n                    ErrorProduction::MissingOpenParen\n                    | ErrorProduction::MissingCloseParen\n                    | ErrorProduction::MissingOpenBrace\n                    | ErrorProduction::MissingCloseBrace =\u003e {\n                        // Skip to next synchronization point\n                        return Self::panic_mode_recovery(\n                            tokens,\n                            \u0026[\n                                SyncToken::StatementTerminator,\n                                SyncToken::ExpressionTerminator,\n                            ],\n                        );\n                    }\n                    ErrorProduction::UnmatchedDelimiter =\u003e {\n                        // Skip the unmatched delimiter\n                        tokens.consume();\n                        if !tokens.is_at_end() {\n                            return Some(tokens.peek().clone());\n                        }\n                    }\n                    ErrorProduction::IncompleteExpression | ErrorProduction::InvalidOperator =\u003e {\n                        // Skip to next expression start\n                        return Self::recover_to_expression(tokens);\n                    }\n                }\n            }\n        }\n\n        // Fallback to panic mode recovery\n        Self::panic_mode_recovery(\n            tokens,\n            \u0026[SyncToken::StatementStart, SyncToken::StatementTerminator],\n        )\n    }\n\n    /// Check if we should attempt recovery or give up\n    pub fn should_continue_recovery\u003cT: TokenStream\u003e(tokens: \u0026T, error_count: usize) -\u003e bool {\n        // Continue if we haven't hit too many errors and aren't at EOF\n        error_count \u003c 100 \u0026\u0026 !tokens.is_at_end()\n    }\n\n    /// Smart recovery that preserves context\n    pub fn smart_recovery\u003cT: TokenStream\u003e(\n        tokens: \u0026mut T,\n        expected_context: \u0026str,\n        collector: \u0026mut ErrorCollector,\n    ) -\u003e Option\u003cToken\u003e {\n        // First try production-based recovery\n        if let Some(token) = Self::recover_with_productions(tokens, expected_context, collector) {\n            return Some(token);\n        }\n\n        // Then try context-specific recovery\n        if expected_context.contains(\"expression\") {\n            Self::recover_to_expression(tokens)\n        } else if expected_context.contains(\"statement\") {\n            Self::recover_to_statement(tokens)\n        } else if expected_context.contains(\"declaration\") {\n            Self::recover_to_declaration(tokens)\n        } else if expected_context.contains(\"block\") {\n            Self::recover_to_block_end(tokens)\n        } else {\n            // Generic recovery\n            Self::panic_mode_recovery(\n                tokens,\n                \u0026[SyncToken::StatementStart, SyncToken::StatementTerminator],\n            )\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::token::{TokenType, VecTokenStream};\n\n    #[test]\n    fn test_sync_token_matches() {\n        let token = Token::dummy(TokenType::Let);\n        assert!(SyncToken::StatementStart.matches(\u0026token));\n        assert!(SyncToken::DeclarationStart.matches(\u0026token));\n\n        let token = Token::dummy(TokenType::RightBrace);\n        assert!(SyncToken::BlockEnd.matches(\u0026token));\n        assert!(SyncToken::StatementTerminator.matches(\u0026token));\n    }\n\n    #[test]\n    fn test_panic_mode_recovery() {\n        let tokens = vec![\n            TokenType::Plus, // Error token\n            TokenType::Star, // Error token\n            TokenType::Let,  // Sync token\n            TokenType::Identifier(\"x\".to_string()),\n        ];\n        let mut stream = VecTokenStream::from_token_types(tokens);\n\n        let sync_token =\n            ErrorRecovery::panic_mode_recovery(\u0026mut stream, \u0026[SyncToken::StatementStart]);\n\n        assert!(sync_token.is_some());\n        assert_eq!(sync_token.unwrap().token_type, TokenType::Let);\n        assert_eq!(stream.peek().token_type, TokenType::Let);\n    }\n\n    #[test]\n    fn test_recover_to_statement() {\n        let tokens = vec![\n            TokenType::Bang,      // Error token\n            TokenType::Plus,      // Error token\n            TokenType::Semicolon, // Statement terminator\n            TokenType::Let,\n        ];\n        let mut stream = VecTokenStream::from_token_types(tokens);\n\n        let sync_token = ErrorRecovery::recover_to_statement(\u0026mut stream);\n\n        assert!(sync_token.is_some());\n        assert_eq!(sync_token.unwrap().token_type, TokenType::Semicolon);\n    }\n\n    #[test]\n    fn test_should_continue_recovery() {\n        let tokens = vec![TokenType::Let];\n        let stream = VecTokenStream::from_token_types(tokens);\n\n        assert!(ErrorRecovery::should_continue_recovery(\u0026stream, 5));\n        assert!(!ErrorRecovery::should_continue_recovery(\u0026stream, 101));\n    }\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":58}},{"line":20,"address":[],"length":0,"stats":{"Line":58}},{"line":21,"address":[],"length":0,"stats":{"Line":18}},{"line":22,"address":[],"length":0,"stats":{"Line":22}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":1}},{"line":42,"address":[],"length":0,"stats":{"Line":1}},{"line":44,"address":[],"length":0,"stats":{"Line":14}},{"line":45,"address":[],"length":0,"stats":{"Line":17}},{"line":52,"address":[],"length":0,"stats":{"Line":4}},{"line":53,"address":[],"length":0,"stats":{"Line":9}},{"line":64,"address":[],"length":0,"stats":{"Line":4}},{"line":65,"address":[],"length":0,"stats":{"Line":8}},{"line":101,"address":[],"length":0,"stats":{"Line":47}},{"line":106,"address":[],"length":0,"stats":{"Line":47}},{"line":108,"address":[],"length":0,"stats":{"Line":47}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":9}},{"line":111,"address":[],"length":0,"stats":{"Line":4}},{"line":112,"address":[],"length":0,"stats":{"Line":4}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":4}},{"line":120,"address":[],"length":0,"stats":{"Line":4}},{"line":121,"address":[],"length":0,"stats":{"Line":4}},{"line":122,"address":[],"length":0,"stats":{"Line":4}},{"line":125,"address":[],"length":0,"stats":{"Line":5}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":6}},{"line":130,"address":[],"length":0,"stats":{"Line":2}},{"line":132,"address":[],"length":0,"stats":{"Line":1}},{"line":133,"address":[],"length":0,"stats":{"Line":1}},{"line":134,"address":[],"length":0,"stats":{"Line":1}},{"line":135,"address":[],"length":0,"stats":{"Line":1}},{"line":138,"address":[],"length":0,"stats":{"Line":5}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":5}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":5}},{"line":154,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":5}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":5}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":5}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":5}},{"line":176,"address":[],"length":0,"stats":{"Line":6}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":2}},{"line":179,"address":[],"length":0,"stats":{"Line":2}},{"line":180,"address":[],"length":0,"stats":{"Line":2}},{"line":181,"address":[],"length":0,"stats":{"Line":2}},{"line":184,"address":[],"length":0,"stats":{"Line":4}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":6}},{"line":188,"address":[],"length":0,"stats":{"Line":1}},{"line":189,"address":[],"length":0,"stats":{"Line":2}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":1}},{"line":205,"address":[],"length":0,"stats":{"Line":5}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":209,"address":[],"length":0,"stats":{"Line":5}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":211,"address":[],"length":0,"stats":{"Line":0}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":5}},{"line":223,"address":[],"length":0,"stats":{"Line":3}},{"line":224,"address":[],"length":0,"stats":{"Line":3}},{"line":225,"address":[],"length":0,"stats":{"Line":1}},{"line":226,"address":[],"length":0,"stats":{"Line":1}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":229,"address":[],"length":0,"stats":{"Line":0}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":1}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":1}},{"line":275,"address":[],"length":0,"stats":{"Line":23}},{"line":277,"address":[],"length":0,"stats":{"Line":23}},{"line":284,"address":[],"length":0,"stats":{"Line":12}},{"line":285,"address":[],"length":0,"stats":{"Line":24}},{"line":286,"address":[],"length":0,"stats":{"Line":12}},{"line":289,"address":[],"length":0,"stats":{"Line":13}},{"line":290,"address":[],"length":0,"stats":{"Line":1}},{"line":295,"address":[],"length":0,"stats":{"Line":6}},{"line":296,"address":[],"length":0,"stats":{"Line":11}},{"line":300,"address":[],"length":0,"stats":{"Line":8}},{"line":301,"address":[],"length":0,"stats":{"Line":8}},{"line":305,"address":[],"length":0,"stats":{"Line":25}},{"line":306,"address":[],"length":0,"stats":{"Line":25}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":1}},{"line":316,"address":[],"length":0,"stats":{"Line":1}},{"line":317,"address":[],"length":0,"stats":{"Line":1}},{"line":326,"address":[],"length":0,"stats":{"Line":12}},{"line":330,"address":[],"length":0,"stats":{"Line":30}},{"line":331,"address":[],"length":0,"stats":{"Line":24}},{"line":334,"address":[],"length":0,"stats":{"Line":102}},{"line":335,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":6}},{"line":341,"address":[],"length":0,"stats":{"Line":18}},{"line":344,"address":[],"length":0,"stats":{"Line":6}},{"line":348,"address":[],"length":0,"stats":{"Line":2}},{"line":350,"address":[],"length":0,"stats":{"Line":2}},{"line":351,"address":[],"length":0,"stats":{"Line":2}},{"line":356,"address":[],"length":0,"stats":{"Line":3}},{"line":357,"address":[],"length":0,"stats":{"Line":3}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":362,"address":[],"length":0,"stats":{"Line":0}},{"line":366,"address":[],"length":0,"stats":{"Line":1}},{"line":368,"address":[],"length":0,"stats":{"Line":1}},{"line":369,"address":[],"length":0,"stats":{"Line":1}},{"line":374,"address":[],"length":0,"stats":{"Line":8}},{"line":379,"address":[],"length":0,"stats":{"Line":8}},{"line":380,"address":[],"length":0,"stats":{"Line":8}},{"line":381,"address":[],"length":0,"stats":{"Line":8}},{"line":382,"address":[],"length":0,"stats":{"Line":8}},{"line":383,"address":[],"length":0,"stats":{"Line":8}},{"line":384,"address":[],"length":0,"stats":{"Line":8}},{"line":385,"address":[],"length":0,"stats":{"Line":8}},{"line":386,"address":[],"length":0,"stats":{"Line":8}},{"line":387,"address":[],"length":0,"stats":{"Line":8}},{"line":390,"address":[],"length":0,"stats":{"Line":91}},{"line":391,"address":[],"length":0,"stats":{"Line":47}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":395,"address":[],"length":0,"stats":{"Line":0}},{"line":396,"address":[],"length":0,"stats":{"Line":0}},{"line":398,"address":[],"length":0,"stats":{"Line":3}},{"line":400,"address":[],"length":0,"stats":{"Line":0}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":0}},{"line":403,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":408,"address":[],"length":0,"stats":{"Line":0}},{"line":409,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":1}},{"line":416,"address":[],"length":0,"stats":{"Line":1}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":0}},{"line":422,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":5}},{"line":431,"address":[],"length":0,"stats":{"Line":5}},{"line":436,"address":[],"length":0,"stats":{"Line":5}},{"line":438,"address":[],"length":0,"stats":{"Line":8}},{"line":442,"address":[],"length":0,"stats":{"Line":5}},{"line":448,"address":[],"length":0,"stats":{"Line":7}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":3}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":3}},{"line":456,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":3}},{"line":458,"address":[],"length":0,"stats":{"Line":3}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":0}},{"line":465,"address":[],"length":0,"stats":{"Line":0}}],"covered":111,"coverable":184},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","generic","mod.rs"],"content":"//! Generic type parameter parsing\n//!\n//! This module handles parsing of generic type parameters, constraints, and where clauses.\n//! Supports syntax like:\n//! - Simple generics: `\u003cT, U\u003e`\n//! - Type constraints: `\u003cT: Clone + Debug\u003e`\n//! - Lifetime parameters: `\u003c'a, 'b\u003e`\n//! - Where clauses: `where T: Clone + Debug, U: Default`\n\npub mod parser;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","generic","parser.rs"],"content":"//! Generic type parameter parser implementation\n//!\n//! Parses generic syntax including:\n//! - Type parameters: `\u003cT, U\u003e`\n//! - Lifetime parameters: `\u003c'a, 'b\u003e`\n//! - Type constraints: `\u003cT: Clone + Debug\u003e`\n//! - Where clauses: `where T: Clone + Debug, U: Default`\n\nuse crate::ast::{\n    GenericParam, GenericParams, GenericType, Type, TypeBound, WhereClause, WhereConstraint,\n};\nuse crate::error::{ParseError, ParseResult};\nuse crate::token::{Span, Token, TokenStream, TokenType};\n\n/// Parse generic parameters `\u003cT, U\u003e` or `\u003cT: Clone + Debug, U: Default\u003e`\npub fn parse_generic_params\u003cT: TokenStream\u003e(tokens: \u0026mut T) -\u003e ParseResult\u003cOption\u003cGenericParams\u003e\u003e {\n    let mut parser = GenericParser::new(tokens);\n    parser.parse_generic_params()\n}\n\n/// Parse a generic type instantiation like `Vec\u003cT\u003e` or `HashMap\u003cK, V\u003e`\npub fn parse_generic_type\u003cT: TokenStream\u003e(\n    tokens: \u0026mut T,\n    base_name: String,\n) -\u003e ParseResult\u003cGenericType\u003e {\n    let mut parser = GenericParser::new(tokens);\n    parser.parse_generic_type(base_name)\n}\n\nstruct GenericParser\u003c'a, T: TokenStream\u003e {\n    tokens: \u0026'a mut T,\n}\n\nimpl\u003c'a, T: TokenStream\u003e GenericParser\u003c'a, T\u003e {\n    fn new(tokens: \u0026'a mut T) -\u003e Self {\n        Self { tokens }\n    }\n\n    fn parse_generic_params(\u0026mut self) -\u003e ParseResult\u003cOption\u003cGenericParams\u003e\u003e {\n        if !matches!(self.peek().token_type, TokenType::Less) {\n            return Ok(None);\n        }\n\n        let start_span = self.consume().span; // consume '\u003c'\n        let mut params = Vec::new();\n\n        // Handle empty generic parameters: \u003c\u003e\n        if matches!(self.peek().token_type, TokenType::Greater) {\n            let end_span = self.consume().span; // consume '\u003e'\n            return Ok(Some(GenericParams {\n                params,\n                where_clause: None,\n                span: start_span.combine(end_span),\n            }));\n        }\n\n        // Parse first parameter\n        params.push(self.parse_generic_param()?);\n\n        // Parse additional parameters\n        while matches!(self.peek().token_type, TokenType::Comma) {\n            self.consume(); // consume ','\n\n            // Allow trailing comma\n            if matches!(self.peek().token_type, TokenType::Greater) {\n                break;\n            }\n\n            params.push(self.parse_generic_param()?);\n        }\n\n        if !matches!(self.peek().token_type, TokenType::Greater) {\n            return Err(ParseError::unexpected_token(\"\u003e\", \u0026self.peek()));\n        }\n\n        let end_span = self.consume().span; // consume '\u003e'\n\n        // Check for where clause\n        let where_clause = if matches!(self.peek().token_type, TokenType::Where) {\n            Some(self.parse_where_clause()?)\n        } else {\n            None\n        };\n\n        let final_span = if let Some(ref wc) = where_clause {\n            start_span.combine(wc.span.clone())\n        } else {\n            start_span.combine(end_span)\n        };\n\n        Ok(Some(GenericParams {\n            params,\n            where_clause,\n            span: final_span,\n        }))\n    }\n\n    fn parse_generic_param(\u0026mut self) -\u003e ParseResult\u003cGenericParam\u003e {\n        let token = self.peek();\n        let start_span = token.span.clone();\n\n        match token.token_type {\n            TokenType::Apostrophe =\u003e {\n                // Lifetime parameter: 'a, 'static\n                self.consume(); // consume \"'\"\n\n                if let TokenType::Identifier(name) = \u0026self.peek().token_type {\n                    let name = name.clone();\n                    let end_span = self.consume().span;\n\n                    Ok(GenericParam {\n                        name: format!(\"'{}\", name),\n                        bounds: Vec::new(),\n                        default: None,\n                        is_lifetime: true,\n                        span: start_span.combine(end_span),\n                    })\n                } else {\n                    Err(ParseError::unexpected_token(\"lifetime name\", \u0026self.peek()))\n                }\n            }\n            TokenType::Identifier(name) =\u003e {\n                // Type parameter: T, U, T: Clone + Debug\n                let name = name.clone();\n                let mut end_span = self.consume().span;\n                let mut bounds = Vec::new();\n                let mut default = None;\n\n                // Check for bounds: T: Clone + Debug\n                if matches!(self.peek().token_type, TokenType::Colon) {\n                    self.consume(); // consume ':'\n                    bounds = self.parse_type_bounds()?;\n\n                    if let Some(last_bound) = bounds.last() {\n                        end_span = last_bound.span.clone();\n                    }\n                }\n\n                // Check for default type: T = DefaultType\n                if matches!(self.peek().token_type, TokenType::Equal) {\n                    self.consume(); // consume '='\n                    let default_type = self.parse_type()?;\n                    end_span = default_type.span();\n                    default = Some(default_type);\n                }\n\n                Ok(GenericParam {\n                    name,\n                    bounds,\n                    default,\n                    is_lifetime: false,\n                    span: start_span.combine(end_span),\n                })\n            }\n            _ =\u003e Err(ParseError::unexpected_token(\"type\", \u0026self.peek())),\n        }\n    }\n\n    fn parse_type_bounds(\u0026mut self) -\u003e ParseResult\u003cVec\u003cTypeBound\u003e\u003e {\n        let mut bounds = Vec::new();\n\n        // Parse first bound\n        bounds.push(self.parse_type_bound()?);\n\n        // Parse additional bounds separated by '+'\n        while matches!(self.peek().token_type, TokenType::Plus) {\n            self.consume(); // consume '+'\n            bounds.push(self.parse_type_bound()?);\n        }\n\n        Ok(bounds)\n    }\n\n    fn parse_type_bound(\u0026mut self) -\u003e ParseResult\u003cTypeBound\u003e {\n        if let TokenType::Identifier(trait_name) = \u0026self.peek().token_type {\n            let trait_name = trait_name.clone();\n            let _span = self.consume().span;\n\n            Ok(TypeBound {\n                trait_name,\n                span: _span,\n            })\n        } else {\n            Err(ParseError::unexpected_token(\"trait name\", \u0026self.peek()))\n        }\n    }\n\n    fn parse_where_clause(\u0026mut self) -\u003e ParseResult\u003cWhereClause\u003e {\n        let start_span = self.consume().span; // consume 'where'\n        let mut constraints = Vec::new();\n\n        // Parse first constraint\n        constraints.push(self.parse_where_constraint()?);\n\n        // Parse additional constraints separated by ','\n        while matches!(self.peek().token_type, TokenType::Comma) {\n            self.consume(); // consume ','\n\n            // Allow trailing comma\n            if self.is_where_clause_end() {\n                break;\n            }\n\n            constraints.push(self.parse_where_constraint()?);\n        }\n\n        let end_span = if let Some(last_constraint) = constraints.last() {\n            last_constraint.span.clone()\n        } else {\n            start_span.clone()\n        };\n\n        Ok(WhereClause {\n            constraints,\n            span: start_span.combine(end_span),\n        })\n    }\n\n    fn parse_where_constraint(\u0026mut self) -\u003e ParseResult\u003cWhereConstraint\u003e {\n        if let TokenType::Identifier(type_name) = \u0026self.peek().token_type {\n            let type_name = type_name.clone();\n            let start_span = self.consume().span;\n\n            if !matches!(self.peek().token_type, TokenType::Colon) {\n                return Err(ParseError::unexpected_token(\":\", \u0026self.peek()));\n            }\n\n            self.consume(); // consume ':'\n            let bounds = self.parse_type_bounds()?;\n\n            let end_span = if let Some(last_bound) = bounds.last() {\n                last_bound.span.clone()\n            } else {\n                start_span.clone()\n            };\n\n            Ok(WhereConstraint {\n                type_name,\n                bounds,\n                span: start_span.combine(end_span),\n            })\n        } else {\n            Err(ParseError::unexpected_token(\"type name\", \u0026self.peek()))\n        }\n    }\n\n    fn parse_generic_type(\u0026mut self, base_name: String) -\u003e ParseResult\u003cGenericType\u003e {\n        let start_span = self.current_span();\n\n        if !matches!(self.peek().token_type, TokenType::Less) {\n            return Err(ParseError::unexpected_token(\"\u003c\", \u0026self.peek()));\n        }\n\n        self.consume(); // consume '\u003c'\n        let mut args = Vec::new();\n\n        // Handle empty type arguments: HashMap\u003c\u003e\n        if matches!(self.peek().token_type, TokenType::Greater) {\n            let end_span = self.consume().span;\n            return Ok(GenericType {\n                base: base_name,\n                args,\n                span: start_span.combine(end_span),\n            });\n        }\n\n        // Parse first type argument\n        args.push(self.parse_type()?);\n\n        // Parse additional type arguments\n        while matches!(self.peek().token_type, TokenType::Comma) {\n            self.consume(); // consume ','\n\n            // Allow trailing comma\n            if matches!(self.peek().token_type, TokenType::Greater) {\n                break;\n            }\n\n            args.push(self.parse_type()?);\n        }\n\n        if !matches!(self.peek().token_type, TokenType::Greater) {\n            return Err(ParseError::unexpected_token(\"\u003e\", \u0026self.peek()));\n        }\n\n        let end_span = self.consume().span;\n\n        Ok(GenericType {\n            base: base_name,\n            args,\n            span: start_span.combine(end_span),\n        })\n    }\n\n    fn parse_type(\u0026mut self) -\u003e ParseResult\u003cType\u003e {\n        // This is a simplified type parser for generic contexts\n        // It will delegate to the main type parser\n        match \u0026self.peek().token_type {\n            TokenType::Identifier(name) =\u003e {\n                let name = name.clone();\n                let _span = self.consume().span;\n\n                // Check if this is a generic type instantiation\n                if matches!(self.peek().token_type, TokenType::Less) {\n                    let generic_type = self.parse_generic_type(name)?;\n                    Ok(Type::Generic(generic_type))\n                } else {\n                    Ok(Type::Identifier(name))\n                }\n            }\n            _ =\u003e Err(ParseError::unexpected_token(\"type\", \u0026self.peek())),\n        }\n    }\n\n    fn is_where_clause_end(\u0026self) -\u003e bool {\n        matches!(\n            self.peek().token_type,\n            TokenType::LeftBrace | TokenType::Semicolon | TokenType::Eof | TokenType::Newline\n        )\n    }\n\n    fn peek(\u0026self) -\u003e Token {\n        self.tokens.peek().clone()\n    }\n\n    fn consume(\u0026mut self) -\u003e Token {\n        self.tokens.consume()\n    }\n\n    fn current_span(\u0026self) -\u003e Span {\n        self.peek().span\n    }\n}\n\n// Add span method to Type enum\nimpl Type {\n    pub fn span(\u0026self) -\u003e Span {\n        match self {\n            Type::Identifier(_) =\u003e Span::dummy(), // Would need actual span tracking\n            Type::Generic(gt) =\u003e gt.span.clone(),\n            Type::Tuple(_) =\u003e Span::dummy(),\n            Type::Array(_) =\u003e Span::dummy(),\n            Type::Function(_) =\u003e Span::dummy(),\n            Type::Pointer(_) =\u003e Span::dummy(),\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::token::stream::VecTokenStream;\n\n    fn create_token_stream(token_types: Vec\u003cTokenType\u003e) -\u003e VecTokenStream {\n        let tokens = token_types.into_iter().map(Token::dummy).collect();\n        VecTokenStream::new(tokens)\n    }\n\n    #[test]\n    fn test_simple_generic_params() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::Less,\n            TokenType::Identifier(\"T\".to_string()),\n            TokenType::Greater,\n        ]);\n\n        let result = parse_generic_params(\u0026mut tokens).unwrap();\n        assert!(result.is_some());\n\n        let generics = result.unwrap();\n        assert_eq!(generics.params.len(), 1);\n        assert_eq!(generics.params[0].name, \"T\");\n        assert!(!generics.params[0].is_lifetime);\n        assert!(generics.params[0].bounds.is_empty());\n    }\n\n    #[test]\n    fn test_multiple_generic_params() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::Less,\n            TokenType::Identifier(\"T\".to_string()),\n            TokenType::Comma,\n            TokenType::Identifier(\"U\".to_string()),\n            TokenType::Greater,\n        ]);\n\n        let result = parse_generic_params(\u0026mut tokens).unwrap();\n        assert!(result.is_some());\n\n        let generics = result.unwrap();\n        assert_eq!(generics.params.len(), 2);\n        assert_eq!(generics.params[0].name, \"T\");\n        assert_eq!(generics.params[1].name, \"U\");\n    }\n\n    #[test]\n    fn test_lifetime_params() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::Less,\n            TokenType::Apostrophe,\n            TokenType::Identifier(\"a\".to_string()),\n            TokenType::Comma,\n            TokenType::Apostrophe,\n            TokenType::Identifier(\"b\".to_string()),\n            TokenType::Greater,\n        ]);\n\n        let result = parse_generic_params(\u0026mut tokens).unwrap();\n        assert!(result.is_some());\n\n        let generics = result.unwrap();\n        assert_eq!(generics.params.len(), 2);\n        assert_eq!(generics.params[0].name, \"'a\");\n        assert_eq!(generics.params[1].name, \"'b\");\n        assert!(generics.params[0].is_lifetime);\n        assert!(generics.params[1].is_lifetime);\n    }\n\n    #[test]\n    fn test_type_bounds() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::Less,\n            TokenType::Identifier(\"T\".to_string()),\n            TokenType::Colon,\n            TokenType::Identifier(\"Clone\".to_string()),\n            TokenType::Plus,\n            TokenType::Identifier(\"Debug\".to_string()),\n            TokenType::Greater,\n        ]);\n\n        let result = parse_generic_params(\u0026mut tokens).unwrap();\n        assert!(result.is_some());\n\n        let generics = result.unwrap();\n        assert_eq!(generics.params.len(), 1);\n        assert_eq!(generics.params[0].bounds.len(), 2);\n        assert_eq!(generics.params[0].bounds[0].trait_name, \"Clone\");\n        assert_eq!(generics.params[0].bounds[1].trait_name, \"Debug\");\n    }\n\n    #[test]\n    fn test_where_clause() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::Less,\n            TokenType::Identifier(\"T\".to_string()),\n            TokenType::Greater,\n            TokenType::Where,\n            TokenType::Identifier(\"T\".to_string()),\n            TokenType::Colon,\n            TokenType::Identifier(\"Clone\".to_string()),\n            TokenType::Plus,\n            TokenType::Identifier(\"Debug\".to_string()),\n        ]);\n\n        let result = parse_generic_params(\u0026mut tokens).unwrap();\n        assert!(result.is_some());\n\n        let generics = result.unwrap();\n        assert!(generics.where_clause.is_some());\n\n        let where_clause = generics.where_clause.unwrap();\n        assert_eq!(where_clause.constraints.len(), 1);\n        assert_eq!(where_clause.constraints[0].type_name, \"T\");\n        assert_eq!(where_clause.constraints[0].bounds.len(), 2);\n    }\n\n    #[test]\n    fn test_generic_type_instantiation() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::Less,\n            TokenType::Identifier(\"i32\".to_string()),\n            TokenType::Greater,\n        ]);\n\n        let result = parse_generic_type(\u0026mut tokens, \"Vec\".to_string()).unwrap();\n        assert_eq!(result.base, \"Vec\");\n        assert_eq!(result.args.len(), 1);\n\n        if let Type::Identifier(name) = \u0026result.args[0] {\n            assert_eq!(name, \"i32\");\n        } else {\n            panic!(\"Expected identifier type\");\n        }\n    }\n\n    #[test]\n    fn test_nested_generic_types() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::Less,\n            TokenType::Identifier(\"Vec\".to_string()),\n            TokenType::Less,\n            TokenType::Identifier(\"i32\".to_string()),\n            TokenType::Greater,\n            TokenType::Greater,\n        ]);\n\n        let result = parse_generic_type(\u0026mut tokens, \"Option\".to_string()).unwrap();\n        assert_eq!(result.base, \"Option\");\n        assert_eq!(result.args.len(), 1);\n\n        if let Type::Generic(inner) = \u0026result.args[0] {\n            assert_eq!(inner.base, \"Vec\");\n            assert_eq!(inner.args.len(), 1);\n        } else {\n            panic!(\"Expected generic type\");\n        }\n    }\n\n    #[test]\n    fn test_empty_generic_params() {\n        let mut tokens = create_token_stream(vec![TokenType::Less, TokenType::Greater]);\n\n        let result = parse_generic_params(\u0026mut tokens).unwrap();\n        assert!(result.is_some());\n\n        let generics = result.unwrap();\n        assert_eq!(generics.params.len(), 0);\n    }\n\n    #[test]\n    fn test_trailing_comma_in_generics() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::Less,\n            TokenType::Identifier(\"T\".to_string()),\n            TokenType::Comma,\n            TokenType::Identifier(\"U\".to_string()),\n            TokenType::Comma,\n            TokenType::Greater,\n        ]);\n\n        let result = parse_generic_params(\u0026mut tokens).unwrap();\n        assert!(result.is_some());\n\n        let generics = result.unwrap();\n        assert_eq!(generics.params.len(), 2);\n    }\n\n    #[test]\n    fn test_complex_where_clause() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::Less,\n            TokenType::Identifier(\"T\".to_string()),\n            TokenType::Comma,\n            TokenType::Identifier(\"U\".to_string()),\n            TokenType::Greater,\n            TokenType::Where,\n            TokenType::Identifier(\"T\".to_string()),\n            TokenType::Colon,\n            TokenType::Identifier(\"Clone\".to_string()),\n            TokenType::Comma,\n            TokenType::Identifier(\"U\".to_string()),\n            TokenType::Colon,\n            TokenType::Identifier(\"Default\".to_string()),\n        ]);\n\n        let result = parse_generic_params(\u0026mut tokens).unwrap();\n        assert!(result.is_some());\n\n        let generics = result.unwrap();\n        assert!(generics.where_clause.is_some());\n\n        let where_clause = generics.where_clause.unwrap();\n        assert_eq!(where_clause.constraints.len(), 2);\n        assert_eq!(where_clause.constraints[0].type_name, \"T\");\n        assert_eq!(where_clause.constraints[1].type_name, \"U\");\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":39}},{"line":17,"address":[],"length":0,"stats":{"Line":39}},{"line":18,"address":[],"length":0,"stats":{"Line":39}},{"line":22,"address":[],"length":0,"stats":{"Line":5}},{"line":26,"address":[],"length":0,"stats":{"Line":5}},{"line":27,"address":[],"length":0,"stats":{"Line":5}},{"line":35,"address":[],"length":0,"stats":{"Line":44}},{"line":39,"address":[],"length":0,"stats":{"Line":39}},{"line":40,"address":[],"length":0,"stats":{"Line":52}},{"line":41,"address":[],"length":0,"stats":{"Line":13}},{"line":44,"address":[],"length":0,"stats":{"Line":26}},{"line":45,"address":[],"length":0,"stats":{"Line":26}},{"line":48,"address":[],"length":0,"stats":{"Line":50}},{"line":49,"address":[],"length":0,"stats":{"Line":2}},{"line":50,"address":[],"length":0,"stats":{"Line":2}},{"line":51,"address":[],"length":0,"stats":{"Line":2}},{"line":52,"address":[],"length":0,"stats":{"Line":2}},{"line":53,"address":[],"length":0,"stats":{"Line":2}},{"line":58,"address":[],"length":0,"stats":{"Line":25}},{"line":61,"address":[],"length":0,"stats":{"Line":57}},{"line":62,"address":[],"length":0,"stats":{"Line":15}},{"line":65,"address":[],"length":0,"stats":{"Line":28}},{"line":66,"address":[],"length":0,"stats":{"Line":2}},{"line":69,"address":[],"length":0,"stats":{"Line":13}},{"line":72,"address":[],"length":0,"stats":{"Line":24}},{"line":73,"address":[],"length":0,"stats":{"Line":1}},{"line":76,"address":[],"length":0,"stats":{"Line":22}},{"line":79,"address":[],"length":0,"stats":{"Line":59}},{"line":80,"address":[],"length":0,"stats":{"Line":7}},{"line":82,"address":[],"length":0,"stats":{"Line":16}},{"line":85,"address":[],"length":0,"stats":{"Line":5}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":16}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":37}},{"line":99,"address":[],"length":0,"stats":{"Line":37}},{"line":100,"address":[],"length":0,"stats":{"Line":37}},{"line":102,"address":[],"length":0,"stats":{"Line":37}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":7}},{"line":107,"address":[],"length":0,"stats":{"Line":13}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":122,"address":[],"length":0,"stats":{"Line":30}},{"line":124,"address":[],"length":0,"stats":{"Line":30}},{"line":125,"address":[],"length":0,"stats":{"Line":30}},{"line":126,"address":[],"length":0,"stats":{"Line":30}},{"line":127,"address":[],"length":0,"stats":{"Line":30}},{"line":130,"address":[],"length":0,"stats":{"Line":24}},{"line":131,"address":[],"length":0,"stats":{"Line":6}},{"line":132,"address":[],"length":0,"stats":{"Line":12}},{"line":134,"address":[],"length":0,"stats":{"Line":6}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":60}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":144,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":30}},{"line":148,"address":[],"length":0,"stats":{"Line":30}},{"line":149,"address":[],"length":0,"stats":{"Line":30}},{"line":150,"address":[],"length":0,"stats":{"Line":30}},{"line":151,"address":[],"length":0,"stats":{"Line":30}},{"line":152,"address":[],"length":0,"stats":{"Line":30}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":13}},{"line":160,"address":[],"length":0,"stats":{"Line":13}},{"line":163,"address":[],"length":0,"stats":{"Line":13}},{"line":166,"address":[],"length":0,"stats":{"Line":32}},{"line":167,"address":[],"length":0,"stats":{"Line":6}},{"line":168,"address":[],"length":0,"stats":{"Line":6}},{"line":171,"address":[],"length":0,"stats":{"Line":13}},{"line":174,"address":[],"length":0,"stats":{"Line":19}},{"line":175,"address":[],"length":0,"stats":{"Line":38}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":179,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":0}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":184,"address":[],"length":0,"stats":{"Line":0}},{"line":188,"address":[],"length":0,"stats":{"Line":6}},{"line":189,"address":[],"length":0,"stats":{"Line":6}},{"line":190,"address":[],"length":0,"stats":{"Line":6}},{"line":193,"address":[],"length":0,"stats":{"Line":7}},{"line":196,"address":[],"length":0,"stats":{"Line":11}},{"line":197,"address":[],"length":0,"stats":{"Line":3}},{"line":200,"address":[],"length":0,"stats":{"Line":3}},{"line":201,"address":[],"length":0,"stats":{"Line":1}},{"line":204,"address":[],"length":0,"stats":{"Line":2}},{"line":207,"address":[],"length":0,"stats":{"Line":10}},{"line":208,"address":[],"length":0,"stats":{"Line":0}},{"line":210,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":8}},{"line":220,"address":[],"length":0,"stats":{"Line":16}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":1}},{"line":225,"address":[],"length":0,"stats":{"Line":1}},{"line":228,"address":[],"length":0,"stats":{"Line":7}},{"line":229,"address":[],"length":0,"stats":{"Line":14}},{"line":231,"address":[],"length":0,"stats":{"Line":7}},{"line":232,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":7}},{"line":248,"address":[],"length":0,"stats":{"Line":7}},{"line":250,"address":[],"length":0,"stats":{"Line":7}},{"line":251,"address":[],"length":0,"stats":{"Line":0}},{"line":254,"address":[],"length":0,"stats":{"Line":7}},{"line":255,"address":[],"length":0,"stats":{"Line":7}},{"line":258,"address":[],"length":0,"stats":{"Line":14}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":7}},{"line":271,"address":[],"length":0,"stats":{"Line":15}},{"line":272,"address":[],"length":0,"stats":{"Line":1}},{"line":275,"address":[],"length":0,"stats":{"Line":2}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":279,"address":[],"length":0,"stats":{"Line":1}},{"line":282,"address":[],"length":0,"stats":{"Line":7}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":7}},{"line":288,"address":[],"length":0,"stats":{"Line":7}},{"line":289,"address":[],"length":0,"stats":{"Line":7}},{"line":290,"address":[],"length":0,"stats":{"Line":7}},{"line":291,"address":[],"length":0,"stats":{"Line":7}},{"line":295,"address":[],"length":0,"stats":{"Line":8}},{"line":298,"address":[],"length":0,"stats":{"Line":8}},{"line":299,"address":[],"length":0,"stats":{"Line":8}},{"line":300,"address":[],"length":0,"stats":{"Line":8}},{"line":301,"address":[],"length":0,"stats":{"Line":8}},{"line":304,"address":[],"length":0,"stats":{"Line":6}},{"line":305,"address":[],"length":0,"stats":{"Line":4}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":6}},{"line":311,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":3}},{"line":316,"address":[],"length":0,"stats":{"Line":2}},{"line":317,"address":[],"length":0,"stats":{"Line":3}},{"line":318,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":385}},{"line":323,"address":[],"length":0,"stats":{"Line":385}},{"line":326,"address":[],"length":0,"stats":{"Line":186}},{"line":327,"address":[],"length":0,"stats":{"Line":186}},{"line":330,"address":[],"length":0,"stats":{"Line":7}},{"line":331,"address":[],"length":0,"stats":{"Line":7}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":341,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}}],"covered":115,"coverable":174},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","lib.rs"],"content":"//! # Ferra Parser v0.1\n//!\n//! The Ferra Parser is the second stage of the Ferra compiler front-end.\n//! It takes a stream of tokens from the lexer and produces an Abstract Syntax Tree (AST)\n//! representing the syntactic structure of the source code according to the Ferra grammar.\n//!\n//! ## Architecture\n//!\n//! - **Recursive Descent**: Used for top-level constructs, declarations, and statements\n//! - **Pratt Parser**: Used for expression parsing with proper precedence handling\n//! - **Arena Allocation**: AST nodes are allocated in an arena for performance\n//! - **Error Recovery**: Panic mode recovery for continuing parsing after errors\n//!\n//! ## Usage\n//!\n//! ```rust,ignore\n//! use ferra_parser::{Parser, parse_file};\n//!\n//! // Parse a complete file\n//! let ast = parse_file(\"example.ferra\")?;\n//!\n//! // Parse from token stream\n//! let mut parser = Parser::new(token_stream);\n//! let ast = parser.parse_compilation_unit()?;\n//! ```\n\npub mod ast;\npub mod attribute; // Phase 2.8.1: Attribute parsing\npub mod block;\npub mod error;\npub mod generic; // Phase 2.8.2: Generic type parameters\npub mod macro_parser; // Phase 2.8.4: Macro system foundation\npub mod pattern;\npub mod pratt;\npub mod program;\npub mod statement;\npub mod token;\npub mod types;\n\n// Re-export commonly used types\npub use ast::{Arena, CompilationUnit, Expression, Item, Statement};\npub use error::{ParseError, ParseResult};\npub use pratt::PrattParser;\npub use program::ProgramParser;\npub use statement::StatementParser;\npub use token::{TokenStream, TokenType};\n\n/// Main parser interface\npub struct Parser\u003c'arena, T: TokenStream\u003e {\n    arena: \u0026'arena Arena,\n    tokens: T,\n}\n\nimpl\u003c'arena, T: TokenStream\u003e Parser\u003c'arena, T\u003e {\n    /// Create a new parser with the given token stream\n    pub fn new(arena: \u0026'arena Arena, tokens: T) -\u003e Self {\n        Self { arena, tokens }\n    }\n\n    /// Parse a complete compilation unit\n    pub fn parse_compilation_unit(\u0026mut self) -\u003e Result\u003c\u0026'arena ast::CompilationUnit, ParseError\u003e {\n        statement::parser::StatementParser::new(self.arena, \u0026mut self.tokens)\n            .parse_compilation_unit()\n    }\n\n    /// Parse a single expression\n    pub fn parse_expression(\u0026mut self) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        let mut pratt_parser = pratt::parser::PrattParser::new(self.arena, \u0026mut self.tokens);\n        pratt_parser.parse_expression(0)\n    }\n\n    /// Parse a single statement\n    pub fn parse_statement(\u0026mut self) -\u003e Result\u003c\u0026'arena Statement, ParseError\u003e {\n        statement::parser::StatementParser::new(self.arena, \u0026mut self.tokens).parse_statement()\n    }\n}\n\n/// Convenience function to parse a file from path\npub fn parse_file\u003cP: AsRef\u003cstd::path::Path\u003e\u003e(_path: P) -\u003e ParseResult\u003cCompilationUnit\u003e {\n    todo!(\"Implementation will be done after lexer integration\")\n}\n\n/// Convenience function to parse source code from string\npub fn parse_source(_source: \u0026str) -\u003e ParseResult\u003cCompilationUnit\u003e {\n    todo!(\"Implementation will be done after lexer integration\")\n}\n\n// Legacy Tests\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::token::VecTokenStream;\n\n    #[test]\n    fn test_parser_creation() {\n        let arena = Arena::new();\n        let tokens = VecTokenStream::new(vec![]);\n        let _parser = Parser::new(\u0026arena, tokens);\n    }\n}\n","traces":[{"line":56,"address":[],"length":0,"stats":{"Line":8}},{"line":61,"address":[],"length":0,"stats":{"Line":1}},{"line":62,"address":[],"length":0,"stats":{"Line":1}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":68,"address":[],"length":0,"stats":{"Line":0}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":73,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":0}}],"covered":3,"coverable":10},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","macro_parser","mod.rs"],"content":"//! Macro system foundation for Ferra parser\n//!\n//! This module provides basic macro parsing functionality including:\n//! - Macro invocation parsing (macro!())\n//! - Token tree parsing for macro arguments\n//! - Basic macro definition parsing framework\n//!\n//! This is a foundation implementation for Phase 2.8.4\n\npub mod parser;\n\npub use parser::*;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","macro_parser","parser.rs"],"content":"//! Macro parsing implementation\n//!\n//! Provides basic macro parsing functionality for Ferra language\n\nuse crate::{\n    ast::{\n        Arena, GroupDelimiter, MacroDefinition, MacroInvocation, MacroRule, TokenGroup, TokenTree,\n    },\n    error::ParseError,\n    token::{TokenStream, TokenType},\n};\n\n/// Macro parser for handling macro invocations and definitions\npub struct MacroParser\u003c'arena, T: TokenStream\u003e {\n    arena: \u0026'arena Arena,\n    tokens: T,\n}\n\nimpl\u003c'arena, T: TokenStream\u003e MacroParser\u003c'arena, T\u003e {\n    /// Create a new macro parser\n    pub fn new(arena: \u0026'arena Arena, tokens: T) -\u003e Self {\n        Self { arena, tokens }\n    }\n\n    /// Parse a macro invocation like `println!(\"Hello, world!\")`\n    pub fn parse_macro_invocation(\n        \u0026mut self,\n        name: String,\n    ) -\u003e Result\u003c\u0026'arena MacroInvocation, ParseError\u003e {\n        // Expect '!' after macro name\n        let bang_token = self.tokens.consume();\n        if !matches!(bang_token.token_type, TokenType::Bang) {\n            return Err(ParseError::unexpected_token(\"!\", \u0026bang_token));\n        }\n\n        // Parse arguments as token tree\n        let arguments = self.parse_token_tree_group()?;\n\n        Ok(self.arena.alloc(MacroInvocation {\n            name,\n            arguments: vec![TokenTree::Group(arguments)],\n            span: bang_token.span.clone(),\n        }))\n    }\n\n    /// Parse a token tree group (parentheses, brackets, or braces)\n    fn parse_token_tree_group(\u0026mut self) -\u003e Result\u003cTokenGroup, ParseError\u003e {\n        let open_token = self.tokens.consume();\n\n        let delimiter = match open_token.token_type {\n            TokenType::LeftParen =\u003e GroupDelimiter::Parentheses,\n            TokenType::LeftBracket =\u003e GroupDelimiter::Brackets,\n            TokenType::LeftBrace =\u003e GroupDelimiter::Braces,\n            _ =\u003e {\n                return Err(ParseError::unexpected_token(\n                    \"opening delimiter\",\n                    \u0026open_token,\n                ))\n            }\n        };\n\n        let mut tokens = Vec::new();\n\n        // Parse tokens until closing delimiter\n        loop {\n            let token = self.tokens.peek();\n\n            match (\u0026delimiter, \u0026token.token_type) {\n                (GroupDelimiter::Parentheses, TokenType::RightParen)\n                | (GroupDelimiter::Brackets, TokenType::RightBracket)\n                | (GroupDelimiter::Braces, TokenType::RightBrace) =\u003e {\n                    let close_token = self.tokens.consume();\n                    return Ok(TokenGroup {\n                        delimiter,\n                        tokens,\n                        span: open_token.span.combine(close_token.span),\n                    });\n                }\n                (_, TokenType::Eof) =\u003e {\n                    return Err(ParseError::unexpected_token(\"closing delimiter\", token));\n                }\n                _ =\u003e {\n                    // Check if this is a nested group\n                    if matches!(\n                        token.token_type,\n                        TokenType::LeftParen | TokenType::LeftBracket | TokenType::LeftBrace\n                    ) {\n                        let nested_group = self.parse_token_tree_group()?;\n                        tokens.push(TokenTree::Group(nested_group));\n                    } else {\n                        let consumed_token = self.tokens.consume();\n                        tokens.push(TokenTree::Token(consumed_token));\n                    }\n                }\n            }\n        }\n    }\n\n    /// Parse a basic macro definition (framework only)\n    pub fn parse_macro_definition(\n        \u0026mut self,\n        name: String,\n    ) -\u003e Result\u003c\u0026'arena MacroDefinition, ParseError\u003e {\n        // This is a basic framework implementation\n        // In a full implementation, this would parse macro rules with patterns and replacements\n\n        // For now, just parse a simple rule structure\n        let _open_brace = self.tokens.consume(); // consume '{'\n        if !matches!(_open_brace.token_type, TokenType::LeftBrace) {\n            return Err(ParseError::unexpected_token(\"{\", \u0026_open_brace));\n        }\n\n        let mut rules = Vec::new();\n\n        // Parse basic rule (pattern =\u003e replacement)\n        while !matches!(\n            self.tokens.peek().token_type,\n            TokenType::RightBrace | TokenType::Eof\n        ) {\n            let rule = self.parse_macro_rule()?;\n            rules.push(rule);\n\n            // Check for continuation\n            if matches!(self.tokens.peek().token_type, TokenType::Semicolon) {\n                self.tokens.consume(); // consume ';'\n            }\n        }\n\n        let close_brace = self.tokens.consume(); // consume '}'\n        if !matches!(close_brace.token_type, TokenType::RightBrace) {\n            return Err(ParseError::unexpected_token(\"}\", \u0026close_brace));\n        }\n\n        Ok(self.arena.alloc(MacroDefinition {\n            name,\n            rules,\n            span: close_brace.span.clone(),\n        }))\n    }\n\n    /// Parse a single macro rule (basic framework)\n    fn parse_macro_rule(\u0026mut self) -\u003e Result\u003cMacroRule, ParseError\u003e {\n        let mut pattern = Vec::new();\n        let mut replacement = Vec::new();\n\n        // Parse pattern until '=\u003e'\n        while !matches!(self.tokens.peek().token_type, TokenType::FatArrow) {\n            let token = self.tokens.consume();\n            if matches!(token.token_type, TokenType::Eof) {\n                return Err(ParseError::unexpected_token(\"=\u003e\", \u0026token));\n            }\n            pattern.push(TokenTree::Token(token));\n        }\n\n        // Consume '=\u003e'\n        let arrow_token = self.tokens.consume();\n        if !matches!(arrow_token.token_type, TokenType::FatArrow) {\n            return Err(ParseError::unexpected_token(\"=\u003e\", \u0026arrow_token));\n        }\n\n        // Parse replacement until ';' or '}'\n        while !matches!(\n            self.tokens.peek().token_type,\n            TokenType::Semicolon | TokenType::RightBrace\n        ) {\n            let token = self.tokens.consume();\n            if matches!(token.token_type, TokenType::Eof) {\n                break;\n            }\n            replacement.push(TokenTree::Token(token));\n        }\n\n        Ok(MacroRule {\n            pattern,\n            replacement,\n            span: arrow_token.span.clone(),\n        })\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::{ast::Arena, token::VecTokenStream};\n\n    fn create_token_stream(token_types: Vec\u003cTokenType\u003e) -\u003e VecTokenStream {\n        VecTokenStream::from_token_types(token_types)\n    }\n\n    #[test]\n    fn test_macro_parser_creation() {\n        let arena = Arena::new();\n        let tokens = create_token_stream(vec![TokenType::Eof]);\n        let _parser = MacroParser::new(\u0026arena, tokens);\n    }\n\n    #[test]\n    fn test_simple_macro_invocation() {\n        let arena = Arena::new();\n        let tokens = create_token_stream(vec![\n            TokenType::Bang,\n            TokenType::LeftParen,\n            TokenType::StringLiteral(\"hello\".to_string()),\n            TokenType::RightParen,\n            TokenType::Eof,\n        ]);\n        let mut parser = MacroParser::new(\u0026arena, tokens);\n\n        let result = parser.parse_macro_invocation(\"println\".to_string());\n        assert!(result.is_ok());\n\n        if let Ok(macro_invocation) = result {\n            assert_eq!(macro_invocation.name, \"println\");\n            assert_eq!(macro_invocation.arguments.len(), 1);\n        }\n    }\n\n    #[test]\n    fn test_nested_token_groups() {\n        let arena = Arena::new();\n        let tokens = create_token_stream(vec![\n            TokenType::Bang,\n            TokenType::LeftBrace,\n            TokenType::LeftParen,\n            TokenType::IntegerLiteral(42),\n            TokenType::RightParen,\n            TokenType::RightBrace,\n            TokenType::Eof,\n        ]);\n        let mut parser = MacroParser::new(\u0026arena, tokens);\n\n        let result = parser.parse_macro_invocation(\"test\".to_string());\n        assert!(result.is_ok());\n\n        if let Ok(macro_invocation) = result {\n            assert_eq!(macro_invocation.name, \"test\");\n            assert_eq!(macro_invocation.arguments.len(), 1);\n\n            if let TokenTree::Group(group) = \u0026macro_invocation.arguments[0] {\n                assert!(matches!(group.delimiter, GroupDelimiter::Braces));\n                assert_eq!(group.tokens.len(), 1);\n            }\n        }\n    }\n\n    #[test]\n    fn test_macro_definition_basic() {\n        let arena = Arena::new();\n        let tokens = create_token_stream(vec![\n            TokenType::LeftBrace,\n            TokenType::Identifier(\"$x\".to_string()),\n            TokenType::FatArrow,\n            TokenType::Identifier(\"$x\".to_string()),\n            TokenType::Plus,\n            TokenType::IntegerLiteral(1),\n            TokenType::RightBrace,\n            TokenType::Eof,\n        ]);\n        let mut parser = MacroParser::new(\u0026arena, tokens);\n\n        let result = parser.parse_macro_definition(\"increment\".to_string());\n        assert!(result.is_ok());\n\n        if let Ok(macro_def) = result {\n            assert_eq!(macro_def.name, \"increment\");\n            assert_eq!(macro_def.rules.len(), 1);\n        }\n    }\n\n    #[test]\n    fn test_macro_parsing_errors() {\n        let arena = Arena::new();\n\n        // Test missing closing delimiter\n        let tokens = create_token_stream(vec![\n            TokenType::Bang,\n            TokenType::LeftParen,\n            TokenType::StringLiteral(\"hello\".to_string()),\n            TokenType::Eof,\n        ]);\n        let mut parser = MacroParser::new(\u0026arena, tokens);\n        let result = parser.parse_macro_invocation(\"println\".to_string());\n        assert!(result.is_err());\n\n        // Test missing bang\n        let tokens = create_token_stream(vec![\n            TokenType::LeftParen,\n            TokenType::StringLiteral(\"hello\".to_string()),\n            TokenType::RightParen,\n            TokenType::Eof,\n        ]);\n        let mut parser = MacroParser::new(\u0026arena, tokens);\n        let result = parser.parse_macro_invocation(\"println\".to_string());\n        assert!(result.is_err());\n    }\n}\n","traces":[{"line":21,"address":[],"length":0,"stats":{"Line":22}},{"line":26,"address":[],"length":0,"stats":{"Line":17}},{"line":31,"address":[],"length":0,"stats":{"Line":17}},{"line":32,"address":[],"length":0,"stats":{"Line":19}},{"line":33,"address":[],"length":0,"stats":{"Line":2}},{"line":37,"address":[],"length":0,"stats":{"Line":30}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":42,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":17}},{"line":48,"address":[],"length":0,"stats":{"Line":17}},{"line":50,"address":[],"length":0,"stats":{"Line":34}},{"line":51,"address":[],"length":0,"stats":{"Line":11}},{"line":52,"address":[],"length":0,"stats":{"Line":2}},{"line":53,"address":[],"length":0,"stats":{"Line":4}},{"line":54,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":51}},{"line":68,"address":[],"length":0,"stats":{"Line":51}},{"line":69,"address":[],"length":0,"stats":{"Line":0}},{"line":70,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":72,"address":[],"length":0,"stats":{"Line":15}},{"line":73,"address":[],"length":0,"stats":{"Line":15}},{"line":74,"address":[],"length":0,"stats":{"Line":15}},{"line":75,"address":[],"length":0,"stats":{"Line":15}},{"line":76,"address":[],"length":0,"stats":{"Line":15}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":2}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":32}},{"line":85,"address":[],"length":0,"stats":{"Line":34}},{"line":86,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":4}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":32}},{"line":92,"address":[],"length":0,"stats":{"Line":32}},{"line":100,"address":[],"length":0,"stats":{"Line":4}},{"line":108,"address":[],"length":0,"stats":{"Line":4}},{"line":109,"address":[],"length":0,"stats":{"Line":4}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":4}},{"line":116,"address":[],"length":0,"stats":{"Line":5}},{"line":117,"address":[],"length":0,"stats":{"Line":8}},{"line":118,"address":[],"length":0,"stats":{"Line":0}},{"line":120,"address":[],"length":0,"stats":{"Line":10}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":124,"address":[],"length":0,"stats":{"Line":4}},{"line":125,"address":[],"length":0,"stats":{"Line":1}},{"line":129,"address":[],"length":0,"stats":{"Line":3}},{"line":130,"address":[],"length":0,"stats":{"Line":3}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":3}},{"line":135,"address":[],"length":0,"stats":{"Line":3}},{"line":136,"address":[],"length":0,"stats":{"Line":3}},{"line":137,"address":[],"length":0,"stats":{"Line":3}},{"line":142,"address":[],"length":0,"stats":{"Line":5}},{"line":143,"address":[],"length":0,"stats":{"Line":5}},{"line":144,"address":[],"length":0,"stats":{"Line":5}},{"line":147,"address":[],"length":0,"stats":{"Line":28}},{"line":148,"address":[],"length":0,"stats":{"Line":12}},{"line":149,"address":[],"length":0,"stats":{"Line":11}},{"line":150,"address":[],"length":0,"stats":{"Line":1}},{"line":152,"address":[],"length":0,"stats":{"Line":11}},{"line":156,"address":[],"length":0,"stats":{"Line":4}},{"line":157,"address":[],"length":0,"stats":{"Line":4}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":12}},{"line":163,"address":[],"length":0,"stats":{"Line":16}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":12}},{"line":167,"address":[],"length":0,"stats":{"Line":12}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":12}},{"line":173,"address":[],"length":0,"stats":{"Line":4}},{"line":174,"address":[],"length":0,"stats":{"Line":4}},{"line":175,"address":[],"length":0,"stats":{"Line":4}},{"line":176,"address":[],"length":0,"stats":{"Line":4}}],"covered":59,"coverable":83},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","pattern","mod.rs"],"content":"//! Pattern parsing for match expressions\n//!\n//! Implementation will be completed during development phase\n\npub mod parser;\n\npub use parser::*;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","pattern","parser.rs"],"content":"//! Pattern parsing implementation for match expressions\n//!\n//! Implementation will be completed during development phase\n\nuse crate::{ast::Pattern, error::ParseResult, token::TokenStream};\n\n/// Parse a pattern\npub fn parse_pattern\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cPattern\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n\n/// Parse a literal pattern\npub fn parse_literal_pattern\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cPattern\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n\n/// Parse an identifier pattern\npub fn parse_identifier_pattern\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cPattern\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n\n/// Parse a wildcard pattern (_)\npub fn parse_wildcard_pattern\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cPattern\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n\n/// Parse a data class pattern\npub fn parse_data_class_pattern\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cPattern\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n","traces":[{"line":8,"address":[],"length":0,"stats":{"Line":0}},{"line":13,"address":[],"length":0,"stats":{"Line":0}},{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":5},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","pratt","handlers.rs"],"content":"//! NUD and LED handlers for the Pratt parser\n//!\n//! NUD (Null Denotation) handlers parse expressions that don't require a left operand\n//! LED (Left Denotation) handlers parse expressions that operate on a left operand\n\nuse crate::{\n    ast::{Arena, BinaryOperator, Expression, Literal, UnaryOperator},\n    error::ParseError,\n    token::{TokenStream, TokenType},\n};\n\n/// NUD handler for expressions that don't require a left operand\npub struct NudHandler\u003c'arena, T: TokenStream\u003e {\n    arena: \u0026'arena Arena,\n    tokens: \u0026'arena mut T,\n}\n\nimpl\u003c'arena, T: TokenStream\u003e NudHandler\u003c'arena, T\u003e {\n    pub fn new(arena: \u0026'arena Arena, tokens: \u0026'arena mut T) -\u003e Self {\n        Self { arena, tokens }\n    }\n\n    pub fn handle(\u0026mut self, token_type: \u0026TokenType) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        match token_type {\n            // Literals\n            TokenType::IntegerLiteral(value) =\u003e Ok(self\n                .arena\n                .alloc(Expression::Literal(Literal::Integer(*value)))),\n            TokenType::StringLiteral(value) =\u003e Ok(self\n                .arena\n                .alloc(Expression::Literal(Literal::String(value.clone())))),\n            TokenType::FloatLiteral(value) =\u003e Ok(self\n                .arena\n                .alloc(Expression::Literal(Literal::Float(*value)))),\n            TokenType::BooleanLiteral(value) =\u003e Ok(self\n                .arena\n                .alloc(Expression::Literal(Literal::Boolean(*value)))),\n\n            // Identifiers\n            TokenType::Identifier(name) =\u003e {\n                Ok(self.arena.alloc(Expression::Identifier(name.clone())))\n            }\n\n            // Grouped expressions\n            TokenType::LeftParen =\u003e self.parse_grouped_or_tuple_expression(),\n\n            // Array literals\n            TokenType::LeftBracket =\u003e self.parse_array_literal(),\n\n            // Unary operators\n            TokenType::Minus =\u003e self.parse_unary_expression(UnaryOperator::Minus),\n            TokenType::Bang =\u003e self.parse_unary_expression(UnaryOperator::Not),\n            TokenType::Plus =\u003e self.parse_unary_expression(UnaryOperator::Plus),\n\n            _ =\u003e {\n                let token = self.tokens.peek();\n                Err(ParseError::unexpected_token(\"expression\", token))\n            }\n        }\n    }\n\n    fn parse_grouped_or_tuple_expression(\u0026mut self) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        // For now, just handle simple cases. TODO: Implement proper recursive parsing\n        // Expect the inner expression to be consumed already\n        let token = self.tokens.consume();\n        if !matches!(token.token_type, TokenType::RightParen) {\n            return Err(ParseError::unexpected_token(\"')'\", \u0026token));\n        }\n\n        // Return a dummy expression for now - this needs proper implementation\n        Ok(self.arena.alloc(Expression::Literal(Literal::Integer(0))))\n    }\n\n    fn parse_array_literal(\u0026mut self) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        // For now, just consume until closing bracket\n        loop {\n            let token = self.tokens.consume();\n            if matches!(token.token_type, TokenType::RightBracket) {\n                break;\n            }\n            if matches!(token.token_type, TokenType::Eof) {\n                return Err(ParseError::unexpected_token(\"']'\", \u0026token));\n            }\n        }\n\n        use crate::ast::ArrayLiteral;\n        let token = self.tokens.peek();\n        Ok(self.arena.alloc(Expression::Array(ArrayLiteral {\n            elements: vec![],\n            span: token.span.clone(),\n        })))\n    }\n\n    fn parse_unary_expression(\n        \u0026mut self,\n        operator: UnaryOperator,\n    ) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        // For now, just parse a simple operand (no recursive parsing)\n        let token = self.tokens.consume();\n        let operand = match \u0026token.token_type {\n            TokenType::IntegerLiteral(value) =\u003e Expression::Literal(Literal::Integer(*value)),\n            TokenType::StringLiteral(value) =\u003e Expression::Literal(Literal::String(value.clone())),\n            TokenType::FloatLiteral(value) =\u003e Expression::Literal(Literal::Float(*value)),\n            TokenType::BooleanLiteral(value) =\u003e Expression::Literal(Literal::Boolean(*value)),\n            TokenType::Identifier(name) =\u003e Expression::Identifier(name.clone()),\n            _ =\u003e return Err(ParseError::unexpected_token(\"expression\", \u0026token)),\n        };\n\n        use crate::ast::UnaryExpression;\n        Ok(self.arena.alloc(Expression::Unary(UnaryExpression {\n            operator,\n            operand: Box::new(operand),\n            span: token.span.clone(),\n        })))\n    }\n}\n\n/// LED handler for expressions that operate on a left operand\npub struct LedHandler\u003c'arena, T: TokenStream\u003e {\n    arena: \u0026'arena Arena,\n    tokens: \u0026'arena mut T,\n}\n\nimpl\u003c'arena, T: TokenStream\u003e LedHandler\u003c'arena, T\u003e {\n    pub fn new(arena: \u0026'arena Arena, tokens: \u0026'arena mut T) -\u003e Self {\n        Self { arena, tokens }\n    }\n\n    pub fn handle(\n        \u0026mut self,\n        left: \u0026'arena Expression,\n        token_type: \u0026TokenType,\n    ) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        match token_type {\n            // Binary operators\n            TokenType::Plus =\u003e self.parse_binary_expression(left, BinaryOperator::Add, token_type),\n            TokenType::Minus =\u003e self.parse_binary_expression(left, BinaryOperator::Sub, token_type),\n            TokenType::Star =\u003e self.parse_binary_expression(left, BinaryOperator::Mul, token_type),\n            TokenType::Slash =\u003e self.parse_binary_expression(left, BinaryOperator::Div, token_type),\n            TokenType::Percent =\u003e {\n                self.parse_binary_expression(left, BinaryOperator::Mod, token_type)\n            }\n\n            // Comparison operators\n            TokenType::EqualEqual =\u003e {\n                self.parse_binary_expression(left, BinaryOperator::Equal, token_type)\n            }\n            TokenType::BangEqual =\u003e {\n                self.parse_binary_expression(left, BinaryOperator::NotEqual, token_type)\n            }\n            TokenType::Less =\u003e self.parse_binary_expression(left, BinaryOperator::Less, token_type),\n            TokenType::LessEqual =\u003e {\n                self.parse_binary_expression(left, BinaryOperator::LessEqual, token_type)\n            }\n            TokenType::Greater =\u003e {\n                self.parse_binary_expression(left, BinaryOperator::Greater, token_type)\n            }\n            TokenType::GreaterEqual =\u003e {\n                self.parse_binary_expression(left, BinaryOperator::GreaterEqual, token_type)\n            }\n\n            // Logical operators\n            TokenType::AmpAmp =\u003e {\n                self.parse_binary_expression(left, BinaryOperator::And, token_type)\n            }\n            TokenType::PipePipe =\u003e {\n                self.parse_binary_expression(left, BinaryOperator::Or, token_type)\n            }\n\n            // Assignment operators\n            TokenType::Equal =\u003e {\n                self.parse_binary_expression(left, BinaryOperator::Assign, token_type)\n            }\n\n            _ =\u003e {\n                let token = self.tokens.peek();\n                Err(ParseError::unexpected_token(\"binary operator\", token))\n            }\n        }\n    }\n\n    fn parse_binary_expression(\n        \u0026mut self,\n        left: \u0026'arena Expression,\n        operator: BinaryOperator,\n        _token_type: \u0026TokenType,\n    ) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        // For now, just parse a simple right operand (no recursive parsing)\n        let token = self.tokens.consume();\n        let right = match \u0026token.token_type {\n            TokenType::IntegerLiteral(value) =\u003e Expression::Literal(Literal::Integer(*value)),\n            TokenType::StringLiteral(value) =\u003e Expression::Literal(Literal::String(value.clone())),\n            TokenType::FloatLiteral(value) =\u003e Expression::Literal(Literal::Float(*value)),\n            TokenType::BooleanLiteral(value) =\u003e Expression::Literal(Literal::Boolean(*value)),\n            TokenType::Identifier(name) =\u003e Expression::Identifier(name.clone()),\n            _ =\u003e return Err(ParseError::unexpected_token(\"expression\", \u0026token)),\n        };\n\n        use crate::ast::BinaryExpression;\n        Ok(self.arena.alloc(Expression::Binary(BinaryExpression {\n            left: Box::new(left.clone()),\n            operator,\n            right: Box::new(right),\n            span: token.span.clone(),\n        })))\n    }\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":23,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}},{"line":28,"address":[],"length":0,"stats":{"Line":0}},{"line":29,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":33,"address":[],"length":0,"stats":{"Line":0}},{"line":34,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":41,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":0}},{"line":48,"address":[],"length":0,"stats":{"Line":0}},{"line":51,"address":[],"length":0,"stats":{"Line":0}},{"line":52,"address":[],"length":0,"stats":{"Line":0}},{"line":53,"address":[],"length":0,"stats":{"Line":0}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":56,"address":[],"length":0,"stats":{"Line":0}},{"line":57,"address":[],"length":0,"stats":{"Line":0}},{"line":62,"address":[],"length":0,"stats":{"Line":0}},{"line":65,"address":[],"length":0,"stats":{"Line":0}},{"line":66,"address":[],"length":0,"stats":{"Line":0}},{"line":67,"address":[],"length":0,"stats":{"Line":0}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":74,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":0}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":82,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":90,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":99,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":104,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":125,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":140,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":0}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":0}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":175,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":0}},{"line":177,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":0}},{"line":191,"address":[],"length":0,"stats":{"Line":0}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":0}},{"line":194,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":0}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":201,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":204,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":97},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","pratt","mod.rs"],"content":"//! Pratt parser implementation for expression parsing\n//!\n//! This module implements a Top-Down Operator Precedence (Pratt) parser\n//! for Ferra expressions, handling all operators with proper precedence\n//! and associativity.\n\npub mod handlers;\npub mod parser;\npub mod precedence;\n\npub use handlers::*;\npub use parser::*;\npub use precedence::*;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","pratt","parser.rs"],"content":"//! Core Pratt parser implementation\n//!\n//! This module implements the main expression parsing algorithm using\n//! Top-Down Operator Precedence (Pratt parsing) with NUD/LED handlers.\n\nuse crate::{\n    ast::{\n        Arena, BinaryExpression, BinaryOperator, Expression, Literal, UnaryExpression,\n        UnaryOperator,\n    },\n    error::ParseError,\n    pratt::precedence::{\n        can_continue_expression, infix_binding_power, Associativity, BindingPower,\n    },\n    token::{Span, Token, TokenStream, TokenType},\n};\n\n/// The main Pratt parser for expressions\npub struct PrattParser\u003c'arena, T: TokenStream\u003e {\n    arena: \u0026'arena Arena,\n    tokens: T,\n}\n\nimpl\u003c'arena, T: TokenStream\u003e PrattParser\u003c'arena, T\u003e {\n    /// Create a new Pratt parser\n    pub fn new(arena: \u0026'arena Arena, tokens: T) -\u003e Self {\n        Self { arena, tokens }\n    }\n\n    /// Parse an expression with the given minimum binding power\n    pub fn parse_expression(\n        \u0026mut self,\n        min_bp: BindingPower,\n    ) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        // Parse the primary expression (NUD)\n        let mut left = self.parse_primary()?;\n\n        // Parse any operators with sufficient binding power (LED)\n        loop {\n            let token = self.tokens.peek();\n\n            // Check if we should stop parsing\n            if token.token_type == TokenType::Eof {\n                break;\n            }\n\n            // Check if this token can continue the expression\n            if !can_continue_expression(\u0026token.token_type) {\n                break;\n            }\n\n            // Get the binding power for this operator\n            let op_info = match infix_binding_power(\u0026token.token_type) {\n                Some(info) =\u003e info,\n                None =\u003e break, // Not an infix operator, stop parsing\n            };\n\n            // If the binding power is too low, stop parsing\n            if op_info.binding_power \u003c min_bp {\n                break;\n            }\n\n            // Consume the operator token\n            let operator_token = self.tokens.consume();\n\n            // Parse the right operand using LED handler\n            left = self.handle_led(left, \u0026operator_token)?;\n        }\n\n        Ok(left)\n    }\n\n    /// Parse primary expressions (literals, identifiers, etc.)\n    fn parse_primary(\u0026mut self) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        let token = self.tokens.consume();\n\n        match \u0026token.token_type {\n            // Literal expressions\n            TokenType::StringLiteral(s) =\u003e Ok(self\n                .arena\n                .alloc(Expression::Literal(Literal::String(s.clone())))),\n            TokenType::IntegerLiteral(i) =\u003e {\n                Ok(self.arena.alloc(Expression::Literal(Literal::Integer(*i))))\n            }\n            TokenType::FloatLiteral(f) =\u003e {\n                Ok(self.arena.alloc(Expression::Literal(Literal::Float(*f))))\n            }\n            TokenType::BooleanLiteral(b) =\u003e {\n                Ok(self.arena.alloc(Expression::Literal(Literal::Boolean(*b))))\n            }\n\n            // Identifier expressions\n            TokenType::Identifier(name) =\u003e {\n                // Check for macro invocation: identifier!\n                if let TokenType::Bang = self.tokens.peek().token_type {\n                    // Parse as macro invocation\n                    let mut macro_parser =\n                        crate::macro_parser::MacroParser::new(self.arena, \u0026mut self.tokens);\n                    let macro_invocation = macro_parser.parse_macro_invocation(name.clone())?;\n                    Ok(self\n                        .arena\n                        .alloc(Expression::Macro(macro_invocation.clone())))\n                } else {\n                    // Simple identifier (qualified identifiers handled as postfix dot operations)\n                    Ok(self.arena.alloc(Expression::Identifier(name.clone())))\n                }\n            }\n\n            // Unary expressions\n            TokenType::Bang | TokenType::Minus =\u003e {\n                let operator = match \u0026token.token_type {\n                    TokenType::Bang =\u003e UnaryOperator::Not,\n                    TokenType::Minus =\u003e UnaryOperator::Minus,\n                    _ =\u003e return Err(ParseError::unexpected_token(\"unary operator\", \u0026token)),\n                };\n\n                // Use a fixed precedence for unary operators\n                let operand = self.parse_expression(100)?; // High precedence for unary\n\n                Ok(self.arena.alloc(Expression::Unary(UnaryExpression {\n                    operator,\n                    operand: Box::new(operand.clone()),\n                    span: token.span.combine(operand.span()),\n                })))\n            }\n\n            // Grouped expressions\n            TokenType::LeftParen =\u003e {\n                let expr = self.parse_expression(0)?;\n                let close_token = self.tokens.consume();\n                if !matches!(close_token.token_type, TokenType::RightParen) {\n                    return Err(ParseError::unexpected_token(\")\", \u0026close_token));\n                }\n                Ok(self\n                    .arena\n                    .alloc(Expression::Grouped(Box::new(expr.clone()))))\n            }\n\n            // Array literals\n            TokenType::LeftBracket =\u003e self.parse_array_literal(),\n\n            _ =\u003e Err(ParseError::unexpected_token(\"expression\", \u0026token)),\n        }\n    }\n\n    fn handle_led(\n        \u0026mut self,\n        left: \u0026'arena Expression,\n        token: \u0026Token,\n    ) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        match \u0026token.token_type {\n            // Binary operators\n            TokenType::Plus =\u003e self.parse_binary_expression(left, BinaryOperator::Add, token),\n            TokenType::Minus =\u003e self.parse_binary_expression(left, BinaryOperator::Sub, token),\n            TokenType::Star =\u003e self.parse_binary_expression(left, BinaryOperator::Mul, token),\n            TokenType::Slash =\u003e self.parse_binary_expression(left, BinaryOperator::Div, token),\n            TokenType::Percent =\u003e self.parse_binary_expression(left, BinaryOperator::Mod, token),\n\n            // Comparison operators\n            TokenType::EqualEqual =\u003e {\n                self.parse_binary_expression(left, BinaryOperator::Equal, token)\n            }\n            TokenType::BangEqual =\u003e {\n                self.parse_binary_expression(left, BinaryOperator::NotEqual, token)\n            }\n            TokenType::Less =\u003e self.parse_binary_expression(left, BinaryOperator::Less, token),\n            TokenType::LessEqual =\u003e {\n                self.parse_binary_expression(left, BinaryOperator::LessEqual, token)\n            }\n            TokenType::Greater =\u003e {\n                self.parse_binary_expression(left, BinaryOperator::Greater, token)\n            }\n            TokenType::GreaterEqual =\u003e {\n                self.parse_binary_expression(left, BinaryOperator::GreaterEqual, token)\n            }\n\n            // Logical operators\n            TokenType::AmpAmp =\u003e self.parse_binary_expression(left, BinaryOperator::And, token),\n            TokenType::PipePipe =\u003e self.parse_binary_expression(left, BinaryOperator::Or, token),\n\n            // Assignment operators\n            TokenType::Equal =\u003e self.parse_binary_expression(left, BinaryOperator::Assign, token),\n\n            // Postfix operators\n            TokenType::Dot =\u003e self.parse_member_access(left, token),\n            TokenType::LeftParen =\u003e self.parse_function_call(left, token),\n            TokenType::LeftBracket =\u003e self.parse_index_expression(left, token),\n\n            _ =\u003e Err(ParseError::unexpected_token(\"binary operator\", token)),\n        }\n    }\n\n    fn parse_binary_expression(\n        \u0026mut self,\n        left: \u0026'arena Expression,\n        operator: BinaryOperator,\n        token: \u0026Token,\n    ) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        // Get the precedence for this operator\n        let op_info = infix_binding_power(\u0026token.token_type)\n            .ok_or_else(|| ParseError::unexpected_token(\"binary operator\", token))?;\n\n        // Parse the right operand with appropriate precedence\n        let right_bp = match op_info.associativity {\n            Associativity::Left =\u003e op_info.binding_power + 1,\n            Associativity::Right =\u003e op_info.binding_power,\n            Associativity::None =\u003e op_info.binding_power + 1,\n        };\n\n        let right = self.parse_expression(right_bp)?;\n\n        Ok(self.arena.alloc(Expression::Binary(BinaryExpression {\n            left: Box::new(left.clone()),\n            operator,\n            right: Box::new(right.clone()),\n            span: token.span.clone(),\n        })))\n    }\n\n    /// Parse qualified identifiers like module.function or simple identifiers\n    #[allow(dead_code)]\n    fn parse_qualified_identifier(\n        \u0026mut self,\n        first_part: String,\n        _start_span: Span,\n    ) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        // Just return a simple identifier - dots are handled as postfix operators\n        Ok(self.arena.alloc(Expression::Identifier(first_part)))\n    }\n\n    /// Parse array literals like [1, 2, 3]\n    fn parse_array_literal(\u0026mut self) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        let start_span = self.tokens.peek().span.clone();\n        let mut elements = Vec::new();\n\n        // Check for empty array\n        if let TokenType::RightBracket = self.tokens.peek().token_type {\n            let end_token = self.tokens.consume();\n            use crate::ast::ArrayLiteral;\n            return Ok(self.arena.alloc(Expression::Array(ArrayLiteral {\n                elements,\n                span: Span::new(\n                    start_span.start,\n                    end_token.span.end,\n                    start_span.line,\n                    start_span.column,\n                ),\n            })));\n        }\n\n        // Parse comma-separated expressions\n        loop {\n            let expr = self.parse_expression(0)?;\n            elements.push(expr.clone());\n\n            let token = self.tokens.consume();\n            match token.token_type {\n                TokenType::Comma =\u003e {\n                    // Check if there's another element or if this is a trailing comma\n                    if let TokenType::RightBracket = self.tokens.peek().token_type {\n                        let end_token = self.tokens.consume();\n                        use crate::ast::ArrayLiteral;\n                        return Ok(self.arena.alloc(Expression::Array(ArrayLiteral {\n                            elements,\n                            span: Span::new(\n                                start_span.start,\n                                end_token.span.end,\n                                start_span.line,\n                                start_span.column,\n                            ),\n                        })));\n                    }\n                    // Continue parsing next element\n                }\n                TokenType::RightBracket =\u003e {\n                    use crate::ast::ArrayLiteral;\n                    return Ok(self.arena.alloc(Expression::Array(ArrayLiteral {\n                        elements,\n                        span: Span::new(\n                            start_span.start,\n                            token.span.end,\n                            start_span.line,\n                            start_span.column,\n                        ),\n                    })));\n                }\n                _ =\u003e return Err(ParseError::unexpected_token(\"',' or ']'\", \u0026token)),\n            }\n        }\n    }\n\n    /// Parse member access like obj.member\n    fn parse_member_access(\n        \u0026mut self,\n        left: \u0026'arena Expression,\n        _token: \u0026Token,\n    ) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        let member_token = self.tokens.consume();\n        match member_token.token_type {\n            TokenType::Identifier(member_name) =\u003e {\n                use crate::ast::MemberAccessExpression;\n                Ok(self\n                    .arena\n                    .alloc(Expression::MemberAccess(MemberAccessExpression {\n                        object: Box::new(left.clone()),\n                        member: member_name,\n                        span: member_token.span.clone(),\n                    })))\n            }\n            _ =\u003e Err(ParseError::unexpected_token(\"member name\", \u0026member_token)),\n        }\n    }\n\n    /// Parse function calls like func(arg1, arg2)\n    fn parse_function_call(\n        \u0026mut self,\n        left: \u0026'arena Expression,\n        _token: \u0026Token,\n    ) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        let mut arguments = Vec::new();\n\n        // Check for empty argument list\n        if let TokenType::RightParen = self.tokens.peek().token_type {\n            self.tokens.consume();\n            use crate::ast::CallExpression;\n            return Ok(self.arena.alloc(Expression::Call(CallExpression {\n                callee: Box::new(left.clone()),\n                arguments,\n                span: _token.span.clone(),\n            })));\n        }\n\n        // Parse comma-separated arguments\n        loop {\n            let arg = self.parse_expression(0)?;\n            arguments.push(arg.clone());\n\n            let token = self.tokens.consume();\n            match token.token_type {\n                TokenType::Comma =\u003e {\n                    // Check for trailing comma\n                    if let TokenType::RightParen = self.tokens.peek().token_type {\n                        self.tokens.consume();\n                        break;\n                    }\n                    // Continue parsing next argument\n                }\n                TokenType::RightParen =\u003e break,\n                _ =\u003e return Err(ParseError::unexpected_token(\"',' or ')'\", \u0026token)),\n            }\n        }\n\n        use crate::ast::CallExpression;\n        Ok(self.arena.alloc(Expression::Call(CallExpression {\n            callee: Box::new(left.clone()),\n            arguments,\n            span: _token.span.clone(),\n        })))\n    }\n\n    /// Parse index expressions like arr[index]\n    fn parse_index_expression(\n        \u0026mut self,\n        left: \u0026'arena Expression,\n        _token: \u0026Token,\n    ) -\u003e Result\u003c\u0026'arena Expression, ParseError\u003e {\n        let index = self.parse_expression(0)?;\n\n        let close_token = self.tokens.consume();\n        if !matches!(close_token.token_type, TokenType::RightBracket) {\n            return Err(ParseError::unexpected_token(\"']'\", \u0026close_token));\n        }\n\n        use crate::ast::IndexExpression;\n        Ok(self.arena.alloc(Expression::Index(IndexExpression {\n            object: Box::new(left.clone()),\n            index: Box::new(index.clone()),\n            span: _token.span.clone(),\n        })))\n    }\n\n    /// Parse patterns for match expressions\n    pub fn parse_pattern(\u0026mut self) -\u003e Result\u003c\u0026'arena crate::ast::Pattern, ParseError\u003e {\n        self.parse_pattern_with_precedence(0)\n    }\n\n    /// Parse pattern with precedence support for or patterns\n    fn parse_pattern_with_precedence(\n        \u0026mut self,\n        min_precedence: u8,\n    ) -\u003e Result\u003c\u0026'arena crate::ast::Pattern, ParseError\u003e {\n        let mut left = self.parse_primary_pattern()?;\n\n        // Handle Or patterns with precedence\n        while let TokenType::Pipe = self.tokens.peek().token_type {\n            if min_precedence \u003e 10 {\n                // Or patterns have low precedence\n                break;\n            }\n\n            self.tokens.consume(); // consume '|'\n            let right = self.parse_pattern_with_precedence(11)?;\n\n            // Convert to or pattern\n            let patterns = match left {\n                crate::ast::Pattern::Or(or_pattern) =\u003e {\n                    let mut patterns = or_pattern.patterns.clone();\n                    patterns.push(right.clone());\n                    patterns\n                }\n                _ =\u003e vec![left.clone(), right.clone()],\n            };\n\n            left = self\n                .arena\n                .alloc(crate::ast::Pattern::Or(crate::ast::OrPattern {\n                    patterns,\n                    span: left.span().combine(right.span()),\n                }));\n        }\n\n        Ok(left)\n    }\n\n    /// Parse primary patterns (not including or patterns)\n    fn parse_primary_pattern(\u0026mut self) -\u003e Result\u003c\u0026'arena crate::ast::Pattern, ParseError\u003e {\n        let token = self.tokens.consume();\n\n        match \u0026token.token_type {\n            // Literal patterns\n            TokenType::StringLiteral(s) =\u003e {\n                let pattern = self\n                    .arena\n                    .alloc(crate::ast::Pattern::Literal(Literal::String(s.clone())));\n                self.check_for_guard_or_binding(pattern)\n            }\n            TokenType::IntegerLiteral(i) =\u003e {\n                let pattern = self\n                    .arena\n                    .alloc(crate::ast::Pattern::Literal(Literal::Integer(*i)));\n                self.check_for_range_or_guard_or_binding(*i, pattern)\n            }\n            TokenType::FloatLiteral(f) =\u003e {\n                let pattern = self\n                    .arena\n                    .alloc(crate::ast::Pattern::Literal(Literal::Float(*f)));\n                self.check_for_guard_or_binding(pattern)\n            }\n            TokenType::BooleanLiteral(b) =\u003e {\n                let pattern = self\n                    .arena\n                    .alloc(crate::ast::Pattern::Literal(Literal::Boolean(*b)));\n                self.check_for_guard_or_binding(pattern)\n            }\n\n            // Identifier patterns\n            TokenType::Identifier(name) =\u003e {\n                // Check for wildcard pattern first\n                if name == \"_\" {\n                    let pattern = self.arena.alloc(crate::ast::Pattern::Wildcard);\n                    self.check_for_guard_or_binding(pattern)\n                } else if let TokenType::LeftBrace = self.tokens.peek().token_type {\n                    // Data class pattern\n                    let pattern = self.parse_data_class_pattern(name.clone())?;\n                    self.check_for_guard_or_binding(pattern)\n                } else if let TokenType::At = self.tokens.peek().token_type {\n                    // Binding pattern: name @ pattern\n                    self.parse_binding_pattern(name.clone())\n                } else {\n                    // Simple identifier pattern\n                    let pattern = self\n                        .arena\n                        .alloc(crate::ast::Pattern::Identifier(name.clone()));\n                    self.check_for_guard_or_binding(pattern)\n                }\n            }\n\n            // Slice patterns: [head, tail @ ..]\n            TokenType::LeftBracket =\u003e self.parse_slice_pattern(),\n\n            // Range patterns starting with .. : ..=10\n            TokenType::DotDot | TokenType::DotDotEqual =\u003e {\n                self.parse_range_pattern_from_operator(\u0026token)\n            }\n\n            _ =\u003e Err(ParseError::unexpected_token(\"pattern\", \u0026token)),\n        }\n    }\n\n    /// Check for range patterns when we have an integer literal\n    fn check_for_range_or_guard_or_binding(\n        \u0026mut self,\n        value: i64,\n        pattern: \u0026'arena crate::ast::Pattern,\n    ) -\u003e Result\u003c\u0026'arena crate::ast::Pattern, ParseError\u003e {\n        match self.tokens.peek().token_type {\n            TokenType::DotDot | TokenType::DotDotEqual =\u003e {\n                self.parse_range_pattern_from_start(value)\n            }\n            _ =\u003e self.check_for_guard_or_binding(pattern),\n        }\n    }\n\n    /// Check for guard expressions: pattern if condition\n    fn check_for_guard_or_binding(\n        \u0026mut self,\n        pattern: \u0026'arena crate::ast::Pattern,\n    ) -\u003e Result\u003c\u0026'arena crate::ast::Pattern, ParseError\u003e {\n        match self.tokens.peek().token_type {\n            TokenType::If =\u003e self.parse_guard_pattern(pattern),\n            _ =\u003e Ok(pattern),\n        }\n    }\n\n    /// Parse range patterns like 1..10 or 1..=10\n    fn parse_range_pattern_from_start(\n        \u0026mut self,\n        start_value: i64,\n    ) -\u003e Result\u003c\u0026'arena crate::ast::Pattern, ParseError\u003e {\n        let range_token = self.tokens.consume(); // consume .. or ..=\n        let inclusive = matches!(range_token.token_type, TokenType::DotDotEqual);\n\n        let start_pattern = self\n            .arena\n            .alloc(crate::ast::Pattern::Literal(Literal::Integer(start_value)));\n\n        // Parse end pattern if present\n        let end_pattern = if matches!(self.tokens.peek().token_type, TokenType::IntegerLiteral(_)) {\n            Some(Box::new(self.parse_primary_pattern()?.clone()))\n        } else {\n            None\n        };\n\n        let pattern = self\n            .arena\n            .alloc(crate::ast::Pattern::Range(crate::ast::RangePattern {\n                start: Some(Box::new(start_pattern.clone())),\n                end: end_pattern,\n                inclusive,\n                span: range_token.span.clone(),\n            }));\n\n        self.check_for_guard_or_binding(pattern)\n    }\n\n    /// Parse range patterns starting with .. : ..10 or ..=10\n    fn parse_range_pattern_from_operator(\n        \u0026mut self,\n        range_token: \u0026Token,\n    ) -\u003e Result\u003c\u0026'arena crate::ast::Pattern, ParseError\u003e {\n        let inclusive = matches!(range_token.token_type, TokenType::DotDotEqual);\n\n        // Parse end pattern if present\n        let end_pattern = if matches!(self.tokens.peek().token_type, TokenType::IntegerLiteral(_)) {\n            Some(Box::new(self.parse_primary_pattern()?.clone()))\n        } else {\n            None\n        };\n\n        let pattern = self\n            .arena\n            .alloc(crate::ast::Pattern::Range(crate::ast::RangePattern {\n                start: None,\n                end: end_pattern,\n                inclusive,\n                span: range_token.span.clone(),\n            }));\n\n        self.check_for_guard_or_binding(pattern)\n    }\n\n    /// Parse slice patterns like [head, tail @ ..]\n    fn parse_slice_pattern(\u0026mut self) -\u003e Result\u003c\u0026'arena crate::ast::Pattern, ParseError\u003e {\n        use crate::ast::SlicePattern;\n\n        let mut prefix = Vec::new();\n        let mut rest = None;\n        let mut suffix = Vec::new();\n        let mut found_rest = false;\n\n        // Handle empty slice pattern\n        if let TokenType::RightBracket = self.tokens.peek().token_type {\n            let close_token = self.tokens.consume();\n            return Ok(self.arena.alloc(crate::ast::Pattern::Slice(SlicePattern {\n                prefix,\n                rest,\n                suffix,\n                span: close_token.span.clone(),\n            })));\n        }\n\n        // Parse slice elements\n        loop {\n            // Check for rest pattern: .. or name @ ..\n            if let TokenType::DotDot = self.tokens.peek().token_type {\n                self.tokens.consume(); // consume '..'\n                found_rest = true;\n            } else if let TokenType::Identifier(name) = \u0026self.tokens.peek().token_type {\n                let name = name.clone();\n                if let Some(at_token) = self.tokens.peek_ahead(1) {\n                    if matches!(at_token.token_type, TokenType::At) {\n                        if let Some(dot_token) = self.tokens.peek_ahead(2) {\n                            if matches!(dot_token.token_type, TokenType::DotDot) {\n                                // Found name @ .. pattern\n                                self.tokens.consume(); // consume name\n                                self.tokens.consume(); // consume '@'\n                                self.tokens.consume(); // consume '..'\n                                rest = Some(name);\n                                found_rest = true;\n                            }\n                        }\n                    }\n                }\n\n                if !found_rest {\n                    // Regular pattern\n                    let pattern = self.parse_primary_pattern()?;\n                    if found_rest {\n                        suffix.push(pattern.clone());\n                    } else {\n                        prefix.push(pattern.clone());\n                    }\n                }\n            } else {\n                // Regular pattern\n                let pattern = self.parse_primary_pattern()?;\n                if found_rest {\n                    suffix.push(pattern.clone());\n                } else {\n                    prefix.push(pattern.clone());\n                }\n            }\n\n            // Check for continuation\n            let next_token = self.tokens.consume();\n            match next_token.token_type {\n                TokenType::Comma =\u003e {\n                    // Check for trailing comma\n                    if let TokenType::RightBracket = self.tokens.peek().token_type {\n                        let close_token = self.tokens.consume();\n                        return Ok(self.arena.alloc(crate::ast::Pattern::Slice(SlicePattern {\n                            prefix,\n                            rest,\n                            suffix,\n                            span: close_token.span.clone(),\n                        })));\n                    }\n                    // Continue parsing\n                }\n                TokenType::RightBracket =\u003e {\n                    return Ok(self.arena.alloc(crate::ast::Pattern::Slice(SlicePattern {\n                        prefix,\n                        rest,\n                        suffix,\n                        span: next_token.span.clone(),\n                    })));\n                }\n                _ =\u003e return Err(ParseError::unexpected_token(\"',' or ']'\", \u0026next_token)),\n            }\n        }\n    }\n\n    /// Parse guard patterns like x if x \u003e 0\n    fn parse_guard_pattern(\n        \u0026mut self,\n        pattern: \u0026'arena crate::ast::Pattern,\n    ) -\u003e Result\u003c\u0026'arena crate::ast::Pattern, ParseError\u003e {\n        self.tokens.consume(); // consume 'if'\n\n        let guard_expr = self.parse_expression(0)?;\n\n        Ok(self\n            .arena\n            .alloc(crate::ast::Pattern::Guard(crate::ast::GuardPattern {\n                pattern: Box::new(pattern.clone()),\n                guard: guard_expr.clone(),\n                span: pattern.span().combine(guard_expr.span()),\n            })))\n    }\n\n    /// Parse binding patterns like name @ pattern\n    fn parse_binding_pattern(\n        \u0026mut self,\n        name: String,\n    ) -\u003e Result\u003c\u0026'arena crate::ast::Pattern, ParseError\u003e {\n        self.tokens.consume(); // consume '@'\n\n        let pattern = self.parse_primary_pattern()?;\n\n        Ok(self\n            .arena\n            .alloc(crate::ast::Pattern::Binding(crate::ast::BindingPattern {\n                name,\n                pattern: Box::new(pattern.clone()),\n                span: pattern.span(), // TODO: Better span calculation\n            })))\n    }\n\n    /// Parse data class patterns like Person { name, age }\n    fn parse_data_class_pattern(\n        \u0026mut self,\n        name: String,\n    ) -\u003e Result\u003c\u0026'arena crate::ast::Pattern, ParseError\u003e {\n        use crate::ast::{DataClassPattern, FieldPattern};\n\n        // Consume the opening brace\n        let open_brace = self.tokens.consume();\n        if !matches!(open_brace.token_type, TokenType::LeftBrace) {\n            return Err(ParseError::unexpected_token(\"'{'\", \u0026open_brace));\n        }\n\n        let mut fields = Vec::new();\n        let has_rest = false;\n\n        // Handle empty pattern\n        if let TokenType::RightBrace = self.tokens.peek().token_type {\n            let close_token = self.tokens.consume();\n            return Ok(self\n                .arena\n                .alloc(crate::ast::Pattern::DataClass(DataClassPattern {\n                    name,\n                    fields,\n                    has_rest,\n                    span: close_token.span.clone(),\n                })));\n        }\n\n        // Parse field patterns\n        loop {\n            let token = self.tokens.consume();\n            match token.token_type {\n                TokenType::Identifier(field_name) =\u003e {\n                    // Check for field binding: field: pattern\n                    if let TokenType::Colon = self.tokens.peek().token_type {\n                        self.tokens.consume(); // consume ':'\n                        let pattern = self.parse_pattern()?;\n                        fields.push(FieldPattern {\n                            name: field_name,\n                            pattern: Some(pattern.clone()),\n                            span: token.span.clone(),\n                        });\n                    } else {\n                        // Simple field binding\n                        fields.push(FieldPattern {\n                            name: field_name,\n                            pattern: None,\n                            span: token.span.clone(),\n                        });\n                    }\n                }\n                _ =\u003e return Err(ParseError::unexpected_token(\"field name\", \u0026token)),\n            }\n\n            // Check for continuation\n            let next_token = self.tokens.consume();\n            match next_token.token_type {\n                TokenType::Comma =\u003e {\n                    // Check for trailing comma or rest pattern\n                    if let TokenType::RightBrace = self.tokens.peek().token_type {\n                        let close_token = self.tokens.consume();\n                        return Ok(self.arena.alloc(crate::ast::Pattern::DataClass(\n                            DataClassPattern {\n                                name,\n                                fields,\n                                has_rest,\n                                span: close_token.span.clone(),\n                            },\n                        )));\n                    }\n                    // Continue parsing\n                }\n                TokenType::RightBrace =\u003e {\n                    return Ok(self.arena.alloc(crate::ast::Pattern::DataClass(\n                        DataClassPattern {\n                            name,\n                            fields,\n                            has_rest,\n                            span: next_token.span.clone(),\n                        },\n                    )));\n                }\n                _ =\u003e return Err(ParseError::unexpected_token(\"',' or '}'\", \u0026next_token)),\n            }\n        }\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::{\n        ast::Arena,\n        token::{TokenType, VecTokenStream},\n    };\n\n    fn create_test_arena() -\u003e Arena {\n        Arena::new()\n    }\n\n    fn create_token_stream(token_types: Vec\u003cTokenType\u003e) -\u003e VecTokenStream {\n        VecTokenStream::from_token_types(token_types)\n    }\n\n    #[test]\n    fn test_pratt_parser_creation() {\n        let arena = create_test_arena();\n        let tokens = create_token_stream(vec![TokenType::IntegerLiteral(42)]);\n        let parser = PrattParser::new(\u0026arena, tokens);\n\n        assert!(!parser.tokens.is_at_end());\n    }\n\n    #[test]\n    fn test_primary_expression_parsing() {\n        let arena = create_test_arena();\n        let tokens = create_token_stream(vec![TokenType::IntegerLiteral(42)]);\n        let mut parser = PrattParser::new(\u0026arena, tokens);\n\n        // This should now work for simple literals\n        let result = parser.parse_primary();\n        assert!(result.is_ok());\n\n        if let Ok(expr) = result {\n            if let Expression::Literal(Literal::Integer(value)) = expr {\n                assert_eq!(*value, 42);\n            } else {\n                panic!(\"Expected integer literal\");\n            }\n        }\n    }\n\n    #[test]\n    fn test_binary_expression_parsing() {\n        let arena = create_test_arena();\n        let tokens = create_token_stream(vec![\n            TokenType::IntegerLiteral(1),\n            TokenType::Plus,\n            TokenType::IntegerLiteral(2),\n        ]);\n        let mut parser = PrattParser::new(\u0026arena, tokens);\n\n        // Use parse_expression for full expression parsing\n        let result = parser.parse_expression(0);\n        assert!(result.is_ok());\n\n        if let Ok(expr) = result {\n            if let Expression::Binary(binary_expr) = expr {\n                assert!(matches!(binary_expr.operator, BinaryOperator::Add));\n            } else {\n                panic!(\"Expected binary expression\");\n            }\n        }\n    }\n\n    #[test]\n    fn test_precedence_binding() {\n        let arena = create_test_arena();\n        let tokens = create_token_stream(vec![\n            TokenType::IntegerLiteral(1),\n            TokenType::Plus,\n            TokenType::IntegerLiteral(2),\n            TokenType::Star,\n            TokenType::IntegerLiteral(3),\n        ]);\n        let mut parser = PrattParser::new(\u0026arena, tokens);\n\n        // Use parse_expression for full expression parsing\n        let result = parser.parse_expression(0);\n        assert!(result.is_ok());\n\n        if let Ok(expr) = result {\n            if let Expression::Binary(binary_expr) = expr {\n                assert!(matches!(binary_expr.operator, BinaryOperator::Add));\n                // Right side should be another binary expression (2 * 3)\n                if let Expression::Binary(right_expr) = binary_expr.right.as_ref() {\n                    assert!(matches!(right_expr.operator, BinaryOperator::Mul));\n                } else {\n                    panic!(\"Expected right side to be binary expression\");\n                }\n            } else {\n                panic!(\"Expected binary expression\");\n            }\n        }\n    }\n\n    #[test]\n    fn test_parser_state_management() {\n        let arena = create_test_arena();\n        let tokens = create_token_stream(vec![\n            TokenType::Identifier(\"a\".to_string()),\n            TokenType::Identifier(\"b\".to_string()),\n            TokenType::Identifier(\"c\".to_string()),\n        ]);\n        let mut parser = PrattParser::new(\u0026arena, tokens);\n\n        // Test token navigation\n        assert!(!parser.tokens.is_at_end());\n\n        parser.tokens.consume();\n        assert!(!parser.tokens.is_at_end());\n\n        parser.tokens.consume();\n        assert!(!parser.tokens.is_at_end());\n\n        parser.tokens.consume();\n        assert!(parser.tokens.is_at_end());\n    }\n}\n","traces":[{"line":26,"address":[],"length":0,"stats":{"Line":88}},{"line":31,"address":[],"length":0,"stats":{"Line":143}},{"line":36,"address":[],"length":0,"stats":{"Line":286}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":202}},{"line":43,"address":[],"length":0,"stats":{"Line":202}},{"line":44,"address":[],"length":0,"stats":{"Line":80}},{"line":48,"address":[],"length":0,"stats":{"Line":122}},{"line":49,"address":[],"length":0,"stats":{"Line":55}},{"line":53,"address":[],"length":0,"stats":{"Line":134}},{"line":54,"address":[],"length":0,"stats":{"Line":67}},{"line":55,"address":[],"length":0,"stats":{"Line":0}},{"line":59,"address":[],"length":0,"stats":{"Line":67}},{"line":60,"address":[],"length":0,"stats":{"Line":6}},{"line":64,"address":[],"length":0,"stats":{"Line":61}},{"line":67,"address":[],"length":0,"stats":{"Line":62}},{"line":70,"address":[],"length":0,"stats":{"Line":141}},{"line":74,"address":[],"length":0,"stats":{"Line":144}},{"line":75,"address":[],"length":0,"stats":{"Line":144}},{"line":77,"address":[],"length":0,"stats":{"Line":144}},{"line":79,"address":[],"length":0,"stats":{"Line":3}},{"line":80,"address":[],"length":0,"stats":{"Line":3}},{"line":81,"address":[],"length":0,"stats":{"Line":3}},{"line":82,"address":[],"length":0,"stats":{"Line":80}},{"line":83,"address":[],"length":0,"stats":{"Line":80}},{"line":85,"address":[],"length":0,"stats":{"Line":1}},{"line":86,"address":[],"length":0,"stats":{"Line":1}},{"line":88,"address":[],"length":0,"stats":{"Line":10}},{"line":89,"address":[],"length":0,"stats":{"Line":10}},{"line":93,"address":[],"length":0,"stats":{"Line":31}},{"line":95,"address":[],"length":0,"stats":{"Line":31}},{"line":97,"address":[],"length":0,"stats":{"Line":2}},{"line":98,"address":[],"length":0,"stats":{"Line":2}},{"line":99,"address":[],"length":0,"stats":{"Line":2}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":29}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":14}},{"line":112,"address":[],"length":0,"stats":{"Line":3}},{"line":113,"address":[],"length":0,"stats":{"Line":4}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":118,"address":[],"length":0,"stats":{"Line":7}},{"line":120,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":123,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":12}},{"line":130,"address":[],"length":0,"stats":{"Line":0}},{"line":131,"address":[],"length":0,"stats":{"Line":0}},{"line":132,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":6}},{"line":135,"address":[],"length":0,"stats":{"Line":6}},{"line":136,"address":[],"length":0,"stats":{"Line":6}},{"line":140,"address":[],"length":0,"stats":{"Line":5}},{"line":142,"address":[],"length":0,"stats":{"Line":1}},{"line":146,"address":[],"length":0,"stats":{"Line":61}},{"line":151,"address":[],"length":0,"stats":{"Line":61}},{"line":153,"address":[],"length":0,"stats":{"Line":15}},{"line":154,"address":[],"length":0,"stats":{"Line":2}},{"line":155,"address":[],"length":0,"stats":{"Line":9}},{"line":156,"address":[],"length":0,"stats":{"Line":0}},{"line":157,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":161,"address":[],"length":0,"stats":{"Line":2}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":0}},{"line":166,"address":[],"length":0,"stats":{"Line":1}},{"line":167,"address":[],"length":0,"stats":{"Line":0}},{"line":168,"address":[],"length":0,"stats":{"Line":0}},{"line":170,"address":[],"length":0,"stats":{"Line":0}},{"line":171,"address":[],"length":0,"stats":{"Line":3}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":178,"address":[],"length":0,"stats":{"Line":3}},{"line":179,"address":[],"length":0,"stats":{"Line":1}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":10}},{"line":186,"address":[],"length":0,"stats":{"Line":9}},{"line":187,"address":[],"length":0,"stats":{"Line":6}},{"line":189,"address":[],"length":0,"stats":{"Line":0}},{"line":193,"address":[],"length":0,"stats":{"Line":36}},{"line":200,"address":[],"length":0,"stats":{"Line":72}},{"line":201,"address":[],"length":0,"stats":{"Line":72}},{"line":204,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":32}},{"line":206,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":4}},{"line":210,"address":[],"length":0,"stats":{"Line":36}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":216,"address":[],"length":0,"stats":{"Line":0}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":232,"address":[],"length":0,"stats":{"Line":5}},{"line":233,"address":[],"length":0,"stats":{"Line":5}},{"line":234,"address":[],"length":0,"stats":{"Line":5}},{"line":237,"address":[],"length":0,"stats":{"Line":5}},{"line":238,"address":[],"length":0,"stats":{"Line":1}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":241,"address":[],"length":0,"stats":{"Line":0}},{"line":242,"address":[],"length":0,"stats":{"Line":0}},{"line":243,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":0}},{"line":245,"address":[],"length":0,"stats":{"Line":0}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":252,"address":[],"length":0,"stats":{"Line":0}},{"line":253,"address":[],"length":0,"stats":{"Line":22}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":256,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":8}},{"line":261,"address":[],"length":0,"stats":{"Line":1}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":265,"address":[],"length":0,"stats":{"Line":0}},{"line":266,"address":[],"length":0,"stats":{"Line":0}},{"line":267,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":0}},{"line":277,"address":[],"length":0,"stats":{"Line":3}},{"line":278,"address":[],"length":0,"stats":{"Line":3}},{"line":279,"address":[],"length":0,"stats":{"Line":3}},{"line":280,"address":[],"length":0,"stats":{"Line":3}},{"line":281,"address":[],"length":0,"stats":{"Line":3}},{"line":282,"address":[],"length":0,"stats":{"Line":3}},{"line":283,"address":[],"length":0,"stats":{"Line":3}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":10}},{"line":298,"address":[],"length":0,"stats":{"Line":10}},{"line":299,"address":[],"length":0,"stats":{"Line":10}},{"line":300,"address":[],"length":0,"stats":{"Line":10}},{"line":302,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":9}},{"line":320,"address":[],"length":0,"stats":{"Line":9}},{"line":323,"address":[],"length":0,"stats":{"Line":9}},{"line":324,"address":[],"length":0,"stats":{"Line":3}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":327,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":334,"address":[],"length":0,"stats":{"Line":0}},{"line":335,"address":[],"length":0,"stats":{"Line":14}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":1}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":6}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":6}},{"line":355,"address":[],"length":0,"stats":{"Line":6}},{"line":356,"address":[],"length":0,"stats":{"Line":6}},{"line":357,"address":[],"length":0,"stats":{"Line":6}},{"line":362,"address":[],"length":0,"stats":{"Line":6}},{"line":367,"address":[],"length":0,"stats":{"Line":12}},{"line":369,"address":[],"length":0,"stats":{"Line":0}},{"line":370,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":0}},{"line":375,"address":[],"length":0,"stats":{"Line":6}},{"line":376,"address":[],"length":0,"stats":{"Line":6}},{"line":377,"address":[],"length":0,"stats":{"Line":6}},{"line":378,"address":[],"length":0,"stats":{"Line":6}},{"line":383,"address":[],"length":0,"stats":{"Line":19}},{"line":384,"address":[],"length":0,"stats":{"Line":19}},{"line":388,"address":[],"length":0,"stats":{"Line":22}},{"line":392,"address":[],"length":0,"stats":{"Line":44}},{"line":395,"address":[],"length":0,"stats":{"Line":24}},{"line":396,"address":[],"length":0,"stats":{"Line":4}},{"line":398,"address":[],"length":0,"stats":{"Line":1}},{"line":401,"address":[],"length":0,"stats":{"Line":3}},{"line":402,"address":[],"length":0,"stats":{"Line":3}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":1}},{"line":407,"address":[],"length":0,"stats":{"Line":1}},{"line":408,"address":[],"length":0,"stats":{"Line":1}},{"line":409,"address":[],"length":0,"stats":{"Line":1}},{"line":411,"address":[],"length":0,"stats":{"Line":2}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":0}},{"line":418,"address":[],"length":0,"stats":{"Line":0}},{"line":422,"address":[],"length":0,"stats":{"Line":21}},{"line":426,"address":[],"length":0,"stats":{"Line":27}},{"line":427,"address":[],"length":0,"stats":{"Line":27}},{"line":429,"address":[],"length":0,"stats":{"Line":27}},{"line":431,"address":[],"length":0,"stats":{"Line":1}},{"line":432,"address":[],"length":0,"stats":{"Line":1}},{"line":433,"address":[],"length":0,"stats":{"Line":1}},{"line":434,"address":[],"length":0,"stats":{"Line":1}},{"line":435,"address":[],"length":0,"stats":{"Line":1}},{"line":437,"address":[],"length":0,"stats":{"Line":11}},{"line":438,"address":[],"length":0,"stats":{"Line":11}},{"line":439,"address":[],"length":0,"stats":{"Line":11}},{"line":440,"address":[],"length":0,"stats":{"Line":11}},{"line":441,"address":[],"length":0,"stats":{"Line":11}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":445,"address":[],"length":0,"stats":{"Line":0}},{"line":446,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":449,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":0}},{"line":451,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":457,"address":[],"length":0,"stats":{"Line":12}},{"line":459,"address":[],"length":0,"stats":{"Line":12}},{"line":460,"address":[],"length":0,"stats":{"Line":1}},{"line":461,"address":[],"length":0,"stats":{"Line":1}},{"line":462,"address":[],"length":0,"stats":{"Line":11}},{"line":464,"address":[],"length":0,"stats":{"Line":8}},{"line":465,"address":[],"length":0,"stats":{"Line":0}},{"line":466,"address":[],"length":0,"stats":{"Line":7}},{"line":468,"address":[],"length":0,"stats":{"Line":1}},{"line":471,"address":[],"length":0,"stats":{"Line":6}},{"line":472,"address":[],"length":0,"stats":{"Line":6}},{"line":473,"address":[],"length":0,"stats":{"Line":6}},{"line":474,"address":[],"length":0,"stats":{"Line":6}},{"line":479,"address":[],"length":0,"stats":{"Line":2}},{"line":482,"address":[],"length":0,"stats":{"Line":0}},{"line":483,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":1}},{"line":491,"address":[],"length":0,"stats":{"Line":11}},{"line":496,"address":[],"length":0,"stats":{"Line":11}},{"line":497,"address":[],"length":0,"stats":{"Line":0}},{"line":498,"address":[],"length":0,"stats":{"Line":3}},{"line":500,"address":[],"length":0,"stats":{"Line":8}},{"line":505,"address":[],"length":0,"stats":{"Line":23}},{"line":509,"address":[],"length":0,"stats":{"Line":23}},{"line":510,"address":[],"length":0,"stats":{"Line":1}},{"line":511,"address":[],"length":0,"stats":{"Line":22}},{"line":516,"address":[],"length":0,"stats":{"Line":3}},{"line":520,"address":[],"length":0,"stats":{"Line":3}},{"line":521,"address":[],"length":0,"stats":{"Line":7}},{"line":523,"address":[],"length":0,"stats":{"Line":3}},{"line":524,"address":[],"length":0,"stats":{"Line":3}},{"line":525,"address":[],"length":0,"stats":{"Line":3}},{"line":528,"address":[],"length":0,"stats":{"Line":6}},{"line":529,"address":[],"length":0,"stats":{"Line":6}},{"line":531,"address":[],"length":0,"stats":{"Line":0}},{"line":534,"address":[],"length":0,"stats":{"Line":0}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":536,"address":[],"length":0,"stats":{"Line":0}},{"line":537,"address":[],"length":0,"stats":{"Line":0}},{"line":538,"address":[],"length":0,"stats":{"Line":0}},{"line":539,"address":[],"length":0,"stats":{"Line":0}},{"line":540,"address":[],"length":0,"stats":{"Line":0}},{"line":543,"address":[],"length":0,"stats":{"Line":0}},{"line":547,"address":[],"length":0,"stats":{"Line":0}},{"line":551,"address":[],"length":0,"stats":{"Line":0}},{"line":554,"address":[],"length":0,"stats":{"Line":0}},{"line":555,"address":[],"length":0,"stats":{"Line":0}},{"line":557,"address":[],"length":0,"stats":{"Line":0}},{"line":560,"address":[],"length":0,"stats":{"Line":0}},{"line":561,"address":[],"length":0,"stats":{"Line":0}},{"line":562,"address":[],"length":0,"stats":{"Line":0}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":564,"address":[],"length":0,"stats":{"Line":0}},{"line":565,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":0}},{"line":573,"address":[],"length":0,"stats":{"Line":2}},{"line":576,"address":[],"length":0,"stats":{"Line":2}},{"line":577,"address":[],"length":0,"stats":{"Line":2}},{"line":578,"address":[],"length":0,"stats":{"Line":2}},{"line":579,"address":[],"length":0,"stats":{"Line":2}},{"line":582,"address":[],"length":0,"stats":{"Line":2}},{"line":583,"address":[],"length":0,"stats":{"Line":1}},{"line":584,"address":[],"length":0,"stats":{"Line":1}},{"line":585,"address":[],"length":0,"stats":{"Line":1}},{"line":586,"address":[],"length":0,"stats":{"Line":1}},{"line":587,"address":[],"length":0,"stats":{"Line":1}},{"line":588,"address":[],"length":0,"stats":{"Line":1}},{"line":593,"address":[],"length":0,"stats":{"Line":0}},{"line":595,"address":[],"length":0,"stats":{"Line":1}},{"line":596,"address":[],"length":0,"stats":{"Line":0}},{"line":597,"address":[],"length":0,"stats":{"Line":0}},{"line":598,"address":[],"length":0,"stats":{"Line":1}},{"line":599,"address":[],"length":0,"stats":{"Line":0}},{"line":600,"address":[],"length":0,"stats":{"Line":0}},{"line":601,"address":[],"length":0,"stats":{"Line":0}},{"line":602,"address":[],"length":0,"stats":{"Line":0}},{"line":603,"address":[],"length":0,"stats":{"Line":0}},{"line":605,"address":[],"length":0,"stats":{"Line":0}},{"line":606,"address":[],"length":0,"stats":{"Line":0}},{"line":607,"address":[],"length":0,"stats":{"Line":0}},{"line":608,"address":[],"length":0,"stats":{"Line":0}},{"line":609,"address":[],"length":0,"stats":{"Line":0}},{"line":615,"address":[],"length":0,"stats":{"Line":0}},{"line":617,"address":[],"length":0,"stats":{"Line":0}},{"line":618,"address":[],"length":0,"stats":{"Line":0}},{"line":619,"address":[],"length":0,"stats":{"Line":0}},{"line":621,"address":[],"length":0,"stats":{"Line":0}},{"line":626,"address":[],"length":0,"stats":{"Line":2}},{"line":627,"address":[],"length":0,"stats":{"Line":0}},{"line":628,"address":[],"length":0,"stats":{"Line":0}},{"line":630,"address":[],"length":0,"stats":{"Line":0}},{"line":635,"address":[],"length":0,"stats":{"Line":0}},{"line":636,"address":[],"length":0,"stats":{"Line":0}},{"line":637,"address":[],"length":0,"stats":{"Line":0}},{"line":639,"address":[],"length":0,"stats":{"Line":0}},{"line":640,"address":[],"length":0,"stats":{"Line":0}},{"line":641,"address":[],"length":0,"stats":{"Line":0}},{"line":642,"address":[],"length":0,"stats":{"Line":0}},{"line":643,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":650,"address":[],"length":0,"stats":{"Line":0}},{"line":651,"address":[],"length":0,"stats":{"Line":0}},{"line":652,"address":[],"length":0,"stats":{"Line":0}},{"line":653,"address":[],"length":0,"stats":{"Line":0}},{"line":654,"address":[],"length":0,"stats":{"Line":0}},{"line":655,"address":[],"length":0,"stats":{"Line":0}},{"line":658,"address":[],"length":0,"stats":{"Line":0}},{"line":664,"address":[],"length":0,"stats":{"Line":1}},{"line":668,"address":[],"length":0,"stats":{"Line":1}},{"line":670,"address":[],"length":0,"stats":{"Line":2}},{"line":672,"address":[],"length":0,"stats":{"Line":0}},{"line":673,"address":[],"length":0,"stats":{"Line":0}},{"line":674,"address":[],"length":0,"stats":{"Line":0}},{"line":675,"address":[],"length":0,"stats":{"Line":0}},{"line":676,"address":[],"length":0,"stats":{"Line":0}},{"line":677,"address":[],"length":0,"stats":{"Line":0}},{"line":682,"address":[],"length":0,"stats":{"Line":1}},{"line":686,"address":[],"length":0,"stats":{"Line":1}},{"line":688,"address":[],"length":0,"stats":{"Line":2}},{"line":690,"address":[],"length":0,"stats":{"Line":0}},{"line":691,"address":[],"length":0,"stats":{"Line":0}},{"line":692,"address":[],"length":0,"stats":{"Line":0}},{"line":693,"address":[],"length":0,"stats":{"Line":0}},{"line":694,"address":[],"length":0,"stats":{"Line":0}},{"line":695,"address":[],"length":0,"stats":{"Line":0}},{"line":700,"address":[],"length":0,"stats":{"Line":4}},{"line":707,"address":[],"length":0,"stats":{"Line":4}},{"line":708,"address":[],"length":0,"stats":{"Line":4}},{"line":709,"address":[],"length":0,"stats":{"Line":0}},{"line":712,"address":[],"length":0,"stats":{"Line":4}},{"line":713,"address":[],"length":0,"stats":{"Line":4}},{"line":716,"address":[],"length":0,"stats":{"Line":4}},{"line":717,"address":[],"length":0,"stats":{"Line":1}},{"line":718,"address":[],"length":0,"stats":{"Line":1}},{"line":719,"address":[],"length":0,"stats":{"Line":1}},{"line":720,"address":[],"length":0,"stats":{"Line":1}},{"line":721,"address":[],"length":0,"stats":{"Line":1}},{"line":722,"address":[],"length":0,"stats":{"Line":1}},{"line":723,"address":[],"length":0,"stats":{"Line":1}},{"line":724,"address":[],"length":0,"stats":{"Line":1}},{"line":729,"address":[],"length":0,"stats":{"Line":0}},{"line":730,"address":[],"length":0,"stats":{"Line":5}},{"line":731,"address":[],"length":0,"stats":{"Line":5}},{"line":732,"address":[],"length":0,"stats":{"Line":5}},{"line":734,"address":[],"length":0,"stats":{"Line":5}},{"line":735,"address":[],"length":0,"stats":{"Line":3}},{"line":736,"address":[],"length":0,"stats":{"Line":3}},{"line":737,"address":[],"length":0,"stats":{"Line":0}},{"line":738,"address":[],"length":0,"stats":{"Line":0}},{"line":739,"address":[],"length":0,"stats":{"Line":0}},{"line":740,"address":[],"length":0,"stats":{"Line":0}},{"line":744,"address":[],"length":0,"stats":{"Line":2}},{"line":745,"address":[],"length":0,"stats":{"Line":2}},{"line":746,"address":[],"length":0,"stats":{"Line":2}},{"line":747,"address":[],"length":0,"stats":{"Line":2}},{"line":751,"address":[],"length":0,"stats":{"Line":0}},{"line":755,"address":[],"length":0,"stats":{"Line":5}},{"line":756,"address":[],"length":0,"stats":{"Line":5}},{"line":757,"address":[],"length":0,"stats":{"Line":0}},{"line":759,"address":[],"length":0,"stats":{"Line":2}},{"line":760,"address":[],"length":0,"stats":{"Line":0}},{"line":761,"address":[],"length":0,"stats":{"Line":0}},{"line":762,"address":[],"length":0,"stats":{"Line":0}},{"line":763,"address":[],"length":0,"stats":{"Line":0}},{"line":764,"address":[],"length":0,"stats":{"Line":0}},{"line":765,"address":[],"length":0,"stats":{"Line":0}},{"line":766,"address":[],"length":0,"stats":{"Line":0}},{"line":772,"address":[],"length":0,"stats":{"Line":0}},{"line":773,"address":[],"length":0,"stats":{"Line":3}},{"line":774,"address":[],"length":0,"stats":{"Line":3}},{"line":775,"address":[],"length":0,"stats":{"Line":3}},{"line":776,"address":[],"length":0,"stats":{"Line":3}},{"line":777,"address":[],"length":0,"stats":{"Line":3}},{"line":778,"address":[],"length":0,"stats":{"Line":3}},{"line":782,"address":[],"length":0,"stats":{"Line":0}}],"covered":210,"coverable":398},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","pratt","precedence.rs"],"content":"//! Precedence and binding power definitions for Pratt parser\n//!\n//! This module defines the binding power table that drives the Pratt parser,\n//! based on the operator precedence table from SYNTAX_GRAMMAR_V0.1.md Appendix A.\n\nuse crate::token::TokenType;\n\n/// Binding power for operators (higher = tighter binding)\npub type BindingPower = u8;\n\n/// Associativity of operators\n#[derive(Debug, Clone, Copy, PartialEq, Eq)]\npub enum Associativity {\n    Left,\n    Right,\n    None, // Non-associative (comparison chains not allowed)\n}\n\n/// Operator information for Pratt parsing\n#[derive(Debug, Clone)]\npub struct OperatorInfo {\n    pub binding_power: BindingPower,\n    pub associativity: Associativity,\n}\n\n/// Get prefix binding power for tokens that can start expressions (NUD)\npub fn prefix_binding_power(token_type: \u0026TokenType) -\u003e Option\u003cBindingPower\u003e {\n    match token_type {\n        // Unary prefix operators (precedence level 15)\n        TokenType::Minus | TokenType::Plus | TokenType::Bang =\u003e Some(150),\n\n        // Primary expressions (highest precedence)\n        TokenType::IntegerLiteral(_)\n        | TokenType::FloatLiteral(_)\n        | TokenType::StringLiteral(_)\n        | TokenType::BooleanLiteral(_)\n        | TokenType::Identifier(_)\n        | TokenType::LeftParen =\u003e Some(160),\n\n        _ =\u003e None,\n    }\n}\n\n/// Get infix binding power for tokens that can continue expressions (LED)\npub fn infix_binding_power(token_type: \u0026TokenType) -\u003e Option\u003cOperatorInfo\u003e {\n    match token_type {\n        // Level 1: Assignment (right associative)\n        TokenType::Equal\n        | TokenType::PlusEqual\n        | TokenType::MinusEqual\n        | TokenType::StarEqual\n        | TokenType::SlashEqual =\u003e Some(OperatorInfo {\n            binding_power: 10,\n            associativity: Associativity::Right,\n        }),\n\n        // Level 2: Logical OR (left associative)\n        TokenType::PipePipe =\u003e Some(OperatorInfo {\n            binding_power: 20,\n            associativity: Associativity::Left,\n        }),\n\n        // Level 3: Logical AND (left associative)\n        TokenType::AmpAmp =\u003e Some(OperatorInfo {\n            binding_power: 30,\n            associativity: Associativity::Left,\n        }),\n\n        // Level 4: Equality (left associative)\n        TokenType::EqualEqual | TokenType::BangEqual =\u003e Some(OperatorInfo {\n            binding_power: 40,\n            associativity: Associativity::Left,\n        }),\n\n        // Level 5: Comparison (non-associative)\n        TokenType::Less\n        | TokenType::LessEqual\n        | TokenType::Greater\n        | TokenType::GreaterEqual =\u003e Some(OperatorInfo {\n            binding_power: 50,\n            associativity: Associativity::None,\n        }),\n\n        // Level 6: Additive (left associative)\n        TokenType::Plus | TokenType::Minus =\u003e Some(OperatorInfo {\n            binding_power: 60,\n            associativity: Associativity::Left,\n        }),\n\n        // Level 7: Multiplicative (left associative)\n        TokenType::Star | TokenType::Slash | TokenType::Percent =\u003e Some(OperatorInfo {\n            binding_power: 70,\n            associativity: Associativity::Left,\n        }),\n\n        // Level 8: Postfix operators (left associative, highest precedence)\n        TokenType::Dot             // Member access: obj.field\n        | TokenType::LeftParen     // Function call: func()\n        | TokenType::LeftBracket   // Indexing: arr[i]\n        | TokenType::Question      // Error propagation: expr?\n        =\u003e Some(OperatorInfo {\n            binding_power: 140,\n            associativity: Associativity::Left,\n        }),\n\n        // Await operator (special case: .await)\n        // This is handled specially in the lexer/parser as Dot + Identifier(\"await\")\n\n        _ =\u003e None,\n    }\n}\n\n/// Check if a token can start an expression (has NUD handler)\npub fn can_start_expression(token_type: \u0026TokenType) -\u003e bool {\n    prefix_binding_power(token_type).is_some()\n}\n\n/// Check if a token can continue an expression (has LED handler)\npub fn can_continue_expression(token_type: \u0026TokenType) -\u003e bool {\n    infix_binding_power(token_type).is_some()\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::token::TokenType;\n\n    #[test]\n    fn test_precedence_ordering() {\n        // Test that precedence levels are correctly ordered\n        let assignment_bp = infix_binding_power(\u0026TokenType::Equal)\n            .unwrap()\n            .binding_power;\n        let or_bp = infix_binding_power(\u0026TokenType::PipePipe)\n            .unwrap()\n            .binding_power;\n        let and_bp = infix_binding_power(\u0026TokenType::AmpAmp)\n            .unwrap()\n            .binding_power;\n        let equality_bp = infix_binding_power(\u0026TokenType::EqualEqual)\n            .unwrap()\n            .binding_power;\n        let comparison_bp = infix_binding_power(\u0026TokenType::Less).unwrap().binding_power;\n        let additive_bp = infix_binding_power(\u0026TokenType::Plus).unwrap().binding_power;\n        let multiplicative_bp = infix_binding_power(\u0026TokenType::Star).unwrap().binding_power;\n        let postfix_bp = infix_binding_power(\u0026TokenType::Dot).unwrap().binding_power;\n        let prefix_bp = prefix_binding_power(\u0026TokenType::Minus).unwrap();\n\n        // Verify precedence ordering: assignment \u003c or \u003c and \u003c equality \u003c comparison \u003c additive \u003c multiplicative \u003c postfix \u003c prefix\n        assert!(assignment_bp \u003c or_bp);\n        assert!(or_bp \u003c and_bp);\n        assert!(and_bp \u003c equality_bp);\n        assert!(equality_bp \u003c comparison_bp);\n        assert!(comparison_bp \u003c additive_bp);\n        assert!(additive_bp \u003c multiplicative_bp);\n        assert!(multiplicative_bp \u003c postfix_bp);\n        assert!(postfix_bp \u003c prefix_bp);\n    }\n\n    #[test]\n    fn test_associativity() {\n        // Assignment is right associative\n        assert_eq!(\n            infix_binding_power(\u0026TokenType::Equal)\n                .unwrap()\n                .associativity,\n            Associativity::Right\n        );\n\n        // Arithmetic is left associative\n        assert_eq!(\n            infix_binding_power(\u0026TokenType::Plus).unwrap().associativity,\n            Associativity::Left\n        );\n\n        // Comparison is non-associative\n        assert_eq!(\n            infix_binding_power(\u0026TokenType::Less).unwrap().associativity,\n            Associativity::None\n        );\n    }\n\n    #[test]\n    fn test_prefix_precedence() {\n        // Unary operators should have high precedence\n        let unary_bp = prefix_binding_power(\u0026TokenType::Minus).unwrap();\n        let postfix_bp = infix_binding_power(\u0026TokenType::Dot).unwrap().binding_power;\n\n        assert!(unary_bp \u003e postfix_bp);\n    }\n}\n","traces":[{"line":27,"address":[],"length":0,"stats":{"Line":2}},{"line":28,"address":[],"length":0,"stats":{"Line":2}},{"line":30,"address":[],"length":0,"stats":{"Line":2}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":45,"address":[],"length":0,"stats":{"Line":237}},{"line":46,"address":[],"length":0,"stats":{"Line":237}},{"line":52,"address":[],"length":0,"stats":{"Line":2}},{"line":53,"address":[],"length":0,"stats":{"Line":2}},{"line":54,"address":[],"length":0,"stats":{"Line":2}},{"line":58,"address":[],"length":0,"stats":{"Line":6}},{"line":59,"address":[],"length":0,"stats":{"Line":6}},{"line":60,"address":[],"length":0,"stats":{"Line":6}},{"line":64,"address":[],"length":0,"stats":{"Line":14}},{"line":65,"address":[],"length":0,"stats":{"Line":14}},{"line":66,"address":[],"length":0,"stats":{"Line":14}},{"line":70,"address":[],"length":0,"stats":{"Line":11}},{"line":71,"address":[],"length":0,"stats":{"Line":11}},{"line":72,"address":[],"length":0,"stats":{"Line":11}},{"line":79,"address":[],"length":0,"stats":{"Line":14}},{"line":80,"address":[],"length":0,"stats":{"Line":14}},{"line":81,"address":[],"length":0,"stats":{"Line":14}},{"line":85,"address":[],"length":0,"stats":{"Line":55}},{"line":86,"address":[],"length":0,"stats":{"Line":55}},{"line":87,"address":[],"length":0,"stats":{"Line":55}},{"line":91,"address":[],"length":0,"stats":{"Line":28}},{"line":92,"address":[],"length":0,"stats":{"Line":28}},{"line":93,"address":[],"length":0,"stats":{"Line":28}},{"line":101,"address":[],"length":0,"stats":{"Line":52}},{"line":102,"address":[],"length":0,"stats":{"Line":52}},{"line":103,"address":[],"length":0,"stats":{"Line":52}},{"line":109,"address":[],"length":0,"stats":{"Line":55}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":119,"address":[],"length":0,"stats":{"Line":122}},{"line":120,"address":[],"length":0,"stats":{"Line":122}}],"covered":32,"coverable":36},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","program","mod.rs"],"content":"//! Top-level program parsing for complete Ferra programs\n//!\n//! This module provides parsers for complete compilation units,\n//! integrating all the component parsers (expressions, statements, blocks)\n//! to parse full Ferra programs.\n\npub mod parser;\n\npub use parser::ProgramParser;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","program","parser.rs"],"content":"//! Program parser for complete Ferra programs\n\nuse crate::{\n    ast::{\n        Arena, Block, CompilationUnit, DataClassDecl, ExternBlock, Field, FunctionDecl, Item,\n        Modifiers, Parameter, Type,\n    },\n    error::{parse_error::*, recovery::*},\n    statement::StatementParser,\n    token::{Span, Token, TokenStream, TokenType},\n};\n\n/// Top-level program parser that integrates all component parsers\npub struct ProgramParser\u003c'arena, T: TokenStream + Clone\u003e {\n    arena: \u0026'arena Arena,\n    tokens: T,\n    error_collector: ErrorCollector,\n}\n\nimpl\u003c'arena, T: TokenStream + Clone\u003e ProgramParser\u003c'arena, T\u003e {\n    /// Create a new program parser\n    pub fn new(arena: \u0026'arena Arena, tokens: T) -\u003e Self {\n        Self {\n            arena,\n            tokens,\n            error_collector: ErrorCollector::new(50),\n        }\n    }\n\n    /// Parse a complete compilation unit (top-level program)\n    pub fn parse_compilation_unit(\u0026mut self) -\u003e Result\u003c\u0026'arena CompilationUnit, Vec\u003cParseError\u003e\u003e {\n        let start_span = self.current_span();\n        let mut items = Vec::new();\n\n        // Parse top-level items until EOF\n        while !self.tokens.is_at_end() {\n            match self.parse_top_level_item() {\n                Ok(item) =\u003e items.push(item.clone()),\n                Err(error) =\u003e {\n                    self.error_collector.add_error(error);\n\n                    // Try to recover to next top-level item\n                    if ErrorRecovery::smart_recovery(\n                        \u0026mut self.tokens,\n                        \"declaration\",\n                        \u0026mut self.error_collector,\n                    )\n                    .is_some()\n                    {\n                        continue;\n                    } else {\n                        // Can't recover, stop parsing\n                        break;\n                    }\n                }\n            }\n        }\n\n        let end_span = self.current_span();\n        let span = start_span.combine(end_span);\n\n        if self.error_collector.has_errors() {\n            Err(self.error_collector.get_errors().to_vec())\n        } else {\n            let compilation_unit = self.arena.alloc(CompilationUnit { items, span });\n            Ok(compilation_unit)\n        }\n    }\n\n    /// Parse a complete program and return both result and diagnostics\n    pub fn parse_program_with_diagnostics(\n        \u0026mut self,\n    ) -\u003e (Option\u003c\u0026'arena CompilationUnit\u003e, DiagnosticReport) {\n        let mut report = DiagnosticReport::new(None);\n\n        match self.parse_compilation_unit() {\n            Ok(program) =\u003e (Some(program), report),\n            Err(errors) =\u003e {\n                report.add_errors(errors);\n                (None, report)\n            }\n        }\n    }\n\n    /// Parse a top-level item (function, data class, extern block, etc.)\n    fn parse_top_level_item(\u0026mut self) -\u003e Result\u003c\u0026'arena Item, ParseError\u003e {\n        let current = self.tokens.peek();\n\n        match current.token_type {\n            TokenType::Fn =\u003e self.parse_function_declaration(),\n            TokenType::Data =\u003e self.parse_data_class_declaration(),\n            TokenType::Extern =\u003e self.parse_extern_block(),\n            TokenType::Pub =\u003e self.parse_public_item(),\n            TokenType::Unsafe =\u003e self.parse_unsafe_item(),\n            TokenType::Static =\u003e self.parse_static_variable(),\n            _ =\u003e Err(ParseError::unexpected_token(\n                \"function, data class, extern block, or other top-level declaration\",\n                current,\n            )),\n        }\n    }\n\n    /// Parse a function declaration at the top level\n    fn parse_function_declaration(\u0026mut self) -\u003e Result\u003c\u0026'arena Item, ParseError\u003e {\n        let start_span = self.current_span();\n\n        // Consume 'fn'\n        let fn_token = self.consume();\n        if !matches!(fn_token.token_type, TokenType::Fn) {\n            return Err(ParseError::unexpected_token(\"'fn'\", \u0026fn_token));\n        }\n\n        // Function name\n        let name_token = self.consume();\n        let name = match name_token.token_type {\n            TokenType::Identifier(name) =\u003e name,\n            _ =\u003e return Err(ParseError::unexpected_token(\"function name\", \u0026name_token)),\n        };\n\n        // Parameters\n        let parameters = self.parse_parameter_list()?;\n\n        // Return type\n        let return_type = if matches!(self.tokens.peek().token_type, TokenType::Arrow) {\n            self.consume(); // consume '-\u003e'\n            Some(self.parse_type()?)\n        } else {\n            None\n        };\n\n        // Body\n        let body = if matches!(self.tokens.peek().token_type, TokenType::LeftBrace) {\n            Some(self.parse_block()?)\n        } else {\n            None\n        };\n\n        let func_decl = FunctionDecl {\n            name,\n            generics: None,\n            parameters,\n            return_type,\n            body,\n            is_async: false,\n            is_extern: false,\n            abi: None,\n            modifiers: Modifiers {\n                is_public: false,\n                is_unsafe: false,\n            },\n            attributes: Vec::new(),\n            span: start_span,\n        };\n\n        Ok(self.arena.alloc(Item::FunctionDecl(func_decl)))\n    }\n\n    /// Parse a data class declaration\n    fn parse_data_class_declaration(\u0026mut self) -\u003e Result\u003c\u0026'arena Item, ParseError\u003e {\n        let start_span = self.current_span();\n\n        // Consume 'data'\n        let data_token = self.consume();\n        if !matches!(data_token.token_type, TokenType::Data) {\n            return Err(ParseError::unexpected_token(\"'data'\", \u0026data_token));\n        }\n\n        // Class name\n        let name_token = self.consume();\n        let name = match name_token.token_type {\n            TokenType::Identifier(name) =\u003e name,\n            _ =\u003e return Err(ParseError::unexpected_token(\"class name\", \u0026name_token)),\n        };\n\n        // Fields\n        let fields = self.parse_field_list()?;\n\n        let data_decl = DataClassDecl {\n            name,\n            generics: None,\n            fields,\n            attributes: Vec::new(),\n            span: start_span,\n        };\n\n        Ok(self.arena.alloc(Item::DataClassDecl(data_decl)))\n    }\n\n    /// Parse an extern block\n    fn parse_extern_block(\u0026mut self) -\u003e Result\u003c\u0026'arena Item, ParseError\u003e {\n        let start_span = self.current_span();\n\n        // Consume 'extern'\n        let extern_token = self.consume();\n        if !matches!(extern_token.token_type, TokenType::Extern) {\n            return Err(ParseError::unexpected_token(\"'extern'\", \u0026extern_token));\n        }\n\n        // ABI string\n        let abi_token = self.consume();\n        let abi = match abi_token.token_type {\n            TokenType::StringLiteral(abi) =\u003e abi,\n            _ =\u003e return Err(ParseError::unexpected_token(\"ABI string\", \u0026abi_token)),\n        };\n\n        // Extern items\n        let items = self.parse_extern_item_list()?;\n\n        let extern_block = ExternBlock {\n            abi,\n            items,\n            span: start_span,\n        };\n\n        Ok(self.arena.alloc(Item::ExternBlock(extern_block)))\n    }\n\n    /// Parse a public item (pub fn, pub data, etc.)\n    fn parse_public_item(\u0026mut self) -\u003e Result\u003c\u0026'arena Item, ParseError\u003e {\n        // Consume 'pub' keyword\n        self.consume();\n\n        // Parse the next item with pub modifier\n        self.parse_top_level_item()\n    }\n\n    /// Parse an unsafe item\n    fn parse_unsafe_item(\u0026mut self) -\u003e Result\u003c\u0026'arena Item, ParseError\u003e {\n        // Consume 'unsafe' keyword\n        self.consume();\n\n        // Parse the next item with unsafe modifier\n        self.parse_top_level_item()\n    }\n\n    /// Parse a static variable declaration\n    fn parse_static_variable(\u0026mut self) -\u003e Result\u003c\u0026'arena Item, ParseError\u003e {\n        // For now, delegate to StatementParser for static variables\n        let mut statement_parser = StatementParser::new(self.arena, self.tokens.clone());\n        statement_parser.parse_item()\n    }\n\n    /// Parse parameter list for functions\n    fn parse_parameter_list(\u0026mut self) -\u003e Result\u003cVec\u003cParameter\u003e, ParseError\u003e {\n        let open_paren = self.consume();\n        if !matches!(open_paren.token_type, TokenType::LeftParen) {\n            return Err(ParseError::unexpected_token(\"'('\", \u0026open_paren));\n        }\n\n        let mut parameters = Vec::new();\n\n        if matches!(self.tokens.peek().token_type, TokenType::RightParen) {\n            self.consume();\n            return Ok(parameters);\n        }\n\n        loop {\n            let param = self.parse_parameter()?;\n            parameters.push(param);\n\n            if matches!(self.tokens.peek().token_type, TokenType::Comma) {\n                self.consume();\n            } else {\n                break;\n            }\n        }\n\n        let close_paren = self.consume();\n        if !matches!(close_paren.token_type, TokenType::RightParen) {\n            return Err(ParseError::unexpected_token(\"')'\", \u0026close_paren));\n        }\n\n        Ok(parameters)\n    }\n\n    /// Parse a single parameter\n    fn parse_parameter(\u0026mut self) -\u003e Result\u003cParameter, ParseError\u003e {\n        let start_span = self.current_span();\n\n        let name_token = self.consume();\n        let name = match name_token.token_type {\n            TokenType::Identifier(name) =\u003e name,\n            _ =\u003e return Err(ParseError::unexpected_token(\"parameter name\", \u0026name_token)),\n        };\n\n        let colon_token = self.consume();\n        if !matches!(colon_token.token_type, TokenType::Colon) {\n            return Err(ParseError::unexpected_token(\"':'\", \u0026colon_token));\n        }\n\n        let param_type = self.parse_type()?;\n\n        Ok(Parameter {\n            name,\n            param_type,\n            attributes: vec![],\n            span: start_span,\n        })\n    }\n\n    /// Parse a type\n    fn parse_type(\u0026mut self) -\u003e Result\u003cType, ParseError\u003e {\n        crate::types::parse_type(\u0026mut self.tokens)\n    }\n\n    /// Parse field list for data classes\n    fn parse_field_list(\u0026mut self) -\u003e Result\u003cVec\u003cField\u003e, ParseError\u003e {\n        let open_brace = self.consume();\n        if !matches!(open_brace.token_type, TokenType::LeftBrace) {\n            return Err(ParseError::unexpected_token(\"'{'\", \u0026open_brace));\n        }\n\n        let mut fields = Vec::new();\n\n        while !matches!(self.tokens.peek().token_type, TokenType::RightBrace) {\n            let field = self.parse_field()?;\n            fields.push(field);\n\n            if matches!(self.tokens.peek().token_type, TokenType::Comma) {\n                self.consume();\n            }\n        }\n\n        let close_brace = self.consume();\n        if !matches!(close_brace.token_type, TokenType::RightBrace) {\n            return Err(ParseError::unexpected_token(\"'}'\", \u0026close_brace));\n        }\n\n        Ok(fields)\n    }\n\n    /// Parse a single field\n    fn parse_field(\u0026mut self) -\u003e Result\u003cField, ParseError\u003e {\n        let start_span = self.current_span();\n\n        let name_token = self.consume();\n        let name = match name_token.token_type {\n            TokenType::Identifier(name) =\u003e name,\n            _ =\u003e return Err(ParseError::unexpected_token(\"field name\", \u0026name_token)),\n        };\n\n        let colon_token = self.consume();\n        if !matches!(colon_token.token_type, TokenType::Colon) {\n            return Err(ParseError::unexpected_token(\"':'\", \u0026colon_token));\n        }\n\n        let field_type = self.parse_type()?;\n\n        Ok(Field {\n            name,\n            field_type,\n            attributes: Vec::new(),\n            span: start_span,\n        })\n    }\n\n    /// Parse extern item list\n    fn parse_extern_item_list(\u0026mut self) -\u003e Result\u003cVec\u003ccrate::ast::ExternItem\u003e, ParseError\u003e {\n        let open_brace = self.consume();\n        if !matches!(open_brace.token_type, TokenType::LeftBrace) {\n            return Err(ParseError::unexpected_token(\"'{'\", \u0026open_brace));\n        }\n\n        let mut items = Vec::new();\n\n        while !matches!(self.tokens.peek().token_type, TokenType::RightBrace) {\n            let item = self.parse_extern_item()?;\n            items.push(item);\n        }\n\n        let close_brace = self.consume();\n        if !matches!(close_brace.token_type, TokenType::RightBrace) {\n            return Err(ParseError::unexpected_token(\"'}'\", \u0026close_brace));\n        }\n\n        Ok(items)\n    }\n\n    /// Parse a single extern item\n    fn parse_extern_item(\u0026mut self) -\u003e Result\u003ccrate::ast::ExternItem, ParseError\u003e {\n        let current = self.tokens.peek();\n\n        match current.token_type {\n            TokenType::Fn =\u003e {\n                let extern_func = self.parse_extern_function()?;\n                Ok(crate::ast::ExternItem::Function(extern_func))\n            }\n            TokenType::Static =\u003e {\n                let extern_var = self.parse_extern_variable()?;\n                Ok(crate::ast::ExternItem::Variable(extern_var))\n            }\n            _ =\u003e Err(ParseError::unexpected_token(\n                \"extern function or variable\",\n                current,\n            )),\n        }\n    }\n\n    /// Parse extern function\n    fn parse_extern_function(\u0026mut self) -\u003e Result\u003ccrate::ast::ExternFunction, ParseError\u003e {\n        let start_span = self.current_span();\n\n        // Consume 'fn'\n        let fn_token = self.consume();\n        if !matches!(fn_token.token_type, TokenType::Fn) {\n            return Err(ParseError::unexpected_token(\"'fn'\", \u0026fn_token));\n        }\n\n        // Function name\n        let name_token = self.consume();\n        let name = match name_token.token_type {\n            TokenType::Identifier(name) =\u003e name,\n            _ =\u003e return Err(ParseError::unexpected_token(\"function name\", \u0026name_token)),\n        };\n\n        // Parameters\n        let parameters = self.parse_parameter_list()?;\n\n        // Return type\n        let return_type = if matches!(self.tokens.peek().token_type, TokenType::Arrow) {\n            self.consume(); // consume '-\u003e'\n            Some(self.parse_type()?)\n        } else {\n            None\n        };\n\n        // Consume semicolon\n        let semicolon = self.consume();\n        if !matches!(semicolon.token_type, TokenType::Semicolon) {\n            return Err(ParseError::unexpected_token(\"';'\", \u0026semicolon));\n        }\n\n        Ok(crate::ast::ExternFunction {\n            name,\n            parameters,\n            return_type,\n            span: start_span,\n        })\n    }\n\n    /// Parse extern variable\n    fn parse_extern_variable(\u0026mut self) -\u003e Result\u003ccrate::ast::ExternVariable, ParseError\u003e {\n        let start_span = self.current_span();\n\n        // Consume 'static'\n        let static_token = self.consume();\n        if !matches!(static_token.token_type, TokenType::Static) {\n            return Err(ParseError::unexpected_token(\"'static'\", \u0026static_token));\n        }\n\n        // Variable name\n        let name_token = self.consume();\n        let name = match name_token.token_type {\n            TokenType::Identifier(name) =\u003e name,\n            _ =\u003e return Err(ParseError::unexpected_token(\"variable name\", \u0026name_token)),\n        };\n\n        // Type\n        let colon_token = self.consume();\n        if !matches!(colon_token.token_type, TokenType::Colon) {\n            return Err(ParseError::unexpected_token(\"':'\", \u0026colon_token));\n        }\n\n        let var_type = self.parse_type()?;\n\n        // Consume semicolon\n        let semicolon = self.consume();\n        if !matches!(semicolon.token_type, TokenType::Semicolon) {\n            return Err(ParseError::unexpected_token(\"';'\", \u0026semicolon));\n        }\n\n        Ok(crate::ast::ExternVariable {\n            name,\n            var_type,\n            span: start_span,\n        })\n    }\n\n    /// Parse a block (simplified version)\n    fn parse_block(\u0026mut self) -\u003e Result\u003cBlock, ParseError\u003e {\n        let start_span = self.current_span();\n\n        let open_brace = self.consume();\n        if !matches!(open_brace.token_type, TokenType::LeftBrace) {\n            return Err(ParseError::unexpected_token(\"'{'\", \u0026open_brace));\n        }\n\n        // For now, just consume tokens until closing brace\n        // In a real implementation, we'd parse statements\n        let statements = Vec::new();\n\n        while !matches!(self.tokens.peek().token_type, TokenType::RightBrace) {\n            // Skip tokens for now - in real implementation we'd parse statements\n            self.consume();\n        }\n\n        let close_brace = self.consume();\n        if !matches!(close_brace.token_type, TokenType::RightBrace) {\n            return Err(ParseError::unexpected_token(\"'}'\", \u0026close_brace));\n        }\n\n        Ok(Block {\n            statements,\n            is_braced: true,\n            span: start_span,\n            scope_depth: 0,\n            is_unsafe: false,\n            is_async: false,\n            is_try: false,\n            label: None,\n        })\n    }\n\n    /// Get the current token span\n    fn current_span(\u0026self) -\u003e Span {\n        self.tokens.peek().span.clone()\n    }\n\n    /// Consume the current token\n    fn consume(\u0026mut self) -\u003e Token {\n        self.tokens.consume()\n    }\n\n    /// Get collected errors\n    pub fn get_errors(\u0026self) -\u003e \u0026[ParseError] {\n        self.error_collector.get_errors()\n    }\n\n    /// Check if there are any errors\n    pub fn has_errors(\u0026self) -\u003e bool {\n        self.error_collector.has_errors()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::token::{TokenType, VecTokenStream};\n\n    #[test]\n    fn test_program_parser_creation() {\n        let arena = Arena::new();\n        let tokens = VecTokenStream::from_token_types(vec![TokenType::Eof]);\n        let _parser = ProgramParser::new(\u0026arena, tokens);\n    }\n\n    #[test]\n    fn test_empty_compilation_unit() {\n        let arena = Arena::new();\n        let tokens = VecTokenStream::from_token_types(vec![TokenType::Eof]);\n        let mut parser = ProgramParser::new(\u0026arena, tokens);\n\n        let result = parser.parse_compilation_unit();\n\n        assert!(result.is_ok());\n        let unit = result.unwrap();\n        assert_eq!(unit.items.len(), 0);\n    }\n\n    #[test]\n    fn test_program_with_diagnostics() {\n        let arena = Arena::new();\n        let tokens = VecTokenStream::from_token_types(vec![TokenType::Eof]);\n        let mut parser = ProgramParser::new(\u0026arena, tokens);\n\n        let (program, report) = parser.parse_program_with_diagnostics();\n\n        assert!(program.is_some());\n        assert!(!report.has_errors());\n    }\n\n    #[test]\n    fn test_invalid_top_level_item() {\n        let arena = Arena::new();\n        let tokens = VecTokenStream::from_token_types(vec![\n            TokenType::Plus, // Invalid top-level token\n            TokenType::Eof,\n        ]);\n        let mut parser = ProgramParser::new(\u0026arena, tokens);\n\n        let result = parser.parse_compilation_unit();\n        assert!(result.is_err());\n    }\n\n    #[test]\n    fn test_error_collection() {\n        let arena = Arena::new();\n        let tokens = VecTokenStream::from_token_types(vec![\n            TokenType::Plus, // Invalid\n            TokenType::Star, // Invalid\n            TokenType::Eof,\n        ]);\n        let mut parser = ProgramParser::new(\u0026arena, tokens);\n\n        let result = parser.parse_compilation_unit();\n        assert!(result.is_err());\n        assert!(parser.has_errors());\n    }\n}\n","traces":[{"line":22,"address":[],"length":0,"stats":{"Line":18}},{"line":26,"address":[],"length":0,"stats":{"Line":18}},{"line":31,"address":[],"length":0,"stats":{"Line":17}},{"line":32,"address":[],"length":0,"stats":{"Line":17}},{"line":33,"address":[],"length":0,"stats":{"Line":17}},{"line":36,"address":[],"length":0,"stats":{"Line":43}},{"line":37,"address":[],"length":0,"stats":{"Line":29}},{"line":38,"address":[],"length":0,"stats":{"Line":25}},{"line":39,"address":[],"length":0,"stats":{"Line":4}},{"line":40,"address":[],"length":0,"stats":{"Line":4}},{"line":44,"address":[],"length":0,"stats":{"Line":4}},{"line":46,"address":[],"length":0,"stats":{"Line":4}},{"line":50,"address":[],"length":0,"stats":{"Line":1}},{"line":53,"address":[],"length":0,"stats":{"Line":3}},{"line":59,"address":[],"length":0,"stats":{"Line":17}},{"line":60,"address":[],"length":0,"stats":{"Line":17}},{"line":62,"address":[],"length":0,"stats":{"Line":17}},{"line":63,"address":[],"length":0,"stats":{"Line":3}},{"line":65,"address":[],"length":0,"stats":{"Line":14}},{"line":66,"address":[],"length":0,"stats":{"Line":14}},{"line":71,"address":[],"length":0,"stats":{"Line":2}},{"line":74,"address":[],"length":0,"stats":{"Line":2}},{"line":76,"address":[],"length":0,"stats":{"Line":2}},{"line":77,"address":[],"length":0,"stats":{"Line":2}},{"line":78,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":29}},{"line":87,"address":[],"length":0,"stats":{"Line":29}},{"line":89,"address":[],"length":0,"stats":{"Line":29}},{"line":90,"address":[],"length":0,"stats":{"Line":15}},{"line":91,"address":[],"length":0,"stats":{"Line":6}},{"line":92,"address":[],"length":0,"stats":{"Line":4}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":4}},{"line":97,"address":[],"length":0,"stats":{"Line":4}},{"line":98,"address":[],"length":0,"stats":{"Line":4}},{"line":104,"address":[],"length":0,"stats":{"Line":15}},{"line":105,"address":[],"length":0,"stats":{"Line":15}},{"line":108,"address":[],"length":0,"stats":{"Line":15}},{"line":109,"address":[],"length":0,"stats":{"Line":15}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":15}},{"line":115,"address":[],"length":0,"stats":{"Line":30}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":117,"address":[],"length":0,"stats":{"Line":0}},{"line":121,"address":[],"length":0,"stats":{"Line":15}},{"line":124,"address":[],"length":0,"stats":{"Line":23}},{"line":125,"address":[],"length":0,"stats":{"Line":7}},{"line":126,"address":[],"length":0,"stats":{"Line":7}},{"line":128,"address":[],"length":0,"stats":{"Line":8}},{"line":132,"address":[],"length":0,"stats":{"Line":15}},{"line":133,"address":[],"length":0,"stats":{"Line":15}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":6}},{"line":160,"address":[],"length":0,"stats":{"Line":6}},{"line":163,"address":[],"length":0,"stats":{"Line":6}},{"line":164,"address":[],"length":0,"stats":{"Line":6}},{"line":165,"address":[],"length":0,"stats":{"Line":0}},{"line":169,"address":[],"length":0,"stats":{"Line":6}},{"line":170,"address":[],"length":0,"stats":{"Line":12}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":176,"address":[],"length":0,"stats":{"Line":6}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":186,"address":[],"length":0,"stats":{"Line":0}},{"line":190,"address":[],"length":0,"stats":{"Line":4}},{"line":191,"address":[],"length":0,"stats":{"Line":4}},{"line":194,"address":[],"length":0,"stats":{"Line":4}},{"line":195,"address":[],"length":0,"stats":{"Line":4}},{"line":196,"address":[],"length":0,"stats":{"Line":0}},{"line":200,"address":[],"length":0,"stats":{"Line":4}},{"line":201,"address":[],"length":0,"stats":{"Line":8}},{"line":202,"address":[],"length":0,"stats":{"Line":0}},{"line":203,"address":[],"length":0,"stats":{"Line":0}},{"line":207,"address":[],"length":0,"stats":{"Line":4}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":219,"address":[],"length":0,"stats":{"Line":0}},{"line":221,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":0}},{"line":230,"address":[],"length":0,"stats":{"Line":0}},{"line":233,"address":[],"length":0,"stats":{"Line":0}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":239,"address":[],"length":0,"stats":{"Line":0}},{"line":240,"address":[],"length":0,"stats":{"Line":0}},{"line":244,"address":[],"length":0,"stats":{"Line":20}},{"line":245,"address":[],"length":0,"stats":{"Line":20}},{"line":246,"address":[],"length":0,"stats":{"Line":20}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":250,"address":[],"length":0,"stats":{"Line":20}},{"line":252,"address":[],"length":0,"stats":{"Line":30}},{"line":253,"address":[],"length":0,"stats":{"Line":10}},{"line":254,"address":[],"length":0,"stats":{"Line":10}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":28}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":14}},{"line":262,"address":[],"length":0,"stats":{"Line":4}},{"line":264,"address":[],"length":0,"stats":{"Line":10}},{"line":268,"address":[],"length":0,"stats":{"Line":10}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":270,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":10}},{"line":277,"address":[],"length":0,"stats":{"Line":14}},{"line":278,"address":[],"length":0,"stats":{"Line":14}},{"line":280,"address":[],"length":0,"stats":{"Line":14}},{"line":281,"address":[],"length":0,"stats":{"Line":28}},{"line":282,"address":[],"length":0,"stats":{"Line":0}},{"line":283,"address":[],"length":0,"stats":{"Line":0}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":287,"address":[],"length":0,"stats":{"Line":0}},{"line":288,"address":[],"length":0,"stats":{"Line":0}},{"line":291,"address":[],"length":0,"stats":{"Line":28}},{"line":293,"address":[],"length":0,"stats":{"Line":0}},{"line":294,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":0}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":297,"address":[],"length":0,"stats":{"Line":0}},{"line":302,"address":[],"length":0,"stats":{"Line":37}},{"line":303,"address":[],"length":0,"stats":{"Line":37}},{"line":307,"address":[],"length":0,"stats":{"Line":6}},{"line":308,"address":[],"length":0,"stats":{"Line":6}},{"line":309,"address":[],"length":0,"stats":{"Line":6}},{"line":310,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":6}},{"line":315,"address":[],"length":0,"stats":{"Line":30}},{"line":316,"address":[],"length":0,"stats":{"Line":24}},{"line":317,"address":[],"length":0,"stats":{"Line":0}},{"line":319,"address":[],"length":0,"stats":{"Line":12}},{"line":320,"address":[],"length":0,"stats":{"Line":7}},{"line":324,"address":[],"length":0,"stats":{"Line":6}},{"line":325,"address":[],"length":0,"stats":{"Line":6}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":6}},{"line":333,"address":[],"length":0,"stats":{"Line":12}},{"line":334,"address":[],"length":0,"stats":{"Line":12}},{"line":336,"address":[],"length":0,"stats":{"Line":12}},{"line":337,"address":[],"length":0,"stats":{"Line":24}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":342,"address":[],"length":0,"stats":{"Line":0}},{"line":343,"address":[],"length":0,"stats":{"Line":0}},{"line":344,"address":[],"length":0,"stats":{"Line":0}},{"line":347,"address":[],"length":0,"stats":{"Line":24}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":4}},{"line":359,"address":[],"length":0,"stats":{"Line":4}},{"line":360,"address":[],"length":0,"stats":{"Line":4}},{"line":361,"address":[],"length":0,"stats":{"Line":0}},{"line":364,"address":[],"length":0,"stats":{"Line":4}},{"line":366,"address":[],"length":0,"stats":{"Line":16}},{"line":367,"address":[],"length":0,"stats":{"Line":12}},{"line":368,"address":[],"length":0,"stats":{"Line":0}},{"line":371,"address":[],"length":0,"stats":{"Line":4}},{"line":372,"address":[],"length":0,"stats":{"Line":4}},{"line":373,"address":[],"length":0,"stats":{"Line":0}},{"line":376,"address":[],"length":0,"stats":{"Line":4}},{"line":380,"address":[],"length":0,"stats":{"Line":6}},{"line":381,"address":[],"length":0,"stats":{"Line":6}},{"line":383,"address":[],"length":0,"stats":{"Line":6}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":385,"address":[],"length":0,"stats":{"Line":10}},{"line":386,"address":[],"length":0,"stats":{"Line":0}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":389,"address":[],"length":0,"stats":{"Line":2}},{"line":390,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":0}},{"line":393,"address":[],"length":0,"stats":{"Line":0}},{"line":394,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":5}},{"line":401,"address":[],"length":0,"stats":{"Line":5}},{"line":404,"address":[],"length":0,"stats":{"Line":5}},{"line":405,"address":[],"length":0,"stats":{"Line":5}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":5}},{"line":411,"address":[],"length":0,"stats":{"Line":10}},{"line":412,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":417,"address":[],"length":0,"stats":{"Line":5}},{"line":420,"address":[],"length":0,"stats":{"Line":7}},{"line":421,"address":[],"length":0,"stats":{"Line":3}},{"line":422,"address":[],"length":0,"stats":{"Line":3}},{"line":424,"address":[],"length":0,"stats":{"Line":2}},{"line":428,"address":[],"length":0,"stats":{"Line":0}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":5}},{"line":434,"address":[],"length":0,"stats":{"Line":5}},{"line":435,"address":[],"length":0,"stats":{"Line":5}},{"line":436,"address":[],"length":0,"stats":{"Line":5}},{"line":437,"address":[],"length":0,"stats":{"Line":5}},{"line":442,"address":[],"length":0,"stats":{"Line":1}},{"line":443,"address":[],"length":0,"stats":{"Line":1}},{"line":446,"address":[],"length":0,"stats":{"Line":1}},{"line":447,"address":[],"length":0,"stats":{"Line":1}},{"line":448,"address":[],"length":0,"stats":{"Line":0}},{"line":452,"address":[],"length":0,"stats":{"Line":1}},{"line":453,"address":[],"length":0,"stats":{"Line":2}},{"line":454,"address":[],"length":0,"stats":{"Line":0}},{"line":455,"address":[],"length":0,"stats":{"Line":0}},{"line":459,"address":[],"length":0,"stats":{"Line":0}},{"line":460,"address":[],"length":0,"stats":{"Line":0}},{"line":461,"address":[],"length":0,"stats":{"Line":0}},{"line":464,"address":[],"length":0,"stats":{"Line":2}},{"line":467,"address":[],"length":0,"stats":{"Line":0}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":469,"address":[],"length":0,"stats":{"Line":0}},{"line":472,"address":[],"length":0,"stats":{"Line":1}},{"line":473,"address":[],"length":0,"stats":{"Line":1}},{"line":474,"address":[],"length":0,"stats":{"Line":1}},{"line":475,"address":[],"length":0,"stats":{"Line":1}},{"line":480,"address":[],"length":0,"stats":{"Line":15}},{"line":481,"address":[],"length":0,"stats":{"Line":15}},{"line":483,"address":[],"length":0,"stats":{"Line":15}},{"line":484,"address":[],"length":0,"stats":{"Line":15}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":490,"address":[],"length":0,"stats":{"Line":15}},{"line":492,"address":[],"length":0,"stats":{"Line":111}},{"line":494,"address":[],"length":0,"stats":{"Line":32}},{"line":497,"address":[],"length":0,"stats":{"Line":15}},{"line":498,"address":[],"length":0,"stats":{"Line":15}},{"line":499,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":15}},{"line":503,"address":[],"length":0,"stats":{"Line":15}},{"line":504,"address":[],"length":0,"stats":{"Line":15}},{"line":505,"address":[],"length":0,"stats":{"Line":15}},{"line":506,"address":[],"length":0,"stats":{"Line":15}},{"line":507,"address":[],"length":0,"stats":{"Line":15}},{"line":508,"address":[],"length":0,"stats":{"Line":15}},{"line":509,"address":[],"length":0,"stats":{"Line":15}},{"line":510,"address":[],"length":0,"stats":{"Line":15}},{"line":515,"address":[],"length":0,"stats":{"Line":106}},{"line":516,"address":[],"length":0,"stats":{"Line":106}},{"line":520,"address":[],"length":0,"stats":{"Line":264}},{"line":521,"address":[],"length":0,"stats":{"Line":264}},{"line":525,"address":[],"length":0,"stats":{"Line":1}},{"line":526,"address":[],"length":0,"stats":{"Line":1}},{"line":530,"address":[],"length":0,"stats":{"Line":2}},{"line":531,"address":[],"length":0,"stats":{"Line":2}}],"covered":163,"coverable":249},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","statement","control_flow.rs"],"content":"//! Control flow statement parsing (if, while, for, return, break, continue)\n//!\n//! Implementation will be completed during development phase\n\nuse crate::{\n    ast::{\n        BreakStatement, ContinueStatement, ForStatement, IfStatement, ReturnStatement,\n        WhileStatement,\n    },\n    error::ParseResult,\n    token::TokenStream,\n};\n\n/// Parse if statements\npub fn parse_if_statement\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cIfStatement\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n\n/// Parse while statements\npub fn parse_while_statement\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cWhileStatement\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n\n/// Parse for statements\npub fn parse_for_statement\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cForStatement\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n\n/// Parse return statements\npub fn parse_return_statement\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cReturnStatement\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n\n/// Parse break statements\npub fn parse_break_statement\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cBreakStatement\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n\n/// Parse continue statements\npub fn parse_continue_statement\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cContinueStatement\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n","traces":[{"line":15,"address":[],"length":0,"stats":{"Line":0}},{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":35,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":6},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","statement","declaration.rs"],"content":"//! Declaration statement parsing (let, var, fn, data, extern)\n//!\n//! Implementation will be completed during development phase\n\nuse crate::{\n    ast::{DataClassDecl, ExternBlock, FunctionDecl, VariableDecl},\n    error::ParseResult,\n    token::TokenStream,\n};\n\n/// Parse variable declarations (let/var)\npub fn parse_variable_declaration\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cVariableDecl\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n\n/// Parse function declarations\npub fn parse_function_declaration\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cFunctionDecl\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n\n/// Parse data class declarations\npub fn parse_data_class_declaration\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cDataClassDecl\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n\n/// Parse extern blocks\npub fn parse_extern_block\u003cT: TokenStream\u003e(_tokens: \u0026mut T) -\u003e ParseResult\u003cExternBlock\u003e {\n    todo!(\"Implementation will be done during development phase\")\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":0}},{"line":17,"address":[],"length":0,"stats":{"Line":0}},{"line":22,"address":[],"length":0,"stats":{"Line":0}},{"line":27,"address":[],"length":0,"stats":{"Line":0}}],"covered":0,"coverable":4},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","statement","mod.rs"],"content":"//! Statement parsing functionality\n//!\n//! Implementation will be completed during development phase\n\npub mod control_flow;\npub mod declaration;\npub mod parser;\n\npub use control_flow::*;\npub use declaration::*;\npub use parser::StatementParser;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","statement","parser.rs"],"content":"use crate::{\n    ast::{\n        Arena, CompilationUnit, DataClassDecl, ExternBlock, FunctionDecl, Item, Statement,\n        VariableDecl,\n    },\n    ast::{\n        Attribute, ExternFunction, ExternItem, ExternVariable, Field, Modifiers, Parameter, Type,\n    },\n    ast::{\n        Block, BreakStatement, ContinueStatement, ForStatement, IfStatement, ReturnStatement,\n        WhileStatement,\n    },\n    error::ParseError,\n    pratt::parser::PrattParser,\n    token::{Span, Token, TokenStream, TokenType},\n};\n\n/// Statement parser for handling all statement types\npub struct StatementParser\u003c'arena, T: TokenStream\u003e {\n    arena: \u0026'arena Arena,\n    tokens: T,\n}\n\nimpl\u003c'arena, T: TokenStream\u003e StatementParser\u003c'arena, T\u003e {\n    pub fn new(arena: \u0026'arena Arena, tokens: T) -\u003e Self {\n        Self { arena, tokens }\n    }\n\n    /// Parse a complete compilation unit\n    pub fn parse_compilation_unit(\u0026mut self) -\u003e Result\u003c\u0026'arena CompilationUnit, ParseError\u003e {\n        let mut items = Vec::new();\n        let start_span = self.current_span();\n\n        // Skip any leading whitespace/newlines\n        self.skip_newlines();\n\n        while !self.is_at_end() {\n            let item = self.parse_item()?;\n            items.push(item.clone());\n            self.skip_newlines();\n        }\n\n        let end_span = self.previous_span();\n        let span = Span::new(\n            start_span.start,\n            end_span.end,\n            start_span.line,\n            start_span.column,\n        );\n\n        Ok(self.arena.alloc(CompilationUnit { items, span }))\n    }\n\n    /// Parse a single statement\n    pub fn parse_statement(\u0026mut self) -\u003e Result\u003c\u0026'arena Statement, ParseError\u003e {\n        // Check for attributes first\n        let attributes = self.parse_attributes()?;\n\n        let token = self.peek();\n\n        match \u0026token.token_type {\n            // Variable declarations\n            TokenType::Let | TokenType::Var =\u003e {\n                let var_decl = self.parse_variable_declaration_with_modifiers_and_attributes(\n                    Modifiers {\n                        is_public: false,\n                        is_unsafe: false,\n                    },\n                    attributes,\n                )?;\n                Ok(self.arena.alloc(Statement::VariableDecl(var_decl.clone())))\n            }\n\n            // Control flow\n            TokenType::If =\u003e {\n                let if_stmt = self.parse_if_statement()?;\n                Ok(self.arena.alloc(Statement::If(if_stmt.clone())))\n            }\n            TokenType::While =\u003e {\n                let while_stmt = self.parse_while_statement()?;\n                Ok(self.arena.alloc(Statement::While(while_stmt.clone())))\n            }\n            TokenType::For =\u003e {\n                let for_stmt = self.parse_for_statement()?;\n                Ok(self.arena.alloc(Statement::For(for_stmt.clone())))\n            }\n            TokenType::Return =\u003e {\n                let return_stmt = self.parse_return_statement()?;\n                Ok(self.arena.alloc(Statement::Return(return_stmt.clone())))\n            }\n            TokenType::Break =\u003e {\n                let break_stmt = self.parse_break_statement()?;\n                Ok(self.arena.alloc(Statement::Break(break_stmt.clone())))\n            }\n            TokenType::Continue =\u003e {\n                let continue_stmt = self.parse_continue_statement()?;\n                Ok(self.arena.alloc(Statement::Continue(continue_stmt.clone())))\n            }\n\n            // Block statements\n            TokenType::LeftBrace =\u003e {\n                let block = self.parse_block()?;\n                Ok(self.arena.alloc(Statement::Block(block.clone())))\n            }\n\n            // Expression statements (fallback)\n            _ =\u003e {\n                // If we have attributes but no statement that can use them, that's an error\n                if !attributes.is_empty() {\n                    return Err(ParseError::unexpected_token(\n                        \"statement that supports attributes\",\n                        \u0026token,\n                    ));\n                }\n\n                let expr = self.parse_expression()?;\n                // Consume optional semicolon\n                if matches!(self.peek().token_type, TokenType::Semicolon) {\n                    self.consume();\n                }\n                Ok(self.arena.alloc(Statement::Expression(expr.clone())))\n            }\n        }\n    }\n\n    /// Parse a top-level item (function, data class, extern block, etc.)\n    pub fn parse_item(\u0026mut self) -\u003e Result\u003c\u0026'arena Item, ParseError\u003e {\n        // Parse optional attributes first\n        let attributes = self.parse_attributes()?;\n\n        // Parse optional modifiers\n        let modifiers = self.parse_modifiers()?;\n\n        let token = self.peek();\n        match \u0026token.token_type {\n            TokenType::Fn | TokenType::Async =\u003e {\n                let func_decl =\n                    self.parse_function_declaration_with_attributes(modifiers, attributes)?;\n                Ok(self.arena.alloc(Item::FunctionDecl(func_decl.clone())))\n            }\n            TokenType::Let | TokenType::Var =\u003e {\n                let var_decl = self.parse_variable_declaration_with_modifiers_and_attributes(\n                    modifiers, attributes,\n                )?;\n                Ok(self.arena.alloc(Item::VariableDecl(var_decl.clone())))\n            }\n            TokenType::Data =\u003e {\n                let data_decl = self.parse_data_class_declaration_with_attributes(attributes)?;\n                Ok(self.arena.alloc(Item::DataClassDecl(data_decl.clone())))\n            }\n            TokenType::Extern =\u003e {\n                let extern_block = self.parse_extern_block()?;\n                Ok(self.arena.alloc(Item::ExternBlock(extern_block.clone())))\n            }\n            _ =\u003e Err(ParseError::unexpected_token(\"item declaration\", \u0026token)),\n        }\n    }\n\n    // Utility methods\n    fn peek(\u0026self) -\u003e Token {\n        self.tokens.peek().clone()\n    }\n\n    fn consume(\u0026mut self) -\u003e Token {\n        self.tokens.consume()\n    }\n\n    fn is_at_end(\u0026self) -\u003e bool {\n        matches!(self.peek().token_type, TokenType::Eof)\n    }\n\n    fn current_span(\u0026self) -\u003e Span {\n        self.peek().span.clone()\n    }\n\n    fn previous_span(\u0026self) -\u003e Span {\n        // For now, return current span - in real implementation we'd track previous\n        self.peek().span.clone()\n    }\n\n    fn skip_newlines(\u0026mut self) {\n        while matches!(self.peek().token_type, TokenType::Newline) {\n            self.consume();\n        }\n    }\n\n    fn parse_expression(\u0026mut self) -\u003e Result\u003c\u0026'arena crate::ast::Expression, ParseError\u003e {\n        let mut pratt_parser = PrattParser::new(self.arena, \u0026mut self.tokens);\n        pratt_parser.parse_expression(0)\n    }\n\n    // Placeholder implementations - we'll implement these in the next steps\n    fn parse_modifiers(\u0026mut self) -\u003e Result\u003cModifiers, ParseError\u003e {\n        let mut is_public = false;\n        let mut is_unsafe = false;\n\n        while matches!(self.peek().token_type, TokenType::Pub | TokenType::Unsafe) {\n            match self.consume().token_type {\n                TokenType::Pub =\u003e is_public = true,\n                TokenType::Unsafe =\u003e is_unsafe = true,\n                _ =\u003e unreachable!(),\n            }\n        }\n\n        Ok(Modifiers {\n            is_public,\n            is_unsafe,\n        })\n    }\n\n    #[allow(dead_code)]\n    fn parse_variable_declaration(\u0026mut self) -\u003e Result\u003cVariableDecl, ParseError\u003e {\n        self.parse_variable_declaration_with_modifiers(Modifiers {\n            is_public: false,\n            is_unsafe: false,\n        })\n    }\n\n    #[allow(dead_code)]\n    fn parse_variable_declaration_with_modifiers(\n        \u0026mut self,\n        modifiers: Modifiers,\n    ) -\u003e Result\u003cVariableDecl, ParseError\u003e {\n        self.parse_variable_declaration_with_modifiers_and_attributes(modifiers, Vec::new())\n    }\n\n    fn parse_variable_declaration_with_modifiers_and_attributes(\n        \u0026mut self,\n        modifiers: Modifiers,\n        attributes: Vec\u003cAttribute\u003e,\n    ) -\u003e Result\u003cVariableDecl, ParseError\u003e {\n        let start_token = self.consume(); // let or var\n        let is_mutable = matches!(start_token.token_type, TokenType::Var);\n\n        let name_token = self.consume();\n        let name = match name_token.token_type {\n            TokenType::Identifier(name) =\u003e name,\n            _ =\u003e return Err(ParseError::unexpected_token(\"variable name\", \u0026name_token)),\n        };\n\n        // Optional type annotation\n        let var_type = if matches!(self.peek().token_type, TokenType::Colon) {\n            self.consume(); // consume ':'\n            Some(self.parse_type()?)\n        } else {\n            None\n        };\n\n        // Optional initializer\n        let initializer = if matches!(self.peek().token_type, TokenType::Equal) {\n            self.consume(); // consume '='\n            Some(self.parse_expression()?.clone())\n        } else {\n            None\n        };\n\n        Ok(VariableDecl {\n            name,\n            var_type,\n            initializer,\n            is_mutable,\n            modifiers,\n            attributes,\n            span: start_token.span,\n        })\n    }\n\n    #[allow(dead_code)]\n    fn parse_function_declaration(\n        \u0026mut self,\n        modifiers: Modifiers,\n    ) -\u003e Result\u003cFunctionDecl, ParseError\u003e {\n        self.parse_function_declaration_with_attributes(modifiers, Vec::new())\n    }\n\n    fn parse_function_declaration_with_attributes(\n        \u0026mut self,\n        modifiers: Modifiers,\n        attributes: Vec\u003cAttribute\u003e,\n    ) -\u003e Result\u003cFunctionDecl, ParseError\u003e {\n        // Check for async keyword first\n        let is_async = if matches!(self.peek().token_type, TokenType::Async) {\n            self.consume(); // consume 'async'\n            true\n        } else {\n            false\n        };\n\n        // Now consume 'fn'\n        if !matches!(self.peek().token_type, TokenType::Fn) {\n            return Err(ParseError::unexpected_token(\"fn\", \u0026self.peek()));\n        }\n        self.consume(); // consume 'fn'\n\n        let name = if let TokenType::Identifier(name) = \u0026self.peek().token_type {\n            name.clone()\n        } else {\n            return Err(ParseError::unexpected_token(\"function name\", \u0026self.peek()));\n        };\n        let name_span = self.consume().span;\n\n        // Parse generic parameters if present\n        let generics = crate::generic::parser::parse_generic_params(\u0026mut self.tokens)?;\n\n        if !matches!(self.peek().token_type, TokenType::LeftParen) {\n            return Err(ParseError::unexpected_token(\"(\", \u0026self.peek()));\n        }\n\n        let parameters = self.parse_parameter_list()?;\n\n        let return_type = if matches!(self.peek().token_type, TokenType::Arrow) {\n            self.consume(); // consume '-\u003e'\n            Some(self.parse_type()?)\n        } else {\n            None\n        };\n\n        // Handle where clause that might come after return type\n        let final_generics = if matches!(self.peek().token_type, TokenType::Where) {\n            // Parse where clause\n            let where_clause = self.parse_where_clause()?;\n            let where_clause_span = where_clause.span.clone();\n\n            if let Some(mut gen) = generics {\n                gen.where_clause = Some(where_clause);\n                Some(gen)\n            } else {\n                // Create new generics with just the where clause\n                Some(crate::ast::GenericParams {\n                    params: Vec::new(),\n                    where_clause: Some(where_clause),\n                    span: where_clause_span,\n                })\n            }\n        } else {\n            generics\n        };\n\n        let body = if matches!(self.peek().token_type, TokenType::LeftBrace) {\n            Some(self.parse_block()?)\n        } else if matches!(self.peek().token_type, TokenType::Semicolon) {\n            self.consume(); // consume ';'\n            None\n        } else {\n            return Err(ParseError::unexpected_token(\"{ or ;\", \u0026self.peek()));\n        };\n\n        Ok(FunctionDecl {\n            name,\n            generics: final_generics,\n            parameters,\n            return_type,\n            body,\n            is_async,\n            is_extern: false,\n            abi: None,\n            modifiers,\n            attributes,\n            span: name_span,\n        })\n    }\n\n    fn parse_parameter_list(\u0026mut self) -\u003e Result\u003cVec\u003cParameter\u003e, ParseError\u003e {\n        let open_paren = self.consume();\n        if !matches!(open_paren.token_type, TokenType::LeftParen) {\n            return Err(ParseError::unexpected_token(\"'('\", \u0026open_paren));\n        }\n\n        let mut parameters = Vec::new();\n\n        if matches!(self.peek().token_type, TokenType::RightParen) {\n            self.consume();\n            return Ok(parameters);\n        }\n\n        loop {\n            let param = self.parse_parameter()?;\n            parameters.push(param);\n\n            match self.consume().token_type {\n                TokenType::Comma =\u003e {\n                    if matches!(self.peek().token_type, TokenType::RightParen) {\n                        self.consume();\n                        break;\n                    }\n                }\n                TokenType::RightParen =\u003e break,\n                _ =\u003e return Err(ParseError::unexpected_token(\"',' or ')'\", \u0026self.peek())),\n            }\n        }\n\n        Ok(parameters)\n    }\n\n    fn parse_parameter(\u0026mut self) -\u003e Result\u003cParameter, ParseError\u003e {\n        // Parse optional attributes\n        let attributes = self.parse_attributes()?;\n\n        let name_token = self.consume();\n        let name = match name_token.token_type {\n            TokenType::Identifier(name) =\u003e name,\n            _ =\u003e return Err(ParseError::unexpected_token(\"parameter name\", \u0026name_token)),\n        };\n\n        let colon_token = self.consume();\n        if !matches!(colon_token.token_type, TokenType::Colon) {\n            return Err(ParseError::unexpected_token(\"':'\", \u0026colon_token));\n        }\n\n        let param_type = self.parse_type()?;\n\n        Ok(Parameter {\n            name,\n            param_type,\n            attributes,\n            span: name_token.span,\n        })\n    }\n\n    fn parse_attributes(\u0026mut self) -\u003e Result\u003cVec\u003cAttribute\u003e, ParseError\u003e {\n        crate::attribute::parse_attributes(\u0026mut self.tokens)\n    }\n\n    fn parse_type(\u0026mut self) -\u003e Result\u003cType, ParseError\u003e {\n        crate::types::parse_type(\u0026mut self.tokens)\n    }\n\n    #[allow(dead_code)]\n    fn parse_data_class_declaration(\u0026mut self) -\u003e Result\u003cDataClassDecl, ParseError\u003e {\n        self.parse_data_class_declaration_with_attributes(Vec::new())\n    }\n\n    fn parse_data_class_declaration_with_attributes(\n        \u0026mut self,\n        attributes: Vec\u003cAttribute\u003e,\n    ) -\u003e Result\u003cDataClassDecl, ParseError\u003e {\n        self.consume(); // consume 'data'\n\n        let name = if let TokenType::Identifier(name) = \u0026self.peek().token_type {\n            name.clone()\n        } else {\n            return Err(ParseError::unexpected_token(\n                \"data class name\",\n                \u0026self.peek(),\n            ));\n        };\n        let name_span = self.consume().span;\n\n        // Parse generic parameters if present\n        let generics = crate::generic::parser::parse_generic_params(\u0026mut self.tokens)?;\n\n        if !matches!(self.peek().token_type, TokenType::LeftBrace) {\n            return Err(ParseError::unexpected_token(\"'{'\", \u0026self.peek()));\n        }\n\n        self.consume(); // consume '{'\n        let mut fields = Vec::new();\n\n        while !matches!(self.peek().token_type, TokenType::RightBrace) \u0026\u0026 !self.is_at_end() {\n            fields.push(self.parse_field()?);\n\n            if matches!(self.peek().token_type, TokenType::Comma) {\n                self.consume(); // consume ','\n            }\n        }\n\n        if !matches!(self.peek().token_type, TokenType::RightBrace) {\n            return Err(ParseError::unexpected_token(\"'}'\", \u0026self.peek()));\n        }\n        self.consume(); // consume '}'\n\n        Ok(DataClassDecl {\n            name,\n            generics,\n            fields,\n            attributes,\n            span: name_span,\n        })\n    }\n\n    fn parse_field(\u0026mut self) -\u003e Result\u003cField, ParseError\u003e {\n        // Parse attributes before field declaration\n        let attributes = self.parse_attributes()?;\n\n        let name_token = self.consume();\n        let name = match name_token.token_type {\n            TokenType::Identifier(name) =\u003e name,\n            _ =\u003e return Err(ParseError::unexpected_token(\"field name\", \u0026name_token)),\n        };\n\n        let colon_token = self.consume();\n        if !matches!(colon_token.token_type, TokenType::Colon) {\n            return Err(ParseError::unexpected_token(\"':'\", \u0026colon_token));\n        }\n\n        let field_type = self.parse_type()?;\n\n        Ok(Field {\n            name,\n            field_type,\n            attributes,\n            span: name_token.span,\n        })\n    }\n\n    fn parse_extern_block(\u0026mut self) -\u003e Result\u003cExternBlock, ParseError\u003e {\n        let extern_token = self.consume();\n        if !matches!(extern_token.token_type, TokenType::Extern) {\n            return Err(ParseError::unexpected_token(\"'extern'\", \u0026extern_token));\n        }\n\n        // ABI string\n        let abi_token = self.consume();\n        let abi = match abi_token.token_type {\n            TokenType::StringLiteral(abi) =\u003e abi,\n            _ =\u003e return Err(ParseError::unexpected_token(\"ABI string\", \u0026abi_token)),\n        };\n\n        let open_brace = self.consume();\n        if !matches!(open_brace.token_type, TokenType::LeftBrace) {\n            return Err(ParseError::unexpected_token(\"'{'\", \u0026open_brace));\n        }\n\n        let mut items = Vec::new();\n        while !matches!(\n            self.peek().token_type,\n            TokenType::RightBrace | TokenType::Eof\n        ) {\n            let item = self.parse_extern_item()?;\n            items.push(item);\n        }\n\n        let close_brace = self.consume();\n        if !matches!(close_brace.token_type, TokenType::RightBrace) {\n            return Err(ParseError::unexpected_token(\"'}'\", \u0026close_brace));\n        }\n\n        Ok(ExternBlock {\n            abi,\n            items,\n            span: extern_token.span,\n        })\n    }\n\n    fn parse_extern_item(\u0026mut self) -\u003e Result\u003cExternItem, ParseError\u003e {\n        let token = self.peek();\n        match \u0026token.token_type {\n            TokenType::Fn =\u003e {\n                let func = self.parse_extern_function()?;\n                Ok(ExternItem::Function(func))\n            }\n            TokenType::Static =\u003e {\n                let var = self.parse_extern_variable()?;\n                Ok(ExternItem::Variable(var))\n            }\n            _ =\u003e Err(ParseError::unexpected_token(\"'fn' or 'static'\", \u0026token)),\n        }\n    }\n\n    fn parse_extern_function(\u0026mut self) -\u003e Result\u003cExternFunction, ParseError\u003e {\n        let fn_token = self.consume();\n        if !matches!(fn_token.token_type, TokenType::Fn) {\n            return Err(ParseError::unexpected_token(\"'fn'\", \u0026fn_token));\n        }\n\n        let name_token = self.consume();\n        let name = match name_token.token_type {\n            TokenType::Identifier(name) =\u003e name,\n            _ =\u003e return Err(ParseError::unexpected_token(\"function name\", \u0026name_token)),\n        };\n\n        let parameters = self.parse_parameter_list()?;\n\n        let return_type = if matches!(self.peek().token_type, TokenType::Arrow) {\n            self.consume(); // consume '-\u003e'\n            Some(self.parse_type()?)\n        } else {\n            None\n        };\n\n        // Expect semicolon\n        let semicolon = self.consume();\n        if !matches!(semicolon.token_type, TokenType::Semicolon) {\n            return Err(ParseError::unexpected_token(\"';'\", \u0026semicolon));\n        }\n\n        Ok(ExternFunction {\n            name,\n            parameters,\n            return_type,\n            span: fn_token.span,\n        })\n    }\n\n    fn parse_extern_variable(\u0026mut self) -\u003e Result\u003cExternVariable, ParseError\u003e {\n        let static_token = self.consume();\n        if !matches!(static_token.token_type, TokenType::Static) {\n            return Err(ParseError::unexpected_token(\"'static'\", \u0026static_token));\n        }\n\n        let name_token = self.consume();\n        let name = match name_token.token_type {\n            TokenType::Identifier(name) =\u003e name,\n            _ =\u003e return Err(ParseError::unexpected_token(\"variable name\", \u0026name_token)),\n        };\n\n        let colon_token = self.consume();\n        if !matches!(colon_token.token_type, TokenType::Colon) {\n            return Err(ParseError::unexpected_token(\"':'\", \u0026colon_token));\n        }\n\n        let var_type = self.parse_type()?;\n\n        let semicolon = self.consume();\n        if !matches!(semicolon.token_type, TokenType::Semicolon) {\n            return Err(ParseError::unexpected_token(\"';'\", \u0026semicolon));\n        }\n\n        Ok(ExternVariable {\n            name,\n            var_type,\n            span: static_token.span,\n        })\n    }\n\n    // Control flow statement parsers\n    fn parse_if_statement(\u0026mut self) -\u003e Result\u003cIfStatement, ParseError\u003e {\n        let if_token = self.consume();\n        if !matches!(if_token.token_type, TokenType::If) {\n            return Err(ParseError::unexpected_token(\"'if'\", \u0026if_token));\n        }\n\n        let condition = self.parse_expression()?.clone();\n        let then_block = self.parse_block()?;\n\n        let else_block = if matches!(self.peek().token_type, TokenType::Else) {\n            self.consume(); // consume 'else'\n            Some(self.parse_block()?)\n        } else {\n            None\n        };\n\n        Ok(IfStatement {\n            condition,\n            then_block,\n            else_block,\n            span: if_token.span,\n        })\n    }\n\n    fn parse_while_statement(\u0026mut self) -\u003e Result\u003cWhileStatement, ParseError\u003e {\n        let while_token = self.consume();\n        if !matches!(while_token.token_type, TokenType::While) {\n            return Err(ParseError::unexpected_token(\"'while'\", \u0026while_token));\n        }\n\n        let condition = self.parse_expression()?.clone();\n        let body = self.parse_block()?;\n\n        Ok(WhileStatement {\n            condition,\n            body,\n            span: while_token.span,\n        })\n    }\n\n    fn parse_for_statement(\u0026mut self) -\u003e Result\u003cForStatement, ParseError\u003e {\n        let for_token = self.consume();\n        if !matches!(for_token.token_type, TokenType::For) {\n            return Err(ParseError::unexpected_token(\"'for'\", \u0026for_token));\n        }\n\n        let var_token = self.consume();\n        let variable = match var_token.token_type {\n            TokenType::Identifier(name) =\u003e name,\n            _ =\u003e return Err(ParseError::unexpected_token(\"variable name\", \u0026var_token)),\n        };\n\n        let in_token = self.consume();\n        if !matches!(in_token.token_type, TokenType::In) {\n            return Err(ParseError::unexpected_token(\"'in'\", \u0026in_token));\n        }\n\n        let iterable = self.parse_expression()?.clone();\n        let body = self.parse_block()?;\n\n        Ok(ForStatement {\n            variable,\n            iterable,\n            body,\n            span: for_token.span,\n        })\n    }\n\n    fn parse_return_statement(\u0026mut self) -\u003e Result\u003cReturnStatement, ParseError\u003e {\n        let return_token = self.consume();\n        if !matches!(return_token.token_type, TokenType::Return) {\n            return Err(ParseError::unexpected_token(\"'return'\", \u0026return_token));\n        }\n\n        let value = if matches!(\n            self.peek().token_type,\n            TokenType::Semicolon | TokenType::Newline | TokenType::Eof\n        ) {\n            None\n        } else {\n            Some(self.parse_expression()?.clone())\n        };\n\n        Ok(ReturnStatement {\n            value,\n            span: return_token.span,\n        })\n    }\n\n    fn parse_break_statement(\u0026mut self) -\u003e Result\u003cBreakStatement, ParseError\u003e {\n        let break_token = self.consume();\n        if !matches!(break_token.token_type, TokenType::Break) {\n            return Err(ParseError::unexpected_token(\"'break'\", \u0026break_token));\n        }\n\n        Ok(BreakStatement {\n            span: break_token.span,\n        })\n    }\n\n    fn parse_continue_statement(\u0026mut self) -\u003e Result\u003cContinueStatement, ParseError\u003e {\n        let continue_token = self.consume();\n        if !matches!(continue_token.token_type, TokenType::Continue) {\n            return Err(ParseError::unexpected_token(\"'continue'\", \u0026continue_token));\n        }\n\n        Ok(ContinueStatement {\n            span: continue_token.span,\n        })\n    }\n\n    fn parse_block(\u0026mut self) -\u003e Result\u003cBlock, ParseError\u003e {\n        let open_brace = self.consume();\n        if !matches!(open_brace.token_type, TokenType::LeftBrace) {\n            return Err(ParseError::unexpected_token(\"'{'\", \u0026open_brace));\n        }\n\n        let mut statements = Vec::new();\n        self.skip_newlines();\n\n        while !matches!(\n            self.peek().token_type,\n            TokenType::RightBrace | TokenType::Eof\n        ) {\n            let stmt = self.parse_statement()?;\n            statements.push(stmt.clone());\n            self.skip_newlines();\n        }\n\n        let close_brace = self.consume();\n        if !matches!(close_brace.token_type, TokenType::RightBrace) {\n            return Err(ParseError::unexpected_token(\"'}'\", \u0026close_brace));\n        }\n\n        let start_span = open_brace.span;\n        let end_span = close_brace.span;\n\n        Ok(Block {\n            statements,\n            is_braced: true,\n            span: start_span.combine(end_span),\n            scope_depth: 0,\n            is_unsafe: false,\n            is_async: false,\n            is_try: false,\n            label: None,\n        })\n    }\n\n    fn parse_where_clause(\u0026mut self) -\u003e Result\u003ccrate::ast::WhereClause, ParseError\u003e {\n        let start_span = self.consume().span; // consume 'where'\n        let mut constraints = Vec::new();\n\n        // Parse first constraint\n        constraints.push(self.parse_where_constraint()?);\n\n        // Parse additional constraints separated by ','\n        while matches!(self.peek().token_type, TokenType::Comma) {\n            self.consume(); // consume ','\n\n            // Allow trailing comma\n            if self.is_where_clause_end() {\n                break;\n            }\n\n            constraints.push(self.parse_where_constraint()?);\n        }\n\n        let end_span = if let Some(last_constraint) = constraints.last() {\n            last_constraint.span.clone()\n        } else {\n            start_span.clone()\n        };\n\n        Ok(crate::ast::WhereClause {\n            constraints,\n            span: start_span.combine(end_span),\n        })\n    }\n\n    fn parse_where_constraint(\u0026mut self) -\u003e Result\u003ccrate::ast::WhereConstraint, ParseError\u003e {\n        if let TokenType::Identifier(type_name) = \u0026self.peek().token_type {\n            let type_name = type_name.clone();\n            let start_span = self.consume().span;\n\n            if !matches!(self.peek().token_type, TokenType::Colon) {\n                return Err(ParseError::unexpected_token(\":\", \u0026self.peek()));\n            }\n\n            self.consume(); // consume ':'\n            let bounds = self.parse_type_bounds()?;\n\n            let end_span = if let Some(last_bound) = bounds.last() {\n                last_bound.span.clone()\n            } else {\n                start_span.clone()\n            };\n\n            Ok(crate::ast::WhereConstraint {\n                type_name,\n                bounds,\n                span: start_span.combine(end_span),\n            })\n        } else {\n            Err(ParseError::unexpected_token(\"type name\", \u0026self.peek()))\n        }\n    }\n\n    fn parse_type_bounds(\u0026mut self) -\u003e Result\u003cVec\u003ccrate::ast::TypeBound\u003e, ParseError\u003e {\n        let mut bounds = Vec::new();\n\n        // Parse first bound\n        bounds.push(self.parse_type_bound()?);\n\n        // Parse additional bounds separated by '+'\n        while matches!(self.peek().token_type, TokenType::Plus) {\n            self.consume(); // consume '+'\n            bounds.push(self.parse_type_bound()?);\n        }\n\n        Ok(bounds)\n    }\n\n    fn parse_type_bound(\u0026mut self) -\u003e Result\u003ccrate::ast::TypeBound, ParseError\u003e {\n        if let TokenType::Identifier(trait_name) = \u0026self.peek().token_type {\n            let trait_name = trait_name.clone();\n            let span = self.consume().span;\n\n            Ok(crate::ast::TypeBound { trait_name, span })\n        } else {\n            Err(ParseError::unexpected_token(\"trait name\", \u0026self.peek()))\n        }\n    }\n\n    fn is_where_clause_end(\u0026self) -\u003e bool {\n        matches!(\n            self.peek().token_type,\n            TokenType::LeftBrace | TokenType::Semicolon | TokenType::Eof | TokenType::Newline\n        )\n    }\n}\n","traces":[{"line":25,"address":[],"length":0,"stats":{"Line":31}},{"line":30,"address":[],"length":0,"stats":{"Line":2}},{"line":31,"address":[],"length":0,"stats":{"Line":2}},{"line":32,"address":[],"length":0,"stats":{"Line":2}},{"line":35,"address":[],"length":0,"stats":{"Line":2}},{"line":37,"address":[],"length":0,"stats":{"Line":5}},{"line":38,"address":[],"length":0,"stats":{"Line":6}},{"line":39,"address":[],"length":0,"stats":{"Line":0}},{"line":40,"address":[],"length":0,"stats":{"Line":0}},{"line":43,"address":[],"length":0,"stats":{"Line":2}},{"line":45,"address":[],"length":0,"stats":{"Line":2}},{"line":46,"address":[],"length":0,"stats":{"Line":2}},{"line":47,"address":[],"length":0,"stats":{"Line":2}},{"line":48,"address":[],"length":0,"stats":{"Line":2}},{"line":51,"address":[],"length":0,"stats":{"Line":2}},{"line":55,"address":[],"length":0,"stats":{"Line":22}},{"line":57,"address":[],"length":0,"stats":{"Line":44}},{"line":59,"address":[],"length":0,"stats":{"Line":0}},{"line":61,"address":[],"length":0,"stats":{"Line":0}},{"line":63,"address":[],"length":0,"stats":{"Line":0}},{"line":64,"address":[],"length":0,"stats":{"Line":17}},{"line":65,"address":[],"length":0,"stats":{"Line":9}},{"line":66,"address":[],"length":0,"stats":{"Line":9}},{"line":67,"address":[],"length":0,"stats":{"Line":9}},{"line":69,"address":[],"length":0,"stats":{"Line":9}},{"line":71,"address":[],"length":0,"stats":{"Line":0}},{"line":75,"address":[],"length":0,"stats":{"Line":0}},{"line":76,"address":[],"length":0,"stats":{"Line":6}},{"line":77,"address":[],"length":0,"stats":{"Line":0}},{"line":79,"address":[],"length":0,"stats":{"Line":0}},{"line":80,"address":[],"length":0,"stats":{"Line":2}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":84,"address":[],"length":0,"stats":{"Line":2}},{"line":85,"address":[],"length":0,"stats":{"Line":0}},{"line":87,"address":[],"length":0,"stats":{"Line":0}},{"line":88,"address":[],"length":0,"stats":{"Line":8}},{"line":89,"address":[],"length":0,"stats":{"Line":0}},{"line":91,"address":[],"length":0,"stats":{"Line":0}},{"line":92,"address":[],"length":0,"stats":{"Line":2}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":2}},{"line":97,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":2}},{"line":103,"address":[],"length":0,"stats":{"Line":0}},{"line":107,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":1}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":111,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":2}},{"line":118,"address":[],"length":0,"stats":{"Line":1}},{"line":119,"address":[],"length":0,"stats":{"Line":1}},{"line":121,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":17}},{"line":129,"address":[],"length":0,"stats":{"Line":34}},{"line":132,"address":[],"length":0,"stats":{"Line":17}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":11}},{"line":138,"address":[],"length":0,"stats":{"Line":11}},{"line":139,"address":[],"length":0,"stats":{"Line":0}},{"line":141,"address":[],"length":0,"stats":{"Line":0}},{"line":142,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":0}},{"line":145,"address":[],"length":0,"stats":{"Line":0}},{"line":147,"address":[],"length":0,"stats":{"Line":0}},{"line":148,"address":[],"length":0,"stats":{"Line":10}},{"line":149,"address":[],"length":0,"stats":{"Line":0}},{"line":151,"address":[],"length":0,"stats":{"Line":0}},{"line":152,"address":[],"length":0,"stats":{"Line":2}},{"line":153,"address":[],"length":0,"stats":{"Line":0}},{"line":155,"address":[],"length":0,"stats":{"Line":0}},{"line":160,"address":[],"length":0,"stats":{"Line":289}},{"line":161,"address":[],"length":0,"stats":{"Line":289}},{"line":164,"address":[],"length":0,"stats":{"Line":204}},{"line":165,"address":[],"length":0,"stats":{"Line":204}},{"line":168,"address":[],"length":0,"stats":{"Line":11}},{"line":169,"address":[],"length":0,"stats":{"Line":20}},{"line":172,"address":[],"length":0,"stats":{"Line":2}},{"line":173,"address":[],"length":0,"stats":{"Line":2}},{"line":176,"address":[],"length":0,"stats":{"Line":2}},{"line":178,"address":[],"length":0,"stats":{"Line":2}},{"line":181,"address":[],"length":0,"stats":{"Line":26}},{"line":182,"address":[],"length":0,"stats":{"Line":52}},{"line":183,"address":[],"length":0,"stats":{"Line":0}},{"line":187,"address":[],"length":0,"stats":{"Line":18}},{"line":188,"address":[],"length":0,"stats":{"Line":18}},{"line":189,"address":[],"length":0,"stats":{"Line":18}},{"line":193,"address":[],"length":0,"stats":{"Line":17}},{"line":194,"address":[],"length":0,"stats":{"Line":17}},{"line":195,"address":[],"length":0,"stats":{"Line":17}},{"line":197,"address":[],"length":0,"stats":{"Line":36}},{"line":198,"address":[],"length":0,"stats":{"Line":2}},{"line":199,"address":[],"length":0,"stats":{"Line":2}},{"line":200,"address":[],"length":0,"stats":{"Line":0}},{"line":205,"address":[],"length":0,"stats":{"Line":17}},{"line":206,"address":[],"length":0,"stats":{"Line":17}},{"line":207,"address":[],"length":0,"stats":{"Line":17}},{"line":212,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":0}},{"line":214,"address":[],"length":0,"stats":{"Line":0}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":220,"address":[],"length":0,"stats":{"Line":0}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":9}},{"line":232,"address":[],"length":0,"stats":{"Line":9}},{"line":233,"address":[],"length":0,"stats":{"Line":26}},{"line":235,"address":[],"length":0,"stats":{"Line":9}},{"line":236,"address":[],"length":0,"stats":{"Line":17}},{"line":237,"address":[],"length":0,"stats":{"Line":0}},{"line":238,"address":[],"length":0,"stats":{"Line":1}},{"line":242,"address":[],"length":0,"stats":{"Line":14}},{"line":243,"address":[],"length":0,"stats":{"Line":2}},{"line":244,"address":[],"length":0,"stats":{"Line":2}},{"line":246,"address":[],"length":0,"stats":{"Line":6}},{"line":250,"address":[],"length":0,"stats":{"Line":8}},{"line":251,"address":[],"length":0,"stats":{"Line":8}},{"line":252,"address":[],"length":0,"stats":{"Line":16}},{"line":254,"address":[],"length":0,"stats":{"Line":0}},{"line":257,"address":[],"length":0,"stats":{"Line":0}},{"line":258,"address":[],"length":0,"stats":{"Line":0}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":264,"address":[],"length":0,"stats":{"Line":0}},{"line":269,"address":[],"length":0,"stats":{"Line":0}},{"line":273,"address":[],"length":0,"stats":{"Line":0}},{"line":276,"address":[],"length":0,"stats":{"Line":11}},{"line":282,"address":[],"length":0,"stats":{"Line":31}},{"line":283,"address":[],"length":0,"stats":{"Line":2}},{"line":284,"address":[],"length":0,"stats":{"Line":2}},{"line":286,"address":[],"length":0,"stats":{"Line":9}},{"line":290,"address":[],"length":0,"stats":{"Line":11}},{"line":291,"address":[],"length":0,"stats":{"Line":0}},{"line":293,"address":[],"length":0,"stats":{"Line":11}},{"line":295,"address":[],"length":0,"stats":{"Line":22}},{"line":296,"address":[],"length":0,"stats":{"Line":0}},{"line":298,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":11}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":306,"address":[],"length":0,"stats":{"Line":0}},{"line":309,"address":[],"length":0,"stats":{"Line":22}},{"line":311,"address":[],"length":0,"stats":{"Line":18}},{"line":312,"address":[],"length":0,"stats":{"Line":4}},{"line":313,"address":[],"length":0,"stats":{"Line":4}},{"line":315,"address":[],"length":0,"stats":{"Line":7}},{"line":319,"address":[],"length":0,"stats":{"Line":21}},{"line":321,"address":[],"length":0,"stats":{"Line":2}},{"line":322,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":1}},{"line":325,"address":[],"length":0,"stats":{"Line":0}},{"line":326,"address":[],"length":0,"stats":{"Line":0}},{"line":329,"address":[],"length":0,"stats":{"Line":0}},{"line":330,"address":[],"length":0,"stats":{"Line":0}},{"line":331,"address":[],"length":0,"stats":{"Line":0}},{"line":332,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":10}},{"line":339,"address":[],"length":0,"stats":{"Line":13}},{"line":340,"address":[],"length":0,"stats":{"Line":9}},{"line":341,"address":[],"length":0,"stats":{"Line":2}},{"line":342,"address":[],"length":0,"stats":{"Line":2}},{"line":343,"address":[],"length":0,"stats":{"Line":2}},{"line":345,"address":[],"length":0,"stats":{"Line":0}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":349,"address":[],"length":0,"stats":{"Line":0}},{"line":350,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":0}},{"line":352,"address":[],"length":0,"stats":{"Line":0}},{"line":353,"address":[],"length":0,"stats":{"Line":0}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}},{"line":356,"address":[],"length":0,"stats":{"Line":0}},{"line":357,"address":[],"length":0,"stats":{"Line":0}},{"line":358,"address":[],"length":0,"stats":{"Line":0}},{"line":359,"address":[],"length":0,"stats":{"Line":0}},{"line":363,"address":[],"length":0,"stats":{"Line":12}},{"line":364,"address":[],"length":0,"stats":{"Line":12}},{"line":365,"address":[],"length":0,"stats":{"Line":12}},{"line":366,"address":[],"length":0,"stats":{"Line":0}},{"line":369,"address":[],"length":0,"stats":{"Line":12}},{"line":371,"address":[],"length":0,"stats":{"Line":18}},{"line":372,"address":[],"length":0,"stats":{"Line":6}},{"line":373,"address":[],"length":0,"stats":{"Line":6}},{"line":376,"address":[],"length":0,"stats":{"Line":0}},{"line":377,"address":[],"length":0,"stats":{"Line":18}},{"line":378,"address":[],"length":0,"stats":{"Line":0}},{"line":380,"address":[],"length":0,"stats":{"Line":0}},{"line":381,"address":[],"length":0,"stats":{"Line":0}},{"line":382,"address":[],"length":0,"stats":{"Line":6}},{"line":383,"address":[],"length":0,"stats":{"Line":0}},{"line":384,"address":[],"length":0,"stats":{"Line":0}},{"line":387,"address":[],"length":0,"stats":{"Line":6}},{"line":388,"address":[],"length":0,"stats":{"Line":0}},{"line":392,"address":[],"length":0,"stats":{"Line":6}},{"line":395,"address":[],"length":0,"stats":{"Line":9}},{"line":397,"address":[],"length":0,"stats":{"Line":18}},{"line":399,"address":[],"length":0,"stats":{"Line":0}},{"line":400,"address":[],"length":0,"stats":{"Line":9}},{"line":401,"address":[],"length":0,"stats":{"Line":0}},{"line":402,"address":[],"length":0,"stats":{"Line":0}},{"line":405,"address":[],"length":0,"stats":{"Line":0}},{"line":406,"address":[],"length":0,"stats":{"Line":0}},{"line":407,"address":[],"length":0,"stats":{"Line":0}},{"line":410,"address":[],"length":0,"stats":{"Line":18}},{"line":412,"address":[],"length":0,"stats":{"Line":0}},{"line":413,"address":[],"length":0,"stats":{"Line":0}},{"line":414,"address":[],"length":0,"stats":{"Line":0}},{"line":415,"address":[],"length":0,"stats":{"Line":0}},{"line":416,"address":[],"length":0,"stats":{"Line":0}},{"line":420,"address":[],"length":0,"stats":{"Line":54}},{"line":421,"address":[],"length":0,"stats":{"Line":54}},{"line":424,"address":[],"length":0,"stats":{"Line":23}},{"line":425,"address":[],"length":0,"stats":{"Line":23}},{"line":429,"address":[],"length":0,"stats":{"Line":0}},{"line":430,"address":[],"length":0,"stats":{"Line":0}},{"line":433,"address":[],"length":0,"stats":{"Line":5}},{"line":437,"address":[],"length":0,"stats":{"Line":5}},{"line":439,"address":[],"length":0,"stats":{"Line":10}},{"line":440,"address":[],"length":0,"stats":{"Line":0}},{"line":442,"address":[],"length":0,"stats":{"Line":0}},{"line":443,"address":[],"length":0,"stats":{"Line":0}},{"line":444,"address":[],"length":0,"stats":{"Line":0}},{"line":447,"address":[],"length":0,"stats":{"Line":0}},{"line":450,"address":[],"length":0,"stats":{"Line":5}},{"line":452,"address":[],"length":0,"stats":{"Line":0}},{"line":453,"address":[],"length":0,"stats":{"Line":0}},{"line":456,"address":[],"length":0,"stats":{"Line":5}},{"line":457,"address":[],"length":0,"stats":{"Line":5}},{"line":459,"address":[],"length":0,"stats":{"Line":23}},{"line":460,"address":[],"length":0,"stats":{"Line":6}},{"line":462,"address":[],"length":0,"stats":{"Line":12}},{"line":463,"address":[],"length":0,"stats":{"Line":1}},{"line":467,"address":[],"length":0,"stats":{"Line":5}},{"line":468,"address":[],"length":0,"stats":{"Line":0}},{"line":470,"address":[],"length":0,"stats":{"Line":5}},{"line":472,"address":[],"length":0,"stats":{"Line":5}},{"line":473,"address":[],"length":0,"stats":{"Line":5}},{"line":474,"address":[],"length":0,"stats":{"Line":5}},{"line":475,"address":[],"length":0,"stats":{"Line":5}},{"line":476,"address":[],"length":0,"stats":{"Line":5}},{"line":477,"address":[],"length":0,"stats":{"Line":5}},{"line":481,"address":[],"length":0,"stats":{"Line":6}},{"line":483,"address":[],"length":0,"stats":{"Line":12}},{"line":485,"address":[],"length":0,"stats":{"Line":0}},{"line":486,"address":[],"length":0,"stats":{"Line":6}},{"line":487,"address":[],"length":0,"stats":{"Line":0}},{"line":488,"address":[],"length":0,"stats":{"Line":0}},{"line":491,"address":[],"length":0,"stats":{"Line":0}},{"line":492,"address":[],"length":0,"stats":{"Line":0}},{"line":493,"address":[],"length":0,"stats":{"Line":0}},{"line":496,"address":[],"length":0,"stats":{"Line":12}},{"line":498,"address":[],"length":0,"stats":{"Line":0}},{"line":499,"address":[],"length":0,"stats":{"Line":0}},{"line":500,"address":[],"length":0,"stats":{"Line":0}},{"line":501,"address":[],"length":0,"stats":{"Line":0}},{"line":502,"address":[],"length":0,"stats":{"Line":0}},{"line":506,"address":[],"length":0,"stats":{"Line":1}},{"line":507,"address":[],"length":0,"stats":{"Line":1}},{"line":508,"address":[],"length":0,"stats":{"Line":1}},{"line":509,"address":[],"length":0,"stats":{"Line":0}},{"line":513,"address":[],"length":0,"stats":{"Line":1}},{"line":514,"address":[],"length":0,"stats":{"Line":2}},{"line":515,"address":[],"length":0,"stats":{"Line":0}},{"line":516,"address":[],"length":0,"stats":{"Line":0}},{"line":519,"address":[],"length":0,"stats":{"Line":0}},{"line":520,"address":[],"length":0,"stats":{"Line":0}},{"line":521,"address":[],"length":0,"stats":{"Line":0}},{"line":524,"address":[],"length":0,"stats":{"Line":1}},{"line":525,"address":[],"length":0,"stats":{"Line":2}},{"line":526,"address":[],"length":0,"stats":{"Line":3}},{"line":527,"address":[],"length":0,"stats":{"Line":0}},{"line":529,"address":[],"length":0,"stats":{"Line":4}},{"line":530,"address":[],"length":0,"stats":{"Line":0}},{"line":533,"address":[],"length":0,"stats":{"Line":1}},{"line":534,"address":[],"length":0,"stats":{"Line":1}},{"line":535,"address":[],"length":0,"stats":{"Line":0}},{"line":538,"address":[],"length":0,"stats":{"Line":1}},{"line":539,"address":[],"length":0,"stats":{"Line":1}},{"line":540,"address":[],"length":0,"stats":{"Line":1}},{"line":541,"address":[],"length":0,"stats":{"Line":1}},{"line":545,"address":[],"length":0,"stats":{"Line":2}},{"line":546,"address":[],"length":0,"stats":{"Line":2}},{"line":547,"address":[],"length":0,"stats":{"Line":2}},{"line":548,"address":[],"length":0,"stats":{"Line":0}},{"line":549,"address":[],"length":0,"stats":{"Line":2}},{"line":550,"address":[],"length":0,"stats":{"Line":0}},{"line":552,"address":[],"length":0,"stats":{"Line":0}},{"line":553,"address":[],"length":0,"stats":{"Line":2}},{"line":554,"address":[],"length":0,"stats":{"Line":0}},{"line":556,"address":[],"length":0,"stats":{"Line":0}},{"line":560,"address":[],"length":0,"stats":{"Line":1}},{"line":561,"address":[],"length":0,"stats":{"Line":1}},{"line":562,"address":[],"length":0,"stats":{"Line":1}},{"line":563,"address":[],"length":0,"stats":{"Line":0}},{"line":566,"address":[],"length":0,"stats":{"Line":1}},{"line":567,"address":[],"length":0,"stats":{"Line":2}},{"line":568,"address":[],"length":0,"stats":{"Line":0}},{"line":569,"address":[],"length":0,"stats":{"Line":0}},{"line":572,"address":[],"length":0,"stats":{"Line":1}},{"line":574,"address":[],"length":0,"stats":{"Line":1}},{"line":575,"address":[],"length":0,"stats":{"Line":1}},{"line":576,"address":[],"length":0,"stats":{"Line":1}},{"line":578,"address":[],"length":0,"stats":{"Line":0}},{"line":582,"address":[],"length":0,"stats":{"Line":0}},{"line":583,"address":[],"length":0,"stats":{"Line":0}},{"line":584,"address":[],"length":0,"stats":{"Line":0}},{"line":587,"address":[],"length":0,"stats":{"Line":1}},{"line":588,"address":[],"length":0,"stats":{"Line":1}},{"line":589,"address":[],"length":0,"stats":{"Line":1}},{"line":590,"address":[],"length":0,"stats":{"Line":1}},{"line":591,"address":[],"length":0,"stats":{"Line":1}},{"line":595,"address":[],"length":0,"stats":{"Line":1}},{"line":596,"address":[],"length":0,"stats":{"Line":1}},{"line":597,"address":[],"length":0,"stats":{"Line":1}},{"line":598,"address":[],"length":0,"stats":{"Line":0}},{"line":601,"address":[],"length":0,"stats":{"Line":1}},{"line":602,"address":[],"length":0,"stats":{"Line":2}},{"line":603,"address":[],"length":0,"stats":{"Line":0}},{"line":604,"address":[],"length":0,"stats":{"Line":0}},{"line":607,"address":[],"length":0,"stats":{"Line":0}},{"line":608,"address":[],"length":0,"stats":{"Line":0}},{"line":609,"address":[],"length":0,"stats":{"Line":0}},{"line":612,"address":[],"length":0,"stats":{"Line":2}},{"line":614,"address":[],"length":0,"stats":{"Line":0}},{"line":615,"address":[],"length":0,"stats":{"Line":0}},{"line":616,"address":[],"length":0,"stats":{"Line":0}},{"line":619,"address":[],"length":0,"stats":{"Line":1}},{"line":620,"address":[],"length":0,"stats":{"Line":1}},{"line":621,"address":[],"length":0,"stats":{"Line":1}},{"line":622,"address":[],"length":0,"stats":{"Line":1}},{"line":627,"address":[],"length":0,"stats":{"Line":3}},{"line":628,"address":[],"length":0,"stats":{"Line":3}},{"line":629,"address":[],"length":0,"stats":{"Line":3}},{"line":630,"address":[],"length":0,"stats":{"Line":0}},{"line":633,"address":[],"length":0,"stats":{"Line":6}},{"line":634,"address":[],"length":0,"stats":{"Line":3}},{"line":636,"address":[],"length":0,"stats":{"Line":6}},{"line":637,"address":[],"length":0,"stats":{"Line":0}},{"line":638,"address":[],"length":0,"stats":{"Line":0}},{"line":640,"address":[],"length":0,"stats":{"Line":3}},{"line":643,"address":[],"length":0,"stats":{"Line":0}},{"line":644,"address":[],"length":0,"stats":{"Line":0}},{"line":645,"address":[],"length":0,"stats":{"Line":0}},{"line":646,"address":[],"length":0,"stats":{"Line":0}},{"line":647,"address":[],"length":0,"stats":{"Line":0}},{"line":651,"address":[],"length":0,"stats":{"Line":1}},{"line":652,"address":[],"length":0,"stats":{"Line":1}},{"line":653,"address":[],"length":0,"stats":{"Line":1}},{"line":654,"address":[],"length":0,"stats":{"Line":0}},{"line":657,"address":[],"length":0,"stats":{"Line":2}},{"line":658,"address":[],"length":0,"stats":{"Line":1}},{"line":660,"address":[],"length":0,"stats":{"Line":0}},{"line":661,"address":[],"length":0,"stats":{"Line":0}},{"line":662,"address":[],"length":0,"stats":{"Line":0}},{"line":663,"address":[],"length":0,"stats":{"Line":0}},{"line":667,"address":[],"length":0,"stats":{"Line":1}},{"line":668,"address":[],"length":0,"stats":{"Line":1}},{"line":669,"address":[],"length":0,"stats":{"Line":1}},{"line":670,"address":[],"length":0,"stats":{"Line":0}},{"line":673,"address":[],"length":0,"stats":{"Line":1}},{"line":674,"address":[],"length":0,"stats":{"Line":2}},{"line":675,"address":[],"length":0,"stats":{"Line":0}},{"line":676,"address":[],"length":0,"stats":{"Line":0}},{"line":679,"address":[],"length":0,"stats":{"Line":0}},{"line":680,"address":[],"length":0,"stats":{"Line":0}},{"line":681,"address":[],"length":0,"stats":{"Line":0}},{"line":684,"address":[],"length":0,"stats":{"Line":2}},{"line":685,"address":[],"length":0,"stats":{"Line":1}},{"line":687,"address":[],"length":0,"stats":{"Line":0}},{"line":688,"address":[],"length":0,"stats":{"Line":0}},{"line":689,"address":[],"length":0,"stats":{"Line":0}},{"line":690,"address":[],"length":0,"stats":{"Line":0}},{"line":691,"address":[],"length":0,"stats":{"Line":0}},{"line":695,"address":[],"length":0,"stats":{"Line":4}},{"line":696,"address":[],"length":0,"stats":{"Line":4}},{"line":697,"address":[],"length":0,"stats":{"Line":4}},{"line":698,"address":[],"length":0,"stats":{"Line":0}},{"line":701,"address":[],"length":0,"stats":{"Line":8}},{"line":702,"address":[],"length":0,"stats":{"Line":4}},{"line":703,"address":[],"length":0,"stats":{"Line":0}},{"line":705,"address":[],"length":0,"stats":{"Line":0}},{"line":707,"address":[],"length":0,"stats":{"Line":8}},{"line":710,"address":[],"length":0,"stats":{"Line":0}},{"line":711,"address":[],"length":0,"stats":{"Line":0}},{"line":712,"address":[],"length":0,"stats":{"Line":0}},{"line":716,"address":[],"length":0,"stats":{"Line":1}},{"line":717,"address":[],"length":0,"stats":{"Line":1}},{"line":718,"address":[],"length":0,"stats":{"Line":1}},{"line":719,"address":[],"length":0,"stats":{"Line":0}},{"line":722,"address":[],"length":0,"stats":{"Line":1}},{"line":723,"address":[],"length":0,"stats":{"Line":1}},{"line":727,"address":[],"length":0,"stats":{"Line":1}},{"line":728,"address":[],"length":0,"stats":{"Line":1}},{"line":729,"address":[],"length":0,"stats":{"Line":1}},{"line":730,"address":[],"length":0,"stats":{"Line":0}},{"line":733,"address":[],"length":0,"stats":{"Line":1}},{"line":734,"address":[],"length":0,"stats":{"Line":1}},{"line":738,"address":[],"length":0,"stats":{"Line":15}},{"line":739,"address":[],"length":0,"stats":{"Line":15}},{"line":740,"address":[],"length":0,"stats":{"Line":15}},{"line":741,"address":[],"length":0,"stats":{"Line":0}},{"line":744,"address":[],"length":0,"stats":{"Line":15}},{"line":745,"address":[],"length":0,"stats":{"Line":15}},{"line":747,"address":[],"length":0,"stats":{"Line":6}},{"line":748,"address":[],"length":0,"stats":{"Line":21}},{"line":749,"address":[],"length":0,"stats":{"Line":0}},{"line":751,"address":[],"length":0,"stats":{"Line":12}},{"line":752,"address":[],"length":0,"stats":{"Line":0}},{"line":753,"address":[],"length":0,"stats":{"Line":0}},{"line":756,"address":[],"length":0,"stats":{"Line":15}},{"line":757,"address":[],"length":0,"stats":{"Line":15}},{"line":758,"address":[],"length":0,"stats":{"Line":0}},{"line":761,"address":[],"length":0,"stats":{"Line":15}},{"line":762,"address":[],"length":0,"stats":{"Line":15}},{"line":764,"address":[],"length":0,"stats":{"Line":15}},{"line":765,"address":[],"length":0,"stats":{"Line":15}},{"line":766,"address":[],"length":0,"stats":{"Line":15}},{"line":767,"address":[],"length":0,"stats":{"Line":15}},{"line":768,"address":[],"length":0,"stats":{"Line":15}},{"line":769,"address":[],"length":0,"stats":{"Line":15}},{"line":770,"address":[],"length":0,"stats":{"Line":15}},{"line":771,"address":[],"length":0,"stats":{"Line":15}},{"line":772,"address":[],"length":0,"stats":{"Line":15}},{"line":776,"address":[],"length":0,"stats":{"Line":1}},{"line":777,"address":[],"length":0,"stats":{"Line":1}},{"line":778,"address":[],"length":0,"stats":{"Line":1}},{"line":781,"address":[],"length":0,"stats":{"Line":1}},{"line":784,"address":[],"length":0,"stats":{"Line":3}},{"line":785,"address":[],"length":0,"stats":{"Line":1}},{"line":788,"address":[],"length":0,"stats":{"Line":1}},{"line":789,"address":[],"length":0,"stats":{"Line":0}},{"line":792,"address":[],"length":0,"stats":{"Line":1}},{"line":795,"address":[],"length":0,"stats":{"Line":2}},{"line":796,"address":[],"length":0,"stats":{"Line":0}},{"line":798,"address":[],"length":0,"stats":{"Line":0}},{"line":801,"address":[],"length":0,"stats":{"Line":0}},{"line":802,"address":[],"length":0,"stats":{"Line":0}},{"line":803,"address":[],"length":0,"stats":{"Line":0}},{"line":807,"address":[],"length":0,"stats":{"Line":2}},{"line":808,"address":[],"length":0,"stats":{"Line":4}},{"line":809,"address":[],"length":0,"stats":{"Line":0}},{"line":810,"address":[],"length":0,"stats":{"Line":0}},{"line":812,"address":[],"length":0,"stats":{"Line":0}},{"line":813,"address":[],"length":0,"stats":{"Line":0}},{"line":816,"address":[],"length":0,"stats":{"Line":2}},{"line":817,"address":[],"length":0,"stats":{"Line":4}},{"line":819,"address":[],"length":0,"stats":{"Line":2}},{"line":820,"address":[],"length":0,"stats":{"Line":0}},{"line":822,"address":[],"length":0,"stats":{"Line":0}},{"line":825,"address":[],"length":0,"stats":{"Line":0}},{"line":826,"address":[],"length":0,"stats":{"Line":0}},{"line":827,"address":[],"length":0,"stats":{"Line":0}},{"line":828,"address":[],"length":0,"stats":{"Line":0}},{"line":831,"address":[],"length":0,"stats":{"Line":0}},{"line":835,"address":[],"length":0,"stats":{"Line":2}},{"line":836,"address":[],"length":0,"stats":{"Line":2}},{"line":839,"address":[],"length":0,"stats":{"Line":2}},{"line":842,"address":[],"length":0,"stats":{"Line":5}},{"line":843,"address":[],"length":0,"stats":{"Line":1}},{"line":844,"address":[],"length":0,"stats":{"Line":1}},{"line":847,"address":[],"length":0,"stats":{"Line":2}},{"line":850,"address":[],"length":0,"stats":{"Line":3}},{"line":851,"address":[],"length":0,"stats":{"Line":6}},{"line":852,"address":[],"length":0,"stats":{"Line":0}},{"line":853,"address":[],"length":0,"stats":{"Line":0}},{"line":855,"address":[],"length":0,"stats":{"Line":0}},{"line":857,"address":[],"length":0,"stats":{"Line":0}},{"line":861,"address":[],"length":0,"stats":{"Line":1}},{"line":862,"address":[],"length":0,"stats":{"Line":1}},{"line":863,"address":[],"length":0,"stats":{"Line":1}},{"line":864,"address":[],"length":0,"stats":{"Line":0}}],"covered":265,"coverable":478},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","token","mod.rs"],"content":"//! Token abstraction layer for interfacing with the lexer\n//!\n//! This module provides the interface between the parser and lexer,\n//! abstracting over token types and providing a stream-like interface\n//! for consuming tokens during parsing.\n\npub mod stream;\npub mod types;\n\npub use stream::*;\npub use types::*;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","token","stream.rs"],"content":"//! Token stream interface and implementations\n//!\n//! Provides traits and implementations for consuming tokens during parsing,\n//! including mock implementations for testing and development.\n\nuse super::{Token, TokenType};\n\n/// Trait for token streams that can be consumed by the parser\npub trait TokenStream {\n    /// Peek at the current token without consuming it\n    fn peek(\u0026self) -\u003e \u0026Token;\n\n    /// Peek at the token at the given offset from current position\n    fn peek_ahead(\u0026self, offset: usize) -\u003e Option\u003c\u0026Token\u003e;\n\n    /// Consume and return the current token\n    fn consume(\u0026mut self) -\u003e Token;\n\n    /// Check if we're at the end of the stream\n    fn is_at_end(\u0026self) -\u003e bool;\n\n    /// Get the current position in the stream\n    fn position(\u0026self) -\u003e usize;\n}\n\n/// A simple vector-based token stream for testing and development\n#[derive(Debug, Clone)]\npub struct VecTokenStream {\n    tokens: Vec\u003cToken\u003e,\n    current: usize,\n}\n\nimpl VecTokenStream {\n    pub fn new(tokens: Vec\u003cToken\u003e) -\u003e Self {\n        let mut stream = Self { tokens, current: 0 };\n\n        // Ensure there's always an EOF token at the end\n        if stream.tokens.is_empty() || !stream.tokens.last().unwrap().is_eof() {\n            stream.tokens.push(Token::dummy(TokenType::Eof));\n        }\n\n        stream\n    }\n\n    pub fn from_token_types(token_types: Vec\u003cTokenType\u003e) -\u003e Self {\n        let tokens = token_types.into_iter().map(Token::dummy).collect();\n        Self::new(tokens)\n    }\n}\n\nimpl TokenStream for VecTokenStream {\n    fn peek(\u0026self) -\u003e \u0026Token {\n        self.tokens\n            .get(self.current)\n            .unwrap_or(\u0026self.tokens[self.tokens.len() - 1])\n    }\n\n    fn peek_ahead(\u0026self, offset: usize) -\u003e Option\u003c\u0026Token\u003e {\n        self.tokens.get(self.current + offset)\n    }\n\n    fn consume(\u0026mut self) -\u003e Token {\n        let token = self.peek().clone();\n        if !self.is_at_end() {\n            self.current += 1;\n        }\n        token\n    }\n\n    fn is_at_end(\u0026self) -\u003e bool {\n        self.current \u003e= self.tokens.len() - 1 || self.peek().is_eof()\n    }\n\n    fn position(\u0026self) -\u003e usize {\n        self.current\n    }\n}\n\nimpl Default for VecTokenStream {\n    fn default() -\u003e Self {\n        Self::new(vec![])\n    }\n}\n\nimpl\u003cT: TokenStream\u003e TokenStream for \u0026mut T {\n    fn peek(\u0026self) -\u003e \u0026Token {\n        (**self).peek()\n    }\n\n    fn consume(\u0026mut self) -\u003e Token {\n        (**self).consume()\n    }\n\n    fn peek_ahead(\u0026self, offset: usize) -\u003e Option\u003c\u0026Token\u003e {\n        (**self).peek_ahead(offset)\n    }\n\n    fn is_at_end(\u0026self) -\u003e bool {\n        (**self).is_at_end()\n    }\n\n    fn position(\u0026self) -\u003e usize {\n        (**self).position()\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n\n    #[test]\n    fn test_vec_token_stream_basic() {\n        let tokens = vec![\n            TokenType::Let,\n            TokenType::Identifier(\"x\".to_string()),\n            TokenType::Equal,\n            TokenType::IntegerLiteral(42),\n        ];\n        let mut stream = VecTokenStream::from_token_types(tokens);\n\n        assert_eq!(stream.peek().token_type, TokenType::Let);\n        assert_eq!(stream.position(), 0);\n\n        let token = stream.consume();\n        assert_eq!(token.token_type, TokenType::Let);\n        assert_eq!(stream.position(), 1);\n\n        assert_eq!(\n            stream.peek().token_type,\n            TokenType::Identifier(\"x\".to_string())\n        );\n    }\n\n    #[test]\n    fn test_vec_token_stream_eof() {\n        let mut stream = VecTokenStream::from_token_types(vec![TokenType::Let]);\n\n        stream.consume(); // consume Let\n        assert_eq!(stream.peek().token_type, TokenType::Eof);\n        assert!(stream.is_at_end());\n\n        // Should stay at EOF\n        let eof_token = stream.consume();\n        assert_eq!(eof_token.token_type, TokenType::Eof);\n        assert!(stream.is_at_end());\n    }\n\n    #[test]\n    fn test_peek_ahead() {\n        let tokens = vec![\n            TokenType::Let,\n            TokenType::Identifier(\"x\".to_string()),\n            TokenType::Equal,\n        ];\n        let stream = VecTokenStream::from_token_types(tokens);\n\n        assert_eq!(stream.peek_ahead(0).unwrap().token_type, TokenType::Let);\n        assert_eq!(\n            stream.peek_ahead(1).unwrap().token_type,\n            TokenType::Identifier(\"x\".to_string())\n        );\n        assert_eq!(stream.peek_ahead(2).unwrap().token_type, TokenType::Equal);\n        assert_eq!(stream.peek_ahead(3).unwrap().token_type, TokenType::Eof);\n        assert!(stream.peek_ahead(4).is_none());\n    }\n}\n","traces":[{"line":34,"address":[],"length":0,"stats":{"Line":293}},{"line":35,"address":[],"length":0,"stats":{"Line":293}},{"line":38,"address":[],"length":0,"stats":{"Line":723}},{"line":39,"address":[],"length":0,"stats":{"Line":139}},{"line":42,"address":[],"length":0,"stats":{"Line":293}},{"line":45,"address":[],"length":0,"stats":{"Line":230}},{"line":46,"address":[],"length":0,"stats":{"Line":230}},{"line":47,"address":[],"length":0,"stats":{"Line":230}},{"line":52,"address":[],"length":0,"stats":{"Line":5965}},{"line":53,"address":[],"length":0,"stats":{"Line":5965}},{"line":54,"address":[],"length":0,"stats":{"Line":5965}},{"line":55,"address":[],"length":0,"stats":{"Line":5965}},{"line":58,"address":[],"length":0,"stats":{"Line":5}},{"line":59,"address":[],"length":0,"stats":{"Line":5}},{"line":62,"address":[],"length":0,"stats":{"Line":1742}},{"line":63,"address":[],"length":0,"stats":{"Line":1742}},{"line":64,"address":[],"length":0,"stats":{"Line":3480}},{"line":65,"address":[],"length":0,"stats":{"Line":1738}},{"line":67,"address":[],"length":0,"stats":{"Line":1742}},{"line":70,"address":[],"length":0,"stats":{"Line":1865}},{"line":71,"address":[],"length":0,"stats":{"Line":3697}},{"line":74,"address":[],"length":0,"stats":{"Line":2}},{"line":75,"address":[],"length":0,"stats":{"Line":2}},{"line":80,"address":[],"length":0,"stats":{"Line":0}},{"line":81,"address":[],"length":0,"stats":{"Line":0}},{"line":86,"address":[],"length":0,"stats":{"Line":3125}},{"line":87,"address":[],"length":0,"stats":{"Line":3125}},{"line":90,"address":[],"length":0,"stats":{"Line":56}},{"line":91,"address":[],"length":0,"stats":{"Line":56}},{"line":94,"address":[],"length":0,"stats":{"Line":0}},{"line":95,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":1811}},{"line":99,"address":[],"length":0,"stats":{"Line":1811}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":103,"address":[],"length":0,"stats":{"Line":0}}],"covered":29,"coverable":35},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","token","types.rs"],"content":"//! Token type definitions and related utilities\n//!\n//! These types will eventually interface with the lexer output.\n//! For now, they provide a mock interface for development.\n\n/// Source location information for tokens\n#[derive(Debug, Clone, PartialEq, Eq)]\npub struct Span {\n    pub start: usize,\n    pub end: usize,\n    pub line: usize,\n    pub column: usize,\n}\n\nimpl Span {\n    pub fn new(start: usize, end: usize, line: usize, column: usize) -\u003e Self {\n        Self {\n            start,\n            end,\n            line,\n            column,\n        }\n    }\n\n    pub fn dummy() -\u003e Self {\n        Self::new(0, 0, 1, 1)\n    }\n\n    /// Combine two spans into one that covers both\n    pub fn combine(\u0026self, other: Span) -\u003e Self {\n        Self {\n            start: self.start.min(other.start),\n            end: self.end.max(other.end),\n            line: self.line,     // Use the start line\n            column: self.column, // Use the start column\n        }\n    }\n}\n\n/// Token types as they would come from the lexer\n#[derive(Debug, Clone, PartialEq)]\npub enum TokenType {\n    // Literals\n    StringLiteral(String),\n    IntegerLiteral(i64),\n    FloatLiteral(f64),\n    BooleanLiteral(bool),\n\n    // Identifiers\n    Identifier(String),\n\n    // Keywords\n    Let,\n    Var,\n    Fn,\n    Async,\n    Data,\n    Match,\n    If,\n    Else,\n    While,\n    For,\n    In,\n    Return,\n    Break,\n    Continue,\n    Extern,\n    Static,\n    Pub,\n    Unsafe,\n    Where, // for generic where clauses\n\n    // Operators\n    Plus,\n    Minus,\n    Star,\n    Slash,\n    Percent,\n    Equal,\n    EqualEqual,\n    BangEqual,\n    Less,\n    LessEqual,\n    Greater,\n    GreaterEqual,\n    AmpAmp,   // \u0026\u0026 (also `and` keyword)\n    PipePipe, // || (also `or` keyword)\n    Bang,\n    Question,\n    QuestionQuestion, // ??\n    Pipe,             // | (for OR patterns in match expressions)\n\n    // Assignment operators\n    PlusEqual,\n    MinusEqual,\n    StarEqual,\n    SlashEqual,\n\n    // Punctuation\n    LeftParen,\n    RightParen,\n    LeftBracket,\n    RightBracket,\n    LeftBrace,\n    RightBrace,\n    Comma,\n    Dot,\n    DotDot,      // .. (for range patterns and slice patterns)\n    DotDotEqual, // ..= (for inclusive range patterns)\n    Semicolon,\n    Colon,\n    DoubleColon, // :: (for path separators like std::vec::Vec)\n    Arrow,       // -\u003e\n    FatArrow,    // =\u003e (for match expressions and macro rules)\n    Hash,        // # (for attributes like #[derive(Debug)])\n    At,          // @ (for alternative attribute syntax like @inline and binding patterns)\n    Apostrophe,  // ' (for lifetimes like 'a, 'static)\n    Ampersand,   // \u0026 (for references)\n\n    // Special tokens for indentation\n    Indent,\n    Dedent,\n    Newline,\n\n    // End of file\n    Eof,\n}\n\n/// A token with its type and location information\n#[derive(Debug, Clone, PartialEq)]\npub struct Token {\n    pub token_type: TokenType,\n    pub span: Span,\n}\n\nimpl Token {\n    pub fn new(token_type: TokenType, span: Span) -\u003e Self {\n        Self { token_type, span }\n    }\n\n    pub fn dummy(token_type: TokenType) -\u003e Self {\n        Self::new(token_type, Span::dummy())\n    }\n\n    pub fn is_eof(\u0026self) -\u003e bool {\n        matches!(self.token_type, TokenType::Eof)\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":2143}},{"line":25,"address":[],"length":0,"stats":{"Line":2039}},{"line":26,"address":[],"length":0,"stats":{"Line":2039}},{"line":30,"address":[],"length":0,"stats":{"Line":162}},{"line":32,"address":[],"length":0,"stats":{"Line":162}},{"line":33,"address":[],"length":0,"stats":{"Line":162}},{"line":34,"address":[],"length":0,"stats":{"Line":162}},{"line":35,"address":[],"length":0,"stats":{"Line":162}},{"line":137,"address":[],"length":0,"stats":{"Line":2100}},{"line":141,"address":[],"length":0,"stats":{"Line":2004}},{"line":142,"address":[],"length":0,"stats":{"Line":2004}},{"line":145,"address":[],"length":0,"stats":{"Line":2123}},{"line":146,"address":[],"length":0,"stats":{"Line":4092}}],"covered":13,"coverable":13},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","types","mod.rs"],"content":"//! Type expression parsing\n//!\n//! Implementation will be completed during development phase\n\npub mod parser;\n\npub use parser::*;\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","src","types","parser.rs"],"content":"//! Type expression parsing implementation\n//!\n//! Comprehensive type parsing for Ferra language Phase 2.7\n\nuse crate::{\n    ast::{FunctionType, PointerType, Type},\n    error::{ParseError, ParseResult},\n    token::{TokenStream, TokenType},\n};\n\n/// Parse a type expression with full Phase 2.7 support\npub fn parse_type\u003cT: TokenStream\u003e(tokens: \u0026mut T) -\u003e ParseResult\u003cType\u003e {\n    let mut parser = TypeParser::new(tokens);\n    parser.parse_type()\n}\n\n/// Parse a simple type (identifier)\npub fn parse_simple_type\u003cT: TokenStream\u003e(tokens: \u0026mut T) -\u003e ParseResult\u003cType\u003e {\n    let mut parser = TypeParser::new(tokens);\n    parser.parse_simple_type()\n}\n\n/// Parse a tuple type\npub fn parse_tuple_type\u003cT: TokenStream\u003e(tokens: \u0026mut T) -\u003e ParseResult\u003cType\u003e {\n    let mut parser = TypeParser::new(tokens);\n    parser.parse_tuple_type()\n}\n\n/// Parse an array type\npub fn parse_array_type\u003cT: TokenStream\u003e(tokens: \u0026mut T) -\u003e ParseResult\u003cType\u003e {\n    let mut parser = TypeParser::new(tokens);\n    parser.parse_array_type()\n}\n\n/// Parse a function type\npub fn parse_function_type\u003cT: TokenStream\u003e(tokens: \u0026mut T) -\u003e ParseResult\u003cType\u003e {\n    let mut parser = TypeParser::new(tokens);\n    parser.parse_function_type()\n}\n\n/// Comprehensive type parser for Phase 2.7\nstruct TypeParser\u003c'a, T: TokenStream\u003e {\n    tokens: \u0026'a mut T,\n}\n\nimpl\u003c'a, T: TokenStream\u003e TypeParser\u003c'a, T\u003e {\n    fn new(tokens: \u0026'a mut T) -\u003e Self {\n        Self { tokens }\n    }\n\n    /// Parse any type expression\n    fn parse_type(\u0026mut self) -\u003e ParseResult\u003cType\u003e {\n        let current = self.tokens.peek();\n\n        match \u0026current.token_type {\n            // Function types: fn(T) -\u003e T or extern \"C\" fn(T) -\u003e T\n            TokenType::Fn =\u003e self.parse_function_type(),\n            TokenType::Extern =\u003e self.parse_extern_function_type(),\n\n            // Pointer types: *const T or *mut T\n            TokenType::Star =\u003e self.parse_pointer_type(),\n\n            // Tuple types: (T, T, ...)\n            TokenType::LeftParen =\u003e self.parse_tuple_type(),\n\n            // Array types: [T]\n            TokenType::LeftBracket =\u003e self.parse_array_type(),\n\n            // Simple identifier types\n            TokenType::Identifier(_) =\u003e self.parse_identifier_type(),\n\n            _ =\u003e Err(ParseError::unexpected_token(\"type\", current)),\n        }\n    }\n\n    /// Parse simple identifier type or qualified identifier\n    fn parse_identifier_type(\u0026mut self) -\u003e ParseResult\u003cType\u003e {\n        let token = self.tokens.consume();\n        match token.token_type {\n            TokenType::Identifier(name) =\u003e {\n                // Check for generic type parameters: Name\u003cT\u003e\n                if matches!(self.tokens.peek().token_type, TokenType::Less) {\n                    self.parse_generic_type(name)\n                } else {\n                    Ok(Type::Identifier(name))\n                }\n            }\n            _ =\u003e Err(ParseError::unexpected_token(\"identifier\", \u0026token)),\n        }\n    }\n\n    /// Parse generic type: Name\u003cT, U, ...\u003e\n    fn parse_generic_type(\u0026mut self, base_name: String) -\u003e ParseResult\u003cType\u003e {\n        // For now, we'll represent generic types as qualified identifiers\n        // In future phases, we'll have a proper Generic variant\n        let _open_bracket = self.tokens.consume(); // consume '\u003c'\n\n        let mut type_args = Vec::new();\n\n        loop {\n            if matches!(self.tokens.peek().token_type, TokenType::Greater) {\n                break;\n            }\n\n            let type_arg = self.parse_type()?;\n            type_args.push(type_arg);\n\n            match self.tokens.peek().token_type {\n                TokenType::Comma =\u003e {\n                    self.tokens.consume(); // consume ','\n                }\n                TokenType::Greater =\u003e break,\n                _ =\u003e {\n                    return Err(ParseError::unexpected_token(\n                        \"',' or '\u003e'\",\n                        self.tokens.peek(),\n                    ))\n                }\n            }\n        }\n\n        let _close_bracket = self.tokens.consume(); // consume '\u003e'\n\n        // For now, represent as a structured identifier\n        // Future phases will have proper generic type support\n        Ok(Type::Identifier(format!(\n            \"{}\u003c{}\u003e\",\n            base_name,\n            type_args.len()\n        )))\n    }\n\n    /// Parse simple type (just identifier)\n    fn parse_simple_type(\u0026mut self) -\u003e ParseResult\u003cType\u003e {\n        let token = self.tokens.consume();\n        match token.token_type {\n            TokenType::Identifier(name) =\u003e Ok(Type::Identifier(name)),\n            _ =\u003e Err(ParseError::unexpected_token(\"identifier\", \u0026token)),\n        }\n    }\n\n    /// Parse tuple type: (T, T, ...)\n    fn parse_tuple_type(\u0026mut self) -\u003e ParseResult\u003cType\u003e {\n        let open_paren = self.tokens.consume();\n        if !matches!(open_paren.token_type, TokenType::LeftParen) {\n            return Err(ParseError::unexpected_token(\"'('\", \u0026open_paren));\n        }\n\n        let mut types = Vec::new();\n\n        // Handle empty tuple: ()\n        if matches!(self.tokens.peek().token_type, TokenType::RightParen) {\n            self.tokens.consume(); // consume ')'\n            return Ok(Type::Tuple(types));\n        }\n\n        // Parse type list\n        loop {\n            let type_expr = self.parse_type()?;\n            types.push(type_expr);\n\n            match self.tokens.peek().token_type {\n                TokenType::Comma =\u003e {\n                    self.tokens.consume(); // consume ','\n                                           // Allow trailing comma\n                    if matches!(self.tokens.peek().token_type, TokenType::RightParen) {\n                        break;\n                    }\n                }\n                TokenType::RightParen =\u003e break,\n                _ =\u003e {\n                    return Err(ParseError::unexpected_token(\n                        \"',' or ')'\",\n                        self.tokens.peek(),\n                    ))\n                }\n            }\n        }\n\n        let close_paren = self.tokens.consume();\n        if !matches!(close_paren.token_type, TokenType::RightParen) {\n            return Err(ParseError::unexpected_token(\"')'\", \u0026close_paren));\n        }\n\n        Ok(Type::Tuple(types))\n    }\n\n    /// Parse array type: [T]\n    fn parse_array_type(\u0026mut self) -\u003e ParseResult\u003cType\u003e {\n        let open_bracket = self.tokens.consume();\n        if !matches!(open_bracket.token_type, TokenType::LeftBracket) {\n            return Err(ParseError::unexpected_token(\"'['\", \u0026open_bracket));\n        }\n\n        let element_type = self.parse_type()?;\n\n        let close_bracket = self.tokens.consume();\n        if !matches!(close_bracket.token_type, TokenType::RightBracket) {\n            return Err(ParseError::unexpected_token(\"']'\", \u0026close_bracket));\n        }\n\n        Ok(Type::Array(Box::new(element_type)))\n    }\n\n    /// Parse function type: fn(T, U) -\u003e V\n    fn parse_function_type(\u0026mut self) -\u003e ParseResult\u003cType\u003e {\n        let fn_token = self.tokens.consume();\n        if !matches!(fn_token.token_type, TokenType::Fn) {\n            return Err(ParseError::unexpected_token(\"'fn'\", \u0026fn_token));\n        }\n\n        // Parse parameter types\n        let open_paren = self.tokens.consume();\n        if !matches!(open_paren.token_type, TokenType::LeftParen) {\n            return Err(ParseError::unexpected_token(\"'('\", \u0026open_paren));\n        }\n\n        let mut parameters = Vec::new();\n\n        // Handle empty parameter list\n        if !matches!(self.tokens.peek().token_type, TokenType::RightParen) {\n            loop {\n                let param_type = self.parse_type()?;\n                parameters.push(param_type);\n\n                match self.tokens.peek().token_type {\n                    TokenType::Comma =\u003e {\n                        self.tokens.consume(); // consume ','\n                                               // Allow trailing comma\n                        if matches!(self.tokens.peek().token_type, TokenType::RightParen) {\n                            break;\n                        }\n                    }\n                    TokenType::RightParen =\u003e break,\n                    _ =\u003e {\n                        return Err(ParseError::unexpected_token(\n                            \"',' or ')'\",\n                            self.tokens.peek(),\n                        ))\n                    }\n                }\n            }\n        }\n\n        let close_paren = self.tokens.consume();\n        if !matches!(close_paren.token_type, TokenType::RightParen) {\n            return Err(ParseError::unexpected_token(\"')'\", \u0026close_paren));\n        }\n\n        // Parse return type (if present)\n        let return_type = if matches!(self.tokens.peek().token_type, TokenType::Arrow) {\n            self.tokens.consume(); // consume '-\u003e'\n            Box::new(self.parse_type()?)\n        } else {\n            // Default to unit type if no return type specified\n            Box::new(Type::Tuple(Vec::new()))\n        };\n\n        Ok(Type::Function(FunctionType {\n            parameters,\n            return_type,\n            is_extern: false,\n            abi: None,\n        }))\n    }\n\n    /// Parse extern function type: extern \"C\" fn(T) -\u003e U\n    fn parse_extern_function_type(\u0026mut self) -\u003e ParseResult\u003cType\u003e {\n        let extern_token = self.tokens.consume();\n        if !matches!(extern_token.token_type, TokenType::Extern) {\n            return Err(ParseError::unexpected_token(\"'extern'\", \u0026extern_token));\n        }\n\n        // Parse ABI string\n        let abi = if let TokenType::StringLiteral(abi_string) = \u0026self.tokens.peek().token_type {\n            let abi_string = abi_string.clone();\n            self.tokens.consume(); // consume ABI string\n            Some(abi_string)\n        } else {\n            None\n        };\n\n        // Parse 'fn'\n        let fn_token = self.tokens.consume();\n        if !matches!(fn_token.token_type, TokenType::Fn) {\n            return Err(ParseError::unexpected_token(\"'fn'\", \u0026fn_token));\n        }\n\n        // Parse parameter types\n        let open_paren = self.tokens.consume();\n        if !matches!(open_paren.token_type, TokenType::LeftParen) {\n            return Err(ParseError::unexpected_token(\"'('\", \u0026open_paren));\n        }\n\n        let mut parameters = Vec::new();\n\n        // Handle empty parameter list\n        if !matches!(self.tokens.peek().token_type, TokenType::RightParen) {\n            loop {\n                let param_type = self.parse_type()?;\n                parameters.push(param_type);\n\n                match self.tokens.peek().token_type {\n                    TokenType::Comma =\u003e {\n                        self.tokens.consume(); // consume ','\n                                               // Allow trailing comma\n                        if matches!(self.tokens.peek().token_type, TokenType::RightParen) {\n                            break;\n                        }\n                    }\n                    TokenType::RightParen =\u003e break,\n                    _ =\u003e {\n                        return Err(ParseError::unexpected_token(\n                            \"',' or ')'\",\n                            self.tokens.peek(),\n                        ))\n                    }\n                }\n            }\n        }\n\n        let close_paren = self.tokens.consume();\n        if !matches!(close_paren.token_type, TokenType::RightParen) {\n            return Err(ParseError::unexpected_token(\"')'\", \u0026close_paren));\n        }\n\n        // Parse return type (if present)\n        let return_type = if matches!(self.tokens.peek().token_type, TokenType::Arrow) {\n            self.tokens.consume(); // consume '-\u003e'\n            Box::new(self.parse_type()?)\n        } else {\n            // Default to unit type if no return type specified\n            Box::new(Type::Tuple(Vec::new()))\n        };\n\n        Ok(Type::Function(FunctionType {\n            parameters,\n            return_type,\n            is_extern: true,\n            abi,\n        }))\n    }\n\n    /// Parse pointer type: *Type (simplified without const/mut for now)\n    fn parse_pointer_type(\u0026mut self) -\u003e ParseResult\u003cType\u003e {\n        let star_token = self.tokens.consume();\n        if !matches!(star_token.token_type, TokenType::Star) {\n            return Err(ParseError::unexpected_token(\"'*'\", \u0026star_token));\n        }\n\n        let target_type = self.parse_type()?;\n\n        // For now, default to mutable pointers since we don't have const/mut tokens\n        Ok(Type::Pointer(PointerType {\n            target: Box::new(target_type),\n            is_mutable: true, // Default to mutable for now\n        }))\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::token::VecTokenStream;\n\n    fn create_token_stream(token_types: Vec\u003cTokenType\u003e) -\u003e VecTokenStream {\n        VecTokenStream::from_token_types(token_types)\n    }\n\n    #[test]\n    fn test_simple_identifier_type() {\n        let mut tokens = create_token_stream(vec![TokenType::Identifier(\"int\".to_string())]);\n\n        let result = parse_type(\u0026mut tokens).unwrap();\n        match result {\n            Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n            _ =\u003e panic!(\"Expected identifier type\"),\n        }\n    }\n\n    #[test]\n    fn test_tuple_type() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::LeftParen,\n            TokenType::Identifier(\"int\".to_string()),\n            TokenType::Comma,\n            TokenType::Identifier(\"string\".to_string()),\n            TokenType::RightParen,\n        ]);\n\n        let result = parse_type(\u0026mut tokens).unwrap();\n        match result {\n            Type::Tuple(types) =\u003e {\n                assert_eq!(types.len(), 2);\n                match (\u0026types[0], \u0026types[1]) {\n                    (Type::Identifier(t1), Type::Identifier(t2)) =\u003e {\n                        assert_eq!(t1, \"int\");\n                        assert_eq!(t2, \"string\");\n                    }\n                    _ =\u003e panic!(\"Expected identifier types in tuple\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected tuple type\"),\n        }\n    }\n\n    #[test]\n    fn test_empty_tuple_type() {\n        let mut tokens = create_token_stream(vec![TokenType::LeftParen, TokenType::RightParen]);\n\n        let result = parse_type(\u0026mut tokens).unwrap();\n        match result {\n            Type::Tuple(types) =\u003e assert_eq!(types.len(), 0),\n            _ =\u003e panic!(\"Expected empty tuple type\"),\n        }\n    }\n\n    #[test]\n    fn test_array_type() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::LeftBracket,\n            TokenType::Identifier(\"int\".to_string()),\n            TokenType::RightBracket,\n        ]);\n\n        let result = parse_type(\u0026mut tokens).unwrap();\n        match result {\n            Type::Array(element_type) =\u003e match element_type.as_ref() {\n                Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n                _ =\u003e panic!(\"Expected identifier type in array\"),\n            },\n            _ =\u003e panic!(\"Expected array type\"),\n        }\n    }\n\n    #[test]\n    fn test_function_type() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::Fn,\n            TokenType::LeftParen,\n            TokenType::Identifier(\"int\".to_string()),\n            TokenType::Comma,\n            TokenType::Identifier(\"string\".to_string()),\n            TokenType::RightParen,\n            TokenType::Arrow,\n            TokenType::Identifier(\"bool\".to_string()),\n        ]);\n\n        let result = parse_type(\u0026mut tokens).unwrap();\n        match result {\n            Type::Function(func_type) =\u003e {\n                assert_eq!(func_type.parameters.len(), 2);\n                assert!(!func_type.is_extern);\n                assert!(func_type.abi.is_none());\n\n                match func_type.return_type.as_ref() {\n                    Type::Identifier(name) =\u003e assert_eq!(name, \"bool\"),\n                    _ =\u003e panic!(\"Expected bool return type\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected function type\"),\n        }\n    }\n\n    #[test]\n    fn test_extern_function_type() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::Extern,\n            TokenType::StringLiteral(\"C\".to_string()),\n            TokenType::Fn,\n            TokenType::LeftParen,\n            TokenType::Identifier(\"int\".to_string()),\n            TokenType::RightParen,\n            TokenType::Arrow,\n            TokenType::Identifier(\"void\".to_string()),\n        ]);\n\n        let result = parse_type(\u0026mut tokens).unwrap();\n        match result {\n            Type::Function(func_type) =\u003e {\n                assert_eq!(func_type.parameters.len(), 1);\n                assert!(func_type.is_extern);\n                assert_eq!(func_type.abi, Some(\"C\".to_string()));\n            }\n            _ =\u003e panic!(\"Expected extern function type\"),\n        }\n    }\n\n    #[test]\n    fn test_pointer_type() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::Star,\n            TokenType::Identifier(\"int\".to_string()),\n        ]);\n\n        let result = parse_type(\u0026mut tokens).unwrap();\n        match result {\n            Type::Pointer(ptr_type) =\u003e {\n                assert!(ptr_type.is_mutable); // Default to mutable for now\n                match ptr_type.target.as_ref() {\n                    Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n                    _ =\u003e panic!(\"Expected int pointer target\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected pointer type\"),\n        }\n    }\n\n    #[test]\n    fn test_mutable_pointer_type() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::Star,\n            TokenType::Identifier(\"int\".to_string()),\n        ]);\n\n        let result = parse_type(\u0026mut tokens).unwrap();\n        match result {\n            Type::Pointer(ptr_type) =\u003e {\n                assert!(ptr_type.is_mutable);\n                match ptr_type.target.as_ref() {\n                    Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n                    _ =\u003e panic!(\"Expected int pointer target\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected mutable pointer type\"),\n        }\n    }\n\n    #[test]\n    fn test_nested_array_type() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::LeftBracket,\n            TokenType::LeftBracket,\n            TokenType::Identifier(\"int\".to_string()),\n            TokenType::RightBracket,\n            TokenType::RightBracket,\n        ]);\n\n        let result = parse_type(\u0026mut tokens).unwrap();\n        match result {\n            Type::Array(outer_element) =\u003e match outer_element.as_ref() {\n                Type::Array(inner_element) =\u003e match inner_element.as_ref() {\n                    Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n                    _ =\u003e panic!(\"Expected int in nested array\"),\n                },\n                _ =\u003e panic!(\"Expected nested array\"),\n            },\n            _ =\u003e panic!(\"Expected array type\"),\n        }\n    }\n\n    #[test]\n    fn test_complex_function_type() {\n        let mut tokens = create_token_stream(vec![\n            TokenType::Fn,\n            TokenType::LeftParen,\n            TokenType::LeftBracket,\n            TokenType::Identifier(\"int\".to_string()),\n            TokenType::RightBracket,\n            TokenType::Comma,\n            TokenType::LeftParen,\n            TokenType::Identifier(\"string\".to_string()),\n            TokenType::Comma,\n            TokenType::Identifier(\"bool\".to_string()),\n            TokenType::RightParen,\n            TokenType::RightParen,\n            TokenType::Arrow,\n            TokenType::Star,\n            TokenType::Identifier(\"char\".to_string()),\n        ]);\n\n        let result = parse_type(\u0026mut tokens).unwrap();\n        match result {\n            Type::Function(func_type) =\u003e {\n                assert_eq!(func_type.parameters.len(), 2);\n\n                // First parameter: [int]\n                match \u0026func_type.parameters[0] {\n                    Type::Array(elem) =\u003e match elem.as_ref() {\n                        Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n                        _ =\u003e panic!(\"Expected int array\"),\n                    },\n                    _ =\u003e panic!(\"Expected array parameter\"),\n                }\n\n                // Second parameter: (string, bool)\n                match \u0026func_type.parameters[1] {\n                    Type::Tuple(types) =\u003e {\n                        assert_eq!(types.len(), 2);\n                    }\n                    _ =\u003e panic!(\"Expected tuple parameter\"),\n                }\n\n                // Return type: *char (simplified)\n                match func_type.return_type.as_ref() {\n                    Type::Pointer(ptr) =\u003e {\n                        assert!(ptr.is_mutable); // Default to mutable\n                        match ptr.target.as_ref() {\n                            Type::Identifier(name) =\u003e assert_eq!(name, \"char\"),\n                            _ =\u003e panic!(\"Expected char pointer\"),\n                        }\n                    }\n                    _ =\u003e panic!(\"Expected pointer return type\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected function type\"),\n        }\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":115}},{"line":13,"address":[],"length":0,"stats":{"Line":115}},{"line":14,"address":[],"length":0,"stats":{"Line":115}},{"line":18,"address":[],"length":0,"stats":{"Line":0}},{"line":19,"address":[],"length":0,"stats":{"Line":0}},{"line":20,"address":[],"length":0,"stats":{"Line":0}},{"line":24,"address":[],"length":0,"stats":{"Line":0}},{"line":25,"address":[],"length":0,"stats":{"Line":0}},{"line":26,"address":[],"length":0,"stats":{"Line":0}},{"line":30,"address":[],"length":0,"stats":{"Line":0}},{"line":31,"address":[],"length":0,"stats":{"Line":0}},{"line":32,"address":[],"length":0,"stats":{"Line":0}},{"line":36,"address":[],"length":0,"stats":{"Line":0}},{"line":37,"address":[],"length":0,"stats":{"Line":0}},{"line":38,"address":[],"length":0,"stats":{"Line":0}},{"line":47,"address":[],"length":0,"stats":{"Line":115}},{"line":52,"address":[],"length":0,"stats":{"Line":197}},{"line":53,"address":[],"length":0,"stats":{"Line":197}},{"line":55,"address":[],"length":0,"stats":{"Line":197}},{"line":57,"address":[],"length":0,"stats":{"Line":12}},{"line":58,"address":[],"length":0,"stats":{"Line":3}},{"line":61,"address":[],"length":0,"stats":{"Line":10}},{"line":64,"address":[],"length":0,"stats":{"Line":11}},{"line":67,"address":[],"length":0,"stats":{"Line":21}},{"line":70,"address":[],"length":0,"stats":{"Line":138}},{"line":72,"address":[],"length":0,"stats":{"Line":2}},{"line":77,"address":[],"length":0,"stats":{"Line":138}},{"line":78,"address":[],"length":0,"stats":{"Line":138}},{"line":79,"address":[],"length":0,"stats":{"Line":138}},{"line":80,"address":[],"length":0,"stats":{"Line":138}},{"line":82,"address":[],"length":0,"stats":{"Line":138}},{"line":83,"address":[],"length":0,"stats":{"Line":0}},{"line":85,"address":[],"length":0,"stats":{"Line":138}},{"line":88,"address":[],"length":0,"stats":{"Line":0}},{"line":93,"address":[],"length":0,"stats":{"Line":0}},{"line":96,"address":[],"length":0,"stats":{"Line":0}},{"line":98,"address":[],"length":0,"stats":{"Line":0}},{"line":100,"address":[],"length":0,"stats":{"Line":0}},{"line":101,"address":[],"length":0,"stats":{"Line":0}},{"line":102,"address":[],"length":0,"stats":{"Line":0}},{"line":105,"address":[],"length":0,"stats":{"Line":0}},{"line":106,"address":[],"length":0,"stats":{"Line":0}},{"line":108,"address":[],"length":0,"stats":{"Line":0}},{"line":109,"address":[],"length":0,"stats":{"Line":0}},{"line":110,"address":[],"length":0,"stats":{"Line":0}},{"line":112,"address":[],"length":0,"stats":{"Line":0}},{"line":113,"address":[],"length":0,"stats":{"Line":0}},{"line":114,"address":[],"length":0,"stats":{"Line":0}},{"line":115,"address":[],"length":0,"stats":{"Line":0}},{"line":116,"address":[],"length":0,"stats":{"Line":0}},{"line":122,"address":[],"length":0,"stats":{"Line":0}},{"line":126,"address":[],"length":0,"stats":{"Line":0}},{"line":127,"address":[],"length":0,"stats":{"Line":0}},{"line":128,"address":[],"length":0,"stats":{"Line":0}},{"line":129,"address":[],"length":0,"stats":{"Line":0}},{"line":134,"address":[],"length":0,"stats":{"Line":0}},{"line":135,"address":[],"length":0,"stats":{"Line":0}},{"line":136,"address":[],"length":0,"stats":{"Line":0}},{"line":137,"address":[],"length":0,"stats":{"Line":0}},{"line":138,"address":[],"length":0,"stats":{"Line":0}},{"line":143,"address":[],"length":0,"stats":{"Line":11}},{"line":144,"address":[],"length":0,"stats":{"Line":11}},{"line":145,"address":[],"length":0,"stats":{"Line":11}},{"line":146,"address":[],"length":0,"stats":{"Line":0}},{"line":149,"address":[],"length":0,"stats":{"Line":11}},{"line":152,"address":[],"length":0,"stats":{"Line":20}},{"line":153,"address":[],"length":0,"stats":{"Line":2}},{"line":154,"address":[],"length":0,"stats":{"Line":2}},{"line":158,"address":[],"length":0,"stats":{"Line":0}},{"line":159,"address":[],"length":0,"stats":{"Line":38}},{"line":160,"address":[],"length":0,"stats":{"Line":0}},{"line":162,"address":[],"length":0,"stats":{"Line":0}},{"line":163,"address":[],"length":0,"stats":{"Line":0}},{"line":164,"address":[],"length":0,"stats":{"Line":11}},{"line":166,"address":[],"length":0,"stats":{"Line":21}},{"line":167,"address":[],"length":0,"stats":{"Line":1}},{"line":170,"address":[],"length":0,"stats":{"Line":8}},{"line":171,"address":[],"length":0,"stats":{"Line":0}},{"line":172,"address":[],"length":0,"stats":{"Line":0}},{"line":173,"address":[],"length":0,"stats":{"Line":0}},{"line":174,"address":[],"length":0,"stats":{"Line":0}},{"line":180,"address":[],"length":0,"stats":{"Line":9}},{"line":181,"address":[],"length":0,"stats":{"Line":0}},{"line":182,"address":[],"length":0,"stats":{"Line":0}},{"line":185,"address":[],"length":0,"stats":{"Line":9}},{"line":189,"address":[],"length":0,"stats":{"Line":21}},{"line":190,"address":[],"length":0,"stats":{"Line":21}},{"line":191,"address":[],"length":0,"stats":{"Line":21}},{"line":192,"address":[],"length":0,"stats":{"Line":0}},{"line":195,"address":[],"length":0,"stats":{"Line":42}},{"line":197,"address":[],"length":0,"stats":{"Line":0}},{"line":198,"address":[],"length":0,"stats":{"Line":0}},{"line":199,"address":[],"length":0,"stats":{"Line":0}},{"line":202,"address":[],"length":0,"stats":{"Line":20}},{"line":206,"address":[],"length":0,"stats":{"Line":12}},{"line":207,"address":[],"length":0,"stats":{"Line":12}},{"line":208,"address":[],"length":0,"stats":{"Line":12}},{"line":209,"address":[],"length":0,"stats":{"Line":0}},{"line":213,"address":[],"length":0,"stats":{"Line":12}},{"line":214,"address":[],"length":0,"stats":{"Line":12}},{"line":215,"address":[],"length":0,"stats":{"Line":0}},{"line":218,"address":[],"length":0,"stats":{"Line":12}},{"line":221,"address":[],"length":0,"stats":{"Line":23}},{"line":222,"address":[],"length":0,"stats":{"Line":0}},{"line":223,"address":[],"length":0,"stats":{"Line":34}},{"line":224,"address":[],"length":0,"stats":{"Line":0}},{"line":226,"address":[],"length":0,"stats":{"Line":0}},{"line":227,"address":[],"length":0,"stats":{"Line":0}},{"line":228,"address":[],"length":0,"stats":{"Line":6}},{"line":230,"address":[],"length":0,"stats":{"Line":12}},{"line":231,"address":[],"length":0,"stats":{"Line":0}},{"line":234,"address":[],"length":0,"stats":{"Line":10}},{"line":235,"address":[],"length":0,"stats":{"Line":0}},{"line":236,"address":[],"length":0,"stats":{"Line":1}},{"line":237,"address":[],"length":0,"stats":{"Line":1}},{"line":238,"address":[],"length":0,"stats":{"Line":1}},{"line":245,"address":[],"length":0,"stats":{"Line":11}},{"line":246,"address":[],"length":0,"stats":{"Line":0}},{"line":247,"address":[],"length":0,"stats":{"Line":0}},{"line":251,"address":[],"length":0,"stats":{"Line":23}},{"line":252,"address":[],"length":0,"stats":{"Line":10}},{"line":253,"address":[],"length":0,"stats":{"Line":10}},{"line":256,"address":[],"length":0,"stats":{"Line":1}},{"line":259,"address":[],"length":0,"stats":{"Line":0}},{"line":260,"address":[],"length":0,"stats":{"Line":0}},{"line":261,"address":[],"length":0,"stats":{"Line":0}},{"line":262,"address":[],"length":0,"stats":{"Line":0}},{"line":263,"address":[],"length":0,"stats":{"Line":0}},{"line":268,"address":[],"length":0,"stats":{"Line":3}},{"line":269,"address":[],"length":0,"stats":{"Line":3}},{"line":270,"address":[],"length":0,"stats":{"Line":3}},{"line":271,"address":[],"length":0,"stats":{"Line":0}},{"line":275,"address":[],"length":0,"stats":{"Line":8}},{"line":276,"address":[],"length":0,"stats":{"Line":0}},{"line":278,"address":[],"length":0,"stats":{"Line":0}},{"line":280,"address":[],"length":0,"stats":{"Line":1}},{"line":284,"address":[],"length":0,"stats":{"Line":3}},{"line":285,"address":[],"length":0,"stats":{"Line":3}},{"line":286,"address":[],"length":0,"stats":{"Line":0}},{"line":290,"address":[],"length":0,"stats":{"Line":3}},{"line":291,"address":[],"length":0,"stats":{"Line":3}},{"line":292,"address":[],"length":0,"stats":{"Line":0}},{"line":295,"address":[],"length":0,"stats":{"Line":3}},{"line":298,"address":[],"length":0,"stats":{"Line":5}},{"line":299,"address":[],"length":0,"stats":{"Line":0}},{"line":300,"address":[],"length":0,"stats":{"Line":4}},{"line":301,"address":[],"length":0,"stats":{"Line":0}},{"line":303,"address":[],"length":0,"stats":{"Line":0}},{"line":304,"address":[],"length":0,"stats":{"Line":0}},{"line":305,"address":[],"length":0,"stats":{"Line":0}},{"line":307,"address":[],"length":0,"stats":{"Line":0}},{"line":308,"address":[],"length":0,"stats":{"Line":0}},{"line":311,"address":[],"length":0,"stats":{"Line":2}},{"line":312,"address":[],"length":0,"stats":{"Line":0}},{"line":313,"address":[],"length":0,"stats":{"Line":0}},{"line":314,"address":[],"length":0,"stats":{"Line":0}},{"line":315,"address":[],"length":0,"stats":{"Line":0}},{"line":322,"address":[],"length":0,"stats":{"Line":3}},{"line":323,"address":[],"length":0,"stats":{"Line":0}},{"line":324,"address":[],"length":0,"stats":{"Line":0}},{"line":328,"address":[],"length":0,"stats":{"Line":6}},{"line":329,"address":[],"length":0,"stats":{"Line":3}},{"line":330,"address":[],"length":0,"stats":{"Line":3}},{"line":333,"address":[],"length":0,"stats":{"Line":0}},{"line":336,"address":[],"length":0,"stats":{"Line":0}},{"line":337,"address":[],"length":0,"stats":{"Line":0}},{"line":338,"address":[],"length":0,"stats":{"Line":0}},{"line":339,"address":[],"length":0,"stats":{"Line":0}},{"line":340,"address":[],"length":0,"stats":{"Line":0}},{"line":345,"address":[],"length":0,"stats":{"Line":10}},{"line":346,"address":[],"length":0,"stats":{"Line":10}},{"line":347,"address":[],"length":0,"stats":{"Line":10}},{"line":348,"address":[],"length":0,"stats":{"Line":0}},{"line":351,"address":[],"length":0,"stats":{"Line":20}},{"line":354,"address":[],"length":0,"stats":{"Line":0}},{"line":355,"address":[],"length":0,"stats":{"Line":0}}],"covered":79,"coverable":176},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","tests","test_additional_coverage.rs"],"content":"//! Additional comprehensive tests to restore missing Phase 2.1 coverage\n\nuse ferra_parser::{\n    ast::{Arena, BinaryOperator, Expression, Item, Literal, Statement, UnaryOperator},\n    pratt::parser::PrattParser,\n    statement::parser::StatementParser,\n    token::{TokenType, VecTokenStream},\n    Parser,\n};\n\n// Test 1: Advanced AST Construction Tests\n#[test]\nfn test_compilation_unit_with_multiple_items() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Fn,\n        TokenType::Identifier(\"func1\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n        TokenType::Data,\n        TokenType::Identifier(\"Point\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"i32\".to_string()),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n\n    let mut parser = Parser::new(\u0026arena, tokens);\n    let result = parser.parse_compilation_unit();\n    assert!(result.is_ok());\n\n    if let Ok(compilation_unit) = result {\n        assert_eq!(compilation_unit.items.len(), 2);\n\n        // First item should be function\n        if let Item::FunctionDecl(func) = \u0026compilation_unit.items[0] {\n            assert_eq!(func.name, \"func1\");\n        } else {\n            panic!(\"Expected function declaration\");\n        }\n\n        // Second item should be data class\n        if let Item::DataClassDecl(data_class) = \u0026compilation_unit.items[1] {\n            assert_eq!(data_class.name, \"Point\");\n            assert_eq!(data_class.fields.len(), 1);\n        } else {\n            panic!(\"Expected data class declaration\");\n        }\n    }\n}\n\n// Test 2: Complex Expression Precedence\n#[test]\nfn test_complex_precedence_chain() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::IntegerLiteral(1),\n        TokenType::Plus,\n        TokenType::IntegerLiteral(2),\n        TokenType::Star,\n        TokenType::IntegerLiteral(3),\n        TokenType::EqualEqual,\n        TokenType::IntegerLiteral(6),\n        TokenType::AmpAmp,\n        TokenType::BooleanLiteral(true),\n        TokenType::Eof,\n    ]);\n\n    let mut pratt_parser = PrattParser::new(\u0026arena, tokens);\n    let result = pratt_parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    // Should parse as: ((1 + (2 * 3)) == 6) \u0026\u0026 true\n    if let Ok(Expression::Binary(and_expr)) = result {\n        assert!(matches!(and_expr.operator, BinaryOperator::And));\n\n        // Left side should be equality comparison\n        if let Expression::Binary(eq_expr) = and_expr.left.as_ref() {\n            assert!(matches!(eq_expr.operator, BinaryOperator::Equal));\n\n            // Left of equality should be addition\n            if let Expression::Binary(add_expr) = eq_expr.left.as_ref() {\n                assert!(matches!(add_expr.operator, BinaryOperator::Add));\n\n                // Right of addition should be multiplication\n                if let Expression::Binary(mul_expr) = add_expr.right.as_ref() {\n                    assert!(matches!(mul_expr.operator, BinaryOperator::Mul));\n                } else {\n                    panic!(\"Expected multiplication in precedence chain\");\n                }\n            } else {\n                panic!(\"Expected addition in precedence chain\");\n            }\n        } else {\n            panic!(\"Expected equality in precedence chain\");\n        }\n    } else {\n        panic!(\"Expected complex precedence expression\");\n    }\n}\n\n// Test 3: Nested Function Calls with Member Access\n#[test]\nfn test_nested_function_calls_with_member_access() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"obj\".to_string()),\n        TokenType::Dot,\n        TokenType::Identifier(\"get_inner\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::Dot,\n        TokenType::Identifier(\"process\".to_string()),\n        TokenType::LeftParen,\n        TokenType::IntegerLiteral(42),\n        TokenType::RightParen,\n        TokenType::LeftBracket,\n        TokenType::IntegerLiteral(0),\n        TokenType::RightBracket,\n        TokenType::Eof,\n    ]);\n\n    let mut pratt_parser = PrattParser::new(\u0026arena, tokens);\n    let result = pratt_parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    // Should parse as: obj.get_inner().process(42)[0]\n    if let Ok(Expression::Index(index_expr)) = result {\n        // Object should be obj.get_inner().process(42)\n        if let Expression::Call(call_expr) = index_expr.object.as_ref() {\n            assert_eq!(call_expr.arguments.len(), 1);\n\n            // Callee should be obj.get_inner().process\n            if let Expression::MemberAccess(member_expr) = call_expr.callee.as_ref() {\n                assert_eq!(member_expr.member, \"process\");\n\n                // Object should be obj.get_inner()\n                if let Expression::Call(inner_call) = member_expr.object.as_ref() {\n                    assert_eq!(inner_call.arguments.len(), 0);\n                } else {\n                    panic!(\"Expected inner function call\");\n                }\n            } else {\n                panic!(\"Expected member access for process\");\n            }\n        } else {\n            panic!(\"Expected function call in index expression\");\n        }\n    } else {\n        panic!(\"Expected index expression\");\n    }\n}\n\n// Test 4: Complex Array Literal with Expressions\n#[test]\nfn test_array_with_complex_expressions() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::LeftBracket,\n        TokenType::IntegerLiteral(1),\n        TokenType::Plus,\n        TokenType::IntegerLiteral(2),\n        TokenType::Comma,\n        TokenType::Identifier(\"func\".to_string()),\n        TokenType::LeftParen,\n        TokenType::IntegerLiteral(3),\n        TokenType::Star,\n        TokenType::IntegerLiteral(4),\n        TokenType::RightParen,\n        TokenType::Comma,\n        TokenType::Bang,\n        TokenType::BooleanLiteral(false),\n        TokenType::RightBracket,\n        TokenType::Eof,\n    ]);\n\n    let mut pratt_parser = PrattParser::new(\u0026arena, tokens);\n    let result = pratt_parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    // Should parse as: [1 + 2, func(3 * 4), !false]\n    if let Ok(Expression::Array(array)) = result {\n        assert_eq!(array.elements.len(), 3);\n\n        // First element: 1 + 2\n        if let Expression::Binary(binary) = \u0026array.elements[0] {\n            assert!(matches!(binary.operator, BinaryOperator::Add));\n        } else {\n            panic!(\"Expected binary expression in array\");\n        }\n\n        // Second element: func(3 * 4)\n        if let Expression::Call(call) = \u0026array.elements[1] {\n            assert_eq!(call.arguments.len(), 1);\n            if let Expression::Binary(arg_binary) = \u0026call.arguments[0] {\n                assert!(matches!(arg_binary.operator, BinaryOperator::Mul));\n            } else {\n                panic!(\"Expected multiplication in function argument\");\n            }\n        } else {\n            panic!(\"Expected function call in array\");\n        }\n\n        // Third element: !false\n        if let Expression::Unary(unary) = \u0026array.elements[2] {\n            assert!(matches!(unary.operator, UnaryOperator::Not));\n        } else {\n            panic!(\"Expected unary expression in array\");\n        }\n    } else {\n        panic!(\"Expected array literal\");\n    }\n}\n\n// Test 5: Statement Integration with Complex Expressions\n#[test]\nfn test_variable_declaration_with_complex_initializer() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Let,\n        TokenType::Identifier(\"result\".to_string()),\n        TokenType::Equal,\n        TokenType::Identifier(\"calculate\".to_string()),\n        TokenType::LeftParen,\n        TokenType::IntegerLiteral(1),\n        TokenType::Plus,\n        TokenType::IntegerLiteral(2),\n        TokenType::RightParen,\n        TokenType::Star,\n        TokenType::IntegerLiteral(3),\n        TokenType::Eof,\n    ]);\n\n    let mut statement_parser = StatementParser::new(\u0026arena, tokens);\n    let result = statement_parser.parse_statement();\n    assert!(result.is_ok());\n\n    // Should parse as: let result = calculate(1 + 2) * 3;\n    if let Ok(Statement::VariableDecl(var_decl)) = result {\n        assert_eq!(var_decl.name, \"result\");\n        assert!(var_decl.initializer.is_some());\n\n        if let Some(Expression::Binary(binary)) = \u0026var_decl.initializer {\n            assert!(matches!(binary.operator, BinaryOperator::Mul));\n\n            // Left should be calculate(1 + 2)\n            if let Expression::Call(call) = binary.left.as_ref() {\n                assert_eq!(call.arguments.len(), 1);\n                if let Expression::Binary(arg_binary) = \u0026call.arguments[0] {\n                    assert!(matches!(arg_binary.operator, BinaryOperator::Add));\n                } else {\n                    panic!(\"Expected addition in function call\");\n                }\n            } else {\n                panic!(\"Expected function call in variable initializer\");\n            }\n        } else {\n            panic!(\"Expected binary expression in variable initializer\");\n        }\n    } else {\n        panic!(\"Expected variable declaration\");\n    }\n}\n\n// Test 6: Error Handling with Specific Error Types\n#[test]\nfn test_expected_expression_error() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::IntegerLiteral(1),\n        TokenType::Plus,\n        TokenType::RightParen, // Invalid - should be expression\n        TokenType::Eof,\n    ]);\n\n    let mut pratt_parser = PrattParser::new(\u0026arena, tokens);\n    let result = pratt_parser.parse_expression(0);\n    assert!(result.is_err());\n}\n\n// Test 7: Complex Control Flow Statement\n#[test]\nfn test_nested_if_with_complex_conditions() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::If,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Greater,\n        TokenType::IntegerLiteral(0),\n        TokenType::AmpAmp,\n        TokenType::Identifier(\"y\".to_string()),\n        TokenType::Less,\n        TokenType::IntegerLiteral(10),\n        TokenType::LeftBrace,\n        TokenType::Return,\n        TokenType::BooleanLiteral(true),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n\n    let mut statement_parser = StatementParser::new(\u0026arena, tokens);\n    let result = statement_parser.parse_statement();\n    assert!(result.is_ok());\n\n    // Should parse as: if x \u003e 0 \u0026\u0026 y \u003c 10 { return true; }\n    if let Ok(Statement::If(if_stmt)) = result {\n        // Condition should be x \u003e 0 \u0026\u0026 y \u003c 10\n        if let Expression::Binary(and_expr) = \u0026if_stmt.condition {\n            assert!(matches!(and_expr.operator, BinaryOperator::And));\n\n            // Left should be x \u003e 0\n            if let Expression::Binary(left_binary) = and_expr.left.as_ref() {\n                assert!(matches!(left_binary.operator, BinaryOperator::Greater));\n            } else {\n                panic!(\"Expected greater than comparison\");\n            }\n\n            // Right should be y \u003c 10\n            if let Expression::Binary(right_binary) = and_expr.right.as_ref() {\n                assert!(matches!(right_binary.operator, BinaryOperator::Less));\n            } else {\n                panic!(\"Expected less than comparison\");\n            }\n        } else {\n            panic!(\"Expected binary AND expression in if condition\");\n        }\n\n        // Body should have return statement\n        assert_eq!(if_stmt.then_block.statements.len(), 1);\n        if let Statement::Return(_) = \u0026if_stmt.then_block.statements[0] {\n            // Success\n        } else {\n            panic!(\"Expected return statement in if body\");\n        }\n    } else {\n        panic!(\"Expected if statement\");\n    }\n}\n\n// Test 8: Multiple Unary Operators\n#[test]\nfn test_multiple_unary_operators() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Bang,\n        TokenType::Bang,\n        TokenType::BooleanLiteral(true),\n        TokenType::Eof,\n    ]);\n\n    let mut pratt_parser = PrattParser::new(\u0026arena, tokens);\n    let result = pratt_parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    // Should parse as: !!true\n    if let Ok(Expression::Unary(outer_not)) = result {\n        assert!(matches!(outer_not.operator, UnaryOperator::Not));\n\n        if let Expression::Unary(inner_not) = outer_not.operand.as_ref() {\n            assert!(matches!(inner_not.operator, UnaryOperator::Not));\n\n            if let Expression::Literal(Literal::Boolean(true)) = inner_not.operand.as_ref() {\n                // Success\n            } else {\n                panic!(\"Expected boolean literal true\");\n            }\n        } else {\n            panic!(\"Expected inner unary not\");\n        }\n    } else {\n        panic!(\"Expected outer unary not\");\n    }\n}\n\n// Test 9: Chained Assignment Operations\n#[test]\nfn test_chained_member_access_with_indexing() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"matrix\".to_string()),\n        TokenType::LeftBracket,\n        TokenType::IntegerLiteral(0),\n        TokenType::RightBracket,\n        TokenType::LeftBracket,\n        TokenType::IntegerLiteral(1),\n        TokenType::RightBracket,\n        TokenType::Dot,\n        TokenType::Identifier(\"value\".to_string()),\n        TokenType::Eof,\n    ]);\n\n    let mut pratt_parser = PrattParser::new(\u0026arena, tokens);\n    let result = pratt_parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    // Should parse as: matrix[0][1].value\n    if let Ok(Expression::MemberAccess(member)) = result {\n        assert_eq!(member.member, \"value\");\n\n        // Object should be matrix[0][1]\n        if let Expression::Index(outer_index) = member.object.as_ref() {\n            // Object should be matrix[0]\n            if let Expression::Index(inner_index) = outer_index.object.as_ref() {\n                // Object should be matrix\n                if let Expression::Identifier(name) = inner_index.object.as_ref() {\n                    assert_eq!(name, \"matrix\");\n                } else {\n                    panic!(\"Expected matrix identifier\");\n                }\n            } else {\n                panic!(\"Expected inner index expression\");\n            }\n        } else {\n            panic!(\"Expected outer index expression\");\n        }\n    } else {\n        panic!(\"Expected member access expression\");\n    }\n}\n\n// Test 10: Parser State Management\n#[test]\nfn test_parser_sequential_parsing() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Let,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Equal,\n        TokenType::IntegerLiteral(1),\n        TokenType::Let,\n        TokenType::Identifier(\"y\".to_string()),\n        TokenType::Equal,\n        TokenType::IntegerLiteral(2),\n        TokenType::Eof,\n    ]);\n\n    let mut statement_parser = StatementParser::new(\u0026arena, tokens);\n\n    // Parse first statement\n    let result1 = statement_parser.parse_statement();\n    assert!(result1.is_ok());\n\n    if let Ok(Statement::VariableDecl(var_decl)) = result1 {\n        assert_eq!(var_decl.name, \"x\");\n    } else {\n        panic!(\"Expected first variable declaration\");\n    }\n\n    // Parse second statement\n    let result2 = statement_parser.parse_statement();\n    assert!(result2.is_ok());\n\n    if let Ok(Statement::VariableDecl(var_decl)) = result2 {\n        assert_eq!(var_decl.name, \"y\");\n    } else {\n        panic!(\"Expected second variable declaration\");\n    }\n}\n\n// Test 11: Comprehensive Function Declaration\n#[test]\nfn test_comprehensive_function_with_all_features() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Pub,\n        TokenType::Async,\n        TokenType::Fn,\n        TokenType::Identifier(\"advanced_func\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"param1\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"i32\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"param2\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"String\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"bool\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::If,\n        TokenType::Identifier(\"param1\".to_string()),\n        TokenType::Greater,\n        TokenType::IntegerLiteral(0),\n        TokenType::LeftBrace,\n        TokenType::Return,\n        TokenType::BooleanLiteral(true),\n        TokenType::RightBrace,\n        TokenType::Return,\n        TokenType::BooleanLiteral(false),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n\n    let mut statement_parser = StatementParser::new(\u0026arena, tokens);\n    let result = statement_parser.parse_item();\n    assert!(result.is_ok());\n\n    if let Ok(Item::FunctionDecl(func)) = result {\n        assert_eq!(func.name, \"advanced_func\");\n        assert!(func.is_async);\n        assert!(func.modifiers.is_public);\n        assert_eq!(func.parameters.len(), 2);\n        assert!(func.return_type.is_some());\n        assert!(func.body.is_some());\n\n        // Check body has if statement and return\n        if let Some(body) = \u0026func.body {\n            assert_eq!(body.statements.len(), 2);\n\n            if let Statement::If(_) = \u0026body.statements[0] {\n                // Success\n            } else {\n                panic!(\"Expected if statement in function body\");\n            }\n\n            if let Statement::Return(_) = \u0026body.statements[1] {\n                // Success\n            } else {\n                panic!(\"Expected return statement in function body\");\n            }\n        }\n    } else {\n        panic!(\"Expected comprehensive function declaration\");\n    }\n}\n\n// Test 12: Error Recovery Testing\n#[test]\nfn test_basic_error_handling() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Let,\n        TokenType::Equal, // Error: missing identifier\n        TokenType::IntegerLiteral(42),\n        TokenType::Eof,\n    ]);\n\n    let mut statement_parser = StatementParser::new(\u0026arena, tokens);\n    let result = statement_parser.parse_statement();\n    assert!(result.is_err());\n\n    // Verify we get a parse error\n    if let Err(error) = result {\n        // Just verify we get some kind of error\n        assert!(!format!(\"{}\", error).is_empty());\n    }\n}\n\n// Test 13: Large Expression Tree\n#[test]\nfn test_large_expression_tree() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::LeftParen,\n        TokenType::LeftParen,\n        TokenType::IntegerLiteral(1),\n        TokenType::Plus,\n        TokenType::IntegerLiteral(2),\n        TokenType::RightParen,\n        TokenType::Star,\n        TokenType::LeftParen,\n        TokenType::IntegerLiteral(3),\n        TokenType::Plus,\n        TokenType::IntegerLiteral(4),\n        TokenType::RightParen,\n        TokenType::RightParen,\n        TokenType::Plus,\n        TokenType::LeftParen,\n        TokenType::IntegerLiteral(5),\n        TokenType::Star,\n        TokenType::IntegerLiteral(6),\n        TokenType::RightParen,\n        TokenType::Eof,\n    ]);\n\n    let mut pratt_parser = PrattParser::new(\u0026arena, tokens);\n    let result = pratt_parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    // Should parse as: ((1 + 2) * (3 + 4)) + (5 * 6)\n    if let Ok(Expression::Binary(outer_add)) = result {\n        assert!(matches!(outer_add.operator, BinaryOperator::Add));\n\n        // Left should be ((1 + 2) * (3 + 4))\n        if let Expression::Grouped(left_grouped) = outer_add.left.as_ref() {\n            if let Expression::Binary(left_mul) = left_grouped.as_ref() {\n                assert!(matches!(left_mul.operator, BinaryOperator::Mul));\n            } else {\n                panic!(\"Expected multiplication in left grouped expression\");\n            }\n        } else {\n            panic!(\"Expected grouped expression on left\");\n        }\n\n        // Right should be (5 * 6)\n        if let Expression::Grouped(right_grouped) = outer_add.right.as_ref() {\n            if let Expression::Binary(right_mul) = right_grouped.as_ref() {\n                assert!(matches!(right_mul.operator, BinaryOperator::Mul));\n            } else {\n                panic!(\"Expected multiplication in right grouped expression\");\n            }\n        } else {\n            panic!(\"Expected grouped expression on right\");\n        }\n    } else {\n        panic!(\"Expected large binary expression tree\");\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","tests","test_blocks.rs"],"content":"//! Integration tests for block parsing\n\nuse ferra_parser::{\n    ast::Arena,\n    error::ParseError,\n    token::{Span, TokenStream, TokenType, VecTokenStream},\n    Parser,\n};\n\n#[test]\nfn test_block_style_detection() {\n    // Test brace-style block detection\n    let brace_tokens = vec![\n        TokenType::LeftBrace,\n        TokenType::IntegerLiteral(42),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(brace_tokens);\n    let _parser = Parser::new(\u0026arena, stream);\n\n    // Test that we can create a parser for brace-style blocks\n}\n\n#[test]\nfn test_indentation_error_detection() {\n    let span = Span::dummy();\n\n    // Test inconsistent indentation error\n    let error = ParseError::inconsistent_indentation(span, 4, 2);\n\n    match error {\n        ParseError::InconsistentIndentation {\n            expected_level: 4,\n            found_level: 2,\n            ..\n        } =\u003e {\n            // Successfully created the error type\n        }\n        _ =\u003e panic!(\"Expected inconsistent indentation error\"),\n    }\n}\n\n#[test]\nfn test_mixed_block_styles_error() {\n    let span = Span::dummy();\n\n    // Test mixed block styles error\n    let error = ParseError::mixed_block_styles(span);\n\n    match error {\n        ParseError::MixedBlockStyles { .. } =\u003e {\n            // Successfully created the error type\n        }\n        _ =\u003e panic!(\"Expected mixed block styles error\"),\n    }\n}\n\n#[test]\nfn test_indented_block_tokens() {\n    let tokens = vec![\n        TokenType::Colon,\n        TokenType::Newline,\n        TokenType::Indent,\n        TokenType::IntegerLiteral(42),\n        TokenType::Newline,\n        TokenType::Dedent,\n        TokenType::Eof,\n    ];\n\n    let stream = VecTokenStream::from_token_types(tokens);\n    assert!(!stream.is_at_end());\n\n    // Verify token sequence for indented blocks - stream is not empty\n}\n\n#[test]\nfn test_nested_block_structure() {\n    let tokens = vec![\n        TokenType::LeftBrace,\n        TokenType::If,\n        TokenType::BooleanLiteral(true),\n        TokenType::LeftBrace,\n        TokenType::IntegerLiteral(1),\n        TokenType::RightBrace,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let _parser = Parser::new(\u0026arena, stream);\n\n    // Test that we can create a parser for nested braced blocks\n}\n\n#[test]\nfn test_parser_basic_functionality() {\n    let tokens = vec![TokenType::LeftBrace, TokenType::RightBrace, TokenType::Eof];\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n\n    // Test that we can create a parser\n    let _parser = Parser::new(\u0026arena, stream);\n\n    // Verify basic functionality - parser should be created successfully\n}\n\n#[test]\nfn test_brace_blocks() {\n    // Test that the block parser can handle brace-delimited blocks\n    use ferra_parser::block::parser::BlockParser;\n\n    let arena = Arena::new();\n    let _parser = BlockParser::new(\u0026arena);\n\n    // This test just verifies the BlockParser exists and can be created\n    // More comprehensive tests are in test_phase_2_4_blocks.rs\n}\n\n#[test]\nfn test_indented_blocks() {\n    // Test that the block parser can handle indentation-based blocks\n    use ferra_parser::block::parser::BlockParser;\n\n    let arena = Arena::new();\n    let _parser = BlockParser::new(\u0026arena);\n\n    // This test just verifies the BlockParser exists and can be created\n    // More comprehensive tests are in test_phase_2_4_blocks.rs\n}\n\n#[test]\nfn test_mixed_block_styles() {\n    // Test that mixed block style detection is available\n    use ferra_parser::error::ParseError;\n\n    let span = Span::dummy();\n    let error = ParseError::mixed_block_styles(span);\n\n    // Verify the error type exists\n    assert!(matches!(error, ParseError::MixedBlockStyles { .. }));\n}\n\n#[test]\nfn test_nested_blocks() {\n    // Test that nested block parsing capability exists\n    use ferra_parser::block::parser::BlockParser;\n\n    let arena = Arena::new();\n    let _parser = BlockParser::new(\u0026arena);\n\n    // This test just verifies the BlockParser exists and can be created\n    // More comprehensive tests are in test_phase_2_4_blocks.rs\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","tests","test_expressions.rs"],"content":"//! Integration tests for expression parsing using the Pratt parser\n\nuse ferra_parser::{\n    ast::{Arena, BinaryOperator, Expression, Literal, Pattern, UnaryOperator},\n    pratt::parser::PrattParser,\n    token::{TokenType, VecTokenStream},\n};\n\n#[test]\nfn test_basic_literal_parsing() {\n    let arena = Arena::new();\n    let tokens =\n        VecTokenStream::from_token_types(vec![TokenType::IntegerLiteral(42), TokenType::Eof]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Literal(Literal::Integer(value)) =\u003e {\n                assert_eq!(*value, 42);\n            }\n            _ =\u003e panic!(\"Expected integer literal, got {:?}\", expr),\n        }\n    }\n}\n\n#[test]\nfn test_string_literal_parsing() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::StringLiteral(\"hello\".to_string()),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Literal(Literal::String(value)) =\u003e {\n                assert_eq!(value, \"hello\");\n            }\n            _ =\u003e panic!(\"Expected string literal, got {:?}\", expr),\n        }\n    }\n}\n\n#[test]\nfn test_identifier_parsing() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"variable\".to_string()),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Identifier(name) =\u003e {\n                assert_eq!(name, \"variable\");\n            }\n            _ =\u003e panic!(\"Expected identifier, got {:?}\", expr),\n        }\n    }\n}\n\n#[test]\nfn test_simple_binary_expression() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::IntegerLiteral(1),\n        TokenType::Plus,\n        TokenType::IntegerLiteral(2),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Binary(binary) =\u003e {\n                assert!(matches!(binary.operator, BinaryOperator::Add));\n\n                // Check left operand\n                match binary.left.as_ref() {\n                    Expression::Literal(Literal::Integer(value)) =\u003e assert_eq!(*value, 1),\n                    _ =\u003e panic!(\"Expected left operand to be integer 1\"),\n                }\n\n                // Check right operand\n                match binary.right.as_ref() {\n                    Expression::Literal(Literal::Integer(value)) =\u003e assert_eq!(*value, 2),\n                    _ =\u003e panic!(\"Expected right operand to be integer 2\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected binary expression, got {:?}\", expr),\n        }\n    }\n}\n\n#[test]\nfn test_unary_expression() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Minus,\n        TokenType::IntegerLiteral(42),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Unary(unary) =\u003e {\n                assert!(matches!(unary.operator, UnaryOperator::Minus));\n\n                // Check operand\n                match unary.operand.as_ref() {\n                    Expression::Literal(Literal::Integer(value)) =\u003e assert_eq!(*value, 42),\n                    _ =\u003e panic!(\"Expected operand to be integer 42\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected unary expression, got {:?}\", expr),\n        }\n    }\n}\n\n#[test]\nfn test_grouped_expression() {\n    let arena = Arena::new();\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::LeftParen,\n        TokenType::IntegerLiteral(42),\n        TokenType::RightParen,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Grouped(inner) =\u003e match inner.as_ref() {\n                Expression::Literal(Literal::Integer(value)) =\u003e assert_eq!(*value, 42),\n                _ =\u003e panic!(\"Expected grouped expression to contain integer 42\"),\n            },\n            _ =\u003e panic!(\"Expected grouped expression, got {:?}\", expr),\n        }\n    }\n}\n\n#[test]\nfn test_precedence_parsing() {\n    let arena = Arena::new();\n\n    // Test: 1 + 2 * 3 should parse as 1 + (2 * 3)\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::IntegerLiteral(1),\n        TokenType::Plus,\n        TokenType::IntegerLiteral(2),\n        TokenType::Star,\n        TokenType::IntegerLiteral(3),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Binary(binary) =\u003e {\n                assert!(matches!(binary.operator, BinaryOperator::Add));\n                // Left should be 1\n                match binary.left.as_ref() {\n                    Expression::Literal(Literal::Integer(1)) =\u003e {}\n                    _ =\u003e panic!(\"Expected left operand to be 1\"),\n                }\n                // Right should be (2 * 3)\n                match binary.right.as_ref() {\n                    Expression::Binary(right_binary) =\u003e {\n                        assert!(matches!(right_binary.operator, BinaryOperator::Mul));\n                        match (right_binary.left.as_ref(), right_binary.right.as_ref()) {\n                            (\n                                Expression::Literal(Literal::Integer(2)),\n                                Expression::Literal(Literal::Integer(3)),\n                            ) =\u003e {}\n                            _ =\u003e panic!(\"Expected right operand to be (2 * 3)\"),\n                        }\n                    }\n                    _ =\u003e panic!(\"Expected right operand to be binary expression\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected binary expression\"),\n        }\n    }\n}\n\n#[test]\nfn test_left_associativity() {\n    let arena = Arena::new();\n\n    // Test: 1 - 2 - 3 should parse as (1 - 2) - 3\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::IntegerLiteral(1),\n        TokenType::Minus,\n        TokenType::IntegerLiteral(2),\n        TokenType::Minus,\n        TokenType::IntegerLiteral(3),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Binary(binary) =\u003e {\n                assert!(matches!(binary.operator, BinaryOperator::Sub));\n                // Left should be (1 - 2)\n                match binary.left.as_ref() {\n                    Expression::Binary(left_binary) =\u003e {\n                        assert!(matches!(left_binary.operator, BinaryOperator::Sub));\n                        match (left_binary.left.as_ref(), left_binary.right.as_ref()) {\n                            (\n                                Expression::Literal(Literal::Integer(1)),\n                                Expression::Literal(Literal::Integer(2)),\n                            ) =\u003e {}\n                            _ =\u003e panic!(\"Expected left operand to be (1 - 2)\"),\n                        }\n                    }\n                    _ =\u003e panic!(\"Expected left operand to be binary expression\"),\n                }\n                // Right should be 3\n                match binary.right.as_ref() {\n                    Expression::Literal(Literal::Integer(3)) =\u003e {}\n                    _ =\u003e panic!(\"Expected right operand to be 3\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected binary expression\"),\n        }\n    }\n}\n\n#[test]\nfn test_comparison_operators() {\n    let arena = Arena::new();\n\n    // Test: a == b\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"a\".to_string()),\n        TokenType::EqualEqual,\n        TokenType::Identifier(\"b\".to_string()),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Binary(binary) =\u003e {\n                assert!(matches!(binary.operator, BinaryOperator::Equal));\n            }\n            _ =\u003e panic!(\"Expected binary expression\"),\n        }\n    }\n}\n\n#[test]\nfn test_logical_operators() {\n    let arena = Arena::new();\n\n    // Test: a \u0026\u0026 b || c\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"a\".to_string()),\n        TokenType::AmpAmp,\n        TokenType::Identifier(\"b\".to_string()),\n        TokenType::PipePipe,\n        TokenType::Identifier(\"c\".to_string()),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Binary(binary) =\u003e {\n                assert!(matches!(binary.operator, BinaryOperator::Or));\n                // Left should be (a \u0026\u0026 b)\n                match binary.left.as_ref() {\n                    Expression::Binary(left_binary) =\u003e {\n                        assert!(matches!(left_binary.operator, BinaryOperator::And));\n                    }\n                    _ =\u003e panic!(\"Expected left operand to be (a \u0026\u0026 b)\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected binary expression\"),\n        }\n    }\n}\n\n#[test]\nfn test_complex_nested_expression() {\n    let arena = Arena::new();\n\n    // Test: (1 + 2) * 3\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::LeftParen,\n        TokenType::IntegerLiteral(1),\n        TokenType::Plus,\n        TokenType::IntegerLiteral(2),\n        TokenType::RightParen,\n        TokenType::Star,\n        TokenType::IntegerLiteral(3),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Binary(binary) =\u003e {\n                assert!(matches!(binary.operator, BinaryOperator::Mul));\n                // Left should be (1 + 2)\n                match binary.left.as_ref() {\n                    Expression::Grouped(grouped) =\u003e match grouped.as_ref() {\n                        Expression::Binary(inner_binary) =\u003e {\n                            assert!(matches!(inner_binary.operator, BinaryOperator::Add));\n                        }\n                        _ =\u003e panic!(\"Expected grouped expression to contain binary expression\"),\n                    },\n                    _ =\u003e panic!(\"Expected left operand to be grouped expression\"),\n                }\n                // Right should be 3\n                match binary.right.as_ref() {\n                    Expression::Literal(Literal::Integer(3)) =\u003e {}\n                    _ =\u003e panic!(\"Expected right operand to be 3\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected binary expression\"),\n        }\n    }\n}\n\n#[test]\nfn test_multiple_unary_operators() {\n    let arena = Arena::new();\n\n    // Test: --42 (double negative)\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Minus,\n        TokenType::Minus,\n        TokenType::IntegerLiteral(42),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Unary(unary) =\u003e {\n                assert!(matches!(unary.operator, UnaryOperator::Minus));\n                // Operand should be another unary expression\n                match unary.operand.as_ref() {\n                    Expression::Unary(inner_unary) =\u003e {\n                        assert!(matches!(inner_unary.operator, UnaryOperator::Minus));\n                        match inner_unary.operand.as_ref() {\n                            Expression::Literal(Literal::Integer(42)) =\u003e {}\n                            _ =\u003e panic!(\"Expected inner operand to be 42\"),\n                        }\n                    }\n                    _ =\u003e panic!(\"Expected operand to be unary expression\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected unary expression\"),\n        }\n    }\n}\n\n#[test]\nfn test_boolean_literals() {\n    let arena = Arena::new();\n\n    // Test true\n    let tokens =\n        VecTokenStream::from_token_types(vec![TokenType::BooleanLiteral(true), TokenType::Eof]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Literal(Literal::Boolean(true)) =\u003e {}\n            _ =\u003e panic!(\"Expected boolean literal true\"),\n        }\n    }\n\n    // Test false\n    let tokens =\n        VecTokenStream::from_token_types(vec![TokenType::BooleanLiteral(false), TokenType::Eof]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Literal(Literal::Boolean(false)) =\u003e {}\n            _ =\u003e panic!(\"Expected boolean literal false\"),\n        }\n    }\n}\n\n#[test]\nfn test_float_literals() {\n    let arena = Arena::new();\n\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::FloatLiteral(std::f64::consts::PI),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n\n    assert!(result.is_ok());\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Literal(Literal::Float(value)) =\u003e {\n                // Use an appropriate tolerance for floating point comparison\n                assert!((*value - std::f64::consts::PI).abs() \u003c f64::EPSILON);\n            }\n            _ =\u003e panic!(\"Expected float literal\"),\n        }\n    }\n}\n\n// Tests for Phase 2.2.2 - Advanced Primary Expressions\n\n#[test]\nfn test_qualified_identifier() {\n    let arena = Arena::new();\n\n    // Test: module.function\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"module\".to_string()),\n        TokenType::Dot,\n        TokenType::Identifier(\"function\".to_string()),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::MemberAccess(member_access) =\u003e {\n                assert_eq!(member_access.member, \"function\");\n                match member_access.object.as_ref() {\n                    Expression::Identifier(name) =\u003e assert_eq!(name, \"module\"),\n                    _ =\u003e panic!(\"Expected object to be identifier 'module'\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected member access, got {:?}\", expr),\n        }\n    }\n}\n\n#[test]\nfn test_deeply_qualified_identifier() {\n    let arena = Arena::new();\n\n    // Test: std.collections.HashMap\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"std\".to_string()),\n        TokenType::Dot,\n        TokenType::Identifier(\"collections\".to_string()),\n        TokenType::Dot,\n        TokenType::Identifier(\"HashMap\".to_string()),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::MemberAccess(outer_access) =\u003e {\n                assert_eq!(outer_access.member, \"HashMap\");\n                match outer_access.object.as_ref() {\n                    Expression::MemberAccess(inner_access) =\u003e {\n                        assert_eq!(inner_access.member, \"collections\");\n                        match inner_access.object.as_ref() {\n                            Expression::Identifier(name) =\u003e assert_eq!(name, \"std\"),\n                            _ =\u003e panic!(\"Expected base object to be 'std'\"),\n                        }\n                    }\n                    _ =\u003e panic!(\"Expected inner object to be member access\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected member access, got {:?}\", expr),\n        }\n    }\n}\n\n#[test]\nfn test_array_literals() {\n    let arena = Arena::new();\n\n    // Test empty array: []\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::LeftBracket,\n        TokenType::RightBracket,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Array(array) =\u003e {\n                assert_eq!(array.elements.len(), 0);\n            }\n            _ =\u003e panic!(\"Expected array literal, got {:?}\", expr),\n        }\n    }\n\n    // Test array with elements: [1, 2, 3]\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::LeftBracket,\n        TokenType::IntegerLiteral(1),\n        TokenType::Comma,\n        TokenType::IntegerLiteral(2),\n        TokenType::Comma,\n        TokenType::IntegerLiteral(3),\n        TokenType::RightBracket,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Array(array) =\u003e {\n                assert_eq!(array.elements.len(), 3);\n                // Verify first element is 1\n                match \u0026array.elements[0] {\n                    Expression::Literal(Literal::Integer(1)) =\u003e {}\n                    _ =\u003e panic!(\"Expected first element to be integer 1\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected array literal, got {:?}\", expr),\n        }\n    }\n}\n\n#[test]\nfn test_array_with_trailing_comma() {\n    let arena = Arena::new();\n\n    // Test: [1, 2,]\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::LeftBracket,\n        TokenType::IntegerLiteral(1),\n        TokenType::Comma,\n        TokenType::IntegerLiteral(2),\n        TokenType::Comma,\n        TokenType::RightBracket,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Array(array) =\u003e {\n                assert_eq!(array.elements.len(), 2);\n            }\n            _ =\u003e panic!(\"Expected array literal, got {:?}\", expr),\n        }\n    }\n}\n\n// Tests for Phase 2.2.3 - Postfix Operators\n\n#[test]\nfn test_function_calls() {\n    let arena = Arena::new();\n\n    // Test: func()\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"func\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Call(call) =\u003e {\n                assert_eq!(call.arguments.len(), 0);\n                match call.callee.as_ref() {\n                    Expression::Identifier(name) =\u003e assert_eq!(name, \"func\"),\n                    _ =\u003e panic!(\"Expected callee to be identifier 'func'\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected function call, got {:?}\", expr),\n        }\n    }\n\n    // Test: func(1, 2)\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"func\".to_string()),\n        TokenType::LeftParen,\n        TokenType::IntegerLiteral(1),\n        TokenType::Comma,\n        TokenType::IntegerLiteral(2),\n        TokenType::RightParen,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Call(call) =\u003e {\n                assert_eq!(call.arguments.len(), 2);\n                match \u0026call.arguments[0] {\n                    Expression::Literal(Literal::Integer(1)) =\u003e {}\n                    _ =\u003e panic!(\"Expected first argument to be integer 1\"),\n                }\n                match \u0026call.arguments[1] {\n                    Expression::Literal(Literal::Integer(2)) =\u003e {}\n                    _ =\u003e panic!(\"Expected second argument to be integer 2\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected function call, got {:?}\", expr),\n        }\n    }\n}\n\n#[test]\nfn test_member_access() {\n    let arena = Arena::new();\n\n    // Test: obj.field\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"obj\".to_string()),\n        TokenType::Dot,\n        TokenType::Identifier(\"field\".to_string()),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::MemberAccess(member_access) =\u003e {\n                assert_eq!(member_access.member, \"field\");\n                match member_access.object.as_ref() {\n                    Expression::Identifier(name) =\u003e assert_eq!(name, \"obj\"),\n                    _ =\u003e panic!(\"Expected object to be identifier 'obj'\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected member access, got {:?}\", expr),\n        }\n    }\n}\n\n#[test]\nfn test_index_expressions() {\n    let arena = Arena::new();\n\n    // Test: arr[0]\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"arr\".to_string()),\n        TokenType::LeftBracket,\n        TokenType::IntegerLiteral(0),\n        TokenType::RightBracket,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Index(index) =\u003e {\n                match index.object.as_ref() {\n                    Expression::Identifier(name) =\u003e assert_eq!(name, \"arr\"),\n                    _ =\u003e panic!(\"Expected object to be identifier 'arr'\"),\n                }\n                match index.index.as_ref() {\n                    Expression::Literal(Literal::Integer(0)) =\u003e {}\n                    _ =\u003e panic!(\"Expected index to be integer 0\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected index expression, got {:?}\", expr),\n        }\n    }\n}\n\n#[test]\nfn test_chained_postfix_operations() {\n    let arena = Arena::new();\n\n    // Test: obj.method()[0]\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"obj\".to_string()),\n        TokenType::Dot,\n        TokenType::Identifier(\"method\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBracket,\n        TokenType::IntegerLiteral(0),\n        TokenType::RightBracket,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expr) = result {\n        match expr {\n            Expression::Index(index) =\u003e {\n                // The object should be a function call\n                match index.object.as_ref() {\n                    Expression::Call(call) =\u003e {\n                        // The callee should be member access\n                        match call.callee.as_ref() {\n                            Expression::MemberAccess(member_access) =\u003e {\n                                assert_eq!(member_access.member, \"method\");\n                                match member_access.object.as_ref() {\n                                    Expression::Identifier(name) =\u003e assert_eq!(name, \"obj\"),\n                                    _ =\u003e panic!(\"Expected base object to be 'obj'\"),\n                                }\n                            }\n                            _ =\u003e panic!(\"Expected callee to be member access\"),\n                        }\n                    }\n                    _ =\u003e panic!(\"Expected object to be function call\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected index expression, got {:?}\", expr),\n        }\n    }\n}\n\n// Tests for Phase 2.2.4 - Pattern Parsing\n\n#[test]\nfn test_literal_patterns() {\n    let arena = Arena::new();\n\n    // Test integer literal pattern\n    let tokens =\n        VecTokenStream::from_token_types(vec![TokenType::IntegerLiteral(42), TokenType::Eof]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::Literal(Literal::Integer(42)) =\u003e {}\n            _ =\u003e panic!(\"Expected integer literal pattern 42, got {:?}\", pattern),\n        }\n    }\n\n    // Test string literal pattern\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::StringLiteral(\"hello\".to_string()),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::Literal(Literal::String(s)) =\u003e assert_eq!(s, \"hello\"),\n            _ =\u003e panic!(\"Expected string literal pattern, got {:?}\", pattern),\n        }\n    }\n}\n\n#[test]\nfn test_identifier_patterns() {\n    let arena = Arena::new();\n\n    // Test simple identifier pattern\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::Identifier(name) =\u003e assert_eq!(name, \"x\"),\n            _ =\u003e panic!(\"Expected identifier pattern, got {:?}\", pattern),\n        }\n    }\n}\n\n#[test]\nfn test_wildcard_pattern() {\n    let arena = Arena::new();\n\n    // Test wildcard pattern\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"_\".to_string()),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::Wildcard =\u003e {}\n            _ =\u003e panic!(\"Expected wildcard pattern, got {:?}\", pattern),\n        }\n    }\n}\n\n#[test]\nfn test_data_class_patterns() {\n    let arena = Arena::new();\n\n    // Test empty data class pattern: Person {}\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"Person\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::DataClass(data_class) =\u003e {\n                assert_eq!(data_class.name, \"Person\");\n                assert_eq!(data_class.fields.len(), 0);\n                assert!(!data_class.has_rest);\n            }\n            _ =\u003e panic!(\"Expected data class pattern, got {:?}\", pattern),\n        }\n    }\n\n    // Test data class pattern with fields: Person { name, age }\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"Person\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"name\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"age\".to_string()),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::DataClass(data_class) =\u003e {\n                assert_eq!(data_class.name, \"Person\");\n                assert_eq!(data_class.fields.len(), 2);\n                assert_eq!(data_class.fields[0].name, \"name\");\n                assert!(data_class.fields[0].pattern.is_none());\n                assert_eq!(data_class.fields[1].name, \"age\");\n                assert!(data_class.fields[1].pattern.is_none());\n            }\n            _ =\u003e panic!(\"Expected data class pattern, got {:?}\", pattern),\n        }\n    }\n}\n\n#[test]\nfn test_data_class_pattern_with_bindings() {\n    let arena = Arena::new();\n\n    // Test: Person { name: n, age: 25 }\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"Person\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"name\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"n\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"age\".to_string()),\n        TokenType::Colon,\n        TokenType::IntegerLiteral(25),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::DataClass(data_class) =\u003e {\n                assert_eq!(data_class.name, \"Person\");\n                assert_eq!(data_class.fields.len(), 2);\n\n                // Check first field: name: n\n                assert_eq!(data_class.fields[0].name, \"name\");\n                assert!(data_class.fields[0].pattern.is_some());\n                match \u0026data_class.fields[0].pattern {\n                    Some(Pattern::Identifier(name)) =\u003e assert_eq!(name, \"n\"),\n                    _ =\u003e panic!(\"Expected identifier pattern for name field\"),\n                }\n\n                // Check second field: age: 25\n                assert_eq!(data_class.fields[1].name, \"age\");\n                assert!(data_class.fields[1].pattern.is_some());\n                match \u0026data_class.fields[1].pattern {\n                    Some(Pattern::Literal(Literal::Integer(25))) =\u003e {}\n                    _ =\u003e panic!(\"Expected integer literal pattern for age field\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected data class pattern, got {:?}\", pattern),\n        }\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","tests","test_full_programs.rs"],"content":"//! Integration tests for full program parsing\n\nuse ferra_parser::{\n    ast::{Arena, CompilationUnit},\n    token::{Span, TokenType, VecTokenStream},\n    Parser, ProgramParser,\n};\n\n#[test]\nfn test_compilation_unit_creation() {\n    let span = Span::dummy();\n\n    // Test creating a compilation unit\n    let compilation_unit = CompilationUnit {\n        items: vec![],\n        span,\n    };\n\n    assert_eq!(compilation_unit.items.len(), 0);\n}\n\n#[test]\nfn test_simple_program_tokens() {\n    let tokens = vec![\n        TokenType::Fn,\n        TokenType::Identifier(\"main\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::Return,\n        TokenType::IntegerLiteral(0),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let _parser = Parser::new(\u0026arena, stream);\n\n    // Test that we can create a parser for simple program tokens\n}\n\n#[test]\nfn test_program_with_data_class_tokens() {\n    let tokens = vec![\n        TokenType::Data,\n        TokenType::Identifier(\"Point\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"y\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let _parser = Parser::new(\u0026arena, stream);\n\n    // Test that we can create a parser for data class tokens\n}\n\n#[test]\nfn test_extern_block_tokens() {\n    let tokens = vec![\n        TokenType::Extern,\n        TokenType::StringLiteral(\"C\".to_string()), // Need ABI string for extern blocks\n        TokenType::LeftBrace,\n        TokenType::Fn,\n        TokenType::Identifier(\"printf\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"format\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"char\".to_string()), // Simplified - should be *const char\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let _parser = Parser::new(\u0026arena, stream);\n\n    // Test that we can create a parser for extern block tokens\n}\n\n// Phase 2.6: Integration Testing - Full program parsing tests\n#[test]\nfn test_simple_program() {\n    // Test parsing of simple complete programs like: fn main() { return 0; }\n    let tokens = vec![\n        TokenType::Fn,\n        TokenType::Identifier(\"main\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::Return,\n        TokenType::IntegerLiteral(0),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let mut parser = ProgramParser::new(\u0026arena, stream);\n\n    let result = parser.parse_compilation_unit();\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse simple program: {:?}\",\n        result.err()\n    );\n    let unit = result.unwrap();\n    assert_eq!(unit.items.len(), 1, \"Expected 1 item in compilation unit\");\n\n    // Verify it's a function declaration\n    match \u0026unit.items[0] {\n        ferra_parser::ast::Item::FunctionDecl(func) =\u003e {\n            assert_eq!(func.name, \"main\");\n            assert_eq!(func.parameters.len(), 0);\n        }\n        _ =\u003e panic!(\"Expected function declaration\"),\n    }\n}\n\n#[test]\nfn test_program_with_functions() {\n    // Test parsing of programs with multiple functions\n    let tokens = vec![\n        // First function: fn add(a: int, b: int) -\u003e int { return a + b; }\n        TokenType::Fn,\n        TokenType::Identifier(\"add\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"a\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"b\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Return,\n        TokenType::Identifier(\"a\".to_string()),\n        TokenType::Plus,\n        TokenType::Identifier(\"b\".to_string()),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        // Second function: fn main() { return 0; }\n        TokenType::Fn,\n        TokenType::Identifier(\"main\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::Return,\n        TokenType::IntegerLiteral(0),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let mut parser = ProgramParser::new(\u0026arena, stream);\n\n    let result = parser.parse_compilation_unit();\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse program with multiple functions: {:?}\",\n        result.err()\n    );\n    let unit = result.unwrap();\n    assert_eq!(unit.items.len(), 2, \"Expected 2 items in compilation unit\");\n\n    // Verify both are function declarations\n    match \u0026unit.items[0] {\n        ferra_parser::ast::Item::FunctionDecl(func) =\u003e {\n            assert_eq!(func.name, \"add\");\n            assert_eq!(func.parameters.len(), 2);\n        }\n        _ =\u003e panic!(\"Expected first item to be function declaration\"),\n    }\n\n    match \u0026unit.items[1] {\n        ferra_parser::ast::Item::FunctionDecl(func) =\u003e {\n            assert_eq!(func.name, \"main\");\n            assert_eq!(func.parameters.len(), 0);\n        }\n        _ =\u003e panic!(\"Expected second item to be function declaration\"),\n    }\n}\n\n#[test]\nfn test_program_with_data_classes() {\n    // Test parsing of programs with data class definitions\n    let tokens = vec![\n        // Data class: data Point { x: int, y: int }\n        TokenType::Data,\n        TokenType::Identifier(\"Point\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"y\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightBrace,\n        // Function using the data class\n        TokenType::Fn,\n        TokenType::Identifier(\"main\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::Return,\n        TokenType::IntegerLiteral(0),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let mut parser = ProgramParser::new(\u0026arena, stream);\n\n    let result = parser.parse_compilation_unit();\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse program with data classes: {:?}\",\n        result.err()\n    );\n    let unit = result.unwrap();\n    assert_eq!(unit.items.len(), 2, \"Expected 2 items in compilation unit\");\n\n    // Verify first is data class, second is function\n    match \u0026unit.items[0] {\n        ferra_parser::ast::Item::DataClassDecl(data) =\u003e {\n            assert_eq!(data.name, \"Point\");\n            assert_eq!(data.fields.len(), 2);\n        }\n        _ =\u003e panic!(\"Expected first item to be data class declaration\"),\n    }\n\n    match \u0026unit.items[1] {\n        ferra_parser::ast::Item::FunctionDecl(func) =\u003e {\n            assert_eq!(func.name, \"main\");\n        }\n        _ =\u003e panic!(\"Expected second item to be function declaration\"),\n    }\n}\n\n#[test]\nfn test_program_with_extern_blocks() {\n    // Test parsing of programs with extern blocks\n    let tokens = vec![\n        // Extern block: extern \"C\" { fn printf(format: char) -\u003e int; }\n        TokenType::Extern,\n        TokenType::StringLiteral(\"C\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Fn,\n        TokenType::Identifier(\"printf\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"format\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"char\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        // Function using extern\n        TokenType::Fn,\n        TokenType::Identifier(\"main\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::Return,\n        TokenType::IntegerLiteral(0),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let mut parser = ProgramParser::new(\u0026arena, stream);\n\n    let result = parser.parse_compilation_unit();\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse program with extern blocks: {:?}\",\n        result.err()\n    );\n    let unit = result.unwrap();\n    assert_eq!(unit.items.len(), 2, \"Expected 2 items in compilation unit\");\n\n    // Verify first is extern block, second is function\n    match \u0026unit.items[0] {\n        ferra_parser::ast::Item::ExternBlock(extern_block) =\u003e {\n            assert_eq!(extern_block.abi, \"C\");\n            assert_eq!(extern_block.items.len(), 1);\n        }\n        _ =\u003e panic!(\"Expected first item to be extern block\"),\n    }\n\n    match \u0026unit.items[1] {\n        ferra_parser::ast::Item::FunctionDecl(func) =\u003e {\n            assert_eq!(func.name, \"main\");\n        }\n        _ =\u003e panic!(\"Expected second item to be function declaration\"),\n    }\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","tests","test_phase_2_4_blocks.rs"],"content":"//! Phase 2.4: Block and Scope Parsing Tests\n//!\n//! Comprehensive test suite for advanced block parsing features\n\nuse ferra_parser::{\n    ast::{Arena, BinaryOperator, Expression, Statement, UnaryOperator},\n    block::parser::{BlockParser, BlockStyle, ScopeInfo},\n    error::ParseError,\n    token::{Span, Token, TokenType, VecTokenStream},\n};\n\nfn create_test_span() -\u003e Span {\n    Span::new(0, 10, 1, 1)\n}\n\n/// Test basic braced block parsing\n#[test]\nfn test_simple_braced_block() {\n    let arena = Arena::new();\n    let tokens = vec![\n        Token::new(TokenType::LeftBrace, create_test_span()),\n        Token::new(TokenType::Let, create_test_span()),\n        Token::new(TokenType::Identifier(\"x\".to_string()), create_test_span()),\n        Token::new(TokenType::Equal, create_test_span()),\n        Token::new(TokenType::IntegerLiteral(42), create_test_span()),\n        Token::new(TokenType::Semicolon, create_test_span()),\n        Token::new(TokenType::RightBrace, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n\n    let mut stream = VecTokenStream::new(tokens);\n    let mut parser = BlockParser::new(\u0026arena);\n\n    let result = parser.parse_braced_block(\u0026mut stream);\n    match \u0026result {\n        Ok(block) =\u003e {\n            println!(\"Success! Block has {} statements\", block.statements.len());\n        }\n        Err(error) =\u003e {\n            println!(\"Error: {:?}\", error);\n        }\n    }\n    assert!(result.is_ok());\n\n    let block = result.unwrap();\n    assert!(block.is_braced);\n    assert_eq!(block.scope_depth, 0);\n    assert!(!block.is_unsafe);\n    assert!(!block.is_async);\n    assert!(!block.is_try);\n    assert_eq!(block.statements.len(), 1);\n}\n\n/// Test indented block parsing\n#[test]\nfn test_simple_indented_block() {\n    let arena = Arena::new();\n    let tokens = vec![\n        Token::new(TokenType::Colon, create_test_span()),\n        Token::new(TokenType::Newline, create_test_span()),\n        Token::new(TokenType::Let, create_test_span()),\n        Token::new(TokenType::Identifier(\"x\".to_string()), create_test_span()),\n        Token::new(TokenType::Equal, create_test_span()),\n        Token::new(TokenType::IntegerLiteral(42), create_test_span()),\n        Token::new(TokenType::Semicolon, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n\n    let mut stream = VecTokenStream::new(tokens);\n    let mut parser = BlockParser::new(\u0026arena);\n\n    let result = parser.parse_indented_block(\u0026mut stream);\n    assert!(result.is_ok());\n\n    let block = result.unwrap();\n    assert!(!block.is_braced);\n    assert_eq!(block.scope_depth, 0);\n    assert_eq!(block.statements.len(), 1);\n}\n\n/// Test mixed block style error detection\n#[test]\nfn test_mixed_block_styles_error() {\n    let arena = Arena::new();\n    let tokens = vec![\n        Token::new(TokenType::LeftBrace, create_test_span()),\n        Token::new(TokenType::Let, create_test_span()),\n        Token::new(TokenType::Identifier(\"x\".to_string()), create_test_span()),\n        Token::new(TokenType::Equal, create_test_span()),\n        Token::new(TokenType::IntegerLiteral(42), create_test_span()),\n        Token::new(TokenType::Semicolon, create_test_span()),\n        Token::new(TokenType::RightBrace, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n\n    let mut stream = VecTokenStream::new(tokens);\n    let mut parser = BlockParser::new(\u0026arena);\n\n    // First parse a braced block to set the style\n    let _first_block = parser.parse_braced_block(\u0026mut stream).unwrap();\n\n    // Now try to parse an indented block - should fail\n    let indented_tokens = vec![\n        Token::new(TokenType::Colon, create_test_span()),\n        Token::new(TokenType::Newline, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n    let mut indented_stream = VecTokenStream::new(indented_tokens);\n\n    let result = parser.parse_indented_block(\u0026mut indented_stream);\n    assert!(result.is_err());\n    assert!(matches!(\n        result.unwrap_err(),\n        ParseError::MixedBlockStyles { .. }\n    ));\n}\n\n/// Test unsafe block parsing\n#[test]\nfn test_unsafe_block() {\n    let arena = Arena::new();\n    let tokens = vec![\n        Token::new(TokenType::Unsafe, create_test_span()),\n        Token::new(TokenType::LeftBrace, create_test_span()),\n        Token::new(TokenType::Let, create_test_span()),\n        Token::new(TokenType::Identifier(\"ptr\".to_string()), create_test_span()),\n        Token::new(TokenType::Equal, create_test_span()),\n        Token::new(TokenType::IntegerLiteral(0), create_test_span()),\n        Token::new(TokenType::Semicolon, create_test_span()),\n        Token::new(TokenType::RightBrace, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n\n    let mut stream = VecTokenStream::new(tokens);\n    let mut parser = BlockParser::new(\u0026arena);\n\n    let result = parser.parse_unsafe_block(\u0026mut stream);\n    assert!(result.is_ok());\n\n    let block = result.unwrap();\n    assert!(block.is_braced);\n    assert!(block.is_unsafe);\n    assert!(!block.is_async);\n    assert!(!block.is_try);\n    assert_eq!(block.statements.len(), 1);\n}\n\n/// Test async block parsing\n#[test]\nfn test_async_block() {\n    let arena = Arena::new();\n    let tokens = vec![\n        Token::new(TokenType::Async, create_test_span()),\n        Token::new(TokenType::LeftBrace, create_test_span()),\n        Token::new(TokenType::Let, create_test_span()),\n        Token::new(\n            TokenType::Identifier(\"result\".to_string()),\n            create_test_span(),\n        ),\n        Token::new(TokenType::Equal, create_test_span()),\n        Token::new(TokenType::IntegerLiteral(42), create_test_span()),\n        Token::new(TokenType::Semicolon, create_test_span()),\n        Token::new(TokenType::RightBrace, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n\n    let mut stream = VecTokenStream::new(tokens);\n    let mut parser = BlockParser::new(\u0026arena);\n\n    let result = parser.parse_async_block(\u0026mut stream);\n    assert!(result.is_ok());\n\n    let block = result.unwrap();\n    assert!(block.is_braced);\n    assert!(!block.is_unsafe);\n    assert!(block.is_async);\n    assert!(!block.is_try);\n    assert_eq!(block.statements.len(), 1);\n}\n\n/// Test labeled block parsing\n#[test]\nfn test_labeled_block() {\n    let arena = Arena::new();\n    let tokens = vec![\n        Token::new(TokenType::LeftBrace, create_test_span()),\n        Token::new(TokenType::Let, create_test_span()),\n        Token::new(TokenType::Identifier(\"x\".to_string()), create_test_span()),\n        Token::new(TokenType::Equal, create_test_span()),\n        Token::new(TokenType::IntegerLiteral(42), create_test_span()),\n        Token::new(TokenType::Semicolon, create_test_span()),\n        Token::new(TokenType::RightBrace, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n\n    let mut stream = VecTokenStream::new(tokens);\n    let mut parser = BlockParser::new(\u0026arena);\n\n    let result = parser.parse_labeled_block(\u0026mut stream, \"outer\".to_string());\n    assert!(result.is_ok());\n\n    let block = result.unwrap();\n    assert!(block.is_braced);\n    assert_eq!(block.label, Some(\"outer\".to_string()));\n    assert_eq!(block.statements.len(), 1);\n}\n\n/// Test nested blocks with scope depth tracking\n#[test]\nfn test_nested_blocks_scope_depth() {\n    let arena = Arena::new();\n    let tokens = vec![\n        Token::new(TokenType::LeftBrace, create_test_span()),\n        Token::new(TokenType::LeftBrace, create_test_span()),\n        Token::new(TokenType::Let, create_test_span()),\n        Token::new(\n            TokenType::Identifier(\"inner\".to_string()),\n            create_test_span(),\n        ),\n        Token::new(TokenType::Equal, create_test_span()),\n        Token::new(TokenType::IntegerLiteral(1), create_test_span()),\n        Token::new(TokenType::Semicolon, create_test_span()),\n        Token::new(TokenType::RightBrace, create_test_span()),\n        Token::new(TokenType::RightBrace, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n\n    let mut stream = VecTokenStream::new(tokens);\n    let mut parser = BlockParser::new(\u0026arena);\n\n    let result = parser.parse_braced_block(\u0026mut stream);\n    assert!(result.is_ok());\n\n    let outer_block = result.unwrap();\n    assert_eq!(outer_block.scope_depth, 0);\n    assert_eq!(outer_block.statements.len(), 1);\n}\n\n/// Test scope validation\n#[test]\nfn test_scope_validation() {\n    let arena = Arena::new();\n    let parser = BlockParser::new(\u0026arena);\n\n    // Test valid scope\n    let valid_scope = ScopeInfo {\n        depth: 1,\n        variables: vec![\"x\".to_string(), \"y\".to_string()],\n        is_unsafe: false,\n        is_async: false,\n        label: None,\n    };\n\n    assert!(parser.validate_scope(\u0026valid_scope).is_ok());\n\n    // Test invalid scope with duplicate variables\n    let invalid_scope = ScopeInfo {\n        depth: 1,\n        variables: vec![\"x\".to_string(), \"y\".to_string(), \"x\".to_string()],\n        is_unsafe: false,\n        is_async: false,\n        label: None,\n    };\n\n    let result = parser.validate_scope(\u0026invalid_scope);\n    assert!(result.is_err());\n    assert!(matches!(\n        result.unwrap_err(),\n        ParseError::VariableRedefinition { .. }\n    ));\n}\n\n/// Test block style consistency\n#[test]\nfn test_block_style_consistency() {\n    assert_eq!(BlockStyle::Braced, BlockStyle::Braced);\n    assert_eq!(BlockStyle::Indented, BlockStyle::Indented);\n    assert_ne!(BlockStyle::Braced, BlockStyle::Indented);\n}\n\n/// Test automatic block style detection\n#[test]\nfn test_automatic_block_detection() {\n    let arena = Arena::new();\n    let mut parser = BlockParser::new(\u0026arena);\n\n    // Test detection of braced block\n    let braced_tokens = vec![\n        Token::new(TokenType::LeftBrace, create_test_span()),\n        Token::new(TokenType::RightBrace, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n    let mut braced_stream = VecTokenStream::new(braced_tokens);\n\n    let result = parser.parse_block(\u0026mut braced_stream);\n    assert!(result.is_ok());\n    assert!(result.unwrap().is_braced);\n\n    // Test detection of indented block\n    let indented_tokens = vec![\n        Token::new(TokenType::Colon, create_test_span()),\n        Token::new(TokenType::Newline, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n    let mut indented_stream = VecTokenStream::new(indented_tokens);\n    let mut new_parser = BlockParser::new(\u0026arena); // Need fresh parser for different style\n\n    let result = new_parser.parse_block(\u0026mut indented_stream);\n    assert!(result.is_ok());\n    assert!(!result.unwrap().is_braced);\n}\n\n/// Test block with complex statements\n#[test]\nfn test_complex_block_parsing() {\n    let arena = Arena::new();\n    let tokens = vec![\n        Token::new(TokenType::LeftBrace, create_test_span()),\n        // Variable declaration\n        Token::new(TokenType::Let, create_test_span()),\n        Token::new(TokenType::Identifier(\"x\".to_string()), create_test_span()),\n        Token::new(TokenType::Equal, create_test_span()),\n        Token::new(TokenType::IntegerLiteral(42), create_test_span()),\n        Token::new(TokenType::Semicolon, create_test_span()),\n        // Expression statement\n        Token::new(TokenType::Identifier(\"y\".to_string()), create_test_span()),\n        Token::new(TokenType::Semicolon, create_test_span()),\n        // Return statement\n        Token::new(TokenType::Return, create_test_span()),\n        Token::new(TokenType::Identifier(\"x\".to_string()), create_test_span()),\n        Token::new(TokenType::Semicolon, create_test_span()),\n        Token::new(TokenType::RightBrace, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n\n    let mut stream = VecTokenStream::new(tokens);\n    let mut parser = BlockParser::new(\u0026arena);\n\n    let result = parser.parse_braced_block(\u0026mut stream);\n    match \u0026result {\n        Ok(block) =\u003e {\n            println!(\"Success! Block has {} statements\", block.statements.len());\n        }\n        Err(error) =\u003e {\n            println!(\"Error: {:?}\", error);\n        }\n    }\n    assert!(result.is_ok());\n\n    let block = result.unwrap();\n    assert_eq!(block.statements.len(), 3); // let, expression, return\n    assert!(block.is_braced);\n}\n\n/// Test error handling for invalid block syntax\n#[test]\nfn test_invalid_block_syntax() {\n    let arena = Arena::new();\n    let tokens = vec![\n        Token::new(TokenType::IntegerLiteral(42), create_test_span()), // Not a block start\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n\n    let mut stream = VecTokenStream::new(tokens);\n    let mut parser = BlockParser::new(\u0026arena);\n\n    let result = parser.parse_block(\u0026mut stream);\n    assert!(result.is_err());\n    assert!(matches!(\n        result.unwrap_err(),\n        ParseError::ExpectedBlock { .. }\n    ));\n}\n\n/// Test empty blocks\n#[test]\nfn test_empty_blocks() {\n    let arena = Arena::new();\n\n    // Empty braced block\n    let braced_tokens = vec![\n        Token::new(TokenType::LeftBrace, create_test_span()),\n        Token::new(TokenType::RightBrace, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n    let mut braced_stream = VecTokenStream::new(braced_tokens);\n    let mut parser = BlockParser::new(\u0026arena);\n\n    let result = parser.parse_braced_block(\u0026mut braced_stream);\n    assert!(result.is_ok());\n\n    let block = result.unwrap();\n    assert_eq!(block.statements.len(), 0);\n    assert!(block.is_braced);\n\n    // Empty indented block\n    let indented_tokens = vec![\n        Token::new(TokenType::Colon, create_test_span()),\n        Token::new(TokenType::Newline, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n    let mut indented_stream = VecTokenStream::new(indented_tokens);\n    let mut new_parser = BlockParser::new(\u0026arena);\n\n    let result = new_parser.parse_indented_block(\u0026mut indented_stream);\n    assert!(result.is_ok());\n\n    let block = result.unwrap();\n    assert_eq!(block.statements.len(), 0);\n    assert!(!block.is_braced);\n}\n\n/// Test convenience functions\n#[test]\nfn test_convenience_functions() {\n    let arena = Arena::new();\n\n    // Test parse_braced_block convenience function\n    let tokens = vec![\n        Token::new(TokenType::LeftBrace, create_test_span()),\n        Token::new(TokenType::RightBrace, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n    let mut stream = VecTokenStream::new(tokens);\n\n    let result = ferra_parser::block::parser::parse_braced_block(\u0026arena, \u0026mut stream);\n    assert!(result.is_ok());\n\n    // Test parse_indented_block convenience function\n    let indented_tokens = vec![\n        Token::new(TokenType::Colon, create_test_span()),\n        Token::new(TokenType::Newline, create_test_span()),\n        Token::new(TokenType::Eof, create_test_span()),\n    ];\n    let mut indented_stream = VecTokenStream::new(indented_tokens);\n\n    let result = ferra_parser::block::parser::parse_indented_block(\u0026arena, \u0026mut indented_stream);\n    assert!(result.is_ok());\n}\n\n#[test]\nfn test_complex_expressions_in_blocks() {\n    let arena = Arena::new();\n\n    // Test complex binary expressions\n    let mut parser = BlockParser::new(\u0026arena);\n    let mut tokens = VecTokenStream::from_token_types(vec![\n        TokenType::LeftBrace,\n        TokenType::Let,\n        TokenType::Identifier(\"result\".to_string()),\n        TokenType::Equal,\n        TokenType::IntegerLiteral(1),\n        TokenType::Plus,\n        TokenType::IntegerLiteral(2),\n        TokenType::Star,\n        TokenType::IntegerLiteral(3),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n\n    let result = parser.parse_braced_block(\u0026mut tokens);\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse complex binary expression: {:?}\",\n        result.err()\n    );\n    let block = result.unwrap();\n    assert_eq!(block.statements.len(), 1);\n\n    // Verify the complex expression was parsed correctly\n    match \u0026block.statements[0] {\n        Statement::VariableDecl(var_decl) =\u003e {\n            assert_eq!(var_decl.name, \"result\");\n            assert!(var_decl.initializer.is_some());\n            // Should parse as 1 + (2 * 3) due to precedence\n            match var_decl.initializer.as_ref().unwrap() {\n                Expression::Binary(binary) =\u003e {\n                    assert!(matches!(binary.operator, BinaryOperator::Add));\n                }\n                _ =\u003e panic!(\"Expected binary expression\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected variable declaration\"),\n    }\n}\n\n#[test]\nfn test_function_calls_in_blocks() {\n    let arena = Arena::new();\n\n    // Test function call expressions\n    let mut parser = BlockParser::new(\u0026arena);\n    let mut tokens = VecTokenStream::from_token_types(vec![\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"println\".to_string()),\n        TokenType::LeftParen,\n        TokenType::StringLiteral(\"Hello, world!\".to_string()),\n        TokenType::RightParen,\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n\n    let result = parser.parse_braced_block(\u0026mut tokens);\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse function call: {:?}\",\n        result.err()\n    );\n    let block = result.unwrap();\n    assert_eq!(block.statements.len(), 1);\n\n    // Verify the function call was parsed correctly\n    match \u0026block.statements[0] {\n        Statement::Expression(expr) =\u003e match expr {\n            Expression::Call(call) =\u003e {\n                match call.callee.as_ref() {\n                    Expression::Identifier(name) =\u003e assert_eq!(name, \"println\"),\n                    _ =\u003e panic!(\"Expected function name to be identifier\"),\n                }\n                assert_eq!(call.arguments.len(), 1);\n            }\n            _ =\u003e panic!(\"Expected function call expression\"),\n        },\n        _ =\u003e panic!(\"Expected expression statement\"),\n    }\n}\n\n#[test]\nfn test_member_access_in_blocks() {\n    let arena = Arena::new();\n\n    // Test member access expressions\n    let mut parser = BlockParser::new(\u0026arena);\n    let mut tokens = VecTokenStream::from_token_types(vec![\n        TokenType::LeftBrace,\n        TokenType::Let,\n        TokenType::Identifier(\"value\".to_string()),\n        TokenType::Equal,\n        TokenType::Identifier(\"object\".to_string()),\n        TokenType::Dot,\n        TokenType::Identifier(\"property\".to_string()),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n\n    let result = parser.parse_braced_block(\u0026mut tokens);\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse member access: {:?}\",\n        result.err()\n    );\n    let block = result.unwrap();\n    assert_eq!(block.statements.len(), 1);\n\n    // Verify the member access was parsed correctly\n    match \u0026block.statements[0] {\n        Statement::VariableDecl(var_decl) =\u003e {\n            assert_eq!(var_decl.name, \"value\");\n            assert!(var_decl.initializer.is_some());\n            match var_decl.initializer.as_ref().unwrap() {\n                Expression::MemberAccess(access) =\u003e {\n                    match access.object.as_ref() {\n                        Expression::Identifier(name) =\u003e assert_eq!(name, \"object\"),\n                        _ =\u003e panic!(\"Expected object to be identifier\"),\n                    }\n                    assert_eq!(access.member, \"property\");\n                }\n                _ =\u003e panic!(\"Expected member access expression\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected variable declaration\"),\n    }\n}\n\n#[test]\nfn test_array_literals_in_blocks() {\n    let arena = Arena::new();\n\n    // Test array literal expressions\n    let mut parser = BlockParser::new(\u0026arena);\n    let mut tokens = VecTokenStream::from_token_types(vec![\n        TokenType::LeftBrace,\n        TokenType::Let,\n        TokenType::Identifier(\"numbers\".to_string()),\n        TokenType::Equal,\n        TokenType::LeftBracket,\n        TokenType::IntegerLiteral(1),\n        TokenType::Comma,\n        TokenType::IntegerLiteral(2),\n        TokenType::Comma,\n        TokenType::IntegerLiteral(3),\n        TokenType::RightBracket,\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n\n    let result = parser.parse_braced_block(\u0026mut tokens);\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse array literal: {:?}\",\n        result.err()\n    );\n    let block = result.unwrap();\n    assert_eq!(block.statements.len(), 1);\n\n    // Verify the array literal was parsed correctly\n    match \u0026block.statements[0] {\n        Statement::VariableDecl(var_decl) =\u003e {\n            assert_eq!(var_decl.name, \"numbers\");\n            assert!(var_decl.initializer.is_some());\n            match var_decl.initializer.as_ref().unwrap() {\n                Expression::Array(array) =\u003e {\n                    assert_eq!(array.elements.len(), 3);\n                }\n                _ =\u003e panic!(\"Expected array literal expression\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected variable declaration\"),\n    }\n}\n\n#[test]\nfn test_complex_nested_expressions_in_blocks() {\n    let arena = Arena::new();\n\n    // Test deeply nested expressions: obj.method(array[index + 1])\n    let mut parser = BlockParser::new(\u0026arena);\n    let mut tokens = VecTokenStream::from_token_types(vec![\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"obj\".to_string()),\n        TokenType::Dot,\n        TokenType::Identifier(\"method\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"array\".to_string()),\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"index\".to_string()),\n        TokenType::Plus,\n        TokenType::IntegerLiteral(1),\n        TokenType::RightBracket,\n        TokenType::RightParen,\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n\n    let result = parser.parse_braced_block(\u0026mut tokens);\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse complex nested expression: {:?}\",\n        result.err()\n    );\n    let block = result.unwrap();\n    assert_eq!(block.statements.len(), 1);\n\n    // Verify the complex expression was parsed correctly\n    match \u0026block.statements[0] {\n        Statement::Expression(expr) =\u003e {\n            match expr {\n                Expression::Call(call) =\u003e {\n                    // Should be a member access for obj.method\n                    match call.callee.as_ref() {\n                        Expression::MemberAccess(access) =\u003e {\n                            assert_eq!(access.member, \"method\");\n                        }\n                        _ =\u003e panic!(\"Expected member access for function\"),\n                    }\n                    // Should have one argument: array[index + 1]\n                    assert_eq!(call.arguments.len(), 1);\n                    match \u0026call.arguments[0] {\n                        Expression::Index(index) =\u003e {\n                            match index.object.as_ref() {\n                                Expression::Identifier(name) =\u003e assert_eq!(name, \"array\"),\n                                _ =\u003e panic!(\"Expected array identifier\"),\n                            }\n                            // Index should be a binary expression (index + 1)\n                            match index.index.as_ref() {\n                                Expression::Binary(binary) =\u003e {\n                                    assert!(matches!(binary.operator, BinaryOperator::Add));\n                                }\n                                _ =\u003e panic!(\"Expected binary expression for index\"),\n                            }\n                        }\n                        _ =\u003e panic!(\"Expected index access as argument\"),\n                    }\n                }\n                _ =\u003e panic!(\"Expected function call expression\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected expression statement\"),\n    }\n}\n\n#[test]\nfn test_unary_expressions_in_blocks() {\n    let arena = Arena::new();\n\n    // Test unary expressions\n    let mut parser = BlockParser::new(\u0026arena);\n    let mut tokens = VecTokenStream::from_token_types(vec![\n        TokenType::LeftBrace,\n        TokenType::Let,\n        TokenType::Identifier(\"negated\".to_string()),\n        TokenType::Equal,\n        TokenType::Minus,\n        TokenType::Identifier(\"value\".to_string()),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n\n    let result = parser.parse_braced_block(\u0026mut tokens);\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse unary expression: {:?}\",\n        result.err()\n    );\n    let block = result.unwrap();\n    assert_eq!(block.statements.len(), 1);\n\n    // Verify the unary expression was parsed correctly\n    match \u0026block.statements[0] {\n        Statement::VariableDecl(var_decl) =\u003e {\n            assert_eq!(var_decl.name, \"negated\");\n            assert!(var_decl.initializer.is_some());\n            match var_decl.initializer.as_ref().unwrap() {\n                Expression::Unary(unary) =\u003e {\n                    assert!(matches!(unary.operator, UnaryOperator::Minus));\n                    match unary.operand.as_ref() {\n                        Expression::Identifier(name) =\u003e assert_eq!(name, \"value\"),\n                        _ =\u003e panic!(\"Expected identifier operand\"),\n                    }\n                }\n                _ =\u003e panic!(\"Expected unary expression\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected variable declaration\"),\n    }\n}\n","traces":[{"line":12,"address":[],"length":0,"stats":{"Line":96}},{"line":13,"address":[],"length":0,"stats":{"Line":96}}],"covered":2,"coverable":2},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","tests","test_phase_2_5_error_recovery.rs"],"content":"//! Phase 2.5: Error Recovery and Diagnostics Tests\n//!\n//! This module tests the enhanced error recovery strategies, multi-error reporting,\n//! and improved diagnostics introduced in Phase 2.5.\n\nuse ferra_parser::{\n    error::{parse_error::*, recovery::*},\n    token::{Span, Token, TokenStream, TokenType, VecTokenStream},\n};\n\n#[test]\nfn test_error_production_missing_semicolon() {\n    let production = ErrorProduction::MissingSemicolon;\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Equal,\n        TokenType::IntegerLiteral(42),\n        TokenType::Let, // Should trigger missing semicolon error\n    ]);\n\n    let error = production.applies_to_context(\u0026tokens, \"statement\").unwrap();\n    assert!(error.to_string().contains(\"Expected\"));\n    assert!(error.suggestion().unwrap().contains(\"Try adding ';'\"));\n    assert_eq!(error.severity(), ErrorSeverity::Error);\n}\n\n#[test]\nfn test_error_production_missing_open_paren() {\n    let production = ErrorProduction::MissingOpenParen;\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"func\".to_string()),\n        TokenType::IntegerLiteral(42), // Should be LeftParen\n    ]);\n\n    let error = production\n        .applies_to_context(\u0026tokens, \"function_call\")\n        .unwrap();\n    assert!(error.to_string().contains(\"opening parenthesis\"));\n    assert!(error.suggestion().unwrap().contains(\"parentheses\"));\n}\n\n#[test]\nfn test_error_production_unmatched_delimiter() {\n    let production = ErrorProduction::UnmatchedDelimiter;\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::RightParen, // Unmatched closing paren\n    ]);\n\n    let error = production.applies_to_context(\u0026tokens, \"\").unwrap();\n    assert!(error.to_string().contains(\"matching opening delimiter\"));\n    assert!(error.suggestion().unwrap().contains(\"properly matched\"));\n}\n\n#[test]\nfn test_error_production_incomplete_expression() {\n    let production = ErrorProduction::IncompleteExpression;\n    let tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Plus, // Operator without operand\n    ]);\n\n    let error = production\n        .applies_to_context(\u0026tokens, \"expression\")\n        .unwrap();\n    assert!(error.to_string().contains(\"Expected expression\"));\n    assert!(error\n        .suggestion()\n        .unwrap()\n        .contains(\"literal, identifier, or parenthesized\"));\n}\n\n#[test]\nfn test_sync_token_expression_start() {\n    let sync_token = SyncToken::ExpressionStart;\n\n    // Should match expression starts\n    assert!(sync_token.matches(\u0026Token::dummy(TokenType::Identifier(\"x\".to_string()))));\n    assert!(sync_token.matches(\u0026Token::dummy(TokenType::IntegerLiteral(42))));\n    assert!(sync_token.matches(\u0026Token::dummy(TokenType::LeftParen)));\n    assert!(sync_token.matches(\u0026Token::dummy(TokenType::Minus)));\n\n    // Should not match non-expression starts\n    assert!(!sync_token.matches(\u0026Token::dummy(TokenType::RightParen)));\n    assert!(!sync_token.matches(\u0026Token::dummy(TokenType::Semicolon)));\n}\n\n#[test]\nfn test_sync_token_expression_terminator() {\n    let sync_token = SyncToken::ExpressionTerminator;\n\n    // Should match expression terminators\n    assert!(sync_token.matches(\u0026Token::dummy(TokenType::Semicolon)));\n    assert!(sync_token.matches(\u0026Token::dummy(TokenType::Comma)));\n    assert!(sync_token.matches(\u0026Token::dummy(TokenType::RightParen)));\n    assert!(sync_token.matches(\u0026Token::dummy(TokenType::Eof)));\n\n    // Should not match expression content\n    assert!(!sync_token.matches(\u0026Token::dummy(TokenType::Plus)));\n    assert!(!sync_token.matches(\u0026Token::dummy(TokenType::Identifier(\"x\".to_string()))));\n}\n\n#[test]\nfn test_error_collector_basic() {\n    let mut collector = ErrorCollector::new(3);\n\n    assert!(!collector.has_errors());\n    assert!(collector.should_continue());\n\n    // Add first error\n    collector.add_error(ParseError::syntax_error(\"test error 1\", Span::dummy()));\n    assert!(collector.has_errors());\n    assert!(collector.should_continue());\n    assert_eq!(collector.get_errors().len(), 1);\n\n    // Add second error\n    collector.add_error(ParseError::syntax_error(\"test error 2\", Span::dummy()));\n    assert_eq!(collector.get_errors().len(), 2);\n    assert!(collector.should_continue());\n\n    // Add third error (should reach limit)\n    collector.add_error(ParseError::syntax_error(\"test error 3\", Span::dummy()));\n    assert_eq!(collector.get_errors().len(), 3);\n    assert!(!collector.should_continue());\n}\n\n#[test]\nfn test_error_collector_clear() {\n    let mut collector = ErrorCollector::new(5);\n\n    collector.add_error(ParseError::syntax_error(\"test error\", Span::dummy()));\n    assert!(collector.has_errors());\n\n    collector.clear();\n    assert!(!collector.has_errors());\n    assert!(collector.should_continue());\n}\n\n#[test]\nfn test_panic_mode_recovery_to_statement() {\n    let mut tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Bang, // Error token\n        TokenType::Plus, // Error token\n        TokenType::Star, // Error token\n        TokenType::Let,  // Statement start (sync point)\n        TokenType::Identifier(\"x\".to_string()),\n    ]);\n\n    let sync_token = ErrorRecovery::recover_to_statement(\u0026mut tokens);\n\n    assert!(sync_token.is_some());\n    assert_eq!(sync_token.unwrap().token_type, TokenType::Let);\n    // Should be positioned at the sync token\n    assert_eq!(tokens.peek().token_type, TokenType::Let);\n}\n\n#[test]\nfn test_panic_mode_recovery_to_expression() {\n    let mut tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Equal,              // Error token (not in any sync category)\n        TokenType::Dot,                // Error token (not in any sync category)\n        TokenType::IntegerLiteral(42), // Expression start (sync point)\n        TokenType::Plus,\n    ]);\n\n    let sync_token = ErrorRecovery::recover_to_expression(\u0026mut tokens);\n\n    assert!(sync_token.is_some());\n    let found_token = sync_token.unwrap();\n\n    // The recovery should find the IntegerLiteral as a sync token\n    assert_eq!(found_token.token_type, TokenType::IntegerLiteral(42));\n}\n\n#[test]\nfn test_smart_recovery_with_context() {\n    let mut tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Equal, // Error token (not in any sync category)\n        TokenType::Dot,   // Error token (not in any sync category)\n        TokenType::Let,   // Statement start\n    ]);\n    let mut collector = ErrorCollector::new(10);\n\n    let sync_token = ErrorRecovery::smart_recovery(\u0026mut tokens, \"statement\", \u0026mut collector);\n\n    assert!(sync_token.is_some());\n    let found_token = sync_token.unwrap();\n\n    // The smart recovery should eventually find the Let token\n    // But it might find Equal first if error productions apply\n    assert!(matches!(\n        found_token.token_type,\n        TokenType::Equal | TokenType::Let\n    ));\n}\n\n#[test]\nfn test_recovery_with_productions() {\n    let mut tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Equal,\n        TokenType::IntegerLiteral(42),\n        TokenType::Let, // Missing semicolon before next statement\n    ]);\n    let mut collector = ErrorCollector::new(10);\n\n    let sync_token =\n        ErrorRecovery::recover_with_productions(\u0026mut tokens, \"statement\", \u0026mut collector);\n\n    assert!(sync_token.is_some());\n    assert!(collector.has_errors());\n    // Should have added a missing semicolon error\n    assert!(collector.get_errors()[0].to_string().contains(\"Expected\"));\n}\n\n#[test]\nfn test_error_severity_levels() {\n    let warning =\n        ParseError::syntax_error(\"test\", Span::dummy()).with_severity(ErrorSeverity::Warning);\n    let error = ParseError::syntax_error(\"test\", Span::dummy()).with_severity(ErrorSeverity::Error);\n    let fatal = ParseError::syntax_error(\"test\", Span::dummy()).with_severity(ErrorSeverity::Fatal);\n\n    assert_eq!(warning.severity(), ErrorSeverity::Warning);\n    assert_eq!(error.severity(), ErrorSeverity::Error);\n    assert_eq!(fatal.severity(), ErrorSeverity::Fatal);\n\n    assert!(warning.is_recoverable());\n    assert!(error.is_recoverable());\n    assert!(!fatal.is_recoverable());\n\n    assert!(!warning.should_stop_parsing());\n    assert!(!error.should_stop_parsing());\n    assert!(fatal.should_stop_parsing());\n}\n\n#[test]\nfn test_error_codes() {\n    let error = ParseError::syntax_error(\"test\", Span::dummy());\n    assert_eq!(error.error_code(), Some(\"E001\"));\n\n    let recovery_error = ParseError::recovery_error(\"test\", Span::dummy(), error.clone());\n    assert_eq!(recovery_error.error_code(), Some(\"R001\"));\n\n    let internal_error = ParseError::internal(\"test\", Span::dummy());\n    assert_eq!(internal_error.error_code(), Some(\"I001\"));\n}\n\n#[test]\nfn test_error_with_custom_code() {\n    let error = ParseError::syntax_error(\"test\", Span::dummy()).with_error_code(\"E999\");\n    assert_eq!(error.error_code(), Some(\"E999\"));\n}\n\n#[test]\nfn test_diagnostic_report_basic() {\n    let mut report = DiagnosticReport::new(Some(\"test.ferra\".to_string()));\n\n    assert!(!report.has_errors());\n    assert!(report.should_continue_parsing());\n\n    // Add warning\n    report.add_error(\n        ParseError::syntax_error(\"warning\", Span::dummy()).with_severity(ErrorSeverity::Warning),\n    );\n    assert!(report.has_errors());\n    assert!(report.should_continue_parsing());\n    assert_eq!(report.error_count_by_severity(ErrorSeverity::Warning), 1);\n\n    // Add error\n    report.add_error(\n        ParseError::syntax_error(\"error\", Span::dummy()).with_severity(ErrorSeverity::Error),\n    );\n    assert_eq!(report.error_count_by_severity(ErrorSeverity::Error), 1);\n    assert!(report.should_continue_parsing());\n\n    // Add fatal error\n    report.add_error(\n        ParseError::syntax_error(\"fatal\", Span::dummy()).with_severity(ErrorSeverity::Fatal),\n    );\n    assert_eq!(report.error_count_by_severity(ErrorSeverity::Fatal), 1);\n    assert!(!report.should_continue_parsing());\n}\n\n#[test]\nfn test_diagnostic_report_formatting() {\n    let mut report = DiagnosticReport::new(Some(\"test.ferra\".to_string()));\n\n    report.add_error(ParseError::syntax_error(\"syntax error\", Span::dummy()));\n    report.add_error(\n        ParseError::syntax_error(\"warning\", Span::dummy()).with_severity(ErrorSeverity::Warning),\n    );\n\n    let formatted = report.format_report();\n    assert!(formatted.contains(\"Parse result:\"));\n    assert!(formatted.contains(\"1 errors\"));\n    assert!(formatted.contains(\"1 warnings\"));\n    assert!(formatted.contains(\"test.ferra\"));\n}\n\n#[test]\nfn test_error_diagnostic_formatting() {\n    let error = ParseError::syntax_error_with_suggestion(\n        \"test error\",\n        Span::new(0, 10, 1, 5),\n        \"try this fix\",\n    );\n\n    let formatted = error.format_diagnostic(Some(\"test.ferra\"));\n    assert!(formatted.contains(\"error: [E001]\"));\n    assert!(formatted.contains(\"test.ferra:1:5\"));\n    assert!(formatted.contains(\"help: try this fix\"));\n}\n\n#[test]\nfn test_recovery_error_chaining() {\n    let original = ParseError::syntax_error(\"original error\", Span::dummy());\n    let recovery = ParseError::recovery_error(\"recovery failed\", Span::dummy(), original);\n\n    let formatted = recovery.format_diagnostic(None);\n    assert!(formatted.contains(\"caused by:\"));\n    assert!(formatted.contains(\"original error\"));\n}\n\n#[test]\nfn test_partial_recovery_defaults() {\n    let recovery = PartialRecovery::default();\n\n    assert!(recovery.create_placeholders);\n    assert_eq!(recovery.max_errors, 50);\n    assert!(recovery.attempt_expression_completion);\n}\n\n#[test]\nfn test_multi_error_integration() {\n    // Simulate parsing with multiple errors\n    let mut tokens = VecTokenStream::from_token_types(vec![\n        TokenType::Let,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Plus, // Missing '=' before expression\n        TokenType::IntegerLiteral(42),\n        TokenType::Let, // Missing semicolon\n        TokenType::Identifier(\"y\".to_string()),\n        TokenType::Equal,\n        TokenType::RightParen, // Unmatched closing paren\n        TokenType::IntegerLiteral(24),\n    ]);\n\n    let mut collector = ErrorCollector::new(10);\n\n    // Simulate multiple recovery attempts\n    ErrorRecovery::recover_with_productions(\u0026mut tokens, \"statement\", \u0026mut collector);\n    ErrorRecovery::recover_with_productions(\u0026mut tokens, \"expression\", \u0026mut collector);\n\n    // Should have collected multiple errors\n    assert!(collector.has_errors());\n    assert!(collector.should_continue());\n}\n\n#[test]\nfn test_error_production_suggestions() {\n    assert_eq!(\n        ErrorProduction::MissingSemicolon.get_suggestion(),\n        \"Add ';' at the end of the statement\"\n    );\n    assert_eq!(\n        ErrorProduction::MissingOpenParen.get_suggestion(),\n        \"Add '(' before function arguments\"\n    );\n    assert_eq!(\n        ErrorProduction::UnmatchedDelimiter.get_suggestion(),\n        \"Check that all delimiters are properly matched\"\n    );\n}\n\n#[test]\nfn test_should_continue_recovery() {\n    let tokens = VecTokenStream::from_token_types(vec![TokenType::Let]);\n\n    assert!(ErrorRecovery::should_continue_recovery(\u0026tokens, 5));\n    assert!(!ErrorRecovery::should_continue_recovery(\u0026tokens, 150));\n\n    let empty_tokens = VecTokenStream::from_token_types(vec![]);\n    assert!(!ErrorRecovery::should_continue_recovery(\u0026empty_tokens, 5));\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","tests","test_phase_2_6_integration.rs"],"content":"//! Phase 2.6: Integration Testing\n//!\n//! Comprehensive integration tests that verify the interaction between\n//! all parser components and test complex real-world scenarios.\n\nuse ferra_parser::{\n    ast::{Arena, Item},\n    token::{TokenType, VecTokenStream},\n    ProgramParser,\n};\n\n#[test]\nfn test_complex_program_with_all_features() {\n    // Test a complex program that uses all major language features\n    let tokens = vec![\n        // Data class: data Vector3 { x: float, y: float, z: float }\n        TokenType::Data,\n        TokenType::Identifier(\"Vector3\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"float\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"y\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"float\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"z\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"float\".to_string()),\n        TokenType::RightBrace,\n        // Extern block: extern \"C\" { fn sqrt(x: float) -\u003e float; }\n        TokenType::Extern,\n        TokenType::StringLiteral(\"C\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Fn,\n        TokenType::Identifier(\"sqrt\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"float\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"float\".to_string()),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        // Function: fn magnitude(v: Vector3) -\u003e float { return 0.0; }\n        TokenType::Fn,\n        TokenType::Identifier(\"magnitude\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"v\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"Vector3\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"float\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Return,\n        TokenType::FloatLiteral(0.0),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        // Main function: fn main() -\u003e int { return 0; }\n        TokenType::Fn,\n        TokenType::Identifier(\"main\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Return,\n        TokenType::IntegerLiteral(0),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let mut parser = ProgramParser::new(\u0026arena, stream);\n\n    let result = parser.parse_compilation_unit();\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse complex program: {:?}\",\n        result.err()\n    );\n    let unit = result.unwrap();\n    assert_eq!(unit.items.len(), 4, \"Expected 4 items in compilation unit\");\n\n    // Verify all items are parsed correctly\n    match \u0026unit.items[0] {\n        Item::DataClassDecl(data) =\u003e {\n            assert_eq!(data.name, \"Vector3\");\n            assert_eq!(data.fields.len(), 3);\n        }\n        _ =\u003e panic!(\"Expected first item to be data class\"),\n    }\n\n    match \u0026unit.items[1] {\n        Item::ExternBlock(extern_block) =\u003e {\n            assert_eq!(extern_block.abi, \"C\");\n            assert_eq!(extern_block.items.len(), 1);\n        }\n        _ =\u003e panic!(\"Expected second item to be extern block\"),\n    }\n\n    match \u0026unit.items[2] {\n        Item::FunctionDecl(func) =\u003e {\n            assert_eq!(func.name, \"magnitude\");\n            assert_eq!(func.parameters.len(), 1);\n            assert!(func.return_type.is_some());\n        }\n        _ =\u003e panic!(\"Expected third item to be function\"),\n    }\n\n    match \u0026unit.items[3] {\n        Item::FunctionDecl(func) =\u003e {\n            assert_eq!(func.name, \"main\");\n            assert_eq!(func.parameters.len(), 0);\n        }\n        _ =\u003e panic!(\"Expected fourth item to be function\"),\n    }\n}\n\n#[test]\nfn test_multiple_data_classes() {\n    // Test parsing multiple data classes with different field counts\n    let tokens = vec![\n        // data Point { x: int, y: int }\n        TokenType::Data,\n        TokenType::Identifier(\"Point\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"y\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightBrace,\n        // data Color { r: int, g: int, b: int, a: int }\n        TokenType::Data,\n        TokenType::Identifier(\"Color\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"r\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"g\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"b\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"a\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightBrace,\n        // data Empty { }\n        TokenType::Data,\n        TokenType::Identifier(\"Empty\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let mut parser = ProgramParser::new(\u0026arena, stream);\n\n    let result = parser.parse_compilation_unit();\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse multiple data classes: {:?}\",\n        result.err()\n    );\n    let unit = result.unwrap();\n    assert_eq!(unit.items.len(), 3);\n\n    // Verify field counts\n    match \u0026unit.items[0] {\n        Item::DataClassDecl(data) =\u003e {\n            assert_eq!(data.name, \"Point\");\n            assert_eq!(data.fields.len(), 2);\n        }\n        _ =\u003e panic!(\"Expected data class\"),\n    }\n\n    match \u0026unit.items[1] {\n        Item::DataClassDecl(data) =\u003e {\n            assert_eq!(data.name, \"Color\");\n            assert_eq!(data.fields.len(), 4);\n        }\n        _ =\u003e panic!(\"Expected data class\"),\n    }\n\n    match \u0026unit.items[2] {\n        Item::DataClassDecl(data) =\u003e {\n            assert_eq!(data.name, \"Empty\");\n            assert_eq!(data.fields.len(), 0);\n        }\n        _ =\u003e panic!(\"Expected data class\"),\n    }\n}\n\n#[test]\nfn test_functions_with_different_signatures() {\n    // Test functions with various parameter counts and return types\n    let tokens = vec![\n        // fn no_params() { }\n        TokenType::Fn,\n        TokenType::Identifier(\"no_params\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n        // fn one_param(x: int) -\u003e int { return x; }\n        TokenType::Fn,\n        TokenType::Identifier(\"one_param\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Return,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        // fn three_params(a: int, b: float, c: string) -\u003e bool { return true; }\n        TokenType::Fn,\n        TokenType::Identifier(\"three_params\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"a\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"b\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"float\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"c\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"string\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"bool\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Return,\n        TokenType::BooleanLiteral(true),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let mut parser = ProgramParser::new(\u0026arena, stream);\n\n    let result = parser.parse_compilation_unit();\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse functions with different signatures: {:?}\",\n        result.err()\n    );\n    let unit = result.unwrap();\n    assert_eq!(unit.items.len(), 3);\n\n    // Verify function signatures\n    match \u0026unit.items[0] {\n        Item::FunctionDecl(func) =\u003e {\n            assert_eq!(func.name, \"no_params\");\n            assert_eq!(func.parameters.len(), 0);\n            assert!(func.return_type.is_none());\n        }\n        _ =\u003e panic!(\"Expected function\"),\n    }\n\n    match \u0026unit.items[1] {\n        Item::FunctionDecl(func) =\u003e {\n            assert_eq!(func.name, \"one_param\");\n            assert_eq!(func.parameters.len(), 1);\n            assert!(func.return_type.is_some());\n        }\n        _ =\u003e panic!(\"Expected function\"),\n    }\n\n    match \u0026unit.items[2] {\n        Item::FunctionDecl(func) =\u003e {\n            assert_eq!(func.name, \"three_params\");\n            assert_eq!(func.parameters.len(), 3);\n            assert!(func.return_type.is_some());\n        }\n        _ =\u003e panic!(\"Expected function\"),\n    }\n}\n\n#[test]\nfn test_extern_blocks_with_multiple_items() {\n    // Test extern blocks with multiple functions and variables\n    let tokens = vec![\n        // extern \"C\" { fn malloc(size: int) -\u003e ptr; fn free(ptr: ptr); static errno: int; }\n        TokenType::Extern,\n        TokenType::StringLiteral(\"C\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Fn,\n        TokenType::Identifier(\"malloc\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"size\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"ptr\".to_string()),\n        TokenType::Semicolon,\n        TokenType::Fn,\n        TokenType::Identifier(\"free\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"ptr\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"ptr\".to_string()),\n        TokenType::RightParen,\n        TokenType::Semicolon,\n        TokenType::Static,\n        TokenType::Identifier(\"errno\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let mut parser = ProgramParser::new(\u0026arena, stream);\n\n    let result = parser.parse_compilation_unit();\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse extern block with multiple items: {:?}\",\n        result.err()\n    );\n    let unit = result.unwrap();\n    assert_eq!(unit.items.len(), 1);\n\n    match \u0026unit.items[0] {\n        Item::ExternBlock(extern_block) =\u003e {\n            assert_eq!(extern_block.abi, \"C\");\n            assert_eq!(extern_block.items.len(), 3);\n\n            // Verify extern items\n            match \u0026extern_block.items[0] {\n                ferra_parser::ast::ExternItem::Function(func) =\u003e {\n                    assert_eq!(func.name, \"malloc\");\n                    assert_eq!(func.parameters.len(), 1);\n                    assert!(func.return_type.is_some());\n                }\n                _ =\u003e panic!(\"Expected extern function\"),\n            }\n\n            match \u0026extern_block.items[1] {\n                ferra_parser::ast::ExternItem::Function(func) =\u003e {\n                    assert_eq!(func.name, \"free\");\n                    assert_eq!(func.parameters.len(), 1);\n                    assert!(func.return_type.is_none());\n                }\n                _ =\u003e panic!(\"Expected extern function\"),\n            }\n\n            match \u0026extern_block.items[2] {\n                ferra_parser::ast::ExternItem::Variable(var) =\u003e {\n                    assert_eq!(var.name, \"errno\");\n                }\n                _ =\u003e panic!(\"Expected extern variable\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected extern block\"),\n    }\n}\n\n#[test]\nfn test_mixed_top_level_items() {\n    // Test a program with mixed top-level items in various orders\n    let tokens = vec![\n        // fn first_function() { }\n        TokenType::Fn,\n        TokenType::Identifier(\"first_function\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n        // data MyData { value: int }\n        TokenType::Data,\n        TokenType::Identifier(\"MyData\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"value\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightBrace,\n        // extern \"C\" { fn external_func(); }\n        TokenType::Extern,\n        TokenType::StringLiteral(\"C\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Fn,\n        TokenType::Identifier(\"external_func\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        // fn second_function(data: MyData) -\u003e int { return 42; }\n        TokenType::Fn,\n        TokenType::Identifier(\"second_function\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"data\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"MyData\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Return,\n        TokenType::IntegerLiteral(42),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let mut parser = ProgramParser::new(\u0026arena, stream);\n\n    let result = parser.parse_compilation_unit();\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse mixed top-level items: {:?}\",\n        result.err()\n    );\n    let unit = result.unwrap();\n    assert_eq!(unit.items.len(), 4);\n\n    // Verify order and types\n    assert!(matches!(unit.items[0], Item::FunctionDecl(_)));\n    assert!(matches!(unit.items[1], Item::DataClassDecl(_)));\n    assert!(matches!(unit.items[2], Item::ExternBlock(_)));\n    assert!(matches!(unit.items[3], Item::FunctionDecl(_)));\n}\n\n#[test]\nfn test_error_recovery_in_program_parsing() {\n    // Test that the parser can recover from errors and continue parsing\n    let tokens = vec![\n        // Valid function\n        TokenType::Fn,\n        TokenType::Identifier(\"valid_func\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n        // Invalid token that should cause error\n        TokenType::Plus, // This should cause an error\n        // Another valid function after error\n        TokenType::Fn,\n        TokenType::Identifier(\"another_func\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let mut parser = ProgramParser::new(\u0026arena, stream);\n\n    let result = parser.parse_compilation_unit();\n\n    // Should have errors but still parse some items\n    assert!(result.is_err(), \"Expected parsing errors\");\n    assert!(\n        parser.has_errors(),\n        \"Expected error collection to have errors\"\n    );\n\n    let errors = parser.get_errors();\n    assert!(!errors.is_empty(), \"Expected at least one error\");\n}\n\n#[test]\nfn test_empty_program() {\n    // Test parsing an empty program (just EOF)\n    let tokens = vec![TokenType::Eof];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let mut parser = ProgramParser::new(\u0026arena, stream);\n\n    let result = parser.parse_compilation_unit();\n\n    assert!(\n        result.is_ok(),\n        \"Failed to parse empty program: {:?}\",\n        result.err()\n    );\n    let unit = result.unwrap();\n    assert_eq!(unit.items.len(), 0, \"Expected empty compilation unit\");\n}\n\n#[test]\nfn test_program_with_diagnostics() {\n    // Test the diagnostic reporting functionality\n    let tokens = vec![\n        TokenType::Fn,\n        TokenType::Identifier(\"test\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ];\n\n    let arena = Arena::new();\n    let stream = VecTokenStream::from_token_types(tokens);\n    let mut parser = ProgramParser::new(\u0026arena, stream);\n\n    let (program, report) = parser.parse_program_with_diagnostics();\n\n    assert!(program.is_some(), \"Expected successful parsing\");\n    assert!(!report.has_errors(), \"Expected no errors in report\");\n\n    let unit = program.unwrap();\n    assert_eq!(unit.items.len(), 1, \"Expected one function\");\n}\n","traces":[],"covered":0,"coverable":0},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","tests","test_phase_2_7_type_parsing.rs"],"content":"//! Phase 2.7: Type Parsing Comprehensive Tests\n//!\n//! Tests for all type expression parsing capabilities introduced in Phase 2.7\n//! including simple types, qualified identifiers, tuples, arrays, function types,\n//! extern function types, pointer types, and complex nested combinations.\n\nuse ferra_parser::{\n    ast::Type,\n    token::{TokenType, VecTokenStream},\n    types::parse_type,\n};\n\nfn create_token_stream(token_types: Vec\u003cTokenType\u003e) -\u003e VecTokenStream {\n    VecTokenStream::from_token_types(token_types)\n}\n\n/// Test Phase 2.7.1: Basic Type Expressions\n\n#[test]\nfn test_simple_identifier_types() {\n    // Test basic built-in types\n    let test_cases = vec![\n        \"int\", \"string\", \"bool\", \"float\", \"char\", \"void\", \"u8\", \"u16\", \"u32\", \"u64\", \"i8\", \"i16\",\n        \"i32\", \"i64\", \"f32\", \"f64\", \"usize\", \"isize\",\n    ];\n\n    for type_name in test_cases {\n        let mut tokens = create_token_stream(vec![TokenType::Identifier(type_name.to_string())]);\n\n        let result = parse_type(\u0026mut tokens).unwrap();\n        match result {\n            Type::Identifier(name) =\u003e assert_eq!(name, type_name),\n            _ =\u003e panic!(\"Expected identifier type for {}\", type_name),\n        }\n    }\n}\n\n#[test]\nfn test_custom_identifier_types() {\n    // Test user-defined types\n    let test_cases = vec![\n        \"MyStruct\",\n        \"DatabaseConnection\",\n        \"Vector3\",\n        \"PlayerState\",\n        \"GameEngine\",\n    ];\n\n    for type_name in test_cases {\n        let mut tokens = create_token_stream(vec![TokenType::Identifier(type_name.to_string())]);\n\n        let result = parse_type(\u0026mut tokens).unwrap();\n        match result {\n            Type::Identifier(name) =\u003e assert_eq!(name, type_name),\n            _ =\u003e panic!(\"Expected identifier type for {}\", type_name),\n        }\n    }\n}\n\n#[test]\nfn test_tuple_types_various_lengths() {\n    // Empty tuple: ()\n    let mut tokens = create_token_stream(vec![TokenType::LeftParen, TokenType::RightParen]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Tuple(types) =\u003e assert_eq!(types.len(), 0),\n        _ =\u003e panic!(\"Expected empty tuple type\"),\n    }\n\n    // Single element tuple: (int,)\n    let mut tokens = create_token_stream(vec![\n        TokenType::LeftParen,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Comma,\n        TokenType::RightParen,\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Tuple(types) =\u003e assert_eq!(types.len(), 1),\n        _ =\u003e panic!(\"Expected single element tuple\"),\n    }\n\n    // Triple tuple: (int, string, bool)\n    let mut tokens = create_token_stream(vec![\n        TokenType::LeftParen,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"string\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"bool\".to_string()),\n        TokenType::RightParen,\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Tuple(types) =\u003e {\n            assert_eq!(types.len(), 3);\n            match (\u0026types[0], \u0026types[1], \u0026types[2]) {\n                (Type::Identifier(t1), Type::Identifier(t2), Type::Identifier(t3)) =\u003e {\n                    assert_eq!(t1, \"int\");\n                    assert_eq!(t2, \"string\");\n                    assert_eq!(t3, \"bool\");\n                }\n                _ =\u003e panic!(\"Expected identifier types in tuple\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected triple tuple type\"),\n    }\n}\n\n#[test]\nfn test_array_types_simple_and_nested() {\n    // Simple array: [int]\n    let mut tokens = create_token_stream(vec![\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Array(element_type) =\u003e match element_type.as_ref() {\n            Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n            _ =\u003e panic!(\"Expected int element type\"),\n        },\n        _ =\u003e panic!(\"Expected array type\"),\n    }\n\n    // Nested array: [[string]]\n    let mut tokens = create_token_stream(vec![\n        TokenType::LeftBracket,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"string\".to_string()),\n        TokenType::RightBracket,\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Array(outer_type) =\u003e match outer_type.as_ref() {\n            Type::Array(inner_type) =\u003e match inner_type.as_ref() {\n                Type::Identifier(name) =\u003e assert_eq!(name, \"string\"),\n                _ =\u003e panic!(\"Expected string in nested array\"),\n            },\n            _ =\u003e panic!(\"Expected nested array\"),\n        },\n        _ =\u003e panic!(\"Expected array type\"),\n    }\n\n    // Triple nested array: [[[bool]]]\n    let mut tokens = create_token_stream(vec![\n        TokenType::LeftBracket,\n        TokenType::LeftBracket,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"bool\".to_string()),\n        TokenType::RightBracket,\n        TokenType::RightBracket,\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Array(l1) =\u003e match l1.as_ref() {\n            Type::Array(l2) =\u003e match l2.as_ref() {\n                Type::Array(l3) =\u003e match l3.as_ref() {\n                    Type::Identifier(name) =\u003e assert_eq!(name, \"bool\"),\n                    _ =\u003e panic!(\"Expected bool in triple nested array\"),\n                },\n                _ =\u003e panic!(\"Expected third level array\"),\n            },\n            _ =\u003e panic!(\"Expected second level array\"),\n        },\n        _ =\u003e panic!(\"Expected array type\"),\n    }\n}\n\n/// Test Phase 2.7.2: Function and Advanced Types\n\n#[test]\nfn test_function_types_various_signatures() {\n    // No parameters, no return: fn()\n    let mut tokens = create_token_stream(vec![\n        TokenType::Fn,\n        TokenType::LeftParen,\n        TokenType::RightParen,\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Function(func_type) =\u003e {\n            assert_eq!(func_type.parameters.len(), 0);\n            assert!(!func_type.is_extern);\n            assert!(func_type.abi.is_none());\n            // Should default to unit type\n            match func_type.return_type.as_ref() {\n                Type::Tuple(types) =\u003e assert_eq!(types.len(), 0),\n                _ =\u003e panic!(\"Expected unit return type\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected function type\"),\n    }\n\n    // Single parameter with return: fn(int) -\u003e string\n    let mut tokens = create_token_stream(vec![\n        TokenType::Fn,\n        TokenType::LeftParen,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"string\".to_string()),\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Function(func_type) =\u003e {\n            assert_eq!(func_type.parameters.len(), 1);\n            match \u0026func_type.parameters[0] {\n                Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n                _ =\u003e panic!(\"Expected int parameter\"),\n            }\n            match func_type.return_type.as_ref() {\n                Type::Identifier(name) =\u003e assert_eq!(name, \"string\"),\n                _ =\u003e panic!(\"Expected string return type\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected function type\"),\n    }\n\n    // Multiple parameters: fn(int, string, bool) -\u003e float\n    let mut tokens = create_token_stream(vec![\n        TokenType::Fn,\n        TokenType::LeftParen,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"string\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"bool\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"float\".to_string()),\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Function(func_type) =\u003e {\n            assert_eq!(func_type.parameters.len(), 3);\n            match (\n                \u0026func_type.parameters[0],\n                \u0026func_type.parameters[1],\n                \u0026func_type.parameters[2],\n            ) {\n                (Type::Identifier(p1), Type::Identifier(p2), Type::Identifier(p3)) =\u003e {\n                    assert_eq!(p1, \"int\");\n                    assert_eq!(p2, \"string\");\n                    assert_eq!(p3, \"bool\");\n                }\n                _ =\u003e panic!(\"Expected identifier parameter types\"),\n            }\n            match func_type.return_type.as_ref() {\n                Type::Identifier(name) =\u003e assert_eq!(name, \"float\"),\n                _ =\u003e panic!(\"Expected float return type\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected function type\"),\n    }\n}\n\n#[test]\nfn test_extern_function_types() {\n    // Extern with ABI: extern \"C\" fn(int) -\u003e void\n    let mut tokens = create_token_stream(vec![\n        TokenType::Extern,\n        TokenType::StringLiteral(\"C\".to_string()),\n        TokenType::Fn,\n        TokenType::LeftParen,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"void\".to_string()),\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Function(func_type) =\u003e {\n            assert!(func_type.is_extern);\n            assert_eq!(func_type.abi, Some(\"C\".to_string()));\n            assert_eq!(func_type.parameters.len(), 1);\n            match func_type.return_type.as_ref() {\n                Type::Identifier(name) =\u003e assert_eq!(name, \"void\"),\n                _ =\u003e panic!(\"Expected void return type\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected extern function type\"),\n    }\n\n    // Extern without explicit ABI: extern fn() -\u003e int\n    let mut tokens = create_token_stream(vec![\n        TokenType::Extern,\n        TokenType::Fn,\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"int\".to_string()),\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Function(func_type) =\u003e {\n            assert!(func_type.is_extern);\n            assert!(func_type.abi.is_none());\n            assert_eq!(func_type.parameters.len(), 0);\n        }\n        _ =\u003e panic!(\"Expected extern function type\"),\n    }\n}\n\n#[test]\nfn test_pointer_types() {\n    // Simple pointer: *int\n    let mut tokens = create_token_stream(vec![\n        TokenType::Star,\n        TokenType::Identifier(\"int\".to_string()),\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Pointer(ptr_type) =\u003e {\n            assert!(ptr_type.is_mutable); // Default to mutable for now\n            match ptr_type.target.as_ref() {\n                Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n                _ =\u003e panic!(\"Expected int pointer target\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected pointer type\"),\n    }\n\n    // Pointer to pointer: **string\n    let mut tokens = create_token_stream(vec![\n        TokenType::Star,\n        TokenType::Star,\n        TokenType::Identifier(\"string\".to_string()),\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Pointer(outer_ptr) =\u003e match outer_ptr.target.as_ref() {\n            Type::Pointer(inner_ptr) =\u003e match inner_ptr.target.as_ref() {\n                Type::Identifier(name) =\u003e assert_eq!(name, \"string\"),\n                _ =\u003e panic!(\"Expected string in nested pointer\"),\n            },\n            _ =\u003e panic!(\"Expected nested pointer\"),\n        },\n        _ =\u003e panic!(\"Expected pointer type\"),\n    }\n}\n\n/// Test Complex Combinations\n\n#[test]\nfn test_array_of_tuples() {\n    // [(int, string)]\n    let mut tokens = create_token_stream(vec![\n        TokenType::LeftBracket,\n        TokenType::LeftParen,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"string\".to_string()),\n        TokenType::RightParen,\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Array(element_type) =\u003e match element_type.as_ref() {\n            Type::Tuple(types) =\u003e {\n                assert_eq!(types.len(), 2);\n                match (\u0026types[0], \u0026types[1]) {\n                    (Type::Identifier(t1), Type::Identifier(t2)) =\u003e {\n                        assert_eq!(t1, \"int\");\n                        assert_eq!(t2, \"string\");\n                    }\n                    _ =\u003e panic!(\"Expected int and string in tuple\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected tuple element in array\"),\n        },\n        _ =\u003e panic!(\"Expected array type\"),\n    }\n}\n\n#[test]\nfn test_tuple_of_arrays() {\n    // ([int], [string], [bool])\n    let mut tokens = create_token_stream(vec![\n        TokenType::LeftParen,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightBracket,\n        TokenType::Comma,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"string\".to_string()),\n        TokenType::RightBracket,\n        TokenType::Comma,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"bool\".to_string()),\n        TokenType::RightBracket,\n        TokenType::RightParen,\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Tuple(types) =\u003e {\n            assert_eq!(types.len(), 3);\n            for (i, expected) in [\"int\", \"string\", \"bool\"].iter().enumerate() {\n                match \u0026types[i] {\n                    Type::Array(element_type) =\u003e match element_type.as_ref() {\n                        Type::Identifier(name) =\u003e assert_eq!(name, expected),\n                        _ =\u003e panic!(\"Expected {} array element\", expected),\n                    },\n                    _ =\u003e panic!(\"Expected array type in tuple position {}\", i),\n                }\n            }\n        }\n        _ =\u003e panic!(\"Expected tuple type\"),\n    }\n}\n\n#[test]\nfn test_function_with_complex_parameters() {\n    // fn([int], (string, bool)) -\u003e *int\n    let mut tokens = create_token_stream(vec![\n        TokenType::Fn,\n        TokenType::LeftParen,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightBracket,\n        TokenType::Comma,\n        TokenType::LeftParen,\n        TokenType::Identifier(\"string\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"bool\".to_string()),\n        TokenType::RightParen,\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Star,\n        TokenType::Identifier(\"int\".to_string()),\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Function(func_type) =\u003e {\n            assert_eq!(func_type.parameters.len(), 2);\n\n            // First parameter: [int]\n            match \u0026func_type.parameters[0] {\n                Type::Array(element_type) =\u003e match element_type.as_ref() {\n                    Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n                    _ =\u003e panic!(\"Expected int array\"),\n                },\n                _ =\u003e panic!(\"Expected array parameter\"),\n            }\n\n            // Second parameter: (string, bool)\n            match \u0026func_type.parameters[1] {\n                Type::Tuple(types) =\u003e {\n                    assert_eq!(types.len(), 2);\n                    match (\u0026types[0], \u0026types[1]) {\n                        (Type::Identifier(t1), Type::Identifier(t2)) =\u003e {\n                            assert_eq!(t1, \"string\");\n                            assert_eq!(t2, \"bool\");\n                        }\n                        _ =\u003e panic!(\"Expected string and bool in tuple\"),\n                    }\n                }\n                _ =\u003e panic!(\"Expected tuple parameter\"),\n            }\n\n            // Return type: *int\n            match func_type.return_type.as_ref() {\n                Type::Pointer(ptr_type) =\u003e match ptr_type.target.as_ref() {\n                    Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n                    _ =\u003e panic!(\"Expected int pointer\"),\n                },\n                _ =\u003e panic!(\"Expected pointer return type\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected function type\"),\n    }\n}\n\n#[test]\nfn test_higher_order_functions() {\n    // fn(fn(int) -\u003e string) -\u003e bool\n    let mut tokens = create_token_stream(vec![\n        TokenType::Fn,\n        TokenType::LeftParen,\n        TokenType::Fn,\n        TokenType::LeftParen,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"string\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"bool\".to_string()),\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Function(outer_func) =\u003e {\n            assert_eq!(outer_func.parameters.len(), 1);\n\n            // Parameter: fn(int) -\u003e string\n            match \u0026outer_func.parameters[0] {\n                Type::Function(inner_func) =\u003e {\n                    assert_eq!(inner_func.parameters.len(), 1);\n                    match \u0026inner_func.parameters[0] {\n                        Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n                        _ =\u003e panic!(\"Expected int parameter in inner function\"),\n                    }\n                    match inner_func.return_type.as_ref() {\n                        Type::Identifier(name) =\u003e assert_eq!(name, \"string\"),\n                        _ =\u003e panic!(\"Expected string return in inner function\"),\n                    }\n                }\n                _ =\u003e panic!(\"Expected function parameter\"),\n            }\n\n            // Return type: bool\n            match outer_func.return_type.as_ref() {\n                Type::Identifier(name) =\u003e assert_eq!(name, \"bool\"),\n                _ =\u003e panic!(\"Expected bool return type\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected function type\"),\n    }\n}\n\n#[test]\nfn test_array_of_function_pointers() {\n    // [fn(int) -\u003e string]\n    let mut tokens = create_token_stream(vec![\n        TokenType::LeftBracket,\n        TokenType::Fn,\n        TokenType::LeftParen,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"string\".to_string()),\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Array(element_type) =\u003e match element_type.as_ref() {\n            Type::Function(func_type) =\u003e {\n                assert_eq!(func_type.parameters.len(), 1);\n                match \u0026func_type.parameters[0] {\n                    Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n                    _ =\u003e panic!(\"Expected int parameter\"),\n                }\n                match func_type.return_type.as_ref() {\n                    Type::Identifier(name) =\u003e assert_eq!(name, \"string\"),\n                    _ =\u003e panic!(\"Expected string return type\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected function type in array\"),\n        },\n        _ =\u003e panic!(\"Expected array type\"),\n    }\n}\n\n#[test]\nfn test_extremely_complex_type() {\n    // [fn(*[int], (string, bool)) -\u003e *(string, [bool])]\n    let mut tokens = create_token_stream(vec![\n        TokenType::LeftBracket,\n        TokenType::Fn,\n        TokenType::LeftParen,\n        TokenType::Star,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightBracket,\n        TokenType::Comma,\n        TokenType::LeftParen,\n        TokenType::Identifier(\"string\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"bool\".to_string()),\n        TokenType::RightParen,\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Star,\n        TokenType::LeftParen,\n        TokenType::Identifier(\"string\".to_string()),\n        TokenType::Comma,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"bool\".to_string()),\n        TokenType::RightBracket,\n        TokenType::RightParen,\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_type(\u0026mut tokens).unwrap();\n    match result {\n        Type::Array(element_type) =\u003e {\n            match element_type.as_ref() {\n                Type::Function(func_type) =\u003e {\n                    assert_eq!(func_type.parameters.len(), 2);\n\n                    // First parameter: *[int]\n                    match \u0026func_type.parameters[0] {\n                        Type::Pointer(ptr_type) =\u003e match ptr_type.target.as_ref() {\n                            Type::Array(arr_type) =\u003e match arr_type.as_ref() {\n                                Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n                                _ =\u003e panic!(\"Expected int in array\"),\n                            },\n                            _ =\u003e panic!(\"Expected array in pointer\"),\n                        },\n                        _ =\u003e panic!(\"Expected pointer parameter\"),\n                    }\n\n                    // Second parameter: (string, bool)\n                    match \u0026func_type.parameters[1] {\n                        Type::Tuple(types) =\u003e {\n                            assert_eq!(types.len(), 2);\n                        }\n                        _ =\u003e panic!(\"Expected tuple parameter\"),\n                    }\n\n                    // Return type: *(string, [bool])\n                    match func_type.return_type.as_ref() {\n                        Type::Pointer(ptr_type) =\u003e match ptr_type.target.as_ref() {\n                            Type::Tuple(types) =\u003e {\n                                assert_eq!(types.len(), 2);\n                                match (\u0026types[0], \u0026types[1]) {\n                                    (Type::Identifier(t1), Type::Array(arr)) =\u003e {\n                                        assert_eq!(t1, \"string\");\n                                        match arr.as_ref() {\n                                            Type::Identifier(name) =\u003e assert_eq!(name, \"bool\"),\n                                            _ =\u003e panic!(\"Expected bool array\"),\n                                        }\n                                    }\n                                    _ =\u003e panic!(\"Expected string and bool array\"),\n                                }\n                            }\n                            _ =\u003e panic!(\"Expected tuple in return pointer\"),\n                        },\n                        _ =\u003e panic!(\"Expected pointer return type\"),\n                    }\n                }\n                _ =\u003e panic!(\"Expected function type in array\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected array type\"),\n    }\n}\n\n/// Test Error Cases\n\n#[test]\nfn test_type_parsing_error_cases() {\n    // Invalid token for type\n    let mut tokens = create_token_stream(vec![\n        TokenType::Plus, // Invalid token for type\n    ]);\n\n    let result = parse_type(\u0026mut tokens);\n    assert!(result.is_err());\n\n    // Incomplete array type\n    let mut tokens = create_token_stream(vec![\n        TokenType::LeftBracket,\n        // Missing element type and closing bracket\n    ]);\n\n    let result = parse_type(\u0026mut tokens);\n    assert!(result.is_err());\n\n    // Incomplete function type\n    let mut tokens = create_token_stream(vec![\n        TokenType::Fn,\n        TokenType::LeftParen,\n        TokenType::Identifier(\"int\".to_string()),\n        // Missing closing paren\n    ]);\n\n    let result = parse_type(\u0026mut tokens);\n    assert!(result.is_err());\n}\n\n/// Test Integration with Existing Parsers\n\n#[test]\nfn test_type_parsing_integration() {\n    use ferra_parser::{ast::Arena, program::ProgramParser, token::VecTokenStream};\n\n    // Test that the enhanced type parser works with existing parsers\n    let tokens = vec![\n        TokenType::Fn,\n        TokenType::Identifier(\"complex_function\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"data\".to_string()),\n        TokenType::Colon,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightBracket,\n        TokenType::Comma,\n        TokenType::Identifier(\"callback\".to_string()),\n        TokenType::Colon,\n        TokenType::Fn,\n        TokenType::LeftParen,\n        TokenType::Identifier(\"string\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"bool\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Star,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n    ];\n\n    let arena = Arena::new();\n    let token_stream = VecTokenStream::from_token_types(tokens);\n    let mut parser = ProgramParser::new(\u0026arena, token_stream);\n\n    let result = parser.parse_compilation_unit();\n    assert!(result.is_ok());\n\n    let compilation_unit = result.unwrap();\n    assert_eq!(compilation_unit.items.len(), 1);\n\n    match \u0026compilation_unit.items[0] {\n        ferra_parser::ast::Item::FunctionDecl(func_decl) =\u003e {\n            assert_eq!(func_decl.name, \"complex_function\");\n            assert_eq!(func_decl.parameters.len(), 2);\n\n            // First parameter should be array type\n            match \u0026func_decl.parameters[0].param_type {\n                Type::Array(element_type) =\u003e match element_type.as_ref() {\n                    Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n                    _ =\u003e panic!(\"Expected int array parameter\"),\n                },\n                _ =\u003e panic!(\"Expected array parameter type\"),\n            }\n\n            // Second parameter should be function type\n            match \u0026func_decl.parameters[1].param_type {\n                Type::Function(func_type) =\u003e {\n                    assert_eq!(func_type.parameters.len(), 1);\n                    match func_type.return_type.as_ref() {\n                        Type::Identifier(name) =\u003e assert_eq!(name, \"bool\"),\n                        _ =\u003e panic!(\"Expected bool return type\"),\n                    }\n                }\n                _ =\u003e panic!(\"Expected function parameter type\"),\n            }\n\n            // Return type should be pointer\n            match func_decl.return_type.as_ref().unwrap() {\n                Type::Pointer(ptr_type) =\u003e match ptr_type.target.as_ref() {\n                    Type::Identifier(name) =\u003e assert_eq!(name, \"int\"),\n                    _ =\u003e panic!(\"Expected int pointer return\"),\n                },\n                _ =\u003e panic!(\"Expected pointer return type\"),\n            }\n        }\n        _ =\u003e panic!(\"Expected function declaration\"),\n    }\n}\n","traces":[{"line":13,"address":[],"length":0,"stats":{"Line":45}},{"line":14,"address":[],"length":0,"stats":{"Line":45}}],"covered":2,"coverable":2},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","tests","test_phase_2_8_1_attribute_parsing.rs"],"content":"//! Tests for Phase 2.8.1: Attribute Parsing\n//!\n//! Tests comprehensive attribute parsing including:\n//! - Simple attributes (#[inline])\n//! - Attributes with arguments (#[derive(Debug, Clone)])\n//! - Multiple attributes\n//! - Attributes on various declarations\n//! - Error handling for malformed attributes\n\nuse ferra_parser::{\n    ast::{Arena, Item, Statement},\n    attribute::parser::{parse_attribute, parse_attributes},\n    statement::parser::StatementParser,\n    token::{stream::VecTokenStream, TokenType},\n};\n\nfn create_token_stream(token_types: Vec\u003cTokenType\u003e) -\u003e VecTokenStream {\n    VecTokenStream::from_token_types(token_types)\n}\n\n/// Test simple attribute parsing\n#[test]\nfn test_simple_attribute_parsing() {\n    // #[inline]\n    let mut tokens = create_token_stream(vec![\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"inline\".to_string()),\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_attribute(\u0026mut tokens).unwrap();\n    assert_eq!(result.name, \"inline\");\n    assert_eq!(result.arguments.len(), 0);\n}\n\n/// Test attribute with single argument\n#[test]\nfn test_attribute_with_single_argument() {\n    // #[cfg(test)]\n    let mut tokens = create_token_stream(vec![\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"cfg\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"test\".to_string()),\n        TokenType::RightParen,\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_attribute(\u0026mut tokens).unwrap();\n    assert_eq!(result.name, \"cfg\");\n    assert_eq!(result.arguments.len(), 1);\n    assert_eq!(result.arguments[0], \"test\");\n}\n\n/// Test derive attribute with multiple arguments\n#[test]\nfn test_derive_attribute_multiple_arguments() {\n    // #[derive(Debug, Clone, PartialEq)]\n    let mut tokens = create_token_stream(vec![\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"derive\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"Debug\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"Clone\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"PartialEq\".to_string()),\n        TokenType::RightParen,\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_attribute(\u0026mut tokens).unwrap();\n    assert_eq!(result.name, \"derive\");\n    assert_eq!(result.arguments.len(), 3);\n    assert_eq!(result.arguments[0], \"Debug\");\n    assert_eq!(result.arguments[1], \"Clone\");\n    assert_eq!(result.arguments[2], \"PartialEq\");\n}\n\n/// Test multiple consecutive attributes\n#[test]\nfn test_multiple_attributes() {\n    // #[inline] #[derive(Debug)]\n    let mut tokens = create_token_stream(vec![\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"inline\".to_string()),\n        TokenType::RightBracket,\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"derive\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"Debug\".to_string()),\n        TokenType::RightParen,\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_attributes(\u0026mut tokens).unwrap();\n    assert_eq!(result.len(), 2);\n    assert_eq!(result[0].name, \"inline\");\n    assert_eq!(result[0].arguments.len(), 0);\n    assert_eq!(result[1].name, \"derive\");\n    assert_eq!(result[1].arguments.len(), 1);\n    assert_eq!(result[1].arguments[0], \"Debug\");\n}\n\n/// Test attribute with string literal argument\n#[test]\nfn test_attribute_with_string_argument() {\n    // #[doc(\"This is documentation\")]\n    let mut tokens = create_token_stream(vec![\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"doc\".to_string()),\n        TokenType::LeftParen,\n        TokenType::StringLiteral(\"This is documentation\".to_string()),\n        TokenType::RightParen,\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_attribute(\u0026mut tokens).unwrap();\n    assert_eq!(result.name, \"doc\");\n    assert_eq!(result.arguments.len(), 1);\n    assert_eq!(result.arguments[0], \"\\\"This is documentation\\\"\");\n}\n\n/// Test attribute with mixed argument types\n#[test]\nfn test_attribute_with_mixed_arguments() {\n    // #[test_attr(\"string\", 42, true)]\n    let mut tokens = create_token_stream(vec![\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"test_attr\".to_string()),\n        TokenType::LeftParen,\n        TokenType::StringLiteral(\"string\".to_string()),\n        TokenType::Comma,\n        TokenType::IntegerLiteral(42),\n        TokenType::Comma,\n        TokenType::BooleanLiteral(true),\n        TokenType::RightParen,\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_attribute(\u0026mut tokens).unwrap();\n    assert_eq!(result.name, \"test_attr\");\n    assert_eq!(result.arguments.len(), 3);\n    assert_eq!(result.arguments[0], \"\\\"string\\\"\");\n    assert_eq!(result.arguments[1], \"42\");\n    assert_eq!(result.arguments[2], \"true\");\n}\n\n/// Test attribute with trailing comma\n#[test]\nfn test_attribute_with_trailing_comma() {\n    // #[derive(Debug, Clone,)]\n    let mut tokens = create_token_stream(vec![\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"derive\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"Debug\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"Clone\".to_string()),\n        TokenType::Comma,\n        TokenType::RightParen,\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_attribute(\u0026mut tokens).unwrap();\n    assert_eq!(result.name, \"derive\");\n    assert_eq!(result.arguments.len(), 2);\n    assert_eq!(result.arguments[0], \"Debug\");\n    assert_eq!(result.arguments[1], \"Clone\");\n}\n\n/// Test function declaration with attributes\n#[test]\nfn test_function_with_attributes() {\n    // #[inline] #[test] fn test_function() {}\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"inline\".to_string()),\n        TokenType::RightBracket,\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"test\".to_string()),\n        TokenType::RightBracket,\n        TokenType::Fn,\n        TokenType::Identifier(\"test_function\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n    ]);\n\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n    let item = parser.parse_item().unwrap();\n\n    match item {\n        Item::FunctionDecl(func) =\u003e {\n            assert_eq!(func.name, \"test_function\");\n            assert_eq!(func.attributes.len(), 2);\n            assert_eq!(func.attributes[0].name, \"inline\");\n            assert_eq!(func.attributes[1].name, \"test\");\n        }\n        _ =\u003e panic!(\"Expected function declaration\"),\n    }\n}\n\n/// Test variable declaration with attributes\n#[test]\nfn test_variable_with_attributes() {\n    // #[allow(unused)] let x: int = 42\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"allow\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"unused\".to_string()),\n        TokenType::RightParen,\n        TokenType::RightBracket,\n        TokenType::Let,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::Equal,\n        TokenType::IntegerLiteral(42),\n    ]);\n\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n    let statement = parser.parse_statement().unwrap();\n\n    match statement {\n        Statement::VariableDecl(var) =\u003e {\n            assert_eq!(var.name, \"x\");\n            assert_eq!(var.attributes.len(), 1);\n            assert_eq!(var.attributes[0].name, \"allow\");\n            assert_eq!(var.attributes[0].arguments[0], \"unused\");\n        }\n        _ =\u003e panic!(\"Expected variable declaration\"),\n    }\n}\n\n/// Test data class with attributes\n#[test]\nfn test_data_class_with_attributes() {\n    // #[derive(Debug)] data Person { name: string }\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"derive\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"Debug\".to_string()),\n        TokenType::RightParen,\n        TokenType::RightBracket,\n        TokenType::Data,\n        TokenType::Identifier(\"Person\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"name\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"string\".to_string()),\n        TokenType::RightBrace,\n    ]);\n\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n    let item = parser.parse_item().unwrap();\n\n    match item {\n        Item::DataClassDecl(data_class) =\u003e {\n            assert_eq!(data_class.name, \"Person\");\n            assert_eq!(data_class.attributes.len(), 1);\n            assert_eq!(data_class.attributes[0].name, \"derive\");\n            assert_eq!(data_class.attributes[0].arguments[0], \"Debug\");\n        }\n        _ =\u003e panic!(\"Expected data class declaration\"),\n    }\n}\n\n/// Test field with attributes\n#[test]\nfn test_field_with_attributes() {\n    // data Person { #[serde(rename = \"full_name\")] name: string }\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Data,\n        TokenType::Identifier(\"Person\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"serde\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"rename\".to_string()),\n        TokenType::RightParen,\n        TokenType::RightBracket,\n        TokenType::Identifier(\"name\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"string\".to_string()),\n        TokenType::RightBrace,\n    ]);\n\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n    let item = parser.parse_item().unwrap();\n\n    match item {\n        Item::DataClassDecl(data_class) =\u003e {\n            assert_eq!(data_class.name, \"Person\");\n            assert_eq!(data_class.fields.len(), 1);\n            assert_eq!(data_class.fields[0].name, \"name\");\n            assert_eq!(data_class.fields[0].attributes.len(), 1);\n            assert_eq!(data_class.fields[0].attributes[0].name, \"serde\");\n            assert_eq!(data_class.fields[0].attributes[0].arguments[0], \"rename\");\n        }\n        _ =\u003e panic!(\"Expected data class declaration\"),\n    }\n}\n\n/// Test parameter with attributes\n#[test]\nfn test_parameter_with_attributes() {\n    // fn test(#[unused] param: int) {}\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Fn,\n        TokenType::Identifier(\"test\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"unused\".to_string()),\n        TokenType::RightBracket,\n        TokenType::Identifier(\"param\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"int\".to_string()),\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n    ]);\n\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n    let item = parser.parse_item().unwrap();\n\n    match item {\n        Item::FunctionDecl(func) =\u003e {\n            assert_eq!(func.name, \"test\");\n            assert_eq!(func.parameters.len(), 1);\n            assert_eq!(func.parameters[0].name, \"param\");\n            assert_eq!(func.parameters[0].attributes.len(), 1);\n            assert_eq!(func.parameters[0].attributes[0].name, \"unused\");\n        }\n        _ =\u003e panic!(\"Expected function declaration\"),\n    }\n}\n\n/// Test attribute parsing error cases\n#[test]\nfn test_attribute_parsing_errors() {\n    // Missing opening bracket: #identifier\n    let mut tokens = create_token_stream(vec![\n        TokenType::Hash,\n        TokenType::Identifier(\"inline\".to_string()),\n    ]);\n\n    let result = parse_attribute(\u0026mut tokens);\n    assert!(result.is_err());\n\n    // Missing closing bracket: #[inline\n    let mut tokens = create_token_stream(vec![\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"inline\".to_string()),\n    ]);\n\n    let result = parse_attribute(\u0026mut tokens);\n    assert!(result.is_err());\n\n    // Invalid attribute name: #[123]\n    let mut tokens = create_token_stream(vec![\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::IntegerLiteral(123),\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_attribute(\u0026mut tokens);\n    assert!(result.is_err());\n}\n\n/// Test complex nested attributes\n#[test]\nfn test_complex_attributes() {\n    // #[derive(Debug, Clone, Serialize, Deserialize)]\n    // #[serde(rename_all = \"camelCase\")]\n    // #[doc(\"A complex data structure\")]\n    let mut tokens = create_token_stream(vec![\n        // First attribute\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"derive\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"Debug\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"Clone\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"Serialize\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"Deserialize\".to_string()),\n        TokenType::RightParen,\n        TokenType::RightBracket,\n        // Second attribute\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"serde\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"rename_all\".to_string()),\n        TokenType::RightParen,\n        TokenType::RightBracket,\n        // Third attribute\n        TokenType::Hash,\n        TokenType::LeftBracket,\n        TokenType::Identifier(\"doc\".to_string()),\n        TokenType::LeftParen,\n        TokenType::StringLiteral(\"A complex data structure\".to_string()),\n        TokenType::RightParen,\n        TokenType::RightBracket,\n    ]);\n\n    let result = parse_attributes(\u0026mut tokens).unwrap();\n    assert_eq!(result.len(), 3);\n\n    // First attribute\n    assert_eq!(result[0].name, \"derive\");\n    assert_eq!(result[0].arguments.len(), 4);\n    assert_eq!(result[0].arguments[0], \"Debug\");\n    assert_eq!(result[0].arguments[1], \"Clone\");\n    assert_eq!(result[0].arguments[2], \"Serialize\");\n    assert_eq!(result[0].arguments[3], \"Deserialize\");\n\n    // Second attribute\n    assert_eq!(result[1].name, \"serde\");\n    assert_eq!(result[1].arguments.len(), 1);\n    assert_eq!(result[1].arguments[0], \"rename_all\");\n\n    // Third attribute\n    assert_eq!(result[2].name, \"doc\");\n    assert_eq!(result[2].arguments.len(), 1);\n    assert_eq!(result[2].arguments[0], \"\\\"A complex data structure\\\"\");\n}\n\n/// Test empty attribute list when no attributes present\n#[test]\nfn test_empty_attribute_list() {\n    // fn test() {} (no attributes)\n    let mut tokens = create_token_stream(vec![\n        TokenType::Fn,\n        TokenType::Identifier(\"test\".to_string()),\n    ]);\n\n    let result = parse_attributes(\u0026mut tokens).unwrap();\n    assert_eq!(result.len(), 0);\n}\n\n/// Test attribute integration with existing parsing\n#[test]\nfn test_attribute_integration_with_existing_parsing() {\n    // Test that existing parsing still works when no attributes are present\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Fn,\n        TokenType::Identifier(\"regular_function\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n    ]);\n\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n    let item = parser.parse_item().unwrap();\n\n    match item {\n        Item::FunctionDecl(func) =\u003e {\n            assert_eq!(func.name, \"regular_function\");\n            assert_eq!(func.attributes.len(), 0); // No attributes\n        }\n        _ =\u003e panic!(\"Expected function declaration\"),\n    }\n}\n","traces":[{"line":17,"address":[],"length":0,"stats":{"Line":18}},{"line":18,"address":[],"length":0,"stats":{"Line":18}}],"covered":2,"coverable":2},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","tests","test_phase_2_8_2_generic_types.rs"],"content":"//! Phase 2.8.2: Generic Type Parameter Tests\n//!\n//! Tests for generic type parameter parsing including:\n//! - Type parameters: `\u003cT, U\u003e`\n//! - Lifetime parameters: `\u003c'a, 'b\u003e`\n//! - Type constraints: `\u003cT: Clone + Debug\u003e`\n//! - Where clauses: `where T: Clone + Debug, U: Default`\n//! - Generic type instantiations: `Vec\u003cT\u003e`, `HashMap\u003cK, V\u003e`\n//! - Integration with function and data class declarations\n\nuse ferra_parser::{\n    ast::{Arena, Item, Type},\n    generic::parser::{parse_generic_params, parse_generic_type},\n    statement::StatementParser,\n    token::stream::VecTokenStream,\n    token::{Token, TokenType},\n};\n\nfn create_token_stream(token_types: Vec\u003cTokenType\u003e) -\u003e VecTokenStream {\n    let tokens = token_types.into_iter().map(Token::dummy).collect();\n    VecTokenStream::new(tokens)\n}\n\n#[test]\nfn test_simple_generic_params() {\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Greater,\n    ]);\n\n    let result = parse_generic_params(\u0026mut tokens).unwrap();\n    assert!(result.is_some());\n\n    let generics = result.unwrap();\n    assert_eq!(generics.params.len(), 1);\n    assert_eq!(generics.params[0].name, \"T\");\n    assert!(!generics.params[0].is_lifetime);\n    assert!(generics.params[0].bounds.is_empty());\n    assert!(generics.where_clause.is_none());\n}\n\n#[test]\nfn test_multiple_generic_params() {\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"U\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"V\".to_string()),\n        TokenType::Greater,\n    ]);\n\n    let result = parse_generic_params(\u0026mut tokens).unwrap();\n    assert!(result.is_some());\n\n    let generics = result.unwrap();\n    assert_eq!(generics.params.len(), 3);\n    assert_eq!(generics.params[0].name, \"T\");\n    assert_eq!(generics.params[1].name, \"U\");\n    assert_eq!(generics.params[2].name, \"V\");\n}\n\n#[test]\nfn test_lifetime_parameters() {\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Apostrophe,\n        TokenType::Identifier(\"a\".to_string()),\n        TokenType::Comma,\n        TokenType::Apostrophe,\n        TokenType::Identifier(\"static\".to_string()),\n        TokenType::Greater,\n    ]);\n\n    let result = parse_generic_params(\u0026mut tokens).unwrap();\n    assert!(result.is_some());\n\n    let generics = result.unwrap();\n    assert_eq!(generics.params.len(), 2);\n    assert_eq!(generics.params[0].name, \"'a\");\n    assert_eq!(generics.params[1].name, \"'static\");\n    assert!(generics.params[0].is_lifetime);\n    assert!(generics.params[1].is_lifetime);\n}\n\n#[test]\nfn test_mixed_type_and_lifetime_params() {\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Apostrophe,\n        TokenType::Identifier(\"a\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Comma,\n        TokenType::Apostrophe,\n        TokenType::Identifier(\"b\".to_string()),\n        TokenType::Greater,\n    ]);\n\n    let result = parse_generic_params(\u0026mut tokens).unwrap();\n    assert!(result.is_some());\n\n    let generics = result.unwrap();\n    assert_eq!(generics.params.len(), 3);\n    assert_eq!(generics.params[0].name, \"'a\");\n    assert!(generics.params[0].is_lifetime);\n    assert_eq!(generics.params[1].name, \"T\");\n    assert!(!generics.params[1].is_lifetime);\n    assert_eq!(generics.params[2].name, \"'b\");\n    assert!(generics.params[2].is_lifetime);\n}\n\n#[test]\nfn test_type_bounds_single_trait() {\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"Clone\".to_string()),\n        TokenType::Greater,\n    ]);\n\n    let result = parse_generic_params(\u0026mut tokens).unwrap();\n    assert!(result.is_some());\n\n    let generics = result.unwrap();\n    assert_eq!(generics.params.len(), 1);\n    assert_eq!(generics.params[0].bounds.len(), 1);\n    assert_eq!(generics.params[0].bounds[0].trait_name, \"Clone\");\n}\n\n#[test]\nfn test_type_bounds_multiple_traits() {\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"Clone\".to_string()),\n        TokenType::Plus,\n        TokenType::Identifier(\"Debug\".to_string()),\n        TokenType::Plus,\n        TokenType::Identifier(\"Send\".to_string()),\n        TokenType::Greater,\n    ]);\n\n    let result = parse_generic_params(\u0026mut tokens).unwrap();\n    assert!(result.is_some());\n\n    let generics = result.unwrap();\n    assert_eq!(generics.params.len(), 1);\n    assert_eq!(generics.params[0].bounds.len(), 3);\n    assert_eq!(generics.params[0].bounds[0].trait_name, \"Clone\");\n    assert_eq!(generics.params[0].bounds[1].trait_name, \"Debug\");\n    assert_eq!(generics.params[0].bounds[2].trait_name, \"Send\");\n}\n\n#[test]\nfn test_complex_mixed_constraints() {\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"Clone\".to_string()),\n        TokenType::Plus,\n        TokenType::Identifier(\"Debug\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"U\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"Default\".to_string()),\n        TokenType::Greater,\n    ]);\n\n    let result = parse_generic_params(\u0026mut tokens).unwrap();\n    assert!(result.is_some());\n\n    let generics = result.unwrap();\n    assert_eq!(generics.params.len(), 2);\n\n    // First parameter: T: Clone + Debug\n    assert_eq!(generics.params[0].name, \"T\");\n    assert_eq!(generics.params[0].bounds.len(), 2);\n    assert_eq!(generics.params[0].bounds[0].trait_name, \"Clone\");\n    assert_eq!(generics.params[0].bounds[1].trait_name, \"Debug\");\n\n    // Second parameter: U: Default\n    assert_eq!(generics.params[1].name, \"U\");\n    assert_eq!(generics.params[1].bounds.len(), 1);\n    assert_eq!(generics.params[1].bounds[0].trait_name, \"Default\");\n}\n\n#[test]\nfn test_where_clause_simple() {\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Greater,\n        TokenType::Where,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"Clone\".to_string()),\n    ]);\n\n    let result = parse_generic_params(\u0026mut tokens).unwrap();\n    assert!(result.is_some());\n\n    let generics = result.unwrap();\n    assert!(generics.where_clause.is_some());\n\n    let where_clause = generics.where_clause.unwrap();\n    assert_eq!(where_clause.constraints.len(), 1);\n    assert_eq!(where_clause.constraints[0].type_name, \"T\");\n    assert_eq!(where_clause.constraints[0].bounds.len(), 1);\n    assert_eq!(where_clause.constraints[0].bounds[0].trait_name, \"Clone\");\n}\n\n#[test]\nfn test_where_clause_complex() {\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"U\".to_string()),\n        TokenType::Greater,\n        TokenType::Where,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"Clone\".to_string()),\n        TokenType::Plus,\n        TokenType::Identifier(\"Debug\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"U\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"Default\".to_string()),\n    ]);\n\n    let result = parse_generic_params(\u0026mut tokens).unwrap();\n    assert!(result.is_some());\n\n    let generics = result.unwrap();\n    assert!(generics.where_clause.is_some());\n\n    let where_clause = generics.where_clause.unwrap();\n    assert_eq!(where_clause.constraints.len(), 2);\n\n    // First constraint: T: Clone + Debug\n    assert_eq!(where_clause.constraints[0].type_name, \"T\");\n    assert_eq!(where_clause.constraints[0].bounds.len(), 2);\n    assert_eq!(where_clause.constraints[0].bounds[0].trait_name, \"Clone\");\n    assert_eq!(where_clause.constraints[0].bounds[1].trait_name, \"Debug\");\n\n    // Second constraint: U: Default\n    assert_eq!(where_clause.constraints[1].type_name, \"U\");\n    assert_eq!(where_clause.constraints[1].bounds.len(), 1);\n    assert_eq!(where_clause.constraints[1].bounds[0].trait_name, \"Default\");\n}\n\n#[test]\nfn test_generic_type_instantiation_simple() {\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Identifier(\"i32\".to_string()),\n        TokenType::Greater,\n    ]);\n\n    let result = parse_generic_type(\u0026mut tokens, \"Vec\".to_string()).unwrap();\n    assert_eq!(result.base, \"Vec\");\n    assert_eq!(result.args.len(), 1);\n\n    if let Type::Identifier(name) = \u0026result.args[0] {\n        assert_eq!(name, \"i32\");\n    } else {\n        panic!(\"Expected identifier type\");\n    }\n}\n\n#[test]\nfn test_generic_type_instantiation_multiple_args() {\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Identifier(\"String\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"i32\".to_string()),\n        TokenType::Greater,\n    ]);\n\n    let result = parse_generic_type(\u0026mut tokens, \"HashMap\".to_string()).unwrap();\n    assert_eq!(result.base, \"HashMap\");\n    assert_eq!(result.args.len(), 2);\n\n    if let Type::Identifier(name) = \u0026result.args[0] {\n        assert_eq!(name, \"String\");\n    } else {\n        panic!(\"Expected identifier type\");\n    }\n\n    if let Type::Identifier(name) = \u0026result.args[1] {\n        assert_eq!(name, \"i32\");\n    } else {\n        panic!(\"Expected identifier type\");\n    }\n}\n\n#[test]\nfn test_nested_generic_types() {\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Identifier(\"Vec\".to_string()),\n        TokenType::Less,\n        TokenType::Identifier(\"i32\".to_string()),\n        TokenType::Greater,\n        TokenType::Greater,\n    ]);\n\n    let result = parse_generic_type(\u0026mut tokens, \"Option\".to_string()).unwrap();\n    assert_eq!(result.base, \"Option\");\n    assert_eq!(result.args.len(), 1);\n\n    if let Type::Generic(inner) = \u0026result.args[0] {\n        assert_eq!(inner.base, \"Vec\");\n        assert_eq!(inner.args.len(), 1);\n\n        if let Type::Identifier(name) = \u0026inner.args[0] {\n            assert_eq!(name, \"i32\");\n        } else {\n            panic!(\"Expected identifier type\");\n        }\n    } else {\n        panic!(\"Expected generic type\");\n    }\n}\n\n#[test]\nfn test_generic_function_declaration() {\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Fn,\n        TokenType::Identifier(\"compare\".to_string()),\n        TokenType::Less,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"PartialOrd\".to_string()),\n        TokenType::Greater,\n        TokenType::LeftParen,\n        TokenType::Identifier(\"a\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"b\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"bool\".to_string()),\n        TokenType::Semicolon,\n    ]);\n\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n    let result = parser.parse_item().unwrap();\n\n    if let Item::FunctionDecl(func) = result {\n        assert_eq!(func.name, \"compare\");\n        assert!(func.generics.is_some());\n\n        let generics = func.generics.as_ref().unwrap();\n        assert_eq!(generics.params.len(), 1);\n        assert_eq!(generics.params[0].name, \"T\");\n        assert_eq!(generics.params[0].bounds.len(), 1);\n        assert_eq!(generics.params[0].bounds[0].trait_name, \"PartialOrd\");\n\n        assert_eq!(func.parameters.len(), 2);\n        assert_eq!(func.parameters[0].name, \"a\");\n        assert_eq!(func.parameters[1].name, \"b\");\n    } else {\n        panic!(\"Expected function declaration\");\n    }\n}\n\n#[test]\nfn test_generic_data_class_declaration() {\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Data,\n        TokenType::Identifier(\"Container\".to_string()),\n        TokenType::Less,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Greater,\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"value\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::RightBrace,\n    ]);\n\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n    let result = parser.parse_item().unwrap();\n\n    if let Item::DataClassDecl(data_class) = result {\n        assert_eq!(data_class.name, \"Container\");\n        assert!(data_class.generics.is_some());\n\n        let generics = data_class.generics.as_ref().unwrap();\n        assert_eq!(generics.params.len(), 1);\n        assert_eq!(generics.params[0].name, \"T\");\n\n        assert_eq!(data_class.fields.len(), 1);\n        assert_eq!(data_class.fields[0].name, \"value\");\n    } else {\n        panic!(\"Expected data class declaration\");\n    }\n}\n\n#[test]\nfn test_complex_generic_function_with_where_clause() {\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Fn,\n        TokenType::Identifier(\"complex_fn\".to_string()),\n        TokenType::Less,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"U\".to_string()),\n        TokenType::Greater,\n        TokenType::LeftParen,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"U\".to_string()),\n        TokenType::Where,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"Clone\".to_string()),\n        TokenType::Plus,\n        TokenType::Identifier(\"Debug\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"U\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"Default\".to_string()),\n        TokenType::Semicolon,\n    ]);\n\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n    let result = parser.parse_item().unwrap();\n\n    if let Item::FunctionDecl(func) = result {\n        assert_eq!(func.name, \"complex_fn\");\n        assert!(func.generics.is_some());\n\n        let generics = func.generics.as_ref().unwrap();\n        assert_eq!(generics.params.len(), 2);\n        assert_eq!(generics.params[0].name, \"T\");\n        assert_eq!(generics.params[1].name, \"U\");\n\n        // Check where clause\n        assert!(generics.where_clause.is_some());\n        let where_clause = generics.where_clause.as_ref().unwrap();\n        assert_eq!(where_clause.constraints.len(), 2);\n\n        // T: Clone + Debug\n        assert_eq!(where_clause.constraints[0].type_name, \"T\");\n        assert_eq!(where_clause.constraints[0].bounds.len(), 2);\n        assert_eq!(where_clause.constraints[0].bounds[0].trait_name, \"Clone\");\n        assert_eq!(where_clause.constraints[0].bounds[1].trait_name, \"Debug\");\n\n        // U: Default\n        assert_eq!(where_clause.constraints[1].type_name, \"U\");\n        assert_eq!(where_clause.constraints[1].bounds.len(), 1);\n        assert_eq!(where_clause.constraints[1].bounds[0].trait_name, \"Default\");\n    } else {\n        panic!(\"Expected function declaration\");\n    }\n}\n\n#[test]\nfn test_empty_generic_params() {\n    let mut tokens = create_token_stream(vec![TokenType::Less, TokenType::Greater]);\n\n    let result = parse_generic_params(\u0026mut tokens).unwrap();\n    assert!(result.is_some());\n\n    let generics = result.unwrap();\n    assert_eq!(generics.params.len(), 0);\n    assert!(generics.where_clause.is_none());\n}\n\n#[test]\nfn test_trailing_comma_in_generic_params() {\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"U\".to_string()),\n        TokenType::Comma,\n        TokenType::Greater,\n    ]);\n\n    let result = parse_generic_params(\u0026mut tokens).unwrap();\n    assert!(result.is_some());\n\n    let generics = result.unwrap();\n    assert_eq!(generics.params.len(), 2);\n    assert_eq!(generics.params[0].name, \"T\");\n    assert_eq!(generics.params[1].name, \"U\");\n}\n\n#[test]\nfn test_trailing_comma_in_where_clause() {\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Greater,\n        TokenType::Where,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"Clone\".to_string()),\n        TokenType::Comma,\n    ]);\n\n    let result = parse_generic_params(\u0026mut tokens).unwrap();\n    assert!(result.is_some());\n\n    let generics = result.unwrap();\n    assert!(generics.where_clause.is_some());\n\n    let where_clause = generics.where_clause.unwrap();\n    assert_eq!(where_clause.constraints.len(), 1);\n    assert_eq!(where_clause.constraints[0].type_name, \"T\");\n}\n\n#[test]\nfn test_generic_parsing_errors() {\n    // Missing closing bracket\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Eof,\n    ]);\n\n    let result = parse_generic_params(\u0026mut tokens);\n    assert!(result.is_err());\n\n    // Invalid lifetime (missing name)\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Apostrophe,\n        TokenType::Greater,\n    ]);\n\n    let result = parse_generic_params(\u0026mut tokens);\n    assert!(result.is_err());\n\n    // Missing colon in where clause\n    let mut tokens = create_token_stream(vec![\n        TokenType::Less,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Greater,\n        TokenType::Where,\n        TokenType::Identifier(\"T\".to_string()),\n        TokenType::Identifier(\"Clone\".to_string()),\n    ]);\n\n    let result = parse_generic_params(\u0026mut tokens);\n    assert!(result.is_err());\n}\n","traces":[{"line":19,"address":[],"length":0,"stats":{"Line":21}},{"line":20,"address":[],"length":0,"stats":{"Line":21}},{"line":21,"address":[],"length":0,"stats":{"Line":21}}],"covered":3,"coverable":3},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","tests","test_phase_2_8_3_advanced_patterns.rs"],"content":"//! Tests for Phase 2.8.3: Advanced Pattern Matching\n//!\n//! This module tests advanced pattern matching features including:\n//! - Range patterns (1..=10)\n//! - Slice patterns ([head, tail @ ..])  \n//! - Or patterns (Some(x) | None)\n//! - Guard patterns (x if x \u003e 0)\n//! - Binding patterns (name @ pattern)\n\nuse ferra_parser::{\n    ast::{Arena, Pattern},\n    pratt::parser::PrattParser,\n    token::{stream::VecTokenStream, TokenType},\n};\n\nfn create_token_stream(token_types: Vec\u003cTokenType\u003e) -\u003e VecTokenStream {\n    VecTokenStream::from_token_types(token_types)\n}\n\n#[test]\nfn test_range_pattern_inclusive() {\n    let arena = Arena::new();\n\n    // Test 1..=10\n    let tokens = create_token_stream(vec![\n        TokenType::IntegerLiteral(1),\n        TokenType::DotDotEqual,\n        TokenType::IntegerLiteral(10),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::Range(range) =\u003e {\n                assert!(range.inclusive);\n                assert!(range.start.is_some());\n                assert!(range.end.is_some());\n            }\n            _ =\u003e panic!(\"Expected range pattern, got {:?}\", pattern),\n        }\n    }\n}\n\n#[test]\nfn test_range_pattern_exclusive() {\n    let arena = Arena::new();\n\n    // Test 1..10\n    let tokens = create_token_stream(vec![\n        TokenType::IntegerLiteral(1),\n        TokenType::DotDot,\n        TokenType::IntegerLiteral(10),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::Range(range) =\u003e {\n                assert!(!range.inclusive);\n                assert!(range.start.is_some());\n                assert!(range.end.is_some());\n            }\n            _ =\u003e panic!(\"Expected range pattern, got {:?}\", pattern),\n        }\n    }\n}\n\n#[test]\nfn test_slice_pattern_empty() {\n    let arena = Arena::new();\n\n    // Test []\n    let tokens = create_token_stream(vec![\n        TokenType::LeftBracket,\n        TokenType::RightBracket,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::Slice(slice) =\u003e {\n                assert_eq!(slice.prefix.len(), 0);\n                assert!(slice.rest.is_none());\n                assert_eq!(slice.suffix.len(), 0);\n            }\n            _ =\u003e panic!(\"Expected slice pattern, got {:?}\", pattern),\n        }\n    }\n}\n\n#[test]\nfn test_or_pattern_simple() {\n    let arena = Arena::new();\n\n    // Test Some | None\n    let tokens = create_token_stream(vec![\n        TokenType::Identifier(\"Some\".to_string()),\n        TokenType::Pipe,\n        TokenType::Identifier(\"None\".to_string()),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::Or(or_pattern) =\u003e {\n                assert_eq!(or_pattern.patterns.len(), 2);\n            }\n            _ =\u003e panic!(\"Expected or pattern, got {:?}\", pattern),\n        }\n    }\n}\n\n#[test]\nfn test_guard_pattern_simple() {\n    let arena = Arena::new();\n\n    // Test x if x \u003e 0 (simplified)\n    let tokens = create_token_stream(vec![\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::If,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Greater,\n        TokenType::IntegerLiteral(0),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::Guard(guard) =\u003e match guard.pattern.as_ref() {\n                Pattern::Identifier(name) =\u003e assert_eq!(name, \"x\"),\n                _ =\u003e panic!(\"Expected identifier pattern for guard base\"),\n            },\n            _ =\u003e panic!(\"Expected guard pattern, got {:?}\", pattern),\n        }\n    }\n}\n\n#[test]\nfn test_binding_pattern_simple() {\n    let arena = Arena::new();\n\n    // Test name @ value\n    let tokens = create_token_stream(vec![\n        TokenType::Identifier(\"name\".to_string()),\n        TokenType::At,\n        TokenType::Identifier(\"value\".to_string()),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::Binding(binding) =\u003e {\n                assert_eq!(binding.name, \"name\");\n                match binding.pattern.as_ref() {\n                    Pattern::Identifier(name) =\u003e assert_eq!(name, \"value\"),\n                    _ =\u003e panic!(\"Expected identifier pattern for binding\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected binding pattern, got {:?}\", pattern),\n        }\n    }\n}\n\n#[test]\nfn test_complex_or_patterns() {\n    let arena = Arena::new();\n\n    // Test 1 | 2 | 3\n    let tokens = create_token_stream(vec![\n        TokenType::IntegerLiteral(1),\n        TokenType::Pipe,\n        TokenType::IntegerLiteral(2),\n        TokenType::Pipe,\n        TokenType::IntegerLiteral(3),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::Or(or_pattern) =\u003e {\n                assert_eq!(or_pattern.patterns.len(), 3);\n            }\n            _ =\u003e panic!(\"Expected or pattern, got {:?}\", pattern),\n        }\n    }\n}\n\n#[test]\nfn test_pattern_parsing_errors() {\n    let arena = Arena::new();\n\n    // Test invalid slice pattern: [,]\n    let tokens = create_token_stream(vec![\n        TokenType::LeftBracket,\n        TokenType::Comma,\n        TokenType::RightBracket,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n    let result = parser.parse_pattern();\n    assert!(result.is_err()); // This should be invalid\n}\n\n#[test]\nfn test_advanced_pattern_integration() {\n    let arena = Arena::new();\n\n    // Test that advanced patterns work with existing patterns\n    // Test simple range in data class field\n    let tokens = create_token_stream(vec![\n        TokenType::Identifier(\"Person\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"age\".to_string()),\n        TokenType::Colon,\n        TokenType::IntegerLiteral(18),\n        TokenType::DotDotEqual,\n        TokenType::IntegerLiteral(65),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_pattern();\n    assert!(result.is_ok());\n\n    if let Ok(pattern) = result {\n        match pattern {\n            Pattern::DataClass(data_class) =\u003e {\n                assert_eq!(data_class.name, \"Person\");\n                assert_eq!(data_class.fields.len(), 1);\n                assert_eq!(data_class.fields[0].name, \"age\");\n                assert!(data_class.fields[0].pattern.is_some());\n            }\n            _ =\u003e panic!(\"Expected data class pattern, got {:?}\", pattern),\n        }\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":9}},{"line":17,"address":[],"length":0,"stats":{"Line":9}}],"covered":2,"coverable":2},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","tests","test_phase_2_8_4_macro_system.rs"],"content":"//! Tests for Phase 2.8.4: Macro System Foundation\n//!\n//! This module tests basic macro system functionality including:\n//! - Macro invocation parsing (println!(\"hello\"))\n//! - Token tree parsing for macro arguments\n//! - Basic macro definition parsing framework\n//! - Integration with expression parsing\n\nuse ferra_parser::{\n    ast::{Arena, Expression, GroupDelimiter, TokenTree},\n    macro_parser::parser::MacroParser,\n    pratt::parser::PrattParser,\n    token::{stream::VecTokenStream, TokenType},\n};\n\nfn create_token_stream(token_types: Vec\u003cTokenType\u003e) -\u003e VecTokenStream {\n    VecTokenStream::from_token_types(token_types)\n}\n\n#[test]\nfn test_simple_macro_invocation() {\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Bang,\n        TokenType::LeftParen,\n        TokenType::StringLiteral(\"Hello, world!\".to_string()),\n        TokenType::RightParen,\n        TokenType::Eof,\n    ]);\n    let mut parser = MacroParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_macro_invocation(\"println\".to_string());\n    assert!(result.is_ok());\n\n    if let Ok(macro_invocation) = result {\n        assert_eq!(macro_invocation.name, \"println\");\n        assert_eq!(macro_invocation.arguments.len(), 1);\n\n        // Check the token group\n        if let TokenTree::Group(group) = \u0026macro_invocation.arguments[0] {\n            assert!(matches!(group.delimiter, GroupDelimiter::Parentheses));\n            assert_eq!(group.tokens.len(), 1);\n\n            if let TokenTree::Token(token) = \u0026group.tokens[0] {\n                if let TokenType::StringLiteral(s) = \u0026token.token_type {\n                    assert_eq!(s, \"Hello, world!\");\n                }\n            }\n        }\n    }\n}\n\n#[test]\nfn test_macro_invocation_with_multiple_arguments() {\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Bang,\n        TokenType::LeftParen,\n        TokenType::StringLiteral(\"Value: {}\".to_string()),\n        TokenType::Comma,\n        TokenType::IntegerLiteral(42),\n        TokenType::RightParen,\n        TokenType::Eof,\n    ]);\n    let mut parser = MacroParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_macro_invocation(\"println\".to_string());\n    assert!(result.is_ok());\n\n    if let Ok(macro_invocation) = result {\n        assert_eq!(macro_invocation.name, \"println\");\n        assert_eq!(macro_invocation.arguments.len(), 1);\n\n        if let TokenTree::Group(group) = \u0026macro_invocation.arguments[0] {\n            assert_eq!(group.tokens.len(), 3); // string, comma, integer\n        }\n    }\n}\n\n#[test]\nfn test_macro_invocation_with_braces() {\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Bang,\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Equal,\n        TokenType::IntegerLiteral(10),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = MacroParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_macro_invocation(\"let_var\".to_string());\n    assert!(result.is_ok());\n\n    if let Ok(macro_invocation) = result {\n        assert_eq!(macro_invocation.name, \"let_var\");\n\n        if let TokenTree::Group(group) = \u0026macro_invocation.arguments[0] {\n            assert!(matches!(group.delimiter, GroupDelimiter::Braces));\n            assert_eq!(group.tokens.len(), 3); // identifier, equal, integer\n        }\n    }\n}\n\n#[test]\nfn test_macro_invocation_with_brackets() {\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Bang,\n        TokenType::LeftBracket,\n        TokenType::IntegerLiteral(1),\n        TokenType::Comma,\n        TokenType::IntegerLiteral(2),\n        TokenType::Comma,\n        TokenType::IntegerLiteral(3),\n        TokenType::RightBracket,\n        TokenType::Eof,\n    ]);\n    let mut parser = MacroParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_macro_invocation(\"vec\".to_string());\n    assert!(result.is_ok());\n\n    if let Ok(macro_invocation) = result {\n        assert_eq!(macro_invocation.name, \"vec\");\n\n        if let TokenTree::Group(group) = \u0026macro_invocation.arguments[0] {\n            assert!(matches!(group.delimiter, GroupDelimiter::Brackets));\n            assert_eq!(group.tokens.len(), 5); // 1, comma, 2, comma, 3\n        }\n    }\n}\n\n#[test]\nfn test_nested_token_groups() {\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Bang,\n        TokenType::LeftBrace,\n        TokenType::LeftParen,\n        TokenType::IntegerLiteral(1),\n        TokenType::Plus,\n        TokenType::IntegerLiteral(2),\n        TokenType::RightParen,\n        TokenType::Star,\n        TokenType::IntegerLiteral(3),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = MacroParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_macro_invocation(\"calculate\".to_string());\n    assert!(result.is_ok());\n\n    if let Ok(macro_invocation) = result {\n        assert_eq!(macro_invocation.name, \"calculate\");\n\n        if let TokenTree::Group(group) = \u0026macro_invocation.arguments[0] {\n            assert!(matches!(group.delimiter, GroupDelimiter::Braces));\n            assert_eq!(group.tokens.len(), 3); // nested group, star, integer\n\n            // Check the nested group\n            if let TokenTree::Group(nested_group) = \u0026group.tokens[0] {\n                assert!(matches!(\n                    nested_group.delimiter,\n                    GroupDelimiter::Parentheses\n                ));\n                assert_eq!(nested_group.tokens.len(), 3); // 1, plus, 2\n            }\n        }\n    }\n}\n\n#[test]\nfn test_empty_macro_invocation() {\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Bang,\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::Eof,\n    ]);\n    let mut parser = MacroParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_macro_invocation(\"empty\".to_string());\n    assert!(result.is_ok());\n\n    if let Ok(macro_invocation) = result {\n        assert_eq!(macro_invocation.name, \"empty\");\n\n        if let TokenTree::Group(group) = \u0026macro_invocation.arguments[0] {\n            assert!(matches!(group.delimiter, GroupDelimiter::Parentheses));\n            assert_eq!(group.tokens.len(), 0);\n        }\n    }\n}\n\n#[test]\nfn test_macro_definition_basic() {\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"$x\".to_string()),\n        TokenType::FatArrow,\n        TokenType::Identifier(\"$x\".to_string()),\n        TokenType::Plus,\n        TokenType::IntegerLiteral(1),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = MacroParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_macro_definition(\"increment\".to_string());\n    assert!(result.is_ok());\n\n    if let Ok(macro_def) = result {\n        assert_eq!(macro_def.name, \"increment\");\n        assert_eq!(macro_def.rules.len(), 1);\n\n        let rule = \u0026macro_def.rules[0];\n        assert_eq!(rule.pattern.len(), 1); // $x\n        assert_eq!(rule.replacement.len(), 3); // $x, +, 1\n    }\n}\n\n#[test]\nfn test_macro_definition_multiple_rules() {\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"$x\".to_string()),\n        TokenType::FatArrow,\n        TokenType::Identifier(\"$x\".to_string()),\n        TokenType::Plus,\n        TokenType::IntegerLiteral(1),\n        TokenType::Semicolon,\n        TokenType::Identifier(\"$x\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"$y\".to_string()),\n        TokenType::FatArrow,\n        TokenType::Identifier(\"$x\".to_string()),\n        TokenType::Plus,\n        TokenType::Identifier(\"$y\".to_string()),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = MacroParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_macro_definition(\"add\".to_string());\n    assert!(result.is_ok());\n\n    if let Ok(macro_def) = result {\n        assert_eq!(macro_def.name, \"add\");\n        assert_eq!(macro_def.rules.len(), 2);\n\n        // First rule: $x =\u003e $x + 1\n        let rule1 = \u0026macro_def.rules[0];\n        assert_eq!(rule1.pattern.len(), 1);\n        assert_eq!(rule1.replacement.len(), 3);\n\n        // Second rule: $x, $y =\u003e $x + $y\n        let rule2 = \u0026macro_def.rules[1];\n        assert_eq!(rule2.pattern.len(), 3); // $x, comma, $y\n        assert_eq!(rule2.replacement.len(), 3); // $x, +, $y\n    }\n}\n\n#[test]\nfn test_macro_in_expression() {\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Identifier(\"println\".to_string()),\n        TokenType::Bang,\n        TokenType::LeftParen,\n        TokenType::StringLiteral(\"hello\".to_string()),\n        TokenType::RightParen,\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expression) = result {\n        match expression {\n            Expression::Macro(macro_invocation) =\u003e {\n                assert_eq!(macro_invocation.name, \"println\");\n                assert_eq!(macro_invocation.arguments.len(), 1);\n            }\n            _ =\u003e panic!(\"Expected macro invocation expression, got {:?}\", expression),\n        }\n    }\n}\n\n#[test]\nfn test_macro_in_complex_expression() {\n    let arena = Arena::new();\n    let tokens = create_token_stream(vec![\n        TokenType::Identifier(\"format\".to_string()),\n        TokenType::Bang,\n        TokenType::LeftParen,\n        TokenType::StringLiteral(\"Result: {}\".to_string()),\n        TokenType::Comma,\n        TokenType::IntegerLiteral(42),\n        TokenType::RightParen,\n        TokenType::Plus,\n        TokenType::StringLiteral(\" done\".to_string()),\n        TokenType::Eof,\n    ]);\n    let mut parser = PrattParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_expression(0);\n    assert!(result.is_ok());\n\n    if let Ok(expression) = result {\n        match expression {\n            Expression::Binary(binary_expr) =\u003e {\n                // Left side should be macro invocation\n                match binary_expr.left.as_ref() {\n                    Expression::Macro(macro_invocation) =\u003e {\n                        assert_eq!(macro_invocation.name, \"format\");\n                    }\n                    _ =\u003e panic!(\"Expected macro invocation on left side\"),\n                }\n\n                // Right side should be string literal\n                match binary_expr.right.as_ref() {\n                    Expression::Literal(_) =\u003e {}\n                    _ =\u003e panic!(\"Expected literal on right side\"),\n                }\n            }\n            _ =\u003e panic!(\"Expected binary expression, got {:?}\", expression),\n        }\n    }\n}\n\n#[test]\nfn test_macro_parsing_errors() {\n    let arena = Arena::new();\n\n    // Test missing closing delimiter\n    let tokens = create_token_stream(vec![\n        TokenType::Bang,\n        TokenType::LeftParen,\n        TokenType::StringLiteral(\"hello\".to_string()),\n        TokenType::Eof,\n    ]);\n    let mut parser = MacroParser::new(\u0026arena, tokens);\n    let result = parser.parse_macro_invocation(\"println\".to_string());\n    assert!(result.is_err());\n\n    // Test missing bang\n    let tokens = create_token_stream(vec![\n        TokenType::LeftParen,\n        TokenType::StringLiteral(\"hello\".to_string()),\n        TokenType::RightParen,\n        TokenType::Eof,\n    ]);\n    let mut parser = MacroParser::new(\u0026arena, tokens);\n    let result = parser.parse_macro_invocation(\"println\".to_string());\n    assert!(result.is_err());\n\n    // Test missing fat arrow in macro definition\n    let tokens = create_token_stream(vec![\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"$x\".to_string()),\n        TokenType::Identifier(\"$x\".to_string()),\n        TokenType::Plus,\n        TokenType::IntegerLiteral(1),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = MacroParser::new(\u0026arena, tokens);\n    let result = parser.parse_macro_definition(\"increment\".to_string());\n    assert!(result.is_err());\n}\n\n#[test]\nfn test_macro_integration_comprehensive() {\n    let arena = Arena::new();\n\n    // Test various macro syntax combinations\n    let test_cases = vec![\n        (\n            \"println\",\n            vec![\n                TokenType::Bang,\n                TokenType::LeftParen,\n                TokenType::StringLiteral(\"test\".to_string()),\n                TokenType::RightParen,\n            ],\n        ),\n        (\n            \"vec\",\n            vec![\n                TokenType::Bang,\n                TokenType::LeftBracket,\n                TokenType::IntegerLiteral(1),\n                TokenType::Comma,\n                TokenType::IntegerLiteral(2),\n                TokenType::RightBracket,\n            ],\n        ),\n        (\n            \"block\",\n            vec![\n                TokenType::Bang,\n                TokenType::LeftBrace,\n                TokenType::Identifier(\"x\".to_string()),\n                TokenType::Equal,\n                TokenType::IntegerLiteral(5),\n                TokenType::RightBrace,\n            ],\n        ),\n    ];\n\n    for (macro_name, mut token_types) in test_cases {\n        token_types.push(TokenType::Eof);\n        let tokens = create_token_stream(token_types);\n        let mut parser = MacroParser::new(\u0026arena, tokens);\n\n        let result = parser.parse_macro_invocation(macro_name.to_string());\n        assert!(result.is_ok(), \"Failed to parse macro: {}\", macro_name);\n\n        if let Ok(macro_invocation) = result {\n            assert_eq!(macro_invocation.name, macro_name);\n            assert_eq!(macro_invocation.arguments.len(), 1);\n        }\n    }\n}\n","traces":[{"line":16,"address":[],"length":0,"stats":{"Line":16}},{"line":17,"address":[],"length":0,"stats":{"Line":16}}],"covered":2,"coverable":2},{"path":["/","Users","amritdoll","Projects","ferra-lang","crates","ferra_parser","tests","test_statement_parsing.rs"],"content":"use ferra_parser::{\n    ast::{Arena, Expression, Item, Literal, Statement, Type},\n    statement::parser::StatementParser,\n    token::{TokenType, VecTokenStream},\n};\n\n// Helper functions\nfn create_test_arena() -\u003e Arena {\n    Arena::new()\n}\n\nfn create_token_stream(token_types: Vec\u003cTokenType\u003e) -\u003e VecTokenStream {\n    VecTokenStream::from_token_types(token_types)\n}\n\n// Phase 2.3.1: Declaration Statements Tests\n\n#[test]\nfn test_variable_declarations() {\n    let arena = create_test_arena();\n\n    // Test: let x = 42\n    let tokens = create_token_stream(vec![\n        TokenType::Let,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Equal,\n        TokenType::IntegerLiteral(42),\n        TokenType::Eof,\n    ]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_statement();\n    assert!(result.is_ok());\n\n    if let Ok(Statement::VariableDecl(var_decl)) = result {\n        assert_eq!(var_decl.name, \"x\");\n        assert!(!var_decl.is_mutable);\n        assert!(var_decl.var_type.is_none());\n        assert!(var_decl.initializer.is_some());\n        if let Some(Expression::Literal(Literal::Integer(42))) = \u0026var_decl.initializer {\n            // Success\n        } else {\n            panic!(\"Expected integer literal 42\");\n        }\n    } else {\n        panic!(\"Expected variable declaration\");\n    }\n\n    // Test: var mut_x: i32 = 10\n    let tokens = create_token_stream(vec![\n        TokenType::Var,\n        TokenType::Identifier(\"mut_x\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"i32\".to_string()),\n        TokenType::Equal,\n        TokenType::IntegerLiteral(10),\n        TokenType::Eof,\n    ]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_statement();\n    assert!(result.is_ok());\n\n    if let Ok(Statement::VariableDecl(var_decl)) = result {\n        assert_eq!(var_decl.name, \"mut_x\");\n        assert!(var_decl.is_mutable);\n        assert!(var_decl.var_type.is_some());\n        if let Some(Type::Identifier(type_name)) = \u0026var_decl.var_type {\n            assert_eq!(type_name, \"i32\");\n        } else {\n            panic!(\"Expected i32 type\");\n        }\n    } else {\n        panic!(\"Expected variable declaration\");\n    }\n}\n\n#[test]\nfn test_function_declarations() {\n    let arena = create_test_arena();\n\n    // Test: fn hello() { }\n    let tokens = create_token_stream(vec![\n        TokenType::Fn,\n        TokenType::Identifier(\"hello\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_item();\n    assert!(result.is_ok());\n\n    if let Ok(Item::FunctionDecl(func_decl)) = result {\n        assert_eq!(func_decl.name, \"hello\");\n        assert!(!func_decl.is_async);\n        assert!(!func_decl.is_extern);\n        assert!(func_decl.parameters.is_empty());\n        assert!(func_decl.return_type.is_none());\n        assert!(func_decl.body.is_some());\n    } else {\n        panic!(\"Expected function declaration\");\n    }\n\n    // Test: async fn calculate(x: i32, y: i32) -\u003e i32 { }\n    let tokens = create_token_stream(vec![\n        TokenType::Async,\n        TokenType::Fn,\n        TokenType::Identifier(\"calculate\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"i32\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"y\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"i32\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"i32\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_item();\n    assert!(result.is_ok());\n\n    if let Ok(Item::FunctionDecl(func_decl)) = result {\n        assert_eq!(func_decl.name, \"calculate\");\n        assert!(func_decl.is_async);\n        assert_eq!(func_decl.parameters.len(), 2);\n        assert_eq!(func_decl.parameters[0].name, \"x\");\n        assert_eq!(func_decl.parameters[1].name, \"y\");\n        assert!(func_decl.return_type.is_some());\n        if let Some(Type::Identifier(return_type)) = \u0026func_decl.return_type {\n            assert_eq!(return_type, \"i32\");\n        }\n    } else {\n        panic!(\"Expected async function declaration\");\n    }\n}\n\n#[test]\nfn test_data_class_declarations() {\n    let arena = create_test_arena();\n\n    // Test: data Person { name: String, age: i32 }\n    let tokens = create_token_stream(vec![\n        TokenType::Data,\n        TokenType::Identifier(\"Person\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Identifier(\"name\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"String\".to_string()),\n        TokenType::Comma,\n        TokenType::Identifier(\"age\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"i32\".to_string()),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_item();\n    assert!(result.is_ok());\n\n    if let Ok(Item::DataClassDecl(data_class)) = result {\n        assert_eq!(data_class.name, \"Person\");\n        assert_eq!(data_class.fields.len(), 2);\n        assert_eq!(data_class.fields[0].name, \"name\");\n        assert_eq!(data_class.fields[1].name, \"age\");\n        if let Type::Identifier(field_type) = \u0026data_class.fields[0].field_type {\n            assert_eq!(field_type, \"String\");\n        }\n        if let Type::Identifier(field_type) = \u0026data_class.fields[1].field_type {\n            assert_eq!(field_type, \"i32\");\n        }\n    } else {\n        panic!(\"Expected data class declaration\");\n    }\n}\n\n#[test]\nfn test_extern_blocks() {\n    let arena = create_test_arena();\n\n    // Test: extern \"C\" { fn printf(format: char) -\u003e i32; static errno: i32; }\n    let tokens = create_token_stream(vec![\n        TokenType::Extern,\n        TokenType::StringLiteral(\"C\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::Fn,\n        TokenType::Identifier(\"printf\".to_string()),\n        TokenType::LeftParen,\n        TokenType::Identifier(\"format\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"char\".to_string()),\n        TokenType::RightParen,\n        TokenType::Arrow,\n        TokenType::Identifier(\"i32\".to_string()),\n        TokenType::Semicolon,\n        TokenType::Static,\n        TokenType::Identifier(\"errno\".to_string()),\n        TokenType::Colon,\n        TokenType::Identifier(\"i32\".to_string()),\n        TokenType::Semicolon,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_item();\n    assert!(result.is_ok());\n\n    if let Ok(Item::ExternBlock(extern_block)) = result {\n        assert_eq!(extern_block.abi, \"C\");\n        assert_eq!(extern_block.items.len(), 2);\n        // More detailed checks could be added for the extern items\n    } else {\n        panic!(\"Expected extern block\");\n    }\n}\n\n#[test]\nfn test_modifiers() {\n    let arena = create_test_arena();\n\n    // Test: pub fn public_function() { }\n    let tokens = create_token_stream(vec![\n        TokenType::Pub,\n        TokenType::Fn,\n        TokenType::Identifier(\"public_function\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_item();\n    assert!(result.is_ok());\n\n    if let Ok(Item::FunctionDecl(func_decl)) = result {\n        assert_eq!(func_decl.name, \"public_function\");\n        assert!(func_decl.modifiers.is_public);\n        assert!(!func_decl.modifiers.is_unsafe);\n    } else {\n        panic!(\"Expected public function declaration\");\n    }\n}\n\n// Phase 2.3.2: Control Flow Statements Tests\n\n#[test]\nfn test_if_statement() {\n    let arena = create_test_arena();\n\n    // Test: if true { }\n    let tokens = create_token_stream(vec![\n        TokenType::If,\n        TokenType::BooleanLiteral(true),\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_statement();\n    assert!(result.is_ok());\n\n    if let Ok(Statement::If(if_stmt)) = result {\n        if let Expression::Literal(Literal::Boolean(true)) = \u0026if_stmt.condition {\n            // Success\n        } else {\n            panic!(\"Expected boolean condition\");\n        }\n        assert!(if_stmt.else_block.is_none());\n    } else {\n        panic!(\"Expected if statement\");\n    }\n}\n\n#[test]\nfn test_while_statement() {\n    let arena = create_test_arena();\n\n    // Test: while true { }\n    let tokens = create_token_stream(vec![\n        TokenType::While,\n        TokenType::BooleanLiteral(true),\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_statement();\n    assert!(result.is_ok());\n\n    if let Ok(Statement::While(while_stmt)) = result {\n        if let Expression::Literal(Literal::Boolean(true)) = \u0026while_stmt.condition {\n            // Success\n        } else {\n            panic!(\"Expected boolean condition\");\n        }\n    } else {\n        panic!(\"Expected while statement\");\n    }\n}\n\n#[test]\nfn test_for_statement() {\n    let arena = create_test_arena();\n\n    // Test: for item in collection { }\n    let tokens = create_token_stream(vec![\n        TokenType::For,\n        TokenType::Identifier(\"item\".to_string()),\n        TokenType::In,\n        TokenType::Identifier(\"collection\".to_string()),\n        TokenType::LeftBrace,\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_statement();\n    assert!(result.is_ok());\n\n    if let Ok(Statement::For(for_stmt)) = result {\n        assert_eq!(for_stmt.variable, \"item\");\n        if let Expression::Identifier(iterable) = \u0026for_stmt.iterable {\n            assert_eq!(iterable, \"collection\");\n        } else {\n            panic!(\"Expected identifier for iterable\");\n        }\n    } else {\n        panic!(\"Expected for statement\");\n    }\n}\n\n#[test]\nfn test_return_statement() {\n    let arena = create_test_arena();\n\n    // Test: return 42\n    let tokens = create_token_stream(vec![\n        TokenType::Return,\n        TokenType::IntegerLiteral(42),\n        TokenType::Eof,\n    ]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_statement();\n    assert!(result.is_ok());\n\n    if let Ok(Statement::Return(return_stmt)) = result {\n        assert!(return_stmt.value.is_some());\n        if let Some(Expression::Literal(Literal::Integer(42))) = \u0026return_stmt.value {\n            // Success\n        } else {\n            panic!(\"Expected integer return value\");\n        }\n    } else {\n        panic!(\"Expected return statement\");\n    }\n}\n\n#[test]\nfn test_break_continue_statements() {\n    let arena = create_test_arena();\n\n    // Test: break\n    let tokens = create_token_stream(vec![TokenType::Break, TokenType::Eof]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_statement();\n    assert!(result.is_ok());\n\n    if let Ok(Statement::Break(_)) = result {\n        // Success\n    } else {\n        panic!(\"Expected break statement\");\n    }\n\n    // Test: continue\n    let tokens = create_token_stream(vec![TokenType::Continue, TokenType::Eof]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_statement();\n    assert!(result.is_ok());\n\n    if let Ok(Statement::Continue(_)) = result {\n        // Success\n    } else {\n        panic!(\"Expected continue statement\");\n    }\n}\n\n// Phase 2.3.3: Expression and Block Statements Tests\n\n#[test]\nfn test_expression_statement() {\n    let arena = create_test_arena();\n\n    // Test: 42;\n    let tokens = create_token_stream(vec![\n        TokenType::IntegerLiteral(42),\n        TokenType::Semicolon,\n        TokenType::Eof,\n    ]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_statement();\n    assert!(result.is_ok());\n\n    if let Ok(Statement::Expression(expr)) = result {\n        if let Expression::Literal(Literal::Integer(42)) = expr {\n            // Success\n        } else {\n            panic!(\"Expected integer literal expression\");\n        }\n    } else {\n        panic!(\"Expected expression statement\");\n    }\n}\n\n#[test]\nfn test_block_statements() {\n    let arena = create_test_arena();\n\n    // Test: { let x = 42; }\n    let tokens = create_token_stream(vec![\n        TokenType::LeftBrace,\n        TokenType::Let,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Equal,\n        TokenType::IntegerLiteral(42),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_statement();\n    assert!(result.is_ok());\n\n    if let Ok(Statement::Block(block)) = result {\n        assert!(block.is_braced);\n        assert_eq!(block.statements.len(), 1);\n        if let Statement::VariableDecl(var_decl) = \u0026block.statements[0] {\n            assert_eq!(var_decl.name, \"x\");\n        } else {\n            panic!(\"Expected variable declaration in block\");\n        }\n    } else {\n        panic!(\"Expected block statement\");\n    }\n}\n\n#[test]\nfn test_compilation_unit() {\n    let arena = create_test_arena();\n\n    // Test complete program: fn main() { let x = 42; }\n    let tokens = create_token_stream(vec![\n        TokenType::Fn,\n        TokenType::Identifier(\"main\".to_string()),\n        TokenType::LeftParen,\n        TokenType::RightParen,\n        TokenType::LeftBrace,\n        TokenType::Let,\n        TokenType::Identifier(\"x\".to_string()),\n        TokenType::Equal,\n        TokenType::IntegerLiteral(42),\n        TokenType::RightBrace,\n        TokenType::Eof,\n    ]);\n    let mut parser = StatementParser::new(\u0026arena, tokens);\n\n    let result = parser.parse_compilation_unit();\n    assert!(result.is_ok());\n\n    if let Ok(compilation_unit) = result {\n        assert_eq!(compilation_unit.items.len(), 1);\n        if let Item::FunctionDecl(func_decl) = \u0026compilation_unit.items[0] {\n            assert_eq!(func_decl.name, \"main\");\n            assert!(func_decl.body.is_some());\n            if let Some(body) = \u0026func_decl.body {\n                assert_eq!(body.statements.len(), 1);\n            }\n        } else {\n            panic!(\"Expected function declaration\");\n        }\n    } else {\n        panic!(\"Expected compilation unit\");\n    }\n}\n","traces":[{"line":8,"address":[],"length":0,"stats":{"Line":13}},{"line":9,"address":[],"length":0,"stats":{"Line":13}},{"line":12,"address":[],"length":0,"stats":{"Line":16}},{"line":13,"address":[],"length":0,"stats":{"Line":16}}],"covered":4,"coverable":4}]};
        var previousData = null;
    </script>
    <script crossorigin>/** @license React v16.13.1
 * react.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */
'use strict';(function(d,r){"object"===typeof exports&&"undefined"!==typeof module?r(exports):"function"===typeof define&&define.amd?define(["exports"],r):(d=d||self,r(d.React={}))})(this,function(d){function r(a){for(var b="https://reactjs.org/docs/error-decoder.html?invariant="+a,c=1;c<arguments.length;c++)b+="&args[]="+encodeURIComponent(arguments[c]);return"Minified React error #"+a+"; visit "+b+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}
function w(a,b,c){this.props=a;this.context=b;this.refs=ba;this.updater=c||ca}function da(){}function L(a,b,c){this.props=a;this.context=b;this.refs=ba;this.updater=c||ca}function ea(a,b,c){var g,e={},fa=null,d=null;if(null!=b)for(g in void 0!==b.ref&&(d=b.ref),void 0!==b.key&&(fa=""+b.key),b)ha.call(b,g)&&!ia.hasOwnProperty(g)&&(e[g]=b[g]);var h=arguments.length-2;if(1===h)e.children=c;else if(1<h){for(var k=Array(h),f=0;f<h;f++)k[f]=arguments[f+2];e.children=k}if(a&&a.defaultProps)for(g in h=a.defaultProps,
h)void 0===e[g]&&(e[g]=h[g]);return{$$typeof:x,type:a,key:fa,ref:d,props:e,_owner:M.current}}function va(a,b){return{$$typeof:x,type:a.type,key:b,ref:a.ref,props:a.props,_owner:a._owner}}function N(a){return"object"===typeof a&&null!==a&&a.$$typeof===x}function wa(a){var b={"=":"=0",":":"=2"};return"$"+(""+a).replace(/[=:]/g,function(a){return b[a]})}function ja(a,b,c,g){if(C.length){var e=C.pop();e.result=a;e.keyPrefix=b;e.func=c;e.context=g;e.count=0;return e}return{result:a,keyPrefix:b,func:c,
context:g,count:0}}function ka(a){a.result=null;a.keyPrefix=null;a.func=null;a.context=null;a.count=0;10>C.length&&C.push(a)}function O(a,b,c,g){var e=typeof a;if("undefined"===e||"boolean"===e)a=null;var d=!1;if(null===a)d=!0;else switch(e){case "string":case "number":d=!0;break;case "object":switch(a.$$typeof){case x:case xa:d=!0}}if(d)return c(g,a,""===b?"."+P(a,0):b),1;d=0;b=""===b?".":b+":";if(Array.isArray(a))for(var f=0;f<a.length;f++){e=a[f];var h=b+P(e,f);d+=O(e,h,c,g)}else if(null===a||
"object"!==typeof a?h=null:(h=la&&a[la]||a["@@iterator"],h="function"===typeof h?h:null),"function"===typeof h)for(a=h.call(a),f=0;!(e=a.next()).done;)e=e.value,h=b+P(e,f++),d+=O(e,h,c,g);else if("object"===e)throw c=""+a,Error(r(31,"[object Object]"===c?"object with keys {"+Object.keys(a).join(", ")+"}":c,""));return d}function Q(a,b,c){return null==a?0:O(a,"",b,c)}function P(a,b){return"object"===typeof a&&null!==a&&null!=a.key?wa(a.key):b.toString(36)}function ya(a,b,c){a.func.call(a.context,b,
a.count++)}function za(a,b,c){var g=a.result,e=a.keyPrefix;a=a.func.call(a.context,b,a.count++);Array.isArray(a)?R(a,g,c,function(a){return a}):null!=a&&(N(a)&&(a=va(a,e+(!a.key||b&&b.key===a.key?"":(""+a.key).replace(ma,"$&/")+"/")+c)),g.push(a))}function R(a,b,c,g,e){var d="";null!=c&&(d=(""+c).replace(ma,"$&/")+"/");b=ja(b,d,g,e);Q(a,za,b);ka(b)}function t(){var a=na.current;if(null===a)throw Error(r(321));return a}function S(a,b){var c=a.length;a.push(b);a:for(;;){var g=c-1>>>1,e=a[g];if(void 0!==
e&&0<D(e,b))a[g]=b,a[c]=e,c=g;else break a}}function n(a){a=a[0];return void 0===a?null:a}function E(a){var b=a[0];if(void 0!==b){var c=a.pop();if(c!==b){a[0]=c;a:for(var g=0,e=a.length;g<e;){var d=2*(g+1)-1,f=a[d],h=d+1,k=a[h];if(void 0!==f&&0>D(f,c))void 0!==k&&0>D(k,f)?(a[g]=k,a[h]=c,g=h):(a[g]=f,a[d]=c,g=d);else if(void 0!==k&&0>D(k,c))a[g]=k,a[h]=c,g=h;else break a}}return b}return null}function D(a,b){var c=a.sortIndex-b.sortIndex;return 0!==c?c:a.id-b.id}function F(a){for(var b=n(u);null!==
b;){if(null===b.callback)E(u);else if(b.startTime<=a)E(u),b.sortIndex=b.expirationTime,S(p,b);else break;b=n(u)}}function T(a){y=!1;F(a);if(!v)if(null!==n(p))v=!0,z(U);else{var b=n(u);null!==b&&G(T,b.startTime-a)}}function U(a,b){v=!1;y&&(y=!1,V());H=!0;var c=m;try{F(b);for(l=n(p);null!==l&&(!(l.expirationTime>b)||a&&!W());){var g=l.callback;if(null!==g){l.callback=null;m=l.priorityLevel;var e=g(l.expirationTime<=b);b=q();"function"===typeof e?l.callback=e:l===n(p)&&E(p);F(b)}else E(p);l=n(p)}if(null!==
l)var d=!0;else{var f=n(u);null!==f&&G(T,f.startTime-b);d=!1}return d}finally{l=null,m=c,H=!1}}function oa(a){switch(a){case 1:return-1;case 2:return 250;case 5:return 1073741823;case 4:return 1E4;default:return 5E3}}var f="function"===typeof Symbol&&Symbol.for,x=f?Symbol.for("react.element"):60103,xa=f?Symbol.for("react.portal"):60106,Aa=f?Symbol.for("react.fragment"):60107,Ba=f?Symbol.for("react.strict_mode"):60108,Ca=f?Symbol.for("react.profiler"):60114,Da=f?Symbol.for("react.provider"):60109,
Ea=f?Symbol.for("react.context"):60110,Fa=f?Symbol.for("react.forward_ref"):60112,Ga=f?Symbol.for("react.suspense"):60113,Ha=f?Symbol.for("react.memo"):60115,Ia=f?Symbol.for("react.lazy"):60116,la="function"===typeof Symbol&&Symbol.iterator,pa=Object.getOwnPropertySymbols,Ja=Object.prototype.hasOwnProperty,Ka=Object.prototype.propertyIsEnumerable,I=function(){try{if(!Object.assign)return!1;var a=new String("abc");a[5]="de";if("5"===Object.getOwnPropertyNames(a)[0])return!1;var b={};for(a=0;10>a;a++)b["_"+
String.fromCharCode(a)]=a;if("0123456789"!==Object.getOwnPropertyNames(b).map(function(a){return b[a]}).join(""))return!1;var c={};"abcdefghijklmnopqrst".split("").forEach(function(a){c[a]=a});return"abcdefghijklmnopqrst"!==Object.keys(Object.assign({},c)).join("")?!1:!0}catch(g){return!1}}()?Object.assign:function(a,b){if(null===a||void 0===a)throw new TypeError("Object.assign cannot be called with null or undefined");var c=Object(a);for(var g,e=1;e<arguments.length;e++){var d=Object(arguments[e]);
for(var f in d)Ja.call(d,f)&&(c[f]=d[f]);if(pa){g=pa(d);for(var h=0;h<g.length;h++)Ka.call(d,g[h])&&(c[g[h]]=d[g[h]])}}return c},ca={isMounted:function(a){return!1},enqueueForceUpdate:function(a,b,c){},enqueueReplaceState:function(a,b,c,d){},enqueueSetState:function(a,b,c,d){}},ba={};w.prototype.isReactComponent={};w.prototype.setState=function(a,b){if("object"!==typeof a&&"function"!==typeof a&&null!=a)throw Error(r(85));this.updater.enqueueSetState(this,a,b,"setState")};w.prototype.forceUpdate=
function(a){this.updater.enqueueForceUpdate(this,a,"forceUpdate")};da.prototype=w.prototype;f=L.prototype=new da;f.constructor=L;I(f,w.prototype);f.isPureReactComponent=!0;var M={current:null},ha=Object.prototype.hasOwnProperty,ia={key:!0,ref:!0,__self:!0,__source:!0},ma=/\/+/g,C=[],na={current:null},X;if("undefined"===typeof window||"function"!==typeof MessageChannel){var A=null,qa=null,ra=function(){if(null!==A)try{var a=q();A(!0,a);A=null}catch(b){throw setTimeout(ra,0),b;}},La=Date.now();var q=
function(){return Date.now()-La};var z=function(a){null!==A?setTimeout(z,0,a):(A=a,setTimeout(ra,0))};var G=function(a,b){qa=setTimeout(a,b)};var V=function(){clearTimeout(qa)};var W=function(){return!1};f=X=function(){}}else{var Y=window.performance,sa=window.Date,Ma=window.setTimeout,Na=window.clearTimeout;"undefined"!==typeof console&&(f=window.cancelAnimationFrame,"function"!==typeof window.requestAnimationFrame&&console.error("This browser doesn't support requestAnimationFrame. Make sure that you load a polyfill in older browsers. https://fb.me/react-polyfills"),
"function"!==typeof f&&console.error("This browser doesn't support cancelAnimationFrame. Make sure that you load a polyfill in older browsers. https://fb.me/react-polyfills"));if("object"===typeof Y&&"function"===typeof Y.now)q=function(){return Y.now()};else{var Oa=sa.now();q=function(){return sa.now()-Oa}}var J=!1,K=null,Z=-1,ta=5,ua=0;W=function(){return q()>=ua};f=function(){};X=function(a){0>a||125<a?console.error("forceFrameRate takes a positive int between 0 and 125, forcing framerates higher than 125 fps is not unsupported"):
ta=0<a?Math.floor(1E3/a):5};var B=new MessageChannel,aa=B.port2;B.port1.onmessage=function(){if(null!==K){var a=q();ua=a+ta;try{K(!0,a)?aa.postMessage(null):(J=!1,K=null)}catch(b){throw aa.postMessage(null),b;}}else J=!1};z=function(a){K=a;J||(J=!0,aa.postMessage(null))};G=function(a,b){Z=Ma(function(){a(q())},b)};V=function(){Na(Z);Z=-1}}var p=[],u=[],Pa=1,l=null,m=3,H=!1,v=!1,y=!1,Qa=0;B={ReactCurrentDispatcher:na,ReactCurrentOwner:M,IsSomeRendererActing:{current:!1},assign:I};I(B,{Scheduler:{__proto__:null,
unstable_ImmediatePriority:1,unstable_UserBlockingPriority:2,unstable_NormalPriority:3,unstable_IdlePriority:5,unstable_LowPriority:4,unstable_runWithPriority:function(a,b){switch(a){case 1:case 2:case 3:case 4:case 5:break;default:a=3}var c=m;m=a;try{return b()}finally{m=c}},unstable_next:function(a){switch(m){case 1:case 2:case 3:var b=3;break;default:b=m}var c=m;m=b;try{return a()}finally{m=c}},unstable_scheduleCallback:function(a,b,c){var d=q();if("object"===typeof c&&null!==c){var e=c.delay;
e="number"===typeof e&&0<e?d+e:d;c="number"===typeof c.timeout?c.timeout:oa(a)}else c=oa(a),e=d;c=e+c;a={id:Pa++,callback:b,priorityLevel:a,startTime:e,expirationTime:c,sortIndex:-1};e>d?(a.sortIndex=e,S(u,a),null===n(p)&&a===n(u)&&(y?V():y=!0,G(T,e-d))):(a.sortIndex=c,S(p,a),v||H||(v=!0,z(U)));return a},unstable_cancelCallback:function(a){a.callback=null},unstable_wrapCallback:function(a){var b=m;return function(){var c=m;m=b;try{return a.apply(this,arguments)}finally{m=c}}},unstable_getCurrentPriorityLevel:function(){return m},
unstable_shouldYield:function(){var a=q();F(a);var b=n(p);return b!==l&&null!==l&&null!==b&&null!==b.callback&&b.startTime<=a&&b.expirationTime<l.expirationTime||W()},unstable_requestPaint:f,unstable_continueExecution:function(){v||H||(v=!0,z(U))},unstable_pauseExecution:function(){},unstable_getFirstCallbackNode:function(){return n(p)},get unstable_now(){return q},get unstable_forceFrameRate(){return X},unstable_Profiling:null},SchedulerTracing:{__proto__:null,__interactionsRef:null,__subscriberRef:null,
unstable_clear:function(a){return a()},unstable_getCurrent:function(){return null},unstable_getThreadID:function(){return++Qa},unstable_trace:function(a,b,c){return c()},unstable_wrap:function(a){return a},unstable_subscribe:function(a){},unstable_unsubscribe:function(a){}}});d.Children={map:function(a,b,c){if(null==a)return a;var d=[];R(a,d,null,b,c);return d},forEach:function(a,b,c){if(null==a)return a;b=ja(null,null,b,c);Q(a,ya,b);ka(b)},count:function(a){return Q(a,function(){return null},null)},
toArray:function(a){var b=[];R(a,b,null,function(a){return a});return b},only:function(a){if(!N(a))throw Error(r(143));return a}};d.Component=w;d.Fragment=Aa;d.Profiler=Ca;d.PureComponent=L;d.StrictMode=Ba;d.Suspense=Ga;d.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=B;d.cloneElement=function(a,b,c){if(null===a||void 0===a)throw Error(r(267,a));var d=I({},a.props),e=a.key,f=a.ref,m=a._owner;if(null!=b){void 0!==b.ref&&(f=b.ref,m=M.current);void 0!==b.key&&(e=""+b.key);if(a.type&&a.type.defaultProps)var h=
a.type.defaultProps;for(k in b)ha.call(b,k)&&!ia.hasOwnProperty(k)&&(d[k]=void 0===b[k]&&void 0!==h?h[k]:b[k])}var k=arguments.length-2;if(1===k)d.children=c;else if(1<k){h=Array(k);for(var l=0;l<k;l++)h[l]=arguments[l+2];d.children=h}return{$$typeof:x,type:a.type,key:e,ref:f,props:d,_owner:m}};d.createContext=function(a,b){void 0===b&&(b=null);a={$$typeof:Ea,_calculateChangedBits:b,_currentValue:a,_currentValue2:a,_threadCount:0,Provider:null,Consumer:null};a.Provider={$$typeof:Da,_context:a};return a.Consumer=
a};d.createElement=ea;d.createFactory=function(a){var b=ea.bind(null,a);b.type=a;return b};d.createRef=function(){return{current:null}};d.forwardRef=function(a){return{$$typeof:Fa,render:a}};d.isValidElement=N;d.lazy=function(a){return{$$typeof:Ia,_ctor:a,_status:-1,_result:null}};d.memo=function(a,b){return{$$typeof:Ha,type:a,compare:void 0===b?null:b}};d.useCallback=function(a,b){return t().useCallback(a,b)};d.useContext=function(a,b){return t().useContext(a,b)};d.useDebugValue=function(a,b){};
d.useEffect=function(a,b){return t().useEffect(a,b)};d.useImperativeHandle=function(a,b,c){return t().useImperativeHandle(a,b,c)};d.useLayoutEffect=function(a,b){return t().useLayoutEffect(a,b)};d.useMemo=function(a,b){return t().useMemo(a,b)};d.useReducer=function(a,b,c){return t().useReducer(a,b,c)};d.useRef=function(a){return t().useRef(a)};d.useState=function(a){return t().useState(a)};d.version="16.13.1"});
</script>
    <script crossorigin>/** @license React v16.13.1
 * react-dom.production.min.js
 *
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * This source code is licensed under the MIT license found in the
 * LICENSE file in the root directory of this source tree.
 */
/*
 Modernizr 3.0.0pre (Custom Build) | MIT
*/
'use strict';(function(I,ea){"object"===typeof exports&&"undefined"!==typeof module?ea(exports,require("react")):"function"===typeof define&&define.amd?define(["exports","react"],ea):(I=I||self,ea(I.ReactDOM={},I.React))})(this,function(I,ea){function k(a){for(var b="https://reactjs.org/docs/error-decoder.html?invariant="+a,c=1;c<arguments.length;c++)b+="&args[]="+encodeURIComponent(arguments[c]);return"Minified React error #"+a+"; visit "+b+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}
function ji(a,b,c,d,e,f,g,h,m){yb=!1;gc=null;ki.apply(li,arguments)}function mi(a,b,c,d,e,f,g,h,m){ji.apply(this,arguments);if(yb){if(yb){var n=gc;yb=!1;gc=null}else throw Error(k(198));hc||(hc=!0,pd=n)}}function lf(a,b,c){var d=a.type||"unknown-event";a.currentTarget=mf(c);mi(d,b,void 0,a);a.currentTarget=null}function nf(){if(ic)for(var a in cb){var b=cb[a],c=ic.indexOf(a);if(!(-1<c))throw Error(k(96,a));if(!jc[c]){if(!b.extractEvents)throw Error(k(97,a));jc[c]=b;c=b.eventTypes;for(var d in c){var e=
void 0;var f=c[d],g=b,h=d;if(qd.hasOwnProperty(h))throw Error(k(99,h));qd[h]=f;var m=f.phasedRegistrationNames;if(m){for(e in m)m.hasOwnProperty(e)&&of(m[e],g,h);e=!0}else f.registrationName?(of(f.registrationName,g,h),e=!0):e=!1;if(!e)throw Error(k(98,d,a));}}}}function of(a,b,c){if(db[a])throw Error(k(100,a));db[a]=b;rd[a]=b.eventTypes[c].dependencies}function pf(a){var b=!1,c;for(c in a)if(a.hasOwnProperty(c)){var d=a[c];if(!cb.hasOwnProperty(c)||cb[c]!==d){if(cb[c])throw Error(k(102,c));cb[c]=
d;b=!0}}b&&nf()}function qf(a){if(a=rf(a)){if("function"!==typeof sd)throw Error(k(280));var b=a.stateNode;b&&(b=td(b),sd(a.stateNode,a.type,b))}}function sf(a){eb?fb?fb.push(a):fb=[a]:eb=a}function tf(){if(eb){var a=eb,b=fb;fb=eb=null;qf(a);if(b)for(a=0;a<b.length;a++)qf(b[a])}}function ud(){if(null!==eb||null!==fb)vd(),tf()}function uf(a,b,c){if(wd)return a(b,c);wd=!0;try{return vf(a,b,c)}finally{wd=!1,ud()}}function ni(a){if(wf.call(xf,a))return!0;if(wf.call(yf,a))return!1;if(oi.test(a))return xf[a]=
!0;yf[a]=!0;return!1}function pi(a,b,c,d){if(null!==c&&0===c.type)return!1;switch(typeof b){case "function":case "symbol":return!0;case "boolean":if(d)return!1;if(null!==c)return!c.acceptsBooleans;a=a.toLowerCase().slice(0,5);return"data-"!==a&&"aria-"!==a;default:return!1}}function qi(a,b,c,d){if(null===b||"undefined"===typeof b||pi(a,b,c,d))return!0;if(d)return!1;if(null!==c)switch(c.type){case 3:return!b;case 4:return!1===b;case 5:return isNaN(b);case 6:return isNaN(b)||1>b}return!1}function L(a,
b,c,d,e,f){this.acceptsBooleans=2===b||3===b||4===b;this.attributeName=d;this.attributeNamespace=e;this.mustUseProperty=c;this.propertyName=a;this.type=b;this.sanitizeURL=f}function xd(a,b,c,d){var e=E.hasOwnProperty(b)?E[b]:null;var f=null!==e?0===e.type:d?!1:!(2<b.length)||"o"!==b[0]&&"O"!==b[0]||"n"!==b[1]&&"N"!==b[1]?!1:!0;f||(qi(b,c,e,d)&&(c=null),d||null===e?ni(b)&&(null===c?a.removeAttribute(b):a.setAttribute(b,""+c)):e.mustUseProperty?a[e.propertyName]=null===c?3===e.type?!1:"":c:(b=e.attributeName,
d=e.attributeNamespace,null===c?a.removeAttribute(b):(e=e.type,c=3===e||4===e&&!0===c?"":""+c,d?a.setAttributeNS(d,b,c):a.setAttribute(b,c))))}function zb(a){if(null===a||"object"!==typeof a)return null;a=zf&&a[zf]||a["@@iterator"];return"function"===typeof a?a:null}function ri(a){if(-1===a._status){a._status=0;var b=a._ctor;b=b();a._result=b;b.then(function(b){0===a._status&&(b=b.default,a._status=1,a._result=b)},function(b){0===a._status&&(a._status=2,a._result=b)})}}function na(a){if(null==a)return null;
if("function"===typeof a)return a.displayName||a.name||null;if("string"===typeof a)return a;switch(a){case Ma:return"Fragment";case gb:return"Portal";case kc:return"Profiler";case Af:return"StrictMode";case lc:return"Suspense";case yd:return"SuspenseList"}if("object"===typeof a)switch(a.$$typeof){case Bf:return"Context.Consumer";case Cf:return"Context.Provider";case zd:var b=a.render;b=b.displayName||b.name||"";return a.displayName||(""!==b?"ForwardRef("+b+")":"ForwardRef");case Ad:return na(a.type);
case Df:return na(a.render);case Ef:if(a=1===a._status?a._result:null)return na(a)}return null}function Bd(a){var b="";do{a:switch(a.tag){case 3:case 4:case 6:case 7:case 10:case 9:var c="";break a;default:var d=a._debugOwner,e=a._debugSource,f=na(a.type);c=null;d&&(c=na(d.type));d=f;f="";e?f=" (at "+e.fileName.replace(si,"")+":"+e.lineNumber+")":c&&(f=" (created by "+c+")");c="\n    in "+(d||"Unknown")+f}b+=c;a=a.return}while(a);return b}function va(a){switch(typeof a){case "boolean":case "number":case "object":case "string":case "undefined":return a;
default:return""}}function Ff(a){var b=a.type;return(a=a.nodeName)&&"input"===a.toLowerCase()&&("checkbox"===b||"radio"===b)}function ti(a){var b=Ff(a)?"checked":"value",c=Object.getOwnPropertyDescriptor(a.constructor.prototype,b),d=""+a[b];if(!a.hasOwnProperty(b)&&"undefined"!==typeof c&&"function"===typeof c.get&&"function"===typeof c.set){var e=c.get,f=c.set;Object.defineProperty(a,b,{configurable:!0,get:function(){return e.call(this)},set:function(a){d=""+a;f.call(this,a)}});Object.defineProperty(a,
b,{enumerable:c.enumerable});return{getValue:function(){return d},setValue:function(a){d=""+a},stopTracking:function(){a._valueTracker=null;delete a[b]}}}}function mc(a){a._valueTracker||(a._valueTracker=ti(a))}function Gf(a){if(!a)return!1;var b=a._valueTracker;if(!b)return!0;var c=b.getValue();var d="";a&&(d=Ff(a)?a.checked?"true":"false":a.value);a=d;return a!==c?(b.setValue(a),!0):!1}function Cd(a,b){var c=b.checked;return M({},b,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:null!=
c?c:a._wrapperState.initialChecked})}function Hf(a,b){var c=null==b.defaultValue?"":b.defaultValue,d=null!=b.checked?b.checked:b.defaultChecked;c=va(null!=b.value?b.value:c);a._wrapperState={initialChecked:d,initialValue:c,controlled:"checkbox"===b.type||"radio"===b.type?null!=b.checked:null!=b.value}}function If(a,b){b=b.checked;null!=b&&xd(a,"checked",b,!1)}function Dd(a,b){If(a,b);var c=va(b.value),d=b.type;if(null!=c)if("number"===d){if(0===c&&""===a.value||a.value!=c)a.value=""+c}else a.value!==
""+c&&(a.value=""+c);else if("submit"===d||"reset"===d){a.removeAttribute("value");return}b.hasOwnProperty("value")?Ed(a,b.type,c):b.hasOwnProperty("defaultValue")&&Ed(a,b.type,va(b.defaultValue));null==b.checked&&null!=b.defaultChecked&&(a.defaultChecked=!!b.defaultChecked)}function Jf(a,b,c){if(b.hasOwnProperty("value")||b.hasOwnProperty("defaultValue")){var d=b.type;if(!("submit"!==d&&"reset"!==d||void 0!==b.value&&null!==b.value))return;b=""+a._wrapperState.initialValue;c||b===a.value||(a.value=
b);a.defaultValue=b}c=a.name;""!==c&&(a.name="");a.defaultChecked=!!a._wrapperState.initialChecked;""!==c&&(a.name=c)}function Ed(a,b,c){if("number"!==b||a.ownerDocument.activeElement!==a)null==c?a.defaultValue=""+a._wrapperState.initialValue:a.defaultValue!==""+c&&(a.defaultValue=""+c)}function ui(a){var b="";ea.Children.forEach(a,function(a){null!=a&&(b+=a)});return b}function Fd(a,b){a=M({children:void 0},b);if(b=ui(b.children))a.children=b;return a}function hb(a,b,c,d){a=a.options;if(b){b={};
for(var e=0;e<c.length;e++)b["$"+c[e]]=!0;for(c=0;c<a.length;c++)e=b.hasOwnProperty("$"+a[c].value),a[c].selected!==e&&(a[c].selected=e),e&&d&&(a[c].defaultSelected=!0)}else{c=""+va(c);b=null;for(e=0;e<a.length;e++){if(a[e].value===c){a[e].selected=!0;d&&(a[e].defaultSelected=!0);return}null!==b||a[e].disabled||(b=a[e])}null!==b&&(b.selected=!0)}}function Gd(a,b){if(null!=b.dangerouslySetInnerHTML)throw Error(k(91));return M({},b,{value:void 0,defaultValue:void 0,children:""+a._wrapperState.initialValue})}
function Kf(a,b){var c=b.value;if(null==c){c=b.children;b=b.defaultValue;if(null!=c){if(null!=b)throw Error(k(92));if(Array.isArray(c)){if(!(1>=c.length))throw Error(k(93));c=c[0]}b=c}null==b&&(b="");c=b}a._wrapperState={initialValue:va(c)}}function Lf(a,b){var c=va(b.value),d=va(b.defaultValue);null!=c&&(c=""+c,c!==a.value&&(a.value=c),null==b.defaultValue&&a.defaultValue!==c&&(a.defaultValue=c));null!=d&&(a.defaultValue=""+d)}function Mf(a,b){b=a.textContent;b===a._wrapperState.initialValue&&""!==
b&&null!==b&&(a.value=b)}function Nf(a){switch(a){case "svg":return"http://www.w3.org/2000/svg";case "math":return"http://www.w3.org/1998/Math/MathML";default:return"http://www.w3.org/1999/xhtml"}}function Hd(a,b){return null==a||"http://www.w3.org/1999/xhtml"===a?Nf(b):"http://www.w3.org/2000/svg"===a&&"foreignObject"===b?"http://www.w3.org/1999/xhtml":a}function nc(a,b){var c={};c[a.toLowerCase()]=b.toLowerCase();c["Webkit"+a]="webkit"+b;c["Moz"+a]="moz"+b;return c}function oc(a){if(Id[a])return Id[a];
if(!ib[a])return a;var b=ib[a],c;for(c in b)if(b.hasOwnProperty(c)&&c in Of)return Id[a]=b[c];return a}function Jd(a){var b=Pf.get(a);void 0===b&&(b=new Map,Pf.set(a,b));return b}function Na(a){var b=a,c=a;if(a.alternate)for(;b.return;)b=b.return;else{a=b;do b=a,0!==(b.effectTag&1026)&&(c=b.return),a=b.return;while(a)}return 3===b.tag?c:null}function Qf(a){if(13===a.tag){var b=a.memoizedState;null===b&&(a=a.alternate,null!==a&&(b=a.memoizedState));if(null!==b)return b.dehydrated}return null}function Rf(a){if(Na(a)!==
a)throw Error(k(188));}function vi(a){var b=a.alternate;if(!b){b=Na(a);if(null===b)throw Error(k(188));return b!==a?null:a}for(var c=a,d=b;;){var e=c.return;if(null===e)break;var f=e.alternate;if(null===f){d=e.return;if(null!==d){c=d;continue}break}if(e.child===f.child){for(f=e.child;f;){if(f===c)return Rf(e),a;if(f===d)return Rf(e),b;f=f.sibling}throw Error(k(188));}if(c.return!==d.return)c=e,d=f;else{for(var g=!1,h=e.child;h;){if(h===c){g=!0;c=e;d=f;break}if(h===d){g=!0;d=e;c=f;break}h=h.sibling}if(!g){for(h=
f.child;h;){if(h===c){g=!0;c=f;d=e;break}if(h===d){g=!0;d=f;c=e;break}h=h.sibling}if(!g)throw Error(k(189));}}if(c.alternate!==d)throw Error(k(190));}if(3!==c.tag)throw Error(k(188));return c.stateNode.current===c?a:b}function Sf(a){a=vi(a);if(!a)return null;for(var b=a;;){if(5===b.tag||6===b.tag)return b;if(b.child)b.child.return=b,b=b.child;else{if(b===a)break;for(;!b.sibling;){if(!b.return||b.return===a)return null;b=b.return}b.sibling.return=b.return;b=b.sibling}}return null}function jb(a,b){if(null==
b)throw Error(k(30));if(null==a)return b;if(Array.isArray(a)){if(Array.isArray(b))return a.push.apply(a,b),a;a.push(b);return a}return Array.isArray(b)?[a].concat(b):[a,b]}function Kd(a,b,c){Array.isArray(a)?a.forEach(b,c):a&&b.call(c,a)}function pc(a){null!==a&&(Ab=jb(Ab,a));a=Ab;Ab=null;if(a){Kd(a,wi);if(Ab)throw Error(k(95));if(hc)throw a=pd,hc=!1,pd=null,a;}}function Ld(a){a=a.target||a.srcElement||window;a.correspondingUseElement&&(a=a.correspondingUseElement);return 3===a.nodeType?a.parentNode:
a}function Tf(a){if(!wa)return!1;a="on"+a;var b=a in document;b||(b=document.createElement("div"),b.setAttribute(a,"return;"),b="function"===typeof b[a]);return b}function Uf(a){a.topLevelType=null;a.nativeEvent=null;a.targetInst=null;a.ancestors.length=0;10>qc.length&&qc.push(a)}function Vf(a,b,c,d){if(qc.length){var e=qc.pop();e.topLevelType=a;e.eventSystemFlags=d;e.nativeEvent=b;e.targetInst=c;return e}return{topLevelType:a,eventSystemFlags:d,nativeEvent:b,targetInst:c,ancestors:[]}}function Wf(a){var b=
a.targetInst,c=b;do{if(!c){a.ancestors.push(c);break}var d=c;if(3===d.tag)d=d.stateNode.containerInfo;else{for(;d.return;)d=d.return;d=3!==d.tag?null:d.stateNode.containerInfo}if(!d)break;b=c.tag;5!==b&&6!==b||a.ancestors.push(c);c=Bb(d)}while(c);for(c=0;c<a.ancestors.length;c++){b=a.ancestors[c];var e=Ld(a.nativeEvent);d=a.topLevelType;var f=a.nativeEvent,g=a.eventSystemFlags;0===c&&(g|=64);for(var h=null,m=0;m<jc.length;m++){var n=jc[m];n&&(n=n.extractEvents(d,b,f,e,g))&&(h=jb(h,n))}pc(h)}}function Md(a,
b,c){if(!c.has(a)){switch(a){case "scroll":Cb(b,"scroll",!0);break;case "focus":case "blur":Cb(b,"focus",!0);Cb(b,"blur",!0);c.set("blur",null);c.set("focus",null);break;case "cancel":case "close":Tf(a)&&Cb(b,a,!0);break;case "invalid":case "submit":case "reset":break;default:-1===Db.indexOf(a)&&w(a,b)}c.set(a,null)}}function xi(a,b){var c=Jd(b);Nd.forEach(function(a){Md(a,b,c)});yi.forEach(function(a){Md(a,b,c)})}function Od(a,b,c,d,e){return{blockedOn:a,topLevelType:b,eventSystemFlags:c|32,nativeEvent:e,
container:d}}function Xf(a,b){switch(a){case "focus":case "blur":xa=null;break;case "dragenter":case "dragleave":ya=null;break;case "mouseover":case "mouseout":za=null;break;case "pointerover":case "pointerout":Eb.delete(b.pointerId);break;case "gotpointercapture":case "lostpointercapture":Fb.delete(b.pointerId)}}function Gb(a,b,c,d,e,f){if(null===a||a.nativeEvent!==f)return a=Od(b,c,d,e,f),null!==b&&(b=Hb(b),null!==b&&Yf(b)),a;a.eventSystemFlags|=d;return a}function zi(a,b,c,d,e){switch(b){case "focus":return xa=
Gb(xa,a,b,c,d,e),!0;case "dragenter":return ya=Gb(ya,a,b,c,d,e),!0;case "mouseover":return za=Gb(za,a,b,c,d,e),!0;case "pointerover":var f=e.pointerId;Eb.set(f,Gb(Eb.get(f)||null,a,b,c,d,e));return!0;case "gotpointercapture":return f=e.pointerId,Fb.set(f,Gb(Fb.get(f)||null,a,b,c,d,e)),!0}return!1}function Ai(a){var b=Bb(a.target);if(null!==b){var c=Na(b);if(null!==c)if(b=c.tag,13===b){if(b=Qf(c),null!==b){a.blockedOn=b;Pd(a.priority,function(){Bi(c)});return}}else if(3===b&&c.stateNode.hydrate){a.blockedOn=
3===c.tag?c.stateNode.containerInfo:null;return}}a.blockedOn=null}function rc(a){if(null!==a.blockedOn)return!1;var b=Qd(a.topLevelType,a.eventSystemFlags,a.container,a.nativeEvent);if(null!==b){var c=Hb(b);null!==c&&Yf(c);a.blockedOn=b;return!1}return!0}function Zf(a,b,c){rc(a)&&c.delete(b)}function Ci(){for(Rd=!1;0<fa.length;){var a=fa[0];if(null!==a.blockedOn){a=Hb(a.blockedOn);null!==a&&Di(a);break}var b=Qd(a.topLevelType,a.eventSystemFlags,a.container,a.nativeEvent);null!==b?a.blockedOn=b:fa.shift()}null!==
xa&&rc(xa)&&(xa=null);null!==ya&&rc(ya)&&(ya=null);null!==za&&rc(za)&&(za=null);Eb.forEach(Zf);Fb.forEach(Zf)}function Ib(a,b){a.blockedOn===b&&(a.blockedOn=null,Rd||(Rd=!0,$f(ag,Ci)))}function bg(a){if(0<fa.length){Ib(fa[0],a);for(var b=1;b<fa.length;b++){var c=fa[b];c.blockedOn===a&&(c.blockedOn=null)}}null!==xa&&Ib(xa,a);null!==ya&&Ib(ya,a);null!==za&&Ib(za,a);b=function(b){return Ib(b,a)};Eb.forEach(b);Fb.forEach(b);for(b=0;b<Jb.length;b++)c=Jb[b],c.blockedOn===a&&(c.blockedOn=null);for(;0<Jb.length&&
(b=Jb[0],null===b.blockedOn);)Ai(b),null===b.blockedOn&&Jb.shift()}function Sd(a,b){for(var c=0;c<a.length;c+=2){var d=a[c],e=a[c+1],f="on"+(e[0].toUpperCase()+e.slice(1));f={phasedRegistrationNames:{bubbled:f,captured:f+"Capture"},dependencies:[d],eventPriority:b};Td.set(d,b);cg.set(d,f);dg[e]=f}}function w(a,b){Cb(b,a,!1)}function Cb(a,b,c){var d=Td.get(b);switch(void 0===d?2:d){case 0:d=Ei.bind(null,b,1,a);break;case 1:d=Fi.bind(null,b,1,a);break;default:d=sc.bind(null,b,1,a)}c?a.addEventListener(b,
d,!0):a.addEventListener(b,d,!1)}function Ei(a,b,c,d){Oa||vd();var e=sc,f=Oa;Oa=!0;try{eg(e,a,b,c,d)}finally{(Oa=f)||ud()}}function Fi(a,b,c,d){Gi(Hi,sc.bind(null,a,b,c,d))}function sc(a,b,c,d){if(tc)if(0<fa.length&&-1<Nd.indexOf(a))a=Od(null,a,b,c,d),fa.push(a);else{var e=Qd(a,b,c,d);if(null===e)Xf(a,d);else if(-1<Nd.indexOf(a))a=Od(e,a,b,c,d),fa.push(a);else if(!zi(e,a,b,c,d)){Xf(a,d);a=Vf(a,d,null,b);try{uf(Wf,a)}finally{Uf(a)}}}}function Qd(a,b,c,d){c=Ld(d);c=Bb(c);if(null!==c){var e=Na(c);if(null===
e)c=null;else{var f=e.tag;if(13===f){c=Qf(e);if(null!==c)return c;c=null}else if(3===f){if(e.stateNode.hydrate)return 3===e.tag?e.stateNode.containerInfo:null;c=null}else e!==c&&(c=null)}}a=Vf(a,d,c,b);try{uf(Wf,a)}finally{Uf(a)}return null}function fg(a,b,c){return null==b||"boolean"===typeof b||""===b?"":c||"number"!==typeof b||0===b||Kb.hasOwnProperty(a)&&Kb[a]?(""+b).trim():b+"px"}function gg(a,b){a=a.style;for(var c in b)if(b.hasOwnProperty(c)){var d=0===c.indexOf("--"),e=fg(c,b[c],d);"float"===
c&&(c="cssFloat");d?a.setProperty(c,e):a[c]=e}}function Ud(a,b){if(b){if(Ii[a]&&(null!=b.children||null!=b.dangerouslySetInnerHTML))throw Error(k(137,a,""));if(null!=b.dangerouslySetInnerHTML){if(null!=b.children)throw Error(k(60));if(!("object"===typeof b.dangerouslySetInnerHTML&&"__html"in b.dangerouslySetInnerHTML))throw Error(k(61));}if(null!=b.style&&"object"!==typeof b.style)throw Error(k(62,""));}}function Vd(a,b){if(-1===a.indexOf("-"))return"string"===typeof b.is;switch(a){case "annotation-xml":case "color-profile":case "font-face":case "font-face-src":case "font-face-uri":case "font-face-format":case "font-face-name":case "missing-glyph":return!1;
default:return!0}}function oa(a,b){a=9===a.nodeType||11===a.nodeType?a:a.ownerDocument;var c=Jd(a);b=rd[b];for(var d=0;d<b.length;d++)Md(b[d],a,c)}function uc(){}function Wd(a){a=a||("undefined"!==typeof document?document:void 0);if("undefined"===typeof a)return null;try{return a.activeElement||a.body}catch(b){return a.body}}function hg(a){for(;a&&a.firstChild;)a=a.firstChild;return a}function ig(a,b){var c=hg(a);a=0;for(var d;c;){if(3===c.nodeType){d=a+c.textContent.length;if(a<=b&&d>=b)return{node:c,
offset:b-a};a=d}a:{for(;c;){if(c.nextSibling){c=c.nextSibling;break a}c=c.parentNode}c=void 0}c=hg(c)}}function jg(a,b){return a&&b?a===b?!0:a&&3===a.nodeType?!1:b&&3===b.nodeType?jg(a,b.parentNode):"contains"in a?a.contains(b):a.compareDocumentPosition?!!(a.compareDocumentPosition(b)&16):!1:!1}function kg(){for(var a=window,b=Wd();b instanceof a.HTMLIFrameElement;){try{var c="string"===typeof b.contentWindow.location.href}catch(d){c=!1}if(c)a=b.contentWindow;else break;b=Wd(a.document)}return b}
function Xd(a){var b=a&&a.nodeName&&a.nodeName.toLowerCase();return b&&("input"===b&&("text"===a.type||"search"===a.type||"tel"===a.type||"url"===a.type||"password"===a.type)||"textarea"===b||"true"===a.contentEditable)}function lg(a,b){switch(a){case "button":case "input":case "select":case "textarea":return!!b.autoFocus}return!1}function Yd(a,b){return"textarea"===a||"option"===a||"noscript"===a||"string"===typeof b.children||"number"===typeof b.children||"object"===typeof b.dangerouslySetInnerHTML&&
null!==b.dangerouslySetInnerHTML&&null!=b.dangerouslySetInnerHTML.__html}function kb(a){for(;null!=a;a=a.nextSibling){var b=a.nodeType;if(1===b||3===b)break}return a}function mg(a){a=a.previousSibling;for(var b=0;a;){if(8===a.nodeType){var c=a.data;if(c===ng||c===Zd||c===$d){if(0===b)return a;b--}else c===og&&b++}a=a.previousSibling}return null}function Bb(a){var b=a[Aa];if(b)return b;for(var c=a.parentNode;c;){if(b=c[Lb]||c[Aa]){c=b.alternate;if(null!==b.child||null!==c&&null!==c.child)for(a=mg(a);null!==
a;){if(c=a[Aa])return c;a=mg(a)}return b}a=c;c=a.parentNode}return null}function Hb(a){a=a[Aa]||a[Lb];return!a||5!==a.tag&&6!==a.tag&&13!==a.tag&&3!==a.tag?null:a}function Pa(a){if(5===a.tag||6===a.tag)return a.stateNode;throw Error(k(33));}function ae(a){return a[vc]||null}function pa(a){do a=a.return;while(a&&5!==a.tag);return a?a:null}function pg(a,b){var c=a.stateNode;if(!c)return null;var d=td(c);if(!d)return null;c=d[b];a:switch(b){case "onClick":case "onClickCapture":case "onDoubleClick":case "onDoubleClickCapture":case "onMouseDown":case "onMouseDownCapture":case "onMouseMove":case "onMouseMoveCapture":case "onMouseUp":case "onMouseUpCapture":case "onMouseEnter":(d=
!d.disabled)||(a=a.type,d=!("button"===a||"input"===a||"select"===a||"textarea"===a));a=!d;break a;default:a=!1}if(a)return null;if(c&&"function"!==typeof c)throw Error(k(231,b,typeof c));return c}function qg(a,b,c){if(b=pg(a,c.dispatchConfig.phasedRegistrationNames[b]))c._dispatchListeners=jb(c._dispatchListeners,b),c._dispatchInstances=jb(c._dispatchInstances,a)}function Ji(a){if(a&&a.dispatchConfig.phasedRegistrationNames){for(var b=a._targetInst,c=[];b;)c.push(b),b=pa(b);for(b=c.length;0<b--;)qg(c[b],
"captured",a);for(b=0;b<c.length;b++)qg(c[b],"bubbled",a)}}function be(a,b,c){a&&c&&c.dispatchConfig.registrationName&&(b=pg(a,c.dispatchConfig.registrationName))&&(c._dispatchListeners=jb(c._dispatchListeners,b),c._dispatchInstances=jb(c._dispatchInstances,a))}function Ki(a){a&&a.dispatchConfig.registrationName&&be(a._targetInst,null,a)}function lb(a){Kd(a,Ji)}function rg(){if(wc)return wc;var a,b=ce,c=b.length,d,e="value"in Ba?Ba.value:Ba.textContent,f=e.length;for(a=0;a<c&&b[a]===e[a];a++);var g=
c-a;for(d=1;d<=g&&b[c-d]===e[f-d];d++);return wc=e.slice(a,1<d?1-d:void 0)}function xc(){return!0}function yc(){return!1}function R(a,b,c,d){this.dispatchConfig=a;this._targetInst=b;this.nativeEvent=c;a=this.constructor.Interface;for(var e in a)a.hasOwnProperty(e)&&((b=a[e])?this[e]=b(c):"target"===e?this.target=d:this[e]=c[e]);this.isDefaultPrevented=(null!=c.defaultPrevented?c.defaultPrevented:!1===c.returnValue)?xc:yc;this.isPropagationStopped=yc;return this}function Li(a,b,c,d){if(this.eventPool.length){var e=
this.eventPool.pop();this.call(e,a,b,c,d);return e}return new this(a,b,c,d)}function Mi(a){if(!(a instanceof this))throw Error(k(279));a.destructor();10>this.eventPool.length&&this.eventPool.push(a)}function sg(a){a.eventPool=[];a.getPooled=Li;a.release=Mi}function tg(a,b){switch(a){case "keyup":return-1!==Ni.indexOf(b.keyCode);case "keydown":return 229!==b.keyCode;case "keypress":case "mousedown":case "blur":return!0;default:return!1}}function ug(a){a=a.detail;return"object"===typeof a&&"data"in
a?a.data:null}function Oi(a,b){switch(a){case "compositionend":return ug(b);case "keypress":if(32!==b.which)return null;vg=!0;return wg;case "textInput":return a=b.data,a===wg&&vg?null:a;default:return null}}function Pi(a,b){if(mb)return"compositionend"===a||!de&&tg(a,b)?(a=rg(),wc=ce=Ba=null,mb=!1,a):null;switch(a){case "paste":return null;case "keypress":if(!(b.ctrlKey||b.altKey||b.metaKey)||b.ctrlKey&&b.altKey){if(b.char&&1<b.char.length)return b.char;if(b.which)return String.fromCharCode(b.which)}return null;
case "compositionend":return xg&&"ko"!==b.locale?null:b.data;default:return null}}function yg(a){var b=a&&a.nodeName&&a.nodeName.toLowerCase();return"input"===b?!!Qi[a.type]:"textarea"===b?!0:!1}function zg(a,b,c){a=R.getPooled(Ag.change,a,b,c);a.type="change";sf(c);lb(a);return a}function Ri(a){pc(a)}function zc(a){var b=Pa(a);if(Gf(b))return a}function Si(a,b){if("change"===a)return b}function Bg(){Mb&&(Mb.detachEvent("onpropertychange",Cg),Nb=Mb=null)}function Cg(a){if("value"===a.propertyName&&
zc(Nb))if(a=zg(Nb,a,Ld(a)),Oa)pc(a);else{Oa=!0;try{ee(Ri,a)}finally{Oa=!1,ud()}}}function Ti(a,b,c){"focus"===a?(Bg(),Mb=b,Nb=c,Mb.attachEvent("onpropertychange",Cg)):"blur"===a&&Bg()}function Ui(a,b){if("selectionchange"===a||"keyup"===a||"keydown"===a)return zc(Nb)}function Vi(a,b){if("click"===a)return zc(b)}function Wi(a,b){if("input"===a||"change"===a)return zc(b)}function Xi(a){var b=this.nativeEvent;return b.getModifierState?b.getModifierState(a):(a=Yi[a])?!!b[a]:!1}function fe(a){return Xi}
function Zi(a,b){return a===b&&(0!==a||1/a===1/b)||a!==a&&b!==b}function Ob(a,b){if(Qa(a,b))return!0;if("object"!==typeof a||null===a||"object"!==typeof b||null===b)return!1;var c=Object.keys(a),d=Object.keys(b);if(c.length!==d.length)return!1;for(d=0;d<c.length;d++)if(!$i.call(b,c[d])||!Qa(a[c[d]],b[c[d]]))return!1;return!0}function Dg(a,b){var c=b.window===b?b.document:9===b.nodeType?b:b.ownerDocument;if(ge||null==nb||nb!==Wd(c))return null;c=nb;"selectionStart"in c&&Xd(c)?c={start:c.selectionStart,
end:c.selectionEnd}:(c=(c.ownerDocument&&c.ownerDocument.defaultView||window).getSelection(),c={anchorNode:c.anchorNode,anchorOffset:c.anchorOffset,focusNode:c.focusNode,focusOffset:c.focusOffset});return Pb&&Ob(Pb,c)?null:(Pb=c,a=R.getPooled(Eg.select,he,a,b),a.type="select",a.target=nb,lb(a),a)}function Ac(a){var b=a.keyCode;"charCode"in a?(a=a.charCode,0===a&&13===b&&(a=13)):a=b;10===a&&(a=13);return 32<=a||13===a?a:0}function q(a,b){0>ob||(a.current=ie[ob],ie[ob]=null,ob--)}function y(a,b,c){ob++;
ie[ob]=a.current;a.current=b}function pb(a,b){var c=a.type.contextTypes;if(!c)return Ca;var d=a.stateNode;if(d&&d.__reactInternalMemoizedUnmaskedChildContext===b)return d.__reactInternalMemoizedMaskedChildContext;var e={},f;for(f in c)e[f]=b[f];d&&(a=a.stateNode,a.__reactInternalMemoizedUnmaskedChildContext=b,a.__reactInternalMemoizedMaskedChildContext=e);return e}function N(a){a=a.childContextTypes;return null!==a&&void 0!==a}function Fg(a,b,c){if(B.current!==Ca)throw Error(k(168));y(B,b);y(G,c)}
function Gg(a,b,c){var d=a.stateNode;a=b.childContextTypes;if("function"!==typeof d.getChildContext)return c;d=d.getChildContext();for(var e in d)if(!(e in a))throw Error(k(108,na(b)||"Unknown",e));return M({},c,{},d)}function Bc(a){a=(a=a.stateNode)&&a.__reactInternalMemoizedMergedChildContext||Ca;Ra=B.current;y(B,a);y(G,G.current);return!0}function Hg(a,b,c){var d=a.stateNode;if(!d)throw Error(k(169));c?(a=Gg(a,b,Ra),d.__reactInternalMemoizedMergedChildContext=a,q(G),q(B),y(B,a)):q(G);y(G,c)}function Cc(){switch(aj()){case Dc:return 99;
case Ig:return 98;case Jg:return 97;case Kg:return 96;case Lg:return 95;default:throw Error(k(332));}}function Mg(a){switch(a){case 99:return Dc;case 98:return Ig;case 97:return Jg;case 96:return Kg;case 95:return Lg;default:throw Error(k(332));}}function Da(a,b){a=Mg(a);return bj(a,b)}function Ng(a,b,c){a=Mg(a);return je(a,b,c)}function Og(a){null===qa?(qa=[a],Ec=je(Dc,Pg)):qa.push(a);return Qg}function ha(){if(null!==Ec){var a=Ec;Ec=null;Rg(a)}Pg()}function Pg(){if(!ke&&null!==qa){ke=!0;var a=0;
try{var b=qa;Da(99,function(){for(;a<b.length;a++){var c=b[a];do c=c(!0);while(null!==c)}});qa=null}catch(c){throw null!==qa&&(qa=qa.slice(a+1)),je(Dc,ha),c;}finally{ke=!1}}}function Fc(a,b,c){c/=10;return 1073741821-(((1073741821-a+b/10)/c|0)+1)*c}function aa(a,b){if(a&&a.defaultProps){b=M({},b);a=a.defaultProps;for(var c in a)void 0===b[c]&&(b[c]=a[c])}return b}function le(){Gc=qb=Hc=null}function me(a){var b=Ic.current;q(Ic);a.type._context._currentValue=b}function Sg(a,b){for(;null!==a;){var c=
a.alternate;if(a.childExpirationTime<b)a.childExpirationTime=b,null!==c&&c.childExpirationTime<b&&(c.childExpirationTime=b);else if(null!==c&&c.childExpirationTime<b)c.childExpirationTime=b;else break;a=a.return}}function rb(a,b){Hc=a;Gc=qb=null;a=a.dependencies;null!==a&&null!==a.firstContext&&(a.expirationTime>=b&&(ia=!0),a.firstContext=null)}function W(a,b){if(Gc!==a&&!1!==b&&0!==b){if("number"!==typeof b||1073741823===b)Gc=a,b=1073741823;b={context:a,observedBits:b,next:null};if(null===qb){if(null===
Hc)throw Error(k(308));qb=b;Hc.dependencies={expirationTime:0,firstContext:b,responders:null}}else qb=qb.next=b}return a._currentValue}function ne(a){a.updateQueue={baseState:a.memoizedState,baseQueue:null,shared:{pending:null},effects:null}}function oe(a,b){a=a.updateQueue;b.updateQueue===a&&(b.updateQueue={baseState:a.baseState,baseQueue:a.baseQueue,shared:a.shared,effects:a.effects})}function Ea(a,b){a={expirationTime:a,suspenseConfig:b,tag:Tg,payload:null,callback:null,next:null};return a.next=
a}function Fa(a,b){a=a.updateQueue;if(null!==a){a=a.shared;var c=a.pending;null===c?b.next=b:(b.next=c.next,c.next=b);a.pending=b}}function Ug(a,b){var c=a.alternate;null!==c&&oe(c,a);a=a.updateQueue;c=a.baseQueue;null===c?(a.baseQueue=b.next=b,b.next=b):(b.next=c.next,c.next=b)}function Qb(a,b,c,d){var e=a.updateQueue;Ga=!1;var f=e.baseQueue,g=e.shared.pending;if(null!==g){if(null!==f){var h=f.next;f.next=g.next;g.next=h}f=g;e.shared.pending=null;h=a.alternate;null!==h&&(h=h.updateQueue,null!==h&&
(h.baseQueue=g))}if(null!==f){h=f.next;var m=e.baseState,n=0,k=null,ba=null,l=null;if(null!==h){var p=h;do{g=p.expirationTime;if(g<d){var t={expirationTime:p.expirationTime,suspenseConfig:p.suspenseConfig,tag:p.tag,payload:p.payload,callback:p.callback,next:null};null===l?(ba=l=t,k=m):l=l.next=t;g>n&&(n=g)}else{null!==l&&(l=l.next={expirationTime:1073741823,suspenseConfig:p.suspenseConfig,tag:p.tag,payload:p.payload,callback:p.callback,next:null});Vg(g,p.suspenseConfig);a:{var q=a,r=p;g=b;t=c;switch(r.tag){case 1:q=
r.payload;if("function"===typeof q){m=q.call(t,m,g);break a}m=q;break a;case 3:q.effectTag=q.effectTag&-4097|64;case Tg:q=r.payload;g="function"===typeof q?q.call(t,m,g):q;if(null===g||void 0===g)break a;m=M({},m,g);break a;case Jc:Ga=!0}}null!==p.callback&&(a.effectTag|=32,g=e.effects,null===g?e.effects=[p]:g.push(p))}p=p.next;if(null===p||p===h)if(g=e.shared.pending,null===g)break;else p=f.next=g.next,g.next=h,e.baseQueue=f=g,e.shared.pending=null}while(1)}null===l?k=m:l.next=ba;e.baseState=k;e.baseQueue=
l;Kc(n);a.expirationTime=n;a.memoizedState=m}}function Wg(a,b,c){a=b.effects;b.effects=null;if(null!==a)for(b=0;b<a.length;b++){var d=a[b],e=d.callback;if(null!==e){d.callback=null;d=e;e=c;if("function"!==typeof d)throw Error(k(191,d));d.call(e)}}}function Lc(a,b,c,d){b=a.memoizedState;c=c(d,b);c=null===c||void 0===c?b:M({},b,c);a.memoizedState=c;0===a.expirationTime&&(a.updateQueue.baseState=c)}function Xg(a,b,c,d,e,f,g){a=a.stateNode;return"function"===typeof a.shouldComponentUpdate?a.shouldComponentUpdate(d,
f,g):b.prototype&&b.prototype.isPureReactComponent?!Ob(c,d)||!Ob(e,f):!0}function Yg(a,b,c){var d=!1,e=Ca;var f=b.contextType;"object"===typeof f&&null!==f?f=W(f):(e=N(b)?Ra:B.current,d=b.contextTypes,f=(d=null!==d&&void 0!==d)?pb(a,e):Ca);b=new b(c,f);a.memoizedState=null!==b.state&&void 0!==b.state?b.state:null;b.updater=Mc;a.stateNode=b;b._reactInternalFiber=a;d&&(a=a.stateNode,a.__reactInternalMemoizedUnmaskedChildContext=e,a.__reactInternalMemoizedMaskedChildContext=f);return b}function Zg(a,
b,c,d){a=b.state;"function"===typeof b.componentWillReceiveProps&&b.componentWillReceiveProps(c,d);"function"===typeof b.UNSAFE_componentWillReceiveProps&&b.UNSAFE_componentWillReceiveProps(c,d);b.state!==a&&Mc.enqueueReplaceState(b,b.state,null)}function pe(a,b,c,d){var e=a.stateNode;e.props=c;e.state=a.memoizedState;e.refs=$g;ne(a);var f=b.contextType;"object"===typeof f&&null!==f?e.context=W(f):(f=N(b)?Ra:B.current,e.context=pb(a,f));Qb(a,c,e,d);e.state=a.memoizedState;f=b.getDerivedStateFromProps;
"function"===typeof f&&(Lc(a,b,f,c),e.state=a.memoizedState);"function"===typeof b.getDerivedStateFromProps||"function"===typeof e.getSnapshotBeforeUpdate||"function"!==typeof e.UNSAFE_componentWillMount&&"function"!==typeof e.componentWillMount||(b=e.state,"function"===typeof e.componentWillMount&&e.componentWillMount(),"function"===typeof e.UNSAFE_componentWillMount&&e.UNSAFE_componentWillMount(),b!==e.state&&Mc.enqueueReplaceState(e,e.state,null),Qb(a,c,e,d),e.state=a.memoizedState);"function"===
typeof e.componentDidMount&&(a.effectTag|=4)}function Rb(a,b,c){a=c.ref;if(null!==a&&"function"!==typeof a&&"object"!==typeof a){if(c._owner){c=c._owner;if(c){if(1!==c.tag)throw Error(k(309));var d=c.stateNode}if(!d)throw Error(k(147,a));var e=""+a;if(null!==b&&null!==b.ref&&"function"===typeof b.ref&&b.ref._stringRef===e)return b.ref;b=function(a){var b=d.refs;b===$g&&(b=d.refs={});null===a?delete b[e]:b[e]=a};b._stringRef=e;return b}if("string"!==typeof a)throw Error(k(284));if(!c._owner)throw Error(k(290,
a));}return a}function Nc(a,b){if("textarea"!==a.type)throw Error(k(31,"[object Object]"===Object.prototype.toString.call(b)?"object with keys {"+Object.keys(b).join(", ")+"}":b,""));}function ah(a){function b(b,c){if(a){var d=b.lastEffect;null!==d?(d.nextEffect=c,b.lastEffect=c):b.firstEffect=b.lastEffect=c;c.nextEffect=null;c.effectTag=8}}function c(c,d){if(!a)return null;for(;null!==d;)b(c,d),d=d.sibling;return null}function d(a,b){for(a=new Map;null!==b;)null!==b.key?a.set(b.key,b):a.set(b.index,
b),b=b.sibling;return a}function e(a,b){a=Sa(a,b);a.index=0;a.sibling=null;return a}function f(b,c,d){b.index=d;if(!a)return c;d=b.alternate;if(null!==d)return d=d.index,d<c?(b.effectTag=2,c):d;b.effectTag=2;return c}function g(b){a&&null===b.alternate&&(b.effectTag=2);return b}function h(a,b,c,d){if(null===b||6!==b.tag)return b=qe(c,a.mode,d),b.return=a,b;b=e(b,c);b.return=a;return b}function m(a,b,c,d){if(null!==b&&b.elementType===c.type)return d=e(b,c.props),d.ref=Rb(a,b,c),d.return=a,d;d=Oc(c.type,
c.key,c.props,null,a.mode,d);d.ref=Rb(a,b,c);d.return=a;return d}function n(a,b,c,d){if(null===b||4!==b.tag||b.stateNode.containerInfo!==c.containerInfo||b.stateNode.implementation!==c.implementation)return b=re(c,a.mode,d),b.return=a,b;b=e(b,c.children||[]);b.return=a;return b}function l(a,b,c,d,f){if(null===b||7!==b.tag)return b=Ha(c,a.mode,d,f),b.return=a,b;b=e(b,c);b.return=a;return b}function ba(a,b,c){if("string"===typeof b||"number"===typeof b)return b=qe(""+b,a.mode,c),b.return=a,b;if("object"===
typeof b&&null!==b){switch(b.$$typeof){case Pc:return c=Oc(b.type,b.key,b.props,null,a.mode,c),c.ref=Rb(a,null,b),c.return=a,c;case gb:return b=re(b,a.mode,c),b.return=a,b}if(Qc(b)||zb(b))return b=Ha(b,a.mode,c,null),b.return=a,b;Nc(a,b)}return null}function p(a,b,c,d){var e=null!==b?b.key:null;if("string"===typeof c||"number"===typeof c)return null!==e?null:h(a,b,""+c,d);if("object"===typeof c&&null!==c){switch(c.$$typeof){case Pc:return c.key===e?c.type===Ma?l(a,b,c.props.children,d,e):m(a,b,c,
d):null;case gb:return c.key===e?n(a,b,c,d):null}if(Qc(c)||zb(c))return null!==e?null:l(a,b,c,d,null);Nc(a,c)}return null}function t(a,b,c,d,e){if("string"===typeof d||"number"===typeof d)return a=a.get(c)||null,h(b,a,""+d,e);if("object"===typeof d&&null!==d){switch(d.$$typeof){case Pc:return a=a.get(null===d.key?c:d.key)||null,d.type===Ma?l(b,a,d.props.children,e,d.key):m(b,a,d,e);case gb:return a=a.get(null===d.key?c:d.key)||null,n(b,a,d,e)}if(Qc(d)||zb(d))return a=a.get(c)||null,l(b,a,d,e,null);
Nc(b,d)}return null}function q(e,g,h,m){for(var n=null,k=null,l=g,r=g=0,C=null;null!==l&&r<h.length;r++){l.index>r?(C=l,l=null):C=l.sibling;var O=p(e,l,h[r],m);if(null===O){null===l&&(l=C);break}a&&l&&null===O.alternate&&b(e,l);g=f(O,g,r);null===k?n=O:k.sibling=O;k=O;l=C}if(r===h.length)return c(e,l),n;if(null===l){for(;r<h.length;r++)l=ba(e,h[r],m),null!==l&&(g=f(l,g,r),null===k?n=l:k.sibling=l,k=l);return n}for(l=d(e,l);r<h.length;r++)C=t(l,e,r,h[r],m),null!==C&&(a&&null!==C.alternate&&l.delete(null===
C.key?r:C.key),g=f(C,g,r),null===k?n=C:k.sibling=C,k=C);a&&l.forEach(function(a){return b(e,a)});return n}function w(e,g,h,n){var m=zb(h);if("function"!==typeof m)throw Error(k(150));h=m.call(h);if(null==h)throw Error(k(151));for(var l=m=null,r=g,C=g=0,O=null,v=h.next();null!==r&&!v.done;C++,v=h.next()){r.index>C?(O=r,r=null):O=r.sibling;var q=p(e,r,v.value,n);if(null===q){null===r&&(r=O);break}a&&r&&null===q.alternate&&b(e,r);g=f(q,g,C);null===l?m=q:l.sibling=q;l=q;r=O}if(v.done)return c(e,r),m;
if(null===r){for(;!v.done;C++,v=h.next())v=ba(e,v.value,n),null!==v&&(g=f(v,g,C),null===l?m=v:l.sibling=v,l=v);return m}for(r=d(e,r);!v.done;C++,v=h.next())v=t(r,e,C,v.value,n),null!==v&&(a&&null!==v.alternate&&r.delete(null===v.key?C:v.key),g=f(v,g,C),null===l?m=v:l.sibling=v,l=v);a&&r.forEach(function(a){return b(e,a)});return m}return function(a,d,f,h){var m="object"===typeof f&&null!==f&&f.type===Ma&&null===f.key;m&&(f=f.props.children);var n="object"===typeof f&&null!==f;if(n)switch(f.$$typeof){case Pc:a:{n=
f.key;for(m=d;null!==m;){if(m.key===n){switch(m.tag){case 7:if(f.type===Ma){c(a,m.sibling);d=e(m,f.props.children);d.return=a;a=d;break a}break;default:if(m.elementType===f.type){c(a,m.sibling);d=e(m,f.props);d.ref=Rb(a,m,f);d.return=a;a=d;break a}}c(a,m);break}else b(a,m);m=m.sibling}f.type===Ma?(d=Ha(f.props.children,a.mode,h,f.key),d.return=a,a=d):(h=Oc(f.type,f.key,f.props,null,a.mode,h),h.ref=Rb(a,d,f),h.return=a,a=h)}return g(a);case gb:a:{for(m=f.key;null!==d;){if(d.key===m)if(4===d.tag&&d.stateNode.containerInfo===
f.containerInfo&&d.stateNode.implementation===f.implementation){c(a,d.sibling);d=e(d,f.children||[]);d.return=a;a=d;break a}else{c(a,d);break}else b(a,d);d=d.sibling}d=re(f,a.mode,h);d.return=a;a=d}return g(a)}if("string"===typeof f||"number"===typeof f)return f=""+f,null!==d&&6===d.tag?(c(a,d.sibling),d=e(d,f),d.return=a,a=d):(c(a,d),d=qe(f,a.mode,h),d.return=a,a=d),g(a);if(Qc(f))return q(a,d,f,h);if(zb(f))return w(a,d,f,h);n&&Nc(a,f);if("undefined"===typeof f&&!m)switch(a.tag){case 1:case 0:throw a=
a.type,Error(k(152,a.displayName||a.name||"Component"));}return c(a,d)}}function Ta(a){if(a===Sb)throw Error(k(174));return a}function se(a,b){y(Tb,b);y(Ub,a);y(ja,Sb);a=b.nodeType;switch(a){case 9:case 11:b=(b=b.documentElement)?b.namespaceURI:Hd(null,"");break;default:a=8===a?b.parentNode:b,b=a.namespaceURI||null,a=a.tagName,b=Hd(b,a)}q(ja);y(ja,b)}function tb(a){q(ja);q(Ub);q(Tb)}function bh(a){Ta(Tb.current);var b=Ta(ja.current);var c=Hd(b,a.type);b!==c&&(y(Ub,a),y(ja,c))}function te(a){Ub.current===
a&&(q(ja),q(Ub))}function Rc(a){for(var b=a;null!==b;){if(13===b.tag){var c=b.memoizedState;if(null!==c&&(c=c.dehydrated,null===c||c.data===$d||c.data===Zd))return b}else if(19===b.tag&&void 0!==b.memoizedProps.revealOrder){if(0!==(b.effectTag&64))return b}else if(null!==b.child){b.child.return=b;b=b.child;continue}if(b===a)break;for(;null===b.sibling;){if(null===b.return||b.return===a)return null;b=b.return}b.sibling.return=b.return;b=b.sibling}return null}function ue(a,b){return{responder:a,props:b}}
function S(){throw Error(k(321));}function ve(a,b){if(null===b)return!1;for(var c=0;c<b.length&&c<a.length;c++)if(!Qa(a[c],b[c]))return!1;return!0}function we(a,b,c,d,e,f){Ia=f;z=b;b.memoizedState=null;b.updateQueue=null;b.expirationTime=0;Sc.current=null===a||null===a.memoizedState?dj:ej;a=c(d,e);if(b.expirationTime===Ia){f=0;do{b.expirationTime=0;if(!(25>f))throw Error(k(301));f+=1;J=K=null;b.updateQueue=null;Sc.current=fj;a=c(d,e)}while(b.expirationTime===Ia)}Sc.current=Tc;b=null!==K&&null!==K.next;
Ia=0;J=K=z=null;Uc=!1;if(b)throw Error(k(300));return a}function ub(){var a={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};null===J?z.memoizedState=J=a:J=J.next=a;return J}function vb(){if(null===K){var a=z.alternate;a=null!==a?a.memoizedState:null}else a=K.next;var b=null===J?z.memoizedState:J.next;if(null!==b)J=b,K=a;else{if(null===a)throw Error(k(310));K=a;a={memoizedState:K.memoizedState,baseState:K.baseState,baseQueue:K.baseQueue,queue:K.queue,next:null};null===J?z.memoizedState=
J=a:J=J.next=a}return J}function Ua(a,b){return"function"===typeof b?b(a):b}function Vc(a,b,c){b=vb();c=b.queue;if(null===c)throw Error(k(311));c.lastRenderedReducer=a;var d=K,e=d.baseQueue,f=c.pending;if(null!==f){if(null!==e){var g=e.next;e.next=f.next;f.next=g}d.baseQueue=e=f;c.pending=null}if(null!==e){e=e.next;d=d.baseState;var h=g=f=null,m=e;do{var n=m.expirationTime;if(n<Ia){var l={expirationTime:m.expirationTime,suspenseConfig:m.suspenseConfig,action:m.action,eagerReducer:m.eagerReducer,eagerState:m.eagerState,
next:null};null===h?(g=h=l,f=d):h=h.next=l;n>z.expirationTime&&(z.expirationTime=n,Kc(n))}else null!==h&&(h=h.next={expirationTime:1073741823,suspenseConfig:m.suspenseConfig,action:m.action,eagerReducer:m.eagerReducer,eagerState:m.eagerState,next:null}),Vg(n,m.suspenseConfig),d=m.eagerReducer===a?m.eagerState:a(d,m.action);m=m.next}while(null!==m&&m!==e);null===h?f=d:h.next=g;Qa(d,b.memoizedState)||(ia=!0);b.memoizedState=d;b.baseState=f;b.baseQueue=h;c.lastRenderedState=d}return[b.memoizedState,
c.dispatch]}function Wc(a,b,c){b=vb();c=b.queue;if(null===c)throw Error(k(311));c.lastRenderedReducer=a;var d=c.dispatch,e=c.pending,f=b.memoizedState;if(null!==e){c.pending=null;var g=e=e.next;do f=a(f,g.action),g=g.next;while(g!==e);Qa(f,b.memoizedState)||(ia=!0);b.memoizedState=f;null===b.baseQueue&&(b.baseState=f);c.lastRenderedState=f}return[f,d]}function xe(a){var b=ub();"function"===typeof a&&(a=a());b.memoizedState=b.baseState=a;a=b.queue={pending:null,dispatch:null,lastRenderedReducer:Ua,
lastRenderedState:a};a=a.dispatch=ch.bind(null,z,a);return[b.memoizedState,a]}function ye(a,b,c,d){a={tag:a,create:b,destroy:c,deps:d,next:null};b=z.updateQueue;null===b?(b={lastEffect:null},z.updateQueue=b,b.lastEffect=a.next=a):(c=b.lastEffect,null===c?b.lastEffect=a.next=a:(d=c.next,c.next=a,a.next=d,b.lastEffect=a));return a}function dh(a){return vb().memoizedState}function ze(a,b,c,d){var e=ub();z.effectTag|=a;e.memoizedState=ye(1|b,c,void 0,void 0===d?null:d)}function Ae(a,b,c,d){var e=vb();
d=void 0===d?null:d;var f=void 0;if(null!==K){var g=K.memoizedState;f=g.destroy;if(null!==d&&ve(d,g.deps)){ye(b,c,f,d);return}}z.effectTag|=a;e.memoizedState=ye(1|b,c,f,d)}function eh(a,b){return ze(516,4,a,b)}function Xc(a,b){return Ae(516,4,a,b)}function fh(a,b){return Ae(4,2,a,b)}function gh(a,b){if("function"===typeof b)return a=a(),b(a),function(){b(null)};if(null!==b&&void 0!==b)return a=a(),b.current=a,function(){b.current=null}}function hh(a,b,c){c=null!==c&&void 0!==c?c.concat([a]):null;
return Ae(4,2,gh.bind(null,b,a),c)}function Be(a,b){}function ih(a,b){ub().memoizedState=[a,void 0===b?null:b];return a}function Yc(a,b){var c=vb();b=void 0===b?null:b;var d=c.memoizedState;if(null!==d&&null!==b&&ve(b,d[1]))return d[0];c.memoizedState=[a,b];return a}function jh(a,b){var c=vb();b=void 0===b?null:b;var d=c.memoizedState;if(null!==d&&null!==b&&ve(b,d[1]))return d[0];a=a();c.memoizedState=[a,b];return a}function Ce(a,b,c){var d=Cc();Da(98>d?98:d,function(){a(!0)});Da(97<d?97:d,function(){var d=
X.suspense;X.suspense=void 0===b?null:b;try{a(!1),c()}finally{X.suspense=d}})}function ch(a,b,c){var d=ka(),e=Vb.suspense;d=Va(d,a,e);e={expirationTime:d,suspenseConfig:e,action:c,eagerReducer:null,eagerState:null,next:null};var f=b.pending;null===f?e.next=e:(e.next=f.next,f.next=e);b.pending=e;f=a.alternate;if(a===z||null!==f&&f===z)Uc=!0,e.expirationTime=Ia,z.expirationTime=Ia;else{if(0===a.expirationTime&&(null===f||0===f.expirationTime)&&(f=b.lastRenderedReducer,null!==f))try{var g=b.lastRenderedState,
h=f(g,c);e.eagerReducer=f;e.eagerState=h;if(Qa(h,g))return}catch(m){}finally{}Ja(a,d)}}function kh(a,b){var c=la(5,null,null,0);c.elementType="DELETED";c.type="DELETED";c.stateNode=b;c.return=a;c.effectTag=8;null!==a.lastEffect?(a.lastEffect.nextEffect=c,a.lastEffect=c):a.firstEffect=a.lastEffect=c}function lh(a,b){switch(a.tag){case 5:var c=a.type;b=1!==b.nodeType||c.toLowerCase()!==b.nodeName.toLowerCase()?null:b;return null!==b?(a.stateNode=b,!0):!1;case 6:return b=""===a.pendingProps||3!==b.nodeType?
null:b,null!==b?(a.stateNode=b,!0):!1;case 13:return!1;default:return!1}}function De(a){if(Wa){var b=Ka;if(b){var c=b;if(!lh(a,b)){b=kb(c.nextSibling);if(!b||!lh(a,b)){a.effectTag=a.effectTag&-1025|2;Wa=!1;ra=a;return}kh(ra,c)}ra=a;Ka=kb(b.firstChild)}else a.effectTag=a.effectTag&-1025|2,Wa=!1,ra=a}}function mh(a){for(a=a.return;null!==a&&5!==a.tag&&3!==a.tag&&13!==a.tag;)a=a.return;ra=a}function Zc(a){if(a!==ra)return!1;if(!Wa)return mh(a),Wa=!0,!1;var b=a.type;if(5!==a.tag||"head"!==b&&"body"!==
b&&!Yd(b,a.memoizedProps))for(b=Ka;b;)kh(a,b),b=kb(b.nextSibling);mh(a);if(13===a.tag){a=a.memoizedState;a=null!==a?a.dehydrated:null;if(!a)throw Error(k(317));a:{a=a.nextSibling;for(b=0;a;){if(8===a.nodeType){var c=a.data;if(c===og){if(0===b){Ka=kb(a.nextSibling);break a}b--}else c!==ng&&c!==Zd&&c!==$d||b++}a=a.nextSibling}Ka=null}}else Ka=ra?kb(a.stateNode.nextSibling):null;return!0}function Ee(){Ka=ra=null;Wa=!1}function T(a,b,c,d){b.child=null===a?Fe(b,null,c,d):wb(b,a.child,c,d)}function nh(a,
b,c,d,e){c=c.render;var f=b.ref;rb(b,e);d=we(a,b,c,d,f,e);if(null!==a&&!ia)return b.updateQueue=a.updateQueue,b.effectTag&=-517,a.expirationTime<=e&&(a.expirationTime=0),sa(a,b,e);b.effectTag|=1;T(a,b,d,e);return b.child}function oh(a,b,c,d,e,f){if(null===a){var g=c.type;if("function"===typeof g&&!Ge(g)&&void 0===g.defaultProps&&null===c.compare&&void 0===c.defaultProps)return b.tag=15,b.type=g,ph(a,b,g,d,e,f);a=Oc(c.type,null,d,null,b.mode,f);a.ref=b.ref;a.return=b;return b.child=a}g=a.child;if(e<
f&&(e=g.memoizedProps,c=c.compare,c=null!==c?c:Ob,c(e,d)&&a.ref===b.ref))return sa(a,b,f);b.effectTag|=1;a=Sa(g,d);a.ref=b.ref;a.return=b;return b.child=a}function ph(a,b,c,d,e,f){return null!==a&&Ob(a.memoizedProps,d)&&a.ref===b.ref&&(ia=!1,e<f)?(b.expirationTime=a.expirationTime,sa(a,b,f)):He(a,b,c,d,f)}function qh(a,b){var c=b.ref;if(null===a&&null!==c||null!==a&&a.ref!==c)b.effectTag|=128}function He(a,b,c,d,e){var f=N(c)?Ra:B.current;f=pb(b,f);rb(b,e);c=we(a,b,c,d,f,e);if(null!==a&&!ia)return b.updateQueue=
a.updateQueue,b.effectTag&=-517,a.expirationTime<=e&&(a.expirationTime=0),sa(a,b,e);b.effectTag|=1;T(a,b,c,e);return b.child}function rh(a,b,c,d,e){if(N(c)){var f=!0;Bc(b)}else f=!1;rb(b,e);if(null===b.stateNode)null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2),Yg(b,c,d),pe(b,c,d,e),d=!0;else if(null===a){var g=b.stateNode,h=b.memoizedProps;g.props=h;var m=g.context,n=c.contextType;"object"===typeof n&&null!==n?n=W(n):(n=N(c)?Ra:B.current,n=pb(b,n));var l=c.getDerivedStateFromProps,k="function"===
typeof l||"function"===typeof g.getSnapshotBeforeUpdate;k||"function"!==typeof g.UNSAFE_componentWillReceiveProps&&"function"!==typeof g.componentWillReceiveProps||(h!==d||m!==n)&&Zg(b,g,d,n);Ga=!1;var p=b.memoizedState;g.state=p;Qb(b,d,g,e);m=b.memoizedState;h!==d||p!==m||G.current||Ga?("function"===typeof l&&(Lc(b,c,l,d),m=b.memoizedState),(h=Ga||Xg(b,c,h,d,p,m,n))?(k||"function"!==typeof g.UNSAFE_componentWillMount&&"function"!==typeof g.componentWillMount||("function"===typeof g.componentWillMount&&
g.componentWillMount(),"function"===typeof g.UNSAFE_componentWillMount&&g.UNSAFE_componentWillMount()),"function"===typeof g.componentDidMount&&(b.effectTag|=4)):("function"===typeof g.componentDidMount&&(b.effectTag|=4),b.memoizedProps=d,b.memoizedState=m),g.props=d,g.state=m,g.context=n,d=h):("function"===typeof g.componentDidMount&&(b.effectTag|=4),d=!1)}else g=b.stateNode,oe(a,b),h=b.memoizedProps,g.props=b.type===b.elementType?h:aa(b.type,h),m=g.context,n=c.contextType,"object"===typeof n&&null!==
n?n=W(n):(n=N(c)?Ra:B.current,n=pb(b,n)),l=c.getDerivedStateFromProps,(k="function"===typeof l||"function"===typeof g.getSnapshotBeforeUpdate)||"function"!==typeof g.UNSAFE_componentWillReceiveProps&&"function"!==typeof g.componentWillReceiveProps||(h!==d||m!==n)&&Zg(b,g,d,n),Ga=!1,m=b.memoizedState,g.state=m,Qb(b,d,g,e),p=b.memoizedState,h!==d||m!==p||G.current||Ga?("function"===typeof l&&(Lc(b,c,l,d),p=b.memoizedState),(l=Ga||Xg(b,c,h,d,m,p,n))?(k||"function"!==typeof g.UNSAFE_componentWillUpdate&&
"function"!==typeof g.componentWillUpdate||("function"===typeof g.componentWillUpdate&&g.componentWillUpdate(d,p,n),"function"===typeof g.UNSAFE_componentWillUpdate&&g.UNSAFE_componentWillUpdate(d,p,n)),"function"===typeof g.componentDidUpdate&&(b.effectTag|=4),"function"===typeof g.getSnapshotBeforeUpdate&&(b.effectTag|=256)):("function"!==typeof g.componentDidUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=4),"function"!==typeof g.getSnapshotBeforeUpdate||h===a.memoizedProps&&m===
a.memoizedState||(b.effectTag|=256),b.memoizedProps=d,b.memoizedState=p),g.props=d,g.state=p,g.context=n,d=l):("function"!==typeof g.componentDidUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=4),"function"!==typeof g.getSnapshotBeforeUpdate||h===a.memoizedProps&&m===a.memoizedState||(b.effectTag|=256),d=!1);return Ie(a,b,c,d,f,e)}function Ie(a,b,c,d,e,f){qh(a,b);var g=0!==(b.effectTag&64);if(!d&&!g)return e&&Hg(b,c,!1),sa(a,b,f);d=b.stateNode;gj.current=b;var h=g&&"function"!==typeof c.getDerivedStateFromError?
null:d.render();b.effectTag|=1;null!==a&&g?(b.child=wb(b,a.child,null,f),b.child=wb(b,null,h,f)):T(a,b,h,f);b.memoizedState=d.state;e&&Hg(b,c,!0);return b.child}function sh(a){var b=a.stateNode;b.pendingContext?Fg(a,b.pendingContext,b.pendingContext!==b.context):b.context&&Fg(a,b.context,!1);se(a,b.containerInfo)}function th(a,b,c){var d=b.mode,e=b.pendingProps,f=D.current,g=!1,h;(h=0!==(b.effectTag&64))||(h=0!==(f&2)&&(null===a||null!==a.memoizedState));h?(g=!0,b.effectTag&=-65):null!==a&&null===
a.memoizedState||void 0===e.fallback||!0===e.unstable_avoidThisFallback||(f|=1);y(D,f&1);if(null===a){void 0!==e.fallback&&De(b);if(g){g=e.fallback;e=Ha(null,d,0,null);e.return=b;if(0===(b.mode&2))for(a=null!==b.memoizedState?b.child.child:b.child,e.child=a;null!==a;)a.return=e,a=a.sibling;c=Ha(g,d,c,null);c.return=b;e.sibling=c;b.memoizedState=Je;b.child=e;return c}d=e.children;b.memoizedState=null;return b.child=Fe(b,null,d,c)}if(null!==a.memoizedState){a=a.child;d=a.sibling;if(g){e=e.fallback;
c=Sa(a,a.pendingProps);c.return=b;if(0===(b.mode&2)&&(g=null!==b.memoizedState?b.child.child:b.child,g!==a.child))for(c.child=g;null!==g;)g.return=c,g=g.sibling;d=Sa(d,e);d.return=b;c.sibling=d;c.childExpirationTime=0;b.memoizedState=Je;b.child=c;return d}c=wb(b,a.child,e.children,c);b.memoizedState=null;return b.child=c}a=a.child;if(g){g=e.fallback;e=Ha(null,d,0,null);e.return=b;e.child=a;null!==a&&(a.return=e);if(0===(b.mode&2))for(a=null!==b.memoizedState?b.child.child:b.child,e.child=a;null!==
a;)a.return=e,a=a.sibling;c=Ha(g,d,c,null);c.return=b;e.sibling=c;c.effectTag|=2;e.childExpirationTime=0;b.memoizedState=Je;b.child=e;return c}b.memoizedState=null;return b.child=wb(b,a,e.children,c)}function uh(a,b){a.expirationTime<b&&(a.expirationTime=b);var c=a.alternate;null!==c&&c.expirationTime<b&&(c.expirationTime=b);Sg(a.return,b)}function Ke(a,b,c,d,e,f){var g=a.memoizedState;null===g?a.memoizedState={isBackwards:b,rendering:null,renderingStartTime:0,last:d,tail:c,tailExpiration:0,tailMode:e,
lastEffect:f}:(g.isBackwards=b,g.rendering=null,g.renderingStartTime=0,g.last=d,g.tail=c,g.tailExpiration=0,g.tailMode=e,g.lastEffect=f)}function vh(a,b,c){var d=b.pendingProps,e=d.revealOrder,f=d.tail;T(a,b,d.children,c);d=D.current;if(0!==(d&2))d=d&1|2,b.effectTag|=64;else{if(null!==a&&0!==(a.effectTag&64))a:for(a=b.child;null!==a;){if(13===a.tag)null!==a.memoizedState&&uh(a,c);else if(19===a.tag)uh(a,c);else if(null!==a.child){a.child.return=a;a=a.child;continue}if(a===b)break a;for(;null===a.sibling;){if(null===
a.return||a.return===b)break a;a=a.return}a.sibling.return=a.return;a=a.sibling}d&=1}y(D,d);if(0===(b.mode&2))b.memoizedState=null;else switch(e){case "forwards":c=b.child;for(e=null;null!==c;)a=c.alternate,null!==a&&null===Rc(a)&&(e=c),c=c.sibling;c=e;null===c?(e=b.child,b.child=null):(e=c.sibling,c.sibling=null);Ke(b,!1,e,c,f,b.lastEffect);break;case "backwards":c=null;e=b.child;for(b.child=null;null!==e;){a=e.alternate;if(null!==a&&null===Rc(a)){b.child=e;break}a=e.sibling;e.sibling=c;c=e;e=a}Ke(b,
!0,c,null,f,b.lastEffect);break;case "together":Ke(b,!1,null,null,void 0,b.lastEffect);break;default:b.memoizedState=null}return b.child}function sa(a,b,c){null!==a&&(b.dependencies=a.dependencies);var d=b.expirationTime;0!==d&&Kc(d);if(b.childExpirationTime<c)return null;if(null!==a&&b.child!==a.child)throw Error(k(153));if(null!==b.child){a=b.child;c=Sa(a,a.pendingProps);b.child=c;for(c.return=b;null!==a.sibling;)a=a.sibling,c=c.sibling=Sa(a,a.pendingProps),c.return=b;c.sibling=null}return b.child}
function $c(a,b){switch(a.tailMode){case "hidden":b=a.tail;for(var c=null;null!==b;)null!==b.alternate&&(c=b),b=b.sibling;null===c?a.tail=null:c.sibling=null;break;case "collapsed":c=a.tail;for(var d=null;null!==c;)null!==c.alternate&&(d=c),c=c.sibling;null===d?b||null===a.tail?a.tail=null:a.tail.sibling=null:d.sibling=null}}function hj(a,b,c){var d=b.pendingProps;switch(b.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return null;case 1:return N(b.type)&&(q(G),q(B)),
null;case 3:return tb(),q(G),q(B),c=b.stateNode,c.pendingContext&&(c.context=c.pendingContext,c.pendingContext=null),null!==a&&null!==a.child||!Zc(b)||(b.effectTag|=4),wh(b),null;case 5:te(b);c=Ta(Tb.current);var e=b.type;if(null!==a&&null!=b.stateNode)ij(a,b,e,d,c),a.ref!==b.ref&&(b.effectTag|=128);else{if(!d){if(null===b.stateNode)throw Error(k(166));return null}a=Ta(ja.current);if(Zc(b)){d=b.stateNode;e=b.type;var f=b.memoizedProps;d[Aa]=b;d[vc]=f;switch(e){case "iframe":case "object":case "embed":w("load",
d);break;case "video":case "audio":for(a=0;a<Db.length;a++)w(Db[a],d);break;case "source":w("error",d);break;case "img":case "image":case "link":w("error",d);w("load",d);break;case "form":w("reset",d);w("submit",d);break;case "details":w("toggle",d);break;case "input":Hf(d,f);w("invalid",d);oa(c,"onChange");break;case "select":d._wrapperState={wasMultiple:!!f.multiple};w("invalid",d);oa(c,"onChange");break;case "textarea":Kf(d,f),w("invalid",d),oa(c,"onChange")}Ud(e,f);a=null;for(var g in f)if(f.hasOwnProperty(g)){var h=
f[g];"children"===g?"string"===typeof h?d.textContent!==h&&(a=["children",h]):"number"===typeof h&&d.textContent!==""+h&&(a=["children",""+h]):db.hasOwnProperty(g)&&null!=h&&oa(c,g)}switch(e){case "input":mc(d);Jf(d,f,!0);break;case "textarea":mc(d);Mf(d);break;case "select":case "option":break;default:"function"===typeof f.onClick&&(d.onclick=uc)}c=a;b.updateQueue=c;null!==c&&(b.effectTag|=4)}else{g=9===c.nodeType?c:c.ownerDocument;"http://www.w3.org/1999/xhtml"===a&&(a=Nf(e));"http://www.w3.org/1999/xhtml"===
a?"script"===e?(a=g.createElement("div"),a.innerHTML="<script>\x3c/script>",a=a.removeChild(a.firstChild)):"string"===typeof d.is?a=g.createElement(e,{is:d.is}):(a=g.createElement(e),"select"===e&&(g=a,d.multiple?g.multiple=!0:d.size&&(g.size=d.size))):a=g.createElementNS(a,e);a[Aa]=b;a[vc]=d;jj(a,b,!1,!1);b.stateNode=a;g=Vd(e,d);switch(e){case "iframe":case "object":case "embed":w("load",a);h=d;break;case "video":case "audio":for(h=0;h<Db.length;h++)w(Db[h],a);h=d;break;case "source":w("error",a);
h=d;break;case "img":case "image":case "link":w("error",a);w("load",a);h=d;break;case "form":w("reset",a);w("submit",a);h=d;break;case "details":w("toggle",a);h=d;break;case "input":Hf(a,d);h=Cd(a,d);w("invalid",a);oa(c,"onChange");break;case "option":h=Fd(a,d);break;case "select":a._wrapperState={wasMultiple:!!d.multiple};h=M({},d,{value:void 0});w("invalid",a);oa(c,"onChange");break;case "textarea":Kf(a,d);h=Gd(a,d);w("invalid",a);oa(c,"onChange");break;default:h=d}Ud(e,h);var m=h;for(f in m)if(m.hasOwnProperty(f)){var n=
m[f];"style"===f?gg(a,n):"dangerouslySetInnerHTML"===f?(n=n?n.__html:void 0,null!=n&&xh(a,n)):"children"===f?"string"===typeof n?("textarea"!==e||""!==n)&&Wb(a,n):"number"===typeof n&&Wb(a,""+n):"suppressContentEditableWarning"!==f&&"suppressHydrationWarning"!==f&&"autoFocus"!==f&&(db.hasOwnProperty(f)?null!=n&&oa(c,f):null!=n&&xd(a,f,n,g))}switch(e){case "input":mc(a);Jf(a,d,!1);break;case "textarea":mc(a);Mf(a);break;case "option":null!=d.value&&a.setAttribute("value",""+va(d.value));break;case "select":a.multiple=
!!d.multiple;c=d.value;null!=c?hb(a,!!d.multiple,c,!1):null!=d.defaultValue&&hb(a,!!d.multiple,d.defaultValue,!0);break;default:"function"===typeof h.onClick&&(a.onclick=uc)}lg(e,d)&&(b.effectTag|=4)}null!==b.ref&&(b.effectTag|=128)}return null;case 6:if(a&&null!=b.stateNode)kj(a,b,a.memoizedProps,d);else{if("string"!==typeof d&&null===b.stateNode)throw Error(k(166));c=Ta(Tb.current);Ta(ja.current);Zc(b)?(c=b.stateNode,d=b.memoizedProps,c[Aa]=b,c.nodeValue!==d&&(b.effectTag|=4)):(c=(9===c.nodeType?
c:c.ownerDocument).createTextNode(d),c[Aa]=b,b.stateNode=c)}return null;case 13:q(D);d=b.memoizedState;if(0!==(b.effectTag&64))return b.expirationTime=c,b;c=null!==d;d=!1;null===a?void 0!==b.memoizedProps.fallback&&Zc(b):(e=a.memoizedState,d=null!==e,c||null===e||(e=a.child.sibling,null!==e&&(f=b.firstEffect,null!==f?(b.firstEffect=e,e.nextEffect=f):(b.firstEffect=b.lastEffect=e,e.nextEffect=null),e.effectTag=8)));if(c&&!d&&0!==(b.mode&2))if(null===a&&!0!==b.memoizedProps.unstable_avoidThisFallback||
0!==(D.current&1))F===Xa&&(F=ad);else{if(F===Xa||F===ad)F=bd;0!==Xb&&null!==U&&(Ya(U,P),yh(U,Xb))}if(c||d)b.effectTag|=4;return null;case 4:return tb(),wh(b),null;case 10:return me(b),null;case 17:return N(b.type)&&(q(G),q(B)),null;case 19:q(D);d=b.memoizedState;if(null===d)return null;e=0!==(b.effectTag&64);f=d.rendering;if(null===f)if(e)$c(d,!1);else{if(F!==Xa||null!==a&&0!==(a.effectTag&64))for(f=b.child;null!==f;){a=Rc(f);if(null!==a){b.effectTag|=64;$c(d,!1);e=a.updateQueue;null!==e&&(b.updateQueue=
e,b.effectTag|=4);null===d.lastEffect&&(b.firstEffect=null);b.lastEffect=d.lastEffect;for(d=b.child;null!==d;)e=d,f=c,e.effectTag&=2,e.nextEffect=null,e.firstEffect=null,e.lastEffect=null,a=e.alternate,null===a?(e.childExpirationTime=0,e.expirationTime=f,e.child=null,e.memoizedProps=null,e.memoizedState=null,e.updateQueue=null,e.dependencies=null):(e.childExpirationTime=a.childExpirationTime,e.expirationTime=a.expirationTime,e.child=a.child,e.memoizedProps=a.memoizedProps,e.memoizedState=a.memoizedState,
e.updateQueue=a.updateQueue,f=a.dependencies,e.dependencies=null===f?null:{expirationTime:f.expirationTime,firstContext:f.firstContext,responders:f.responders}),d=d.sibling;y(D,D.current&1|2);return b.child}f=f.sibling}}else{if(!e)if(a=Rc(f),null!==a){if(b.effectTag|=64,e=!0,c=a.updateQueue,null!==c&&(b.updateQueue=c,b.effectTag|=4),$c(d,!0),null===d.tail&&"hidden"===d.tailMode&&!f.alternate)return b=b.lastEffect=d.lastEffect,null!==b&&(b.nextEffect=null),null}else 2*Y()-d.renderingStartTime>d.tailExpiration&&
1<c&&(b.effectTag|=64,e=!0,$c(d,!1),b.expirationTime=b.childExpirationTime=c-1);d.isBackwards?(f.sibling=b.child,b.child=f):(c=d.last,null!==c?c.sibling=f:b.child=f,d.last=f)}return null!==d.tail?(0===d.tailExpiration&&(d.tailExpiration=Y()+500),c=d.tail,d.rendering=c,d.tail=c.sibling,d.lastEffect=b.lastEffect,d.renderingStartTime=Y(),c.sibling=null,b=D.current,y(D,e?b&1|2:b&1),c):null}throw Error(k(156,b.tag));}function lj(a,b){switch(a.tag){case 1:return N(a.type)&&(q(G),q(B)),b=a.effectTag,b&4096?
(a.effectTag=b&-4097|64,a):null;case 3:tb();q(G);q(B);b=a.effectTag;if(0!==(b&64))throw Error(k(285));a.effectTag=b&-4097|64;return a;case 5:return te(a),null;case 13:return q(D),b=a.effectTag,b&4096?(a.effectTag=b&-4097|64,a):null;case 19:return q(D),null;case 4:return tb(),null;case 10:return me(a),null;default:return null}}function Le(a,b){return{value:a,source:b,stack:Bd(b)}}function Me(a,b){var c=b.source,d=b.stack;null===d&&null!==c&&(d=Bd(c));null!==c&&na(c.type);b=b.value;null!==a&&1===a.tag&&
na(a.type);try{console.error(b)}catch(e){setTimeout(function(){throw e;})}}function mj(a,b){try{b.props=a.memoizedProps,b.state=a.memoizedState,b.componentWillUnmount()}catch(c){Za(a,c)}}function zh(a){var b=a.ref;if(null!==b)if("function"===typeof b)try{b(null)}catch(c){Za(a,c)}else b.current=null}function nj(a,b){switch(b.tag){case 0:case 11:case 15:case 22:return;case 1:if(b.effectTag&256&&null!==a){var c=a.memoizedProps,d=a.memoizedState;a=b.stateNode;b=a.getSnapshotBeforeUpdate(b.elementType===
b.type?c:aa(b.type,c),d);a.__reactInternalSnapshotBeforeUpdate=b}return;case 3:case 5:case 6:case 4:case 17:return}throw Error(k(163));}function Ah(a,b){b=b.updateQueue;b=null!==b?b.lastEffect:null;if(null!==b){var c=b=b.next;do{if((c.tag&a)===a){var d=c.destroy;c.destroy=void 0;void 0!==d&&d()}c=c.next}while(c!==b)}}function Bh(a,b){b=b.updateQueue;b=null!==b?b.lastEffect:null;if(null!==b){var c=b=b.next;do{if((c.tag&a)===a){var d=c.create;c.destroy=d()}c=c.next}while(c!==b)}}function oj(a,b,c,d){switch(c.tag){case 0:case 11:case 15:case 22:Bh(3,
c);return;case 1:a=c.stateNode;c.effectTag&4&&(null===b?a.componentDidMount():(d=c.elementType===c.type?b.memoizedProps:aa(c.type,b.memoizedProps),a.componentDidUpdate(d,b.memoizedState,a.__reactInternalSnapshotBeforeUpdate)));b=c.updateQueue;null!==b&&Wg(c,b,a);return;case 3:b=c.updateQueue;if(null!==b){a=null;if(null!==c.child)switch(c.child.tag){case 5:a=c.child.stateNode;break;case 1:a=c.child.stateNode}Wg(c,b,a)}return;case 5:a=c.stateNode;null===b&&c.effectTag&4&&lg(c.type,c.memoizedProps)&&
a.focus();return;case 6:return;case 4:return;case 12:return;case 13:null===c.memoizedState&&(c=c.alternate,null!==c&&(c=c.memoizedState,null!==c&&(c=c.dehydrated,null!==c&&bg(c))));return;case 19:case 17:case 20:case 21:return}throw Error(k(163));}function Ch(a,b,c){"function"===typeof Ne&&Ne(b);switch(b.tag){case 0:case 11:case 14:case 15:case 22:a=b.updateQueue;if(null!==a&&(a=a.lastEffect,null!==a)){var d=a.next;Da(97<c?97:c,function(){var a=d;do{var c=a.destroy;if(void 0!==c){var g=b;try{c()}catch(h){Za(g,
h)}}a=a.next}while(a!==d)})}break;case 1:zh(b);c=b.stateNode;"function"===typeof c.componentWillUnmount&&mj(b,c);break;case 5:zh(b);break;case 4:Dh(a,b,c)}}function Eh(a){var b=a.alternate;a.return=null;a.child=null;a.memoizedState=null;a.updateQueue=null;a.dependencies=null;a.alternate=null;a.firstEffect=null;a.lastEffect=null;a.pendingProps=null;a.memoizedProps=null;a.stateNode=null;null!==b&&Eh(b)}function Fh(a){return 5===a.tag||3===a.tag||4===a.tag}function Gh(a){a:{for(var b=a.return;null!==
b;){if(Fh(b)){var c=b;break a}b=b.return}throw Error(k(160));}b=c.stateNode;switch(c.tag){case 5:var d=!1;break;case 3:b=b.containerInfo;d=!0;break;case 4:b=b.containerInfo;d=!0;break;default:throw Error(k(161));}c.effectTag&16&&(Wb(b,""),c.effectTag&=-17);a:b:for(c=a;;){for(;null===c.sibling;){if(null===c.return||Fh(c.return)){c=null;break a}c=c.return}c.sibling.return=c.return;for(c=c.sibling;5!==c.tag&&6!==c.tag&&18!==c.tag;){if(c.effectTag&2)continue b;if(null===c.child||4===c.tag)continue b;
else c.child.return=c,c=c.child}if(!(c.effectTag&2)){c=c.stateNode;break a}}d?Oe(a,c,b):Pe(a,c,b)}function Oe(a,b,c){var d=a.tag,e=5===d||6===d;if(e)a=e?a.stateNode:a.stateNode.instance,b?8===c.nodeType?c.parentNode.insertBefore(a,b):c.insertBefore(a,b):(8===c.nodeType?(b=c.parentNode,b.insertBefore(a,c)):(b=c,b.appendChild(a)),c=c._reactRootContainer,null!==c&&void 0!==c||null!==b.onclick||(b.onclick=uc));else if(4!==d&&(a=a.child,null!==a))for(Oe(a,b,c),a=a.sibling;null!==a;)Oe(a,b,c),a=a.sibling}
function Pe(a,b,c){var d=a.tag,e=5===d||6===d;if(e)a=e?a.stateNode:a.stateNode.instance,b?c.insertBefore(a,b):c.appendChild(a);else if(4!==d&&(a=a.child,null!==a))for(Pe(a,b,c),a=a.sibling;null!==a;)Pe(a,b,c),a=a.sibling}function Dh(a,b,c){for(var d=b,e=!1,f,g;;){if(!e){e=d.return;a:for(;;){if(null===e)throw Error(k(160));f=e.stateNode;switch(e.tag){case 5:g=!1;break a;case 3:f=f.containerInfo;g=!0;break a;case 4:f=f.containerInfo;g=!0;break a}e=e.return}e=!0}if(5===d.tag||6===d.tag){a:for(var h=
a,m=d,n=c,l=m;;)if(Ch(h,l,n),null!==l.child&&4!==l.tag)l.child.return=l,l=l.child;else{if(l===m)break a;for(;null===l.sibling;){if(null===l.return||l.return===m)break a;l=l.return}l.sibling.return=l.return;l=l.sibling}g?(h=f,m=d.stateNode,8===h.nodeType?h.parentNode.removeChild(m):h.removeChild(m)):f.removeChild(d.stateNode)}else if(4===d.tag){if(null!==d.child){f=d.stateNode.containerInfo;g=!0;d.child.return=d;d=d.child;continue}}else if(Ch(a,d,c),null!==d.child){d.child.return=d;d=d.child;continue}if(d===
b)break;for(;null===d.sibling;){if(null===d.return||d.return===b)return;d=d.return;4===d.tag&&(e=!1)}d.sibling.return=d.return;d=d.sibling}}function Qe(a,b){switch(b.tag){case 0:case 11:case 14:case 15:case 22:Ah(3,b);return;case 1:return;case 5:var c=b.stateNode;if(null!=c){var d=b.memoizedProps,e=null!==a?a.memoizedProps:d;a=b.type;var f=b.updateQueue;b.updateQueue=null;if(null!==f){c[vc]=d;"input"===a&&"radio"===d.type&&null!=d.name&&If(c,d);Vd(a,e);b=Vd(a,d);for(e=0;e<f.length;e+=2){var g=f[e],
h=f[e+1];"style"===g?gg(c,h):"dangerouslySetInnerHTML"===g?xh(c,h):"children"===g?Wb(c,h):xd(c,g,h,b)}switch(a){case "input":Dd(c,d);break;case "textarea":Lf(c,d);break;case "select":b=c._wrapperState.wasMultiple,c._wrapperState.wasMultiple=!!d.multiple,a=d.value,null!=a?hb(c,!!d.multiple,a,!1):b!==!!d.multiple&&(null!=d.defaultValue?hb(c,!!d.multiple,d.defaultValue,!0):hb(c,!!d.multiple,d.multiple?[]:"",!1))}}}return;case 6:if(null===b.stateNode)throw Error(k(162));b.stateNode.nodeValue=b.memoizedProps;
return;case 3:b=b.stateNode;b.hydrate&&(b.hydrate=!1,bg(b.containerInfo));return;case 12:return;case 13:c=b;null===b.memoizedState?d=!1:(d=!0,c=b.child,Re=Y());if(null!==c)a:for(a=c;;){if(5===a.tag)f=a.stateNode,d?(f=f.style,"function"===typeof f.setProperty?f.setProperty("display","none","important"):f.display="none"):(f=a.stateNode,e=a.memoizedProps.style,e=void 0!==e&&null!==e&&e.hasOwnProperty("display")?e.display:null,f.style.display=fg("display",e));else if(6===a.tag)a.stateNode.nodeValue=d?
"":a.memoizedProps;else if(13===a.tag&&null!==a.memoizedState&&null===a.memoizedState.dehydrated){f=a.child.sibling;f.return=a;a=f;continue}else if(null!==a.child){a.child.return=a;a=a.child;continue}if(a===c)break;for(;null===a.sibling;){if(null===a.return||a.return===c)break a;a=a.return}a.sibling.return=a.return;a=a.sibling}Hh(b);return;case 19:Hh(b);return;case 17:return}throw Error(k(163));}function Hh(a){var b=a.updateQueue;if(null!==b){a.updateQueue=null;var c=a.stateNode;null===c&&(c=a.stateNode=
new pj);b.forEach(function(b){var d=qj.bind(null,a,b);c.has(b)||(c.add(b),b.then(d,d))})}}function Ih(a,b,c){c=Ea(c,null);c.tag=3;c.payload={element:null};var d=b.value;c.callback=function(){cd||(cd=!0,Se=d);Me(a,b)};return c}function Jh(a,b,c){c=Ea(c,null);c.tag=3;var d=a.type.getDerivedStateFromError;if("function"===typeof d){var e=b.value;c.payload=function(){Me(a,b);return d(e)}}var f=a.stateNode;null!==f&&"function"===typeof f.componentDidCatch&&(c.callback=function(){"function"!==typeof d&&
(null===La?La=new Set([this]):La.add(this),Me(a,b));var c=b.stack;this.componentDidCatch(b.value,{componentStack:null!==c?c:""})});return c}function ka(){return(p&(ca|ma))!==H?1073741821-(Y()/10|0):0!==dd?dd:dd=1073741821-(Y()/10|0)}function Va(a,b,c){b=b.mode;if(0===(b&2))return 1073741823;var d=Cc();if(0===(b&4))return 99===d?1073741823:1073741822;if((p&ca)!==H)return P;if(null!==c)a=Fc(a,c.timeoutMs|0||5E3,250);else switch(d){case 99:a=1073741823;break;case 98:a=Fc(a,150,100);break;case 97:case 96:a=
Fc(a,5E3,250);break;case 95:a=2;break;default:throw Error(k(326));}null!==U&&a===P&&--a;return a}function ed(a,b){a.expirationTime<b&&(a.expirationTime=b);var c=a.alternate;null!==c&&c.expirationTime<b&&(c.expirationTime=b);var d=a.return,e=null;if(null===d&&3===a.tag)e=a.stateNode;else for(;null!==d;){c=d.alternate;d.childExpirationTime<b&&(d.childExpirationTime=b);null!==c&&c.childExpirationTime<b&&(c.childExpirationTime=b);if(null===d.return&&3===d.tag){e=d.stateNode;break}d=d.return}null!==e&&
(U===e&&(Kc(b),F===bd&&Ya(e,P)),yh(e,b));return e}function fd(a){var b=a.lastExpiredTime;if(0!==b)return b;b=a.firstPendingTime;if(!Kh(a,b))return b;var c=a.lastPingedTime;a=a.nextKnownPendingLevel;a=c>a?c:a;return 2>=a&&b!==a?0:a}function V(a){if(0!==a.lastExpiredTime)a.callbackExpirationTime=1073741823,a.callbackPriority=99,a.callbackNode=Og(Te.bind(null,a));else{var b=fd(a),c=a.callbackNode;if(0===b)null!==c&&(a.callbackNode=null,a.callbackExpirationTime=0,a.callbackPriority=90);else{var d=ka();
1073741823===b?d=99:1===b||2===b?d=95:(d=10*(1073741821-b)-10*(1073741821-d),d=0>=d?99:250>=d?98:5250>=d?97:95);if(null!==c){var e=a.callbackPriority;if(a.callbackExpirationTime===b&&e>=d)return;c!==Qg&&Rg(c)}a.callbackExpirationTime=b;a.callbackPriority=d;b=1073741823===b?Og(Te.bind(null,a)):Ng(d,Lh.bind(null,a),{timeout:10*(1073741821-b)-Y()});a.callbackNode=b}}}function Lh(a,b){dd=0;if(b)return b=ka(),Ue(a,b),V(a),null;var c=fd(a);if(0!==c){b=a.callbackNode;if((p&(ca|ma))!==H)throw Error(k(327));
xb();a===U&&c===P||$a(a,c);if(null!==t){var d=p;p|=ca;var e=Mh();do try{rj();break}catch(h){Nh(a,h)}while(1);le();p=d;gd.current=e;if(F===hd)throw b=id,$a(a,c),Ya(a,c),V(a),b;if(null===t)switch(e=a.finishedWork=a.current.alternate,a.finishedExpirationTime=c,d=F,U=null,d){case Xa:case hd:throw Error(k(345));case Oh:Ue(a,2<c?2:c);break;case ad:Ya(a,c);d=a.lastSuspendedTime;c===d&&(a.nextKnownPendingLevel=Ve(e));if(1073741823===ta&&(e=Re+Ph-Y(),10<e)){if(jd){var f=a.lastPingedTime;if(0===f||f>=c){a.lastPingedTime=
c;$a(a,c);break}}f=fd(a);if(0!==f&&f!==c)break;if(0!==d&&d!==c){a.lastPingedTime=d;break}a.timeoutHandle=We(ab.bind(null,a),e);break}ab(a);break;case bd:Ya(a,c);d=a.lastSuspendedTime;c===d&&(a.nextKnownPendingLevel=Ve(e));if(jd&&(e=a.lastPingedTime,0===e||e>=c)){a.lastPingedTime=c;$a(a,c);break}e=fd(a);if(0!==e&&e!==c)break;if(0!==d&&d!==c){a.lastPingedTime=d;break}1073741823!==Yb?d=10*(1073741821-Yb)-Y():1073741823===ta?d=0:(d=10*(1073741821-ta)-5E3,e=Y(),c=10*(1073741821-c)-e,d=e-d,0>d&&(d=0),d=
(120>d?120:480>d?480:1080>d?1080:1920>d?1920:3E3>d?3E3:4320>d?4320:1960*sj(d/1960))-d,c<d&&(d=c));if(10<d){a.timeoutHandle=We(ab.bind(null,a),d);break}ab(a);break;case Xe:if(1073741823!==ta&&null!==kd){f=ta;var g=kd;d=g.busyMinDurationMs|0;0>=d?d=0:(e=g.busyDelayMs|0,f=Y()-(10*(1073741821-f)-(g.timeoutMs|0||5E3)),d=f<=e?0:e+d-f);if(10<d){Ya(a,c);a.timeoutHandle=We(ab.bind(null,a),d);break}}ab(a);break;default:throw Error(k(329));}V(a);if(a.callbackNode===b)return Lh.bind(null,a)}}return null}function Te(a){var b=
a.lastExpiredTime;b=0!==b?b:1073741823;if((p&(ca|ma))!==H)throw Error(k(327));xb();a===U&&b===P||$a(a,b);if(null!==t){var c=p;p|=ca;var d=Mh();do try{tj();break}catch(e){Nh(a,e)}while(1);le();p=c;gd.current=d;if(F===hd)throw c=id,$a(a,b),Ya(a,b),V(a),c;if(null!==t)throw Error(k(261));a.finishedWork=a.current.alternate;a.finishedExpirationTime=b;U=null;ab(a);V(a)}return null}function uj(){if(null!==bb){var a=bb;bb=null;a.forEach(function(a,c){Ue(c,a);V(c)});ha()}}function Qh(a,b){var c=p;p|=1;try{return a(b)}finally{p=
c,p===H&&ha()}}function Rh(a,b){var c=p;p&=-2;p|=Ye;try{return a(b)}finally{p=c,p===H&&ha()}}function $a(a,b){a.finishedWork=null;a.finishedExpirationTime=0;var c=a.timeoutHandle;-1!==c&&(a.timeoutHandle=-1,vj(c));if(null!==t)for(c=t.return;null!==c;){var d=c;switch(d.tag){case 1:d=d.type.childContextTypes;null!==d&&void 0!==d&&(q(G),q(B));break;case 3:tb();q(G);q(B);break;case 5:te(d);break;case 4:tb();break;case 13:q(D);break;case 19:q(D);break;case 10:me(d)}c=c.return}U=a;t=Sa(a.current,null);
P=b;F=Xa;id=null;Yb=ta=1073741823;kd=null;Xb=0;jd=!1}function Nh(a,b){do{try{le();Sc.current=Tc;if(Uc)for(var c=z.memoizedState;null!==c;){var d=c.queue;null!==d&&(d.pending=null);c=c.next}Ia=0;J=K=z=null;Uc=!1;if(null===t||null===t.return)return F=hd,id=b,t=null;a:{var e=a,f=t.return,g=t,h=b;b=P;g.effectTag|=2048;g.firstEffect=g.lastEffect=null;if(null!==h&&"object"===typeof h&&"function"===typeof h.then){var m=h;if(0===(g.mode&2)){var n=g.alternate;n?(g.updateQueue=n.updateQueue,g.memoizedState=
n.memoizedState,g.expirationTime=n.expirationTime):(g.updateQueue=null,g.memoizedState=null)}var l=0!==(D.current&1),k=f;do{var p;if(p=13===k.tag){var q=k.memoizedState;if(null!==q)p=null!==q.dehydrated?!0:!1;else{var w=k.memoizedProps;p=void 0===w.fallback?!1:!0!==w.unstable_avoidThisFallback?!0:l?!1:!0}}if(p){var y=k.updateQueue;if(null===y){var r=new Set;r.add(m);k.updateQueue=r}else y.add(m);if(0===(k.mode&2)){k.effectTag|=64;g.effectTag&=-2981;if(1===g.tag)if(null===g.alternate)g.tag=17;else{var O=
Ea(1073741823,null);O.tag=Jc;Fa(g,O)}g.expirationTime=1073741823;break a}h=void 0;g=b;var v=e.pingCache;null===v?(v=e.pingCache=new wj,h=new Set,v.set(m,h)):(h=v.get(m),void 0===h&&(h=new Set,v.set(m,h)));if(!h.has(g)){h.add(g);var x=xj.bind(null,e,m,g);m.then(x,x)}k.effectTag|=4096;k.expirationTime=b;break a}k=k.return}while(null!==k);h=Error((na(g.type)||"A React component")+" suspended while rendering, but no fallback UI was specified.\n\nAdd a <Suspense fallback=...> component higher in the tree to provide a loading indicator or placeholder to display."+
Bd(g))}F!==Xe&&(F=Oh);h=Le(h,g);k=f;do{switch(k.tag){case 3:m=h;k.effectTag|=4096;k.expirationTime=b;var A=Ih(k,m,b);Ug(k,A);break a;case 1:m=h;var u=k.type,B=k.stateNode;if(0===(k.effectTag&64)&&("function"===typeof u.getDerivedStateFromError||null!==B&&"function"===typeof B.componentDidCatch&&(null===La||!La.has(B)))){k.effectTag|=4096;k.expirationTime=b;var H=Jh(k,m,b);Ug(k,H);break a}}k=k.return}while(null!==k)}t=Sh(t)}catch(cj){b=cj;continue}break}while(1)}function Mh(a){a=gd.current;gd.current=
Tc;return null===a?Tc:a}function Vg(a,b){a<ta&&2<a&&(ta=a);null!==b&&a<Yb&&2<a&&(Yb=a,kd=b)}function Kc(a){a>Xb&&(Xb=a)}function tj(){for(;null!==t;)t=Th(t)}function rj(){for(;null!==t&&!yj();)t=Th(t)}function Th(a){var b=zj(a.alternate,a,P);a.memoizedProps=a.pendingProps;null===b&&(b=Sh(a));Uh.current=null;return b}function Sh(a){t=a;do{var b=t.alternate;a=t.return;if(0===(t.effectTag&2048)){b=hj(b,t,P);if(1===P||1!==t.childExpirationTime){for(var c=0,d=t.child;null!==d;){var e=d.expirationTime,
f=d.childExpirationTime;e>c&&(c=e);f>c&&(c=f);d=d.sibling}t.childExpirationTime=c}if(null!==b)return b;null!==a&&0===(a.effectTag&2048)&&(null===a.firstEffect&&(a.firstEffect=t.firstEffect),null!==t.lastEffect&&(null!==a.lastEffect&&(a.lastEffect.nextEffect=t.firstEffect),a.lastEffect=t.lastEffect),1<t.effectTag&&(null!==a.lastEffect?a.lastEffect.nextEffect=t:a.firstEffect=t,a.lastEffect=t))}else{b=lj(t);if(null!==b)return b.effectTag&=2047,b;null!==a&&(a.firstEffect=a.lastEffect=null,a.effectTag|=
2048)}b=t.sibling;if(null!==b)return b;t=a}while(null!==t);F===Xa&&(F=Xe);return null}function Ve(a){var b=a.expirationTime;a=a.childExpirationTime;return b>a?b:a}function ab(a){var b=Cc();Da(99,Aj.bind(null,a,b));return null}function Aj(a,b){do xb();while(null!==Zb);if((p&(ca|ma))!==H)throw Error(k(327));var c=a.finishedWork,d=a.finishedExpirationTime;if(null===c)return null;a.finishedWork=null;a.finishedExpirationTime=0;if(c===a.current)throw Error(k(177));a.callbackNode=null;a.callbackExpirationTime=
0;a.callbackPriority=90;a.nextKnownPendingLevel=0;var e=Ve(c);a.firstPendingTime=e;d<=a.lastSuspendedTime?a.firstSuspendedTime=a.lastSuspendedTime=a.nextKnownPendingLevel=0:d<=a.firstSuspendedTime&&(a.firstSuspendedTime=d-1);d<=a.lastPingedTime&&(a.lastPingedTime=0);d<=a.lastExpiredTime&&(a.lastExpiredTime=0);a===U&&(t=U=null,P=0);1<c.effectTag?null!==c.lastEffect?(c.lastEffect.nextEffect=c,e=c.firstEffect):e=c:e=c.firstEffect;if(null!==e){var f=p;p|=ma;Uh.current=null;Ze=tc;var g=kg();if(Xd(g)){if("selectionStart"in
g)var h={start:g.selectionStart,end:g.selectionEnd};else a:{h=(h=g.ownerDocument)&&h.defaultView||window;var m=h.getSelection&&h.getSelection();if(m&&0!==m.rangeCount){h=m.anchorNode;var n=m.anchorOffset,q=m.focusNode;m=m.focusOffset;try{h.nodeType,q.nodeType}catch(sb){h=null;break a}var ba=0,w=-1,y=-1,B=0,D=0,r=g,z=null;b:for(;;){for(var v;;){r!==h||0!==n&&3!==r.nodeType||(w=ba+n);r!==q||0!==m&&3!==r.nodeType||(y=ba+m);3===r.nodeType&&(ba+=r.nodeValue.length);if(null===(v=r.firstChild))break;z=r;
r=v}for(;;){if(r===g)break b;z===h&&++B===n&&(w=ba);z===q&&++D===m&&(y=ba);if(null!==(v=r.nextSibling))break;r=z;z=r.parentNode}r=v}h=-1===w||-1===y?null:{start:w,end:y}}else h=null}h=h||{start:0,end:0}}else h=null;$e={activeElementDetached:null,focusedElem:g,selectionRange:h};tc=!1;l=e;do try{Bj()}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);l=e;do try{for(g=a,h=b;null!==l;){var x=l.effectTag;x&16&&Wb(l.stateNode,"");if(x&128){var A=l.alternate;if(null!==A){var u=
A.ref;null!==u&&("function"===typeof u?u(null):u.current=null)}}switch(x&1038){case 2:Gh(l);l.effectTag&=-3;break;case 6:Gh(l);l.effectTag&=-3;Qe(l.alternate,l);break;case 1024:l.effectTag&=-1025;break;case 1028:l.effectTag&=-1025;Qe(l.alternate,l);break;case 4:Qe(l.alternate,l);break;case 8:n=l,Dh(g,n,h),Eh(n)}l=l.nextEffect}}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);u=$e;A=kg();x=u.focusedElem;h=u.selectionRange;if(A!==x&&x&&x.ownerDocument&&jg(x.ownerDocument.documentElement,
x)){null!==h&&Xd(x)&&(A=h.start,u=h.end,void 0===u&&(u=A),"selectionStart"in x?(x.selectionStart=A,x.selectionEnd=Math.min(u,x.value.length)):(u=(A=x.ownerDocument||document)&&A.defaultView||window,u.getSelection&&(u=u.getSelection(),n=x.textContent.length,g=Math.min(h.start,n),h=void 0===h.end?g:Math.min(h.end,n),!u.extend&&g>h&&(n=h,h=g,g=n),n=ig(x,g),q=ig(x,h),n&&q&&(1!==u.rangeCount||u.anchorNode!==n.node||u.anchorOffset!==n.offset||u.focusNode!==q.node||u.focusOffset!==q.offset)&&(A=A.createRange(),
A.setStart(n.node,n.offset),u.removeAllRanges(),g>h?(u.addRange(A),u.extend(q.node,q.offset)):(A.setEnd(q.node,q.offset),u.addRange(A))))));A=[];for(u=x;u=u.parentNode;)1===u.nodeType&&A.push({element:u,left:u.scrollLeft,top:u.scrollTop});"function"===typeof x.focus&&x.focus();for(x=0;x<A.length;x++)u=A[x],u.element.scrollLeft=u.left,u.element.scrollTop=u.top}tc=!!Ze;$e=Ze=null;a.current=c;l=e;do try{for(x=a;null!==l;){var F=l.effectTag;F&36&&oj(x,l.alternate,l);if(F&128){A=void 0;var E=l.ref;if(null!==
E){var G=l.stateNode;switch(l.tag){case 5:A=G;break;default:A=G}"function"===typeof E?E(A):E.current=A}}l=l.nextEffect}}catch(sb){if(null===l)throw Error(k(330));Za(l,sb);l=l.nextEffect}while(null!==l);l=null;Cj();p=f}else a.current=c;if(ld)ld=!1,Zb=a,$b=b;else for(l=e;null!==l;)b=l.nextEffect,l.nextEffect=null,l=b;b=a.firstPendingTime;0===b&&(La=null);1073741823===b?a===af?ac++:(ac=0,af=a):ac=0;"function"===typeof bf&&bf(c.stateNode,d);V(a);if(cd)throw cd=!1,a=Se,Se=null,a;if((p&Ye)!==H)return null;
ha();return null}function Bj(){for(;null!==l;){var a=l.effectTag;0!==(a&256)&&nj(l.alternate,l);0===(a&512)||ld||(ld=!0,Ng(97,function(){xb();return null}));l=l.nextEffect}}function xb(){if(90!==$b){var a=97<$b?97:$b;$b=90;return Da(a,Dj)}}function Dj(){if(null===Zb)return!1;var a=Zb;Zb=null;if((p&(ca|ma))!==H)throw Error(k(331));var b=p;p|=ma;for(a=a.current.firstEffect;null!==a;){try{var c=a;if(0!==(c.effectTag&512))switch(c.tag){case 0:case 11:case 15:case 22:Ah(5,c),Bh(5,c)}}catch(d){if(null===
a)throw Error(k(330));Za(a,d)}c=a.nextEffect;a.nextEffect=null;a=c}p=b;ha();return!0}function Vh(a,b,c){b=Le(c,b);b=Ih(a,b,1073741823);Fa(a,b);a=ed(a,1073741823);null!==a&&V(a)}function Za(a,b){if(3===a.tag)Vh(a,a,b);else for(var c=a.return;null!==c;){if(3===c.tag){Vh(c,a,b);break}else if(1===c.tag){var d=c.stateNode;if("function"===typeof c.type.getDerivedStateFromError||"function"===typeof d.componentDidCatch&&(null===La||!La.has(d))){a=Le(b,a);a=Jh(c,a,1073741823);Fa(c,a);c=ed(c,1073741823);null!==
c&&V(c);break}}c=c.return}}function xj(a,b,c){var d=a.pingCache;null!==d&&d.delete(b);U===a&&P===c?F===bd||F===ad&&1073741823===ta&&Y()-Re<Ph?$a(a,P):jd=!0:Kh(a,c)&&(b=a.lastPingedTime,0!==b&&b<c||(a.lastPingedTime=c,V(a)))}function qj(a,b){var c=a.stateNode;null!==c&&c.delete(b);b=0;0===b&&(b=ka(),b=Va(b,a,null));a=ed(a,b);null!==a&&V(a)}function Ej(a){if("undefined"===typeof __REACT_DEVTOOLS_GLOBAL_HOOK__)return!1;var b=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(b.isDisabled||!b.supportsFiber)return!0;try{var c=
b.inject(a);bf=function(a,e){try{b.onCommitFiberRoot(c,a,void 0,64===(a.current.effectTag&64))}catch(f){}};Ne=function(a){try{b.onCommitFiberUnmount(c,a)}catch(e){}}}catch(d){}return!0}function Fj(a,b,c,d){this.tag=a;this.key=c;this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null;this.index=0;this.ref=null;this.pendingProps=b;this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null;this.mode=d;this.effectTag=0;this.lastEffect=this.firstEffect=this.nextEffect=
null;this.childExpirationTime=this.expirationTime=0;this.alternate=null}function Ge(a){a=a.prototype;return!(!a||!a.isReactComponent)}function Gj(a){if("function"===typeof a)return Ge(a)?1:0;if(void 0!==a&&null!==a){a=a.$$typeof;if(a===zd)return 11;if(a===Ad)return 14}return 2}function Sa(a,b){var c=a.alternate;null===c?(c=la(a.tag,b,a.key,a.mode),c.elementType=a.elementType,c.type=a.type,c.stateNode=a.stateNode,c.alternate=a,a.alternate=c):(c.pendingProps=b,c.effectTag=0,c.nextEffect=null,c.firstEffect=
null,c.lastEffect=null);c.childExpirationTime=a.childExpirationTime;c.expirationTime=a.expirationTime;c.child=a.child;c.memoizedProps=a.memoizedProps;c.memoizedState=a.memoizedState;c.updateQueue=a.updateQueue;b=a.dependencies;c.dependencies=null===b?null:{expirationTime:b.expirationTime,firstContext:b.firstContext,responders:b.responders};c.sibling=a.sibling;c.index=a.index;c.ref=a.ref;return c}function Oc(a,b,c,d,e,f){var g=2;d=a;if("function"===typeof a)Ge(a)&&(g=1);else if("string"===typeof a)g=
5;else a:switch(a){case Ma:return Ha(c.children,e,f,b);case Hj:g=8;e|=7;break;case Af:g=8;e|=1;break;case kc:return a=la(12,c,b,e|8),a.elementType=kc,a.type=kc,a.expirationTime=f,a;case lc:return a=la(13,c,b,e),a.type=lc,a.elementType=lc,a.expirationTime=f,a;case yd:return a=la(19,c,b,e),a.elementType=yd,a.expirationTime=f,a;default:if("object"===typeof a&&null!==a)switch(a.$$typeof){case Cf:g=10;break a;case Bf:g=9;break a;case zd:g=11;break a;case Ad:g=14;break a;case Ef:g=16;d=null;break a;case Df:g=
22;break a}throw Error(k(130,null==a?a:typeof a,""));}b=la(g,c,b,e);b.elementType=a;b.type=d;b.expirationTime=f;return b}function Ha(a,b,c,d){a=la(7,a,d,b);a.expirationTime=c;return a}function qe(a,b,c){a=la(6,a,null,b);a.expirationTime=c;return a}function re(a,b,c){b=la(4,null!==a.children?a.children:[],a.key,b);b.expirationTime=c;b.stateNode={containerInfo:a.containerInfo,pendingChildren:null,implementation:a.implementation};return b}function Ij(a,b,c){this.tag=b;this.current=null;this.containerInfo=
a;this.pingCache=this.pendingChildren=null;this.finishedExpirationTime=0;this.finishedWork=null;this.timeoutHandle=-1;this.pendingContext=this.context=null;this.hydrate=c;this.callbackNode=null;this.callbackPriority=90;this.lastExpiredTime=this.lastPingedTime=this.nextKnownPendingLevel=this.lastSuspendedTime=this.firstSuspendedTime=this.firstPendingTime=0}function Kh(a,b){var c=a.firstSuspendedTime;a=a.lastSuspendedTime;return 0!==c&&c>=b&&a<=b}function Ya(a,b){var c=a.firstSuspendedTime,d=a.lastSuspendedTime;
c<b&&(a.firstSuspendedTime=b);if(d>b||0===c)a.lastSuspendedTime=b;b<=a.lastPingedTime&&(a.lastPingedTime=0);b<=a.lastExpiredTime&&(a.lastExpiredTime=0)}function yh(a,b){b>a.firstPendingTime&&(a.firstPendingTime=b);var c=a.firstSuspendedTime;0!==c&&(b>=c?a.firstSuspendedTime=a.lastSuspendedTime=a.nextKnownPendingLevel=0:b>=a.lastSuspendedTime&&(a.lastSuspendedTime=b+1),b>a.nextKnownPendingLevel&&(a.nextKnownPendingLevel=b))}function Ue(a,b){var c=a.lastExpiredTime;if(0===c||c>b)a.lastExpiredTime=b}
function md(a,b,c,d){var e=b.current,f=ka(),g=Vb.suspense;f=Va(f,e,g);a:if(c){c=c._reactInternalFiber;b:{if(Na(c)!==c||1!==c.tag)throw Error(k(170));var h=c;do{switch(h.tag){case 3:h=h.stateNode.context;break b;case 1:if(N(h.type)){h=h.stateNode.__reactInternalMemoizedMergedChildContext;break b}}h=h.return}while(null!==h);throw Error(k(171));}if(1===c.tag){var m=c.type;if(N(m)){c=Gg(c,m,h);break a}}c=h}else c=Ca;null===b.context?b.context=c:b.pendingContext=c;b=Ea(f,g);b.payload={element:a};d=void 0===
d?null:d;null!==d&&(b.callback=d);Fa(e,b);Ja(e,f);return f}function cf(a){a=a.current;if(!a.child)return null;switch(a.child.tag){case 5:return a.child.stateNode;default:return a.child.stateNode}}function Wh(a,b){a=a.memoizedState;null!==a&&null!==a.dehydrated&&a.retryTime<b&&(a.retryTime=b)}function df(a,b){Wh(a,b);(a=a.alternate)&&Wh(a,b)}function ef(a,b,c){c=null!=c&&!0===c.hydrate;var d=new Ij(a,b,c),e=la(3,null,null,2===b?7:1===b?3:0);d.current=e;e.stateNode=d;ne(e);a[Lb]=d.current;c&&0!==b&&
xi(a,9===a.nodeType?a:a.ownerDocument);this._internalRoot=d}function bc(a){return!(!a||1!==a.nodeType&&9!==a.nodeType&&11!==a.nodeType&&(8!==a.nodeType||" react-mount-point-unstable "!==a.nodeValue))}function Jj(a,b){b||(b=a?9===a.nodeType?a.documentElement:a.firstChild:null,b=!(!b||1!==b.nodeType||!b.hasAttribute("data-reactroot")));if(!b)for(var c;c=a.lastChild;)a.removeChild(c);return new ef(a,0,b?{hydrate:!0}:void 0)}function nd(a,b,c,d,e){var f=c._reactRootContainer;if(f){var g=f._internalRoot;
if("function"===typeof e){var h=e;e=function(){var a=cf(g);h.call(a)}}md(b,g,a,e)}else{f=c._reactRootContainer=Jj(c,d);g=f._internalRoot;if("function"===typeof e){var m=e;e=function(){var a=cf(g);m.call(a)}}Rh(function(){md(b,g,a,e)})}return cf(g)}function Kj(a,b,c){var d=3<arguments.length&&void 0!==arguments[3]?arguments[3]:null;return{$$typeof:gb,key:null==d?null:""+d,children:a,containerInfo:b,implementation:c}}function Xh(a,b){var c=2<arguments.length&&void 0!==arguments[2]?arguments[2]:null;
if(!bc(b))throw Error(k(200));return Kj(a,b,null,c)}if(!ea)throw Error(k(227));var ki=function(a,b,c,d,e,f,g,h,m){var n=Array.prototype.slice.call(arguments,3);try{b.apply(c,n)}catch(C){this.onError(C)}},yb=!1,gc=null,hc=!1,pd=null,li={onError:function(a){yb=!0;gc=a}},td=null,rf=null,mf=null,ic=null,cb={},jc=[],qd={},db={},rd={},wa=!("undefined"===typeof window||"undefined"===typeof window.document||"undefined"===typeof window.document.createElement),M=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.assign,
sd=null,eb=null,fb=null,ee=function(a,b){return a(b)},eg=function(a,b,c,d,e){return a(b,c,d,e)},vd=function(){},vf=ee,Oa=!1,wd=!1,Z=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.Scheduler,Lj=Z.unstable_cancelCallback,ff=Z.unstable_now,$f=Z.unstable_scheduleCallback,Mj=Z.unstable_shouldYield,Yh=Z.unstable_requestPaint,Pd=Z.unstable_runWithPriority,Nj=Z.unstable_getCurrentPriorityLevel,Oj=Z.unstable_ImmediatePriority,Zh=Z.unstable_UserBlockingPriority,ag=Z.unstable_NormalPriority,Pj=Z.unstable_LowPriority,
Qj=Z.unstable_IdlePriority,oi=/^[:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD][:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\-.0-9\u00B7\u0300-\u036F\u203F-\u2040]*$/,wf=Object.prototype.hasOwnProperty,yf={},xf={},E={};"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style".split(" ").forEach(function(a){E[a]=
new L(a,0,!1,a,null,!1)});[["acceptCharset","accept-charset"],["className","class"],["htmlFor","for"],["httpEquiv","http-equiv"]].forEach(function(a){var b=a[0];E[b]=new L(b,1,!1,a[1],null,!1)});["contentEditable","draggable","spellCheck","value"].forEach(function(a){E[a]=new L(a,2,!1,a.toLowerCase(),null,!1)});["autoReverse","externalResourcesRequired","focusable","preserveAlpha"].forEach(function(a){E[a]=new L(a,2,!1,a,null,!1)});"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope".split(" ").forEach(function(a){E[a]=
new L(a,3,!1,a.toLowerCase(),null,!1)});["checked","multiple","muted","selected"].forEach(function(a){E[a]=new L(a,3,!0,a,null,!1)});["capture","download"].forEach(function(a){E[a]=new L(a,4,!1,a,null,!1)});["cols","rows","size","span"].forEach(function(a){E[a]=new L(a,6,!1,a,null,!1)});["rowSpan","start"].forEach(function(a){E[a]=new L(a,5,!1,a.toLowerCase(),null,!1)});var gf=/[\-:]([a-z])/g,hf=function(a){return a[1].toUpperCase()};"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height".split(" ").forEach(function(a){var b=
a.replace(gf,hf);E[b]=new L(b,1,!1,a,null,!1)});"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type".split(" ").forEach(function(a){var b=a.replace(gf,hf);E[b]=new L(b,1,!1,a,"http://www.w3.org/1999/xlink",!1)});["xml:base","xml:lang","xml:space"].forEach(function(a){var b=a.replace(gf,hf);E[b]=new L(b,1,!1,a,"http://www.w3.org/XML/1998/namespace",!1)});["tabIndex","crossOrigin"].forEach(function(a){E[a]=new L(a,1,!1,a.toLowerCase(),null,!1)});E.xlinkHref=new L("xlinkHref",1,
!1,"xlink:href","http://www.w3.org/1999/xlink",!0);["src","href","action","formAction"].forEach(function(a){E[a]=new L(a,1,!1,a.toLowerCase(),null,!0)});var da=ea.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;da.hasOwnProperty("ReactCurrentDispatcher")||(da.ReactCurrentDispatcher={current:null});da.hasOwnProperty("ReactCurrentBatchConfig")||(da.ReactCurrentBatchConfig={suspense:null});var si=/^(.*)[\\\/]/,Q="function"===typeof Symbol&&Symbol.for,Pc=Q?Symbol.for("react.element"):60103,gb=Q?Symbol.for("react.portal"):
60106,Ma=Q?Symbol.for("react.fragment"):60107,Af=Q?Symbol.for("react.strict_mode"):60108,kc=Q?Symbol.for("react.profiler"):60114,Cf=Q?Symbol.for("react.provider"):60109,Bf=Q?Symbol.for("react.context"):60110,Hj=Q?Symbol.for("react.concurrent_mode"):60111,zd=Q?Symbol.for("react.forward_ref"):60112,lc=Q?Symbol.for("react.suspense"):60113,yd=Q?Symbol.for("react.suspense_list"):60120,Ad=Q?Symbol.for("react.memo"):60115,Ef=Q?Symbol.for("react.lazy"):60116,Df=Q?Symbol.for("react.block"):60121,zf="function"===
typeof Symbol&&Symbol.iterator,od,xh=function(a){return"undefined"!==typeof MSApp&&MSApp.execUnsafeLocalFunction?function(b,c,d,e){MSApp.execUnsafeLocalFunction(function(){return a(b,c,d,e)})}:a}(function(a,b){if("http://www.w3.org/2000/svg"!==a.namespaceURI||"innerHTML"in a)a.innerHTML=b;else{od=od||document.createElement("div");od.innerHTML="<svg>"+b.valueOf().toString()+"</svg>";for(b=od.firstChild;a.firstChild;)a.removeChild(a.firstChild);for(;b.firstChild;)a.appendChild(b.firstChild)}}),Wb=function(a,
b){if(b){var c=a.firstChild;if(c&&c===a.lastChild&&3===c.nodeType){c.nodeValue=b;return}}a.textContent=b},ib={animationend:nc("Animation","AnimationEnd"),animationiteration:nc("Animation","AnimationIteration"),animationstart:nc("Animation","AnimationStart"),transitionend:nc("Transition","TransitionEnd")},Id={},Of={};wa&&(Of=document.createElement("div").style,"AnimationEvent"in window||(delete ib.animationend.animation,delete ib.animationiteration.animation,delete ib.animationstart.animation),"TransitionEvent"in
window||delete ib.transitionend.transition);var $h=oc("animationend"),ai=oc("animationiteration"),bi=oc("animationstart"),ci=oc("transitionend"),Db="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),Pf=new ("function"===typeof WeakMap?WeakMap:Map),Ab=null,wi=function(a){if(a){var b=a._dispatchListeners,c=a._dispatchInstances;
if(Array.isArray(b))for(var d=0;d<b.length&&!a.isPropagationStopped();d++)lf(a,b[d],c[d]);else b&&lf(a,b,c);a._dispatchListeners=null;a._dispatchInstances=null;a.isPersistent()||a.constructor.release(a)}},qc=[],Rd=!1,fa=[],xa=null,ya=null,za=null,Eb=new Map,Fb=new Map,Jb=[],Nd="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput close cancel copy cut paste click change contextmenu reset submit".split(" "),
yi="focus blur dragenter dragleave mouseover mouseout pointerover pointerout gotpointercapture lostpointercapture".split(" "),dg={},cg=new Map,Td=new Map,Rj=["abort","abort",$h,"animationEnd",ai,"animationIteration",bi,"animationStart","canplay","canPlay","canplaythrough","canPlayThrough","durationchange","durationChange","emptied","emptied","encrypted","encrypted","ended","ended","error","error","gotpointercapture","gotPointerCapture","load","load","loadeddata","loadedData","loadedmetadata","loadedMetadata",
"loadstart","loadStart","lostpointercapture","lostPointerCapture","playing","playing","progress","progress","seeking","seeking","stalled","stalled","suspend","suspend","timeupdate","timeUpdate",ci,"transitionEnd","waiting","waiting"];Sd("blur blur cancel cancel click click close close contextmenu contextMenu copy copy cut cut auxclick auxClick dblclick doubleClick dragend dragEnd dragstart dragStart drop drop focus focus input input invalid invalid keydown keyDown keypress keyPress keyup keyUp mousedown mouseDown mouseup mouseUp paste paste pause pause play play pointercancel pointerCancel pointerdown pointerDown pointerup pointerUp ratechange rateChange reset reset seeked seeked submit submit touchcancel touchCancel touchend touchEnd touchstart touchStart volumechange volumeChange".split(" "),
0);Sd("drag drag dragenter dragEnter dragexit dragExit dragleave dragLeave dragover dragOver mousemove mouseMove mouseout mouseOut mouseover mouseOver pointermove pointerMove pointerout pointerOut pointerover pointerOver scroll scroll toggle toggle touchmove touchMove wheel wheel".split(" "),1);Sd(Rj,2);(function(a,b){for(var c=0;c<a.length;c++)Td.set(a[c],b)})("change selectionchange textInput compositionstart compositionend compositionupdate".split(" "),0);var Hi=Zh,Gi=Pd,tc=!0,Kb={animationIterationCount:!0,
borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,
strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},Sj=["Webkit","ms","Moz","O"];Object.keys(Kb).forEach(function(a){Sj.forEach(function(b){b=b+a.charAt(0).toUpperCase()+a.substring(1);Kb[b]=Kb[a]})});var Ii=M({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0}),ng="$",og="/$",$d="$?",Zd="$!",Ze=null,$e=null,We="function"===typeof setTimeout?setTimeout:void 0,vj="function"===
typeof clearTimeout?clearTimeout:void 0,jf=Math.random().toString(36).slice(2),Aa="__reactInternalInstance$"+jf,vc="__reactEventHandlers$"+jf,Lb="__reactContainere$"+jf,Ba=null,ce=null,wc=null;M(R.prototype,{preventDefault:function(){this.defaultPrevented=!0;var a=this.nativeEvent;a&&(a.preventDefault?a.preventDefault():"unknown"!==typeof a.returnValue&&(a.returnValue=!1),this.isDefaultPrevented=xc)},stopPropagation:function(){var a=this.nativeEvent;a&&(a.stopPropagation?a.stopPropagation():"unknown"!==
typeof a.cancelBubble&&(a.cancelBubble=!0),this.isPropagationStopped=xc)},persist:function(){this.isPersistent=xc},isPersistent:yc,destructor:function(){var a=this.constructor.Interface,b;for(b in a)this[b]=null;this.nativeEvent=this._targetInst=this.dispatchConfig=null;this.isPropagationStopped=this.isDefaultPrevented=yc;this._dispatchInstances=this._dispatchListeners=null}});R.Interface={type:null,target:null,currentTarget:function(){return null},eventPhase:null,bubbles:null,cancelable:null,timeStamp:function(a){return a.timeStamp||
Date.now()},defaultPrevented:null,isTrusted:null};R.extend=function(a){function b(){return c.apply(this,arguments)}var c=this,d=function(){};d.prototype=c.prototype;d=new d;M(d,b.prototype);b.prototype=d;b.prototype.constructor=b;b.Interface=M({},c.Interface,a);b.extend=c.extend;sg(b);return b};sg(R);var Tj=R.extend({data:null}),Uj=R.extend({data:null}),Ni=[9,13,27,32],de=wa&&"CompositionEvent"in window,cc=null;wa&&"documentMode"in document&&(cc=document.documentMode);var Vj=wa&&"TextEvent"in window&&
!cc,xg=wa&&(!de||cc&&8<cc&&11>=cc),wg=String.fromCharCode(32),ua={beforeInput:{phasedRegistrationNames:{bubbled:"onBeforeInput",captured:"onBeforeInputCapture"},dependencies:["compositionend","keypress","textInput","paste"]},compositionEnd:{phasedRegistrationNames:{bubbled:"onCompositionEnd",captured:"onCompositionEndCapture"},dependencies:"blur compositionend keydown keypress keyup mousedown".split(" ")},compositionStart:{phasedRegistrationNames:{bubbled:"onCompositionStart",captured:"onCompositionStartCapture"},
dependencies:"blur compositionstart keydown keypress keyup mousedown".split(" ")},compositionUpdate:{phasedRegistrationNames:{bubbled:"onCompositionUpdate",captured:"onCompositionUpdateCapture"},dependencies:"blur compositionupdate keydown keypress keyup mousedown".split(" ")}},vg=!1,mb=!1,Wj={eventTypes:ua,extractEvents:function(a,b,c,d,e){var f;if(de)b:{switch(a){case "compositionstart":var g=ua.compositionStart;break b;case "compositionend":g=ua.compositionEnd;break b;case "compositionupdate":g=
ua.compositionUpdate;break b}g=void 0}else mb?tg(a,c)&&(g=ua.compositionEnd):"keydown"===a&&229===c.keyCode&&(g=ua.compositionStart);g?(xg&&"ko"!==c.locale&&(mb||g!==ua.compositionStart?g===ua.compositionEnd&&mb&&(f=rg()):(Ba=d,ce="value"in Ba?Ba.value:Ba.textContent,mb=!0)),e=Tj.getPooled(g,b,c,d),f?e.data=f:(f=ug(c),null!==f&&(e.data=f)),lb(e),f=e):f=null;(a=Vj?Oi(a,c):Pi(a,c))?(b=Uj.getPooled(ua.beforeInput,b,c,d),b.data=a,lb(b)):b=null;return null===f?b:null===b?f:[f,b]}},Qi={color:!0,date:!0,
datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0},Ag={change:{phasedRegistrationNames:{bubbled:"onChange",captured:"onChangeCapture"},dependencies:"blur change click focus input keydown keyup selectionchange".split(" ")}},Mb=null,Nb=null,kf=!1;wa&&(kf=Tf("input")&&(!document.documentMode||9<document.documentMode));var Xj={eventTypes:Ag,_isInputEventSupported:kf,extractEvents:function(a,b,c,d,e){e=b?Pa(b):window;var f=
e.nodeName&&e.nodeName.toLowerCase();if("select"===f||"input"===f&&"file"===e.type)var g=Si;else if(yg(e))if(kf)g=Wi;else{g=Ui;var h=Ti}else(f=e.nodeName)&&"input"===f.toLowerCase()&&("checkbox"===e.type||"radio"===e.type)&&(g=Vi);if(g&&(g=g(a,b)))return zg(g,c,d);h&&h(a,e,b);"blur"===a&&(a=e._wrapperState)&&a.controlled&&"number"===e.type&&Ed(e,"number",e.value)}},dc=R.extend({view:null,detail:null}),Yi={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"},di=0,ei=0,fi=!1,gi=!1,ec=dc.extend({screenX:null,
screenY:null,clientX:null,clientY:null,pageX:null,pageY:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,getModifierState:fe,button:null,buttons:null,relatedTarget:function(a){return a.relatedTarget||(a.fromElement===a.srcElement?a.toElement:a.fromElement)},movementX:function(a){if("movementX"in a)return a.movementX;var b=di;di=a.screenX;return fi?"mousemove"===a.type?a.screenX-b:0:(fi=!0,0)},movementY:function(a){if("movementY"in a)return a.movementY;var b=ei;ei=a.screenY;return gi?"mousemove"===
a.type?a.screenY-b:0:(gi=!0,0)}}),hi=ec.extend({pointerId:null,width:null,height:null,pressure:null,tangentialPressure:null,tiltX:null,tiltY:null,twist:null,pointerType:null,isPrimary:null}),fc={mouseEnter:{registrationName:"onMouseEnter",dependencies:["mouseout","mouseover"]},mouseLeave:{registrationName:"onMouseLeave",dependencies:["mouseout","mouseover"]},pointerEnter:{registrationName:"onPointerEnter",dependencies:["pointerout","pointerover"]},pointerLeave:{registrationName:"onPointerLeave",dependencies:["pointerout",
"pointerover"]}},Yj={eventTypes:fc,extractEvents:function(a,b,c,d,e){var f="mouseover"===a||"pointerover"===a,g="mouseout"===a||"pointerout"===a;if(f&&0===(e&32)&&(c.relatedTarget||c.fromElement)||!g&&!f)return null;f=d.window===d?d:(f=d.ownerDocument)?f.defaultView||f.parentWindow:window;if(g){if(g=b,b=(b=c.relatedTarget||c.toElement)?Bb(b):null,null!==b){var h=Na(b);if(b!==h||5!==b.tag&&6!==b.tag)b=null}}else g=null;if(g===b)return null;if("mouseout"===a||"mouseover"===a){var m=ec;var n=fc.mouseLeave;
var l=fc.mouseEnter;var k="mouse"}else if("pointerout"===a||"pointerover"===a)m=hi,n=fc.pointerLeave,l=fc.pointerEnter,k="pointer";a=null==g?f:Pa(g);f=null==b?f:Pa(b);n=m.getPooled(n,g,c,d);n.type=k+"leave";n.target=a;n.relatedTarget=f;c=m.getPooled(l,b,c,d);c.type=k+"enter";c.target=f;c.relatedTarget=a;d=g;k=b;if(d&&k)a:{m=d;l=k;g=0;for(a=m;a;a=pa(a))g++;a=0;for(b=l;b;b=pa(b))a++;for(;0<g-a;)m=pa(m),g--;for(;0<a-g;)l=pa(l),a--;for(;g--;){if(m===l||m===l.alternate)break a;m=pa(m);l=pa(l)}m=null}else m=
null;l=m;for(m=[];d&&d!==l;){g=d.alternate;if(null!==g&&g===l)break;m.push(d);d=pa(d)}for(d=[];k&&k!==l;){g=k.alternate;if(null!==g&&g===l)break;d.push(k);k=pa(k)}for(k=0;k<m.length;k++)be(m[k],"bubbled",n);for(k=d.length;0<k--;)be(d[k],"captured",c);return 0===(e&64)?[n]:[n,c]}},Qa="function"===typeof Object.is?Object.is:Zi,$i=Object.prototype.hasOwnProperty,Zj=wa&&"documentMode"in document&&11>=document.documentMode,Eg={select:{phasedRegistrationNames:{bubbled:"onSelect",captured:"onSelectCapture"},
dependencies:"blur contextmenu dragend focus keydown keyup mousedown mouseup selectionchange".split(" ")}},nb=null,he=null,Pb=null,ge=!1,ak={eventTypes:Eg,extractEvents:function(a,b,c,d,e,f){e=f||(d.window===d?d.document:9===d.nodeType?d:d.ownerDocument);if(!(f=!e)){a:{e=Jd(e);f=rd.onSelect;for(var g=0;g<f.length;g++)if(!e.has(f[g])){e=!1;break a}e=!0}f=!e}if(f)return null;e=b?Pa(b):window;switch(a){case "focus":if(yg(e)||"true"===e.contentEditable)nb=e,he=b,Pb=null;break;case "blur":Pb=he=nb=null;
break;case "mousedown":ge=!0;break;case "contextmenu":case "mouseup":case "dragend":return ge=!1,Dg(c,d);case "selectionchange":if(Zj)break;case "keydown":case "keyup":return Dg(c,d)}return null}},bk=R.extend({animationName:null,elapsedTime:null,pseudoElement:null}),ck=R.extend({clipboardData:function(a){return"clipboardData"in a?a.clipboardData:window.clipboardData}}),dk=dc.extend({relatedTarget:null}),ek={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",
Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},fk={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",
224:"Meta"},gk=dc.extend({key:function(a){if(a.key){var b=ek[a.key]||a.key;if("Unidentified"!==b)return b}return"keypress"===a.type?(a=Ac(a),13===a?"Enter":String.fromCharCode(a)):"keydown"===a.type||"keyup"===a.type?fk[a.keyCode]||"Unidentified":""},location:null,ctrlKey:null,shiftKey:null,altKey:null,metaKey:null,repeat:null,locale:null,getModifierState:fe,charCode:function(a){return"keypress"===a.type?Ac(a):0},keyCode:function(a){return"keydown"===a.type||"keyup"===a.type?a.keyCode:0},which:function(a){return"keypress"===
a.type?Ac(a):"keydown"===a.type||"keyup"===a.type?a.keyCode:0}}),hk=ec.extend({dataTransfer:null}),ik=dc.extend({touches:null,targetTouches:null,changedTouches:null,altKey:null,metaKey:null,ctrlKey:null,shiftKey:null,getModifierState:fe}),jk=R.extend({propertyName:null,elapsedTime:null,pseudoElement:null}),kk=ec.extend({deltaX:function(a){return"deltaX"in a?a.deltaX:"wheelDeltaX"in a?-a.wheelDeltaX:0},deltaY:function(a){return"deltaY"in a?a.deltaY:"wheelDeltaY"in a?-a.wheelDeltaY:"wheelDelta"in a?
-a.wheelDelta:0},deltaZ:null,deltaMode:null}),lk={eventTypes:dg,extractEvents:function(a,b,c,d,e){e=cg.get(a);if(!e)return null;switch(a){case "keypress":if(0===Ac(c))return null;case "keydown":case "keyup":a=gk;break;case "blur":case "focus":a=dk;break;case "click":if(2===c.button)return null;case "auxclick":case "dblclick":case "mousedown":case "mousemove":case "mouseup":case "mouseout":case "mouseover":case "contextmenu":a=ec;break;case "drag":case "dragend":case "dragenter":case "dragexit":case "dragleave":case "dragover":case "dragstart":case "drop":a=
hk;break;case "touchcancel":case "touchend":case "touchmove":case "touchstart":a=ik;break;case $h:case ai:case bi:a=bk;break;case ci:a=jk;break;case "scroll":a=dc;break;case "wheel":a=kk;break;case "copy":case "cut":case "paste":a=ck;break;case "gotpointercapture":case "lostpointercapture":case "pointercancel":case "pointerdown":case "pointermove":case "pointerout":case "pointerover":case "pointerup":a=hi;break;default:a=R}b=a.getPooled(e,b,c,d);lb(b);return b}};(function(a){if(ic)throw Error(k(101));
ic=Array.prototype.slice.call(a);nf()})("ResponderEventPlugin SimpleEventPlugin EnterLeaveEventPlugin ChangeEventPlugin SelectEventPlugin BeforeInputEventPlugin".split(" "));(function(a,b,c){td=a;rf=b;mf=c})(ae,Hb,Pa);pf({SimpleEventPlugin:lk,EnterLeaveEventPlugin:Yj,ChangeEventPlugin:Xj,SelectEventPlugin:ak,BeforeInputEventPlugin:Wj});var ie=[],ob=-1,Ca={},B={current:Ca},G={current:!1},Ra=Ca,bj=Pd,je=$f,Rg=Lj,aj=Nj,Dc=Oj,Ig=Zh,Jg=ag,Kg=Pj,Lg=Qj,Qg={},yj=Mj,Cj=void 0!==Yh?Yh:function(){},qa=null,
Ec=null,ke=!1,ii=ff(),Y=1E4>ii?ff:function(){return ff()-ii},Ic={current:null},Hc=null,qb=null,Gc=null,Tg=0,Jc=2,Ga=!1,Vb=da.ReactCurrentBatchConfig,$g=(new ea.Component).refs,Mc={isMounted:function(a){return(a=a._reactInternalFiber)?Na(a)===a:!1},enqueueSetState:function(a,b,c){a=a._reactInternalFiber;var d=ka(),e=Vb.suspense;d=Va(d,a,e);e=Ea(d,e);e.payload=b;void 0!==c&&null!==c&&(e.callback=c);Fa(a,e);Ja(a,d)},enqueueReplaceState:function(a,b,c){a=a._reactInternalFiber;var d=ka(),e=Vb.suspense;
d=Va(d,a,e);e=Ea(d,e);e.tag=1;e.payload=b;void 0!==c&&null!==c&&(e.callback=c);Fa(a,e);Ja(a,d)},enqueueForceUpdate:function(a,b){a=a._reactInternalFiber;var c=ka(),d=Vb.suspense;c=Va(c,a,d);d=Ea(c,d);d.tag=Jc;void 0!==b&&null!==b&&(d.callback=b);Fa(a,d);Ja(a,c)}},Qc=Array.isArray,wb=ah(!0),Fe=ah(!1),Sb={},ja={current:Sb},Ub={current:Sb},Tb={current:Sb},D={current:0},Sc=da.ReactCurrentDispatcher,X=da.ReactCurrentBatchConfig,Ia=0,z=null,K=null,J=null,Uc=!1,Tc={readContext:W,useCallback:S,useContext:S,
useEffect:S,useImperativeHandle:S,useLayoutEffect:S,useMemo:S,useReducer:S,useRef:S,useState:S,useDebugValue:S,useResponder:S,useDeferredValue:S,useTransition:S},dj={readContext:W,useCallback:ih,useContext:W,useEffect:eh,useImperativeHandle:function(a,b,c){c=null!==c&&void 0!==c?c.concat([a]):null;return ze(4,2,gh.bind(null,b,a),c)},useLayoutEffect:function(a,b){return ze(4,2,a,b)},useMemo:function(a,b){var c=ub();b=void 0===b?null:b;a=a();c.memoizedState=[a,b];return a},useReducer:function(a,b,c){var d=
ub();b=void 0!==c?c(b):b;d.memoizedState=d.baseState=b;a=d.queue={pending:null,dispatch:null,lastRenderedReducer:a,lastRenderedState:b};a=a.dispatch=ch.bind(null,z,a);return[d.memoizedState,a]},useRef:function(a){var b=ub();a={current:a};return b.memoizedState=a},useState:xe,useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=xe(a),d=c[0],e=c[1];eh(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=
xe(!1),c=b[0];b=b[1];return[ih(Ce.bind(null,b,a),[b,a]),c]}},ej={readContext:W,useCallback:Yc,useContext:W,useEffect:Xc,useImperativeHandle:hh,useLayoutEffect:fh,useMemo:jh,useReducer:Vc,useRef:dh,useState:function(a){return Vc(Ua)},useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=Vc(Ua),d=c[0],e=c[1];Xc(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=Vc(Ua),c=b[0];b=b[1];return[Yc(Ce.bind(null,
b,a),[b,a]),c]}},fj={readContext:W,useCallback:Yc,useContext:W,useEffect:Xc,useImperativeHandle:hh,useLayoutEffect:fh,useMemo:jh,useReducer:Wc,useRef:dh,useState:function(a){return Wc(Ua)},useDebugValue:Be,useResponder:ue,useDeferredValue:function(a,b){var c=Wc(Ua),d=c[0],e=c[1];Xc(function(){var c=X.suspense;X.suspense=void 0===b?null:b;try{e(a)}finally{X.suspense=c}},[a,b]);return d},useTransition:function(a){var b=Wc(Ua),c=b[0];b=b[1];return[Yc(Ce.bind(null,b,a),[b,a]),c]}},ra=null,Ka=null,Wa=
!1,gj=da.ReactCurrentOwner,ia=!1,Je={dehydrated:null,retryTime:0};var jj=function(a,b,c,d){for(c=b.child;null!==c;){if(5===c.tag||6===c.tag)a.appendChild(c.stateNode);else if(4!==c.tag&&null!==c.child){c.child.return=c;c=c.child;continue}if(c===b)break;for(;null===c.sibling;){if(null===c.return||c.return===b)return;c=c.return}c.sibling.return=c.return;c=c.sibling}};var wh=function(a){};var ij=function(a,b,c,d,e){var f=a.memoizedProps;if(f!==d){var g=b.stateNode;Ta(ja.current);a=null;switch(c){case "input":f=
Cd(g,f);d=Cd(g,d);a=[];break;case "option":f=Fd(g,f);d=Fd(g,d);a=[];break;case "select":f=M({},f,{value:void 0});d=M({},d,{value:void 0});a=[];break;case "textarea":f=Gd(g,f);d=Gd(g,d);a=[];break;default:"function"!==typeof f.onClick&&"function"===typeof d.onClick&&(g.onclick=uc)}Ud(c,d);var h,m;c=null;for(h in f)if(!d.hasOwnProperty(h)&&f.hasOwnProperty(h)&&null!=f[h])if("style"===h)for(m in g=f[h],g)g.hasOwnProperty(m)&&(c||(c={}),c[m]="");else"dangerouslySetInnerHTML"!==h&&"children"!==h&&"suppressContentEditableWarning"!==
h&&"suppressHydrationWarning"!==h&&"autoFocus"!==h&&(db.hasOwnProperty(h)?a||(a=[]):(a=a||[]).push(h,null));for(h in d){var k=d[h];g=null!=f?f[h]:void 0;if(d.hasOwnProperty(h)&&k!==g&&(null!=k||null!=g))if("style"===h)if(g){for(m in g)!g.hasOwnProperty(m)||k&&k.hasOwnProperty(m)||(c||(c={}),c[m]="");for(m in k)k.hasOwnProperty(m)&&g[m]!==k[m]&&(c||(c={}),c[m]=k[m])}else c||(a||(a=[]),a.push(h,c)),c=k;else"dangerouslySetInnerHTML"===h?(k=k?k.__html:void 0,g=g?g.__html:void 0,null!=k&&g!==k&&(a=a||
[]).push(h,k)):"children"===h?g===k||"string"!==typeof k&&"number"!==typeof k||(a=a||[]).push(h,""+k):"suppressContentEditableWarning"!==h&&"suppressHydrationWarning"!==h&&(db.hasOwnProperty(h)?(null!=k&&oa(e,h),a||g===k||(a=[])):(a=a||[]).push(h,k))}c&&(a=a||[]).push("style",c);e=a;if(b.updateQueue=e)b.effectTag|=4}};var kj=function(a,b,c,d){c!==d&&(b.effectTag|=4)};var pj="function"===typeof WeakSet?WeakSet:Set,wj="function"===typeof WeakMap?WeakMap:Map,sj=Math.ceil,gd=da.ReactCurrentDispatcher,
Uh=da.ReactCurrentOwner,H=0,Ye=8,ca=16,ma=32,Xa=0,hd=1,Oh=2,ad=3,bd=4,Xe=5,p=H,U=null,t=null,P=0,F=Xa,id=null,ta=1073741823,Yb=1073741823,kd=null,Xb=0,jd=!1,Re=0,Ph=500,l=null,cd=!1,Se=null,La=null,ld=!1,Zb=null,$b=90,bb=null,ac=0,af=null,dd=0,Ja=function(a,b){if(50<ac)throw ac=0,af=null,Error(k(185));a=ed(a,b);if(null!==a){var c=Cc();1073741823===b?(p&Ye)!==H&&(p&(ca|ma))===H?Te(a):(V(a),p===H&&ha()):V(a);(p&4)===H||98!==c&&99!==c||(null===bb?bb=new Map([[a,b]]):(c=bb.get(a),(void 0===c||c>b)&&bb.set(a,
b)))}};var zj=function(a,b,c){var d=b.expirationTime;if(null!==a){var e=b.pendingProps;if(a.memoizedProps!==e||G.current)ia=!0;else{if(d<c){ia=!1;switch(b.tag){case 3:sh(b);Ee();break;case 5:bh(b);if(b.mode&4&&1!==c&&e.hidden)return b.expirationTime=b.childExpirationTime=1,null;break;case 1:N(b.type)&&Bc(b);break;case 4:se(b,b.stateNode.containerInfo);break;case 10:d=b.memoizedProps.value;e=b.type._context;y(Ic,e._currentValue);e._currentValue=d;break;case 13:if(null!==b.memoizedState){d=b.child.childExpirationTime;
if(0!==d&&d>=c)return th(a,b,c);y(D,D.current&1);b=sa(a,b,c);return null!==b?b.sibling:null}y(D,D.current&1);break;case 19:d=b.childExpirationTime>=c;if(0!==(a.effectTag&64)){if(d)return vh(a,b,c);b.effectTag|=64}e=b.memoizedState;null!==e&&(e.rendering=null,e.tail=null);y(D,D.current);if(!d)return null}return sa(a,b,c)}ia=!1}}else ia=!1;b.expirationTime=0;switch(b.tag){case 2:d=b.type;null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2);a=b.pendingProps;e=pb(b,B.current);rb(b,c);e=we(null,
b,d,a,e,c);b.effectTag|=1;if("object"===typeof e&&null!==e&&"function"===typeof e.render&&void 0===e.$$typeof){b.tag=1;b.memoizedState=null;b.updateQueue=null;if(N(d)){var f=!0;Bc(b)}else f=!1;b.memoizedState=null!==e.state&&void 0!==e.state?e.state:null;ne(b);var g=d.getDerivedStateFromProps;"function"===typeof g&&Lc(b,d,g,a);e.updater=Mc;b.stateNode=e;e._reactInternalFiber=b;pe(b,d,a,c);b=Ie(null,b,d,!0,f,c)}else b.tag=0,T(null,b,e,c),b=b.child;return b;case 16:a:{e=b.elementType;null!==a&&(a.alternate=
null,b.alternate=null,b.effectTag|=2);a=b.pendingProps;ri(e);if(1!==e._status)throw e._result;e=e._result;b.type=e;f=b.tag=Gj(e);a=aa(e,a);switch(f){case 0:b=He(null,b,e,a,c);break a;case 1:b=rh(null,b,e,a,c);break a;case 11:b=nh(null,b,e,a,c);break a;case 14:b=oh(null,b,e,aa(e.type,a),d,c);break a}throw Error(k(306,e,""));}return b;case 0:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),He(a,b,d,e,c);case 1:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),rh(a,b,d,e,c);
case 3:sh(b);d=b.updateQueue;if(null===a||null===d)throw Error(k(282));d=b.pendingProps;e=b.memoizedState;e=null!==e?e.element:null;oe(a,b);Qb(b,d,null,c);d=b.memoizedState.element;if(d===e)Ee(),b=sa(a,b,c);else{if(e=b.stateNode.hydrate)Ka=kb(b.stateNode.containerInfo.firstChild),ra=b,e=Wa=!0;if(e)for(c=Fe(b,null,d,c),b.child=c;c;)c.effectTag=c.effectTag&-3|1024,c=c.sibling;else T(a,b,d,c),Ee();b=b.child}return b;case 5:return bh(b),null===a&&De(b),d=b.type,e=b.pendingProps,f=null!==a?a.memoizedProps:
null,g=e.children,Yd(d,e)?g=null:null!==f&&Yd(d,f)&&(b.effectTag|=16),qh(a,b),b.mode&4&&1!==c&&e.hidden?(b.expirationTime=b.childExpirationTime=1,b=null):(T(a,b,g,c),b=b.child),b;case 6:return null===a&&De(b),null;case 13:return th(a,b,c);case 4:return se(b,b.stateNode.containerInfo),d=b.pendingProps,null===a?b.child=wb(b,null,d,c):T(a,b,d,c),b.child;case 11:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),nh(a,b,d,e,c);case 7:return T(a,b,b.pendingProps,c),b.child;case 8:return T(a,
b,b.pendingProps.children,c),b.child;case 12:return T(a,b,b.pendingProps.children,c),b.child;case 10:a:{d=b.type._context;e=b.pendingProps;g=b.memoizedProps;f=e.value;var h=b.type._context;y(Ic,h._currentValue);h._currentValue=f;if(null!==g)if(h=g.value,f=Qa(h,f)?0:("function"===typeof d._calculateChangedBits?d._calculateChangedBits(h,f):1073741823)|0,0===f){if(g.children===e.children&&!G.current){b=sa(a,b,c);break a}}else for(h=b.child,null!==h&&(h.return=b);null!==h;){var m=h.dependencies;if(null!==
m){g=h.child;for(var l=m.firstContext;null!==l;){if(l.context===d&&0!==(l.observedBits&f)){1===h.tag&&(l=Ea(c,null),l.tag=Jc,Fa(h,l));h.expirationTime<c&&(h.expirationTime=c);l=h.alternate;null!==l&&l.expirationTime<c&&(l.expirationTime=c);Sg(h.return,c);m.expirationTime<c&&(m.expirationTime=c);break}l=l.next}}else g=10===h.tag?h.type===b.type?null:h.child:h.child;if(null!==g)g.return=h;else for(g=h;null!==g;){if(g===b){g=null;break}h=g.sibling;if(null!==h){h.return=g.return;g=h;break}g=g.return}h=
g}T(a,b,e.children,c);b=b.child}return b;case 9:return e=b.type,f=b.pendingProps,d=f.children,rb(b,c),e=W(e,f.unstable_observedBits),d=d(e),b.effectTag|=1,T(a,b,d,c),b.child;case 14:return e=b.type,f=aa(e,b.pendingProps),f=aa(e.type,f),oh(a,b,e,f,d,c);case 15:return ph(a,b,b.type,b.pendingProps,d,c);case 17:return d=b.type,e=b.pendingProps,e=b.elementType===d?e:aa(d,e),null!==a&&(a.alternate=null,b.alternate=null,b.effectTag|=2),b.tag=1,N(d)?(a=!0,Bc(b)):a=!1,rb(b,c),Yg(b,d,e),pe(b,d,e,c),Ie(null,
b,d,!0,a,c);case 19:return vh(a,b,c)}throw Error(k(156,b.tag));};var bf=null,Ne=null,la=function(a,b,c,d){return new Fj(a,b,c,d)};ef.prototype.render=function(a){md(a,this._internalRoot,null,null)};ef.prototype.unmount=function(){var a=this._internalRoot,b=a.containerInfo;md(null,a,null,function(){b[Lb]=null})};var Di=function(a){if(13===a.tag){var b=Fc(ka(),150,100);Ja(a,b);df(a,b)}};var Yf=function(a){13===a.tag&&(Ja(a,3),df(a,3))};var Bi=function(a){if(13===a.tag){var b=ka();b=Va(b,a,null);Ja(a,
b);df(a,b)}};sd=function(a,b,c){switch(b){case "input":Dd(a,c);b=c.name;if("radio"===c.type&&null!=b){for(c=a;c.parentNode;)c=c.parentNode;c=c.querySelectorAll("input[name="+JSON.stringify(""+b)+'][type="radio"]');for(b=0;b<c.length;b++){var d=c[b];if(d!==a&&d.form===a.form){var e=ae(d);if(!e)throw Error(k(90));Gf(d);Dd(d,e)}}}break;case "textarea":Lf(a,c);break;case "select":b=c.value,null!=b&&hb(a,!!c.multiple,b,!1)}};(function(a,b,c,d){ee=a;eg=b;vd=c;vf=d})(Qh,function(a,b,c,d,e){var f=p;p|=4;
try{return Da(98,a.bind(null,b,c,d,e))}finally{p=f,p===H&&ha()}},function(){(p&(1|ca|ma))===H&&(uj(),xb())},function(a,b){var c=p;p|=2;try{return a(b)}finally{p=c,p===H&&ha()}});var mk={Events:[Hb,Pa,ae,pf,qd,lb,function(a){Kd(a,Ki)},sf,tf,sc,pc,xb,{current:!1}]};(function(a){var b=a.findFiberByHostInstance;return Ej(M({},a,{overrideHookState:null,overrideProps:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:da.ReactCurrentDispatcher,findHostInstanceByFiber:function(a){a=Sf(a);
return null===a?null:a.stateNode},findFiberByHostInstance:function(a){return b?b(a):null},findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null}))})({findFiberByHostInstance:Bb,bundleType:0,version:"16.13.1",rendererPackageName:"react-dom"});I.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=mk;I.createPortal=Xh;I.findDOMNode=function(a){if(null==a)return null;if(1===a.nodeType)return a;var b=a._reactInternalFiber;if(void 0===
b){if("function"===typeof a.render)throw Error(k(188));throw Error(k(268,Object.keys(a)));}a=Sf(b);a=null===a?null:a.stateNode;return a};I.flushSync=function(a,b){if((p&(ca|ma))!==H)throw Error(k(187));var c=p;p|=1;try{return Da(99,a.bind(null,b))}finally{p=c,ha()}};I.hydrate=function(a,b,c){if(!bc(b))throw Error(k(200));return nd(null,a,b,!0,c)};I.render=function(a,b,c){if(!bc(b))throw Error(k(200));return nd(null,a,b,!1,c)};I.unmountComponentAtNode=function(a){if(!bc(a))throw Error(k(40));return a._reactRootContainer?
(Rh(function(){nd(null,null,a,!1,function(){a._reactRootContainer=null;a[Lb]=null})}),!0):!1};I.unstable_batchedUpdates=Qh;I.unstable_createPortal=function(a,b){return Xh(a,b,2<arguments.length&&void 0!==arguments[2]?arguments[2]:null)};I.unstable_renderSubtreeIntoContainer=function(a,b,c,d){if(!bc(c))throw Error(k(200));if(null==a||void 0===a._reactInternalFiber)throw Error(k(38));return nd(a,b,c,!1,d)};I.version="16.13.1"});
</script>
    <script>const e = React.createElement;

function pathToString(path) {
  if (path[0] === '/') {
    return '/' + path.slice(1).join('/');
  } else {
    return path.join('/');
  }
}

function findCommonPath(files) {
  if (!files || !files.length) {
    return [];
  }

  function isPrefix(arr, prefix) {
    if (arr.length < prefix.length) {
      return false;
    }
    for (let i = prefix.length - 1; i >= 0; --i) {
      if (arr[i] !== prefix[i]) {
        return false;
      }
    }
    return true;
  }

  let commonPath = files[0].path.slice(0, -1);
  while (commonPath.length) {
    if (files.every(file => isPrefix(file.path, commonPath))) {
      break;
    }
    commonPath.pop();
  }
  return commonPath;
}

function findFolders(files) {
  if (!files || !files.length) {
    return [];
  }

  let folders = files.filter(file => file.path.length > 1).map(file => file.path[0]);
  folders = [...new Set(folders)]; // unique
  folders.sort();

  folders = folders.map(folder => {
    let filesInFolder = files
      .filter(file => file.path[0] === folder)
      .map(file => ({
        ...file,
        path: file.path.slice(1),
        parent: [...file.parent, file.path[0]],
      }));

    const children = findFolders(filesInFolder); // recursion

    return {
      is_folder: true,
      path: [folder],
      parent: files[0].parent,
      children,
      covered: children.reduce((sum, file) => sum + file.covered, 0),
      coverable: children.reduce((sum, file) => sum + file.coverable, 0),
      prevRun: {
        covered: children.reduce((sum, file) => sum + file.prevRun.covered, 0),
        coverable: children.reduce((sum, file) => sum + file.prevRun.coverable, 0),
      }
    };
  });

  return [
    ...folders,
    ...files.filter(file => file.path.length === 1),
  ];
}

class App extends React.Component {
  constructor(...args) {
    super(...args);

    this.state = {
      current: [],
    };
  }

  componentDidMount() {
    this.updateStateFromLocation();
    window.addEventListener("hashchange", () => this.updateStateFromLocation(), false);
  }

  updateStateFromLocation() {
    if (window.location.hash.length > 1) {
      const current = window.location.hash.substr(1).split('/');
      this.setState({current});
    } else {
      this.setState({current: []});
    }
  }

  getCurrentPath() {
    let file = this.props.root;
    let path = [file];
    for (let p of this.state.current) {
      file = file.children.find(file => file.path[0] === p);
      if (!file) {
        return path;
      }
      path.push(file);
    }
    return path;
  }

  render() {
    const path = this.getCurrentPath();
    const file = path[path.length - 1];

    let w = null;
    if (file.is_folder) {
      w = e(FilesList, {
        folder: file,
        onSelectFile: this.selectFile.bind(this),
        onBack: path.length > 1 ? this.back.bind(this) : null,
      });
    } else {
      w = e(DisplayFile, {
        file,
        onBack: this.back.bind(this),
      });
    }

    return e('div', {className: 'app'}, w);
  }

  selectFile(file) {
    this.setState(({current}) => {
      return {current: [...current, file.path[0]]};
    }, () => this.updateHash());
  }

  back(file) {
    this.setState(({current}) => {
      return {current: current.slice(0, current.length - 1)};
    }, () => this.updateHash());
  }

  updateHash() {
    if (!this.state.current || !this.state.current.length) {
      window.location = '#';
    } else {
      window.location = '#' + this.state.current.join('/');
    }
  }
}

function FilesList({folder, onSelectFile, onBack}) {
  let files = folder.children;
  return e('div', {className: 'display-folder'},
    e(FileHeader, {file: folder, onBack}),
    e('table', {className: 'files-list'},
      e('thead', {className: 'files-list__head'},
        e('tr', null,
          e('th', null, "Path"),
          e('th', null, "Coverage")
        )
      ),
      e('tbody', {className: 'files-list__body'},
        files.map(file => e(File, {file, onClick: onSelectFile}))
      )
    )
  );
}

function File({file, onClick}) {
  const coverage = file.coverable ? file.covered / file.coverable * 100 : -1;
  const coverageDelta = file.prevRun &&
    (file.covered / file.coverable * 100 - file.prevRun.covered / file.prevRun.coverable * 100);

  return e('tr', {
      className: 'files-list__file'
        + (coverage >= 0 && coverage < 50 ? ' files-list__file_low': '')
        + (coverage >= 50 && coverage < 80 ? ' files-list__file_medium': '')
        + (coverage >= 80 ? ' files-list__file_high': '')
        + (file.is_folder ? ' files-list__file_folder': ''),
      onClick: () => onClick(file),
    },
    e('td', null, e('a', null, pathToString(file.path))),
    e('td', null,
      file.covered + ' / ' + file.coverable +
      (coverage >= 0 ? ' (' + coverage.toFixed(2) + '%)' : ''),
      e('span', {title: 'Change from the previous run'},
        (coverageDelta ? ` (${coverageDelta > 0 ? '+' : ''}${coverageDelta.toFixed(2)}%)` : ''))
    )
  );
}

function DisplayFile({file, onBack}) {
  return e('div', {className: 'display-file'},
    e(FileHeader, {file, onBack}),
    e(FileContent, {file})
  );
}

function FileHeader({file, onBack}) {
  const coverage = file.covered / file.coverable * 100;
  const coverageDelta = file.prevRun && (coverage - file.prevRun.covered / file.prevRun.coverable * 100);

  return e('div', {className: 'file-header'},
    onBack ? e('a', {className: 'file-header__back', onClick: onBack}, 'Back') : null,
    e('div', {className: 'file-header__name'}, pathToString([...file.parent, ...file.path])),
    e('div', {className: 'file-header__stat'},
      'Covered: ' + file.covered + ' of ' + file.coverable +
      (file.coverable ? ' (' + coverage.toFixed(2) + '%)' : ''),
      e('span', {title: 'Change from the previous run'},
        (coverageDelta ? ` (${coverageDelta > 0 ? '+' : ''}${coverageDelta.toFixed(2)}%)` : ''))
    )
  );
}

function FileContent({file}) {
  return e('pre', {className: 'file-content'},
    file.content.split(/\r?\n/).map((line, index) => {
      const trace = file.traces.find(trace => trace.line === index + 1);
      const covered = trace && trace.stats.Line;
      const uncovered = trace && !trace.stats.Line;
      return e('code', {
          className: 'code-line'
            + (covered ? ' code-line_covered' : '')
            + (uncovered ? ' code-line_uncovered' : ''),
          title: trace ? JSON.stringify(trace.stats, null, 2) : null,
        }, line);
    })
  );
}

(function(){
  const commonPath = findCommonPath(data.files);
  const prevFilesMap = new Map();

  previousData && previousData.files.forEach((file) => {
    const path = file.path.slice(commonPath.length).join('/');
    prevFilesMap.set(path, file);
  });

  const files = data.files.map((file) => {
    const path = file.path.slice(commonPath.length);
    const { covered = 0, coverable = 0 } = prevFilesMap.get(path.join('/')) || {};
    return {
      ...file,
      path,
      parent: commonPath,
      prevRun: { covered, coverable },
    };
  });

  const children = findFolders(files);

  const root = {
    is_folder: true,
    children,
    path: commonPath,
    parent: [],
    covered: children.reduce((sum, file) => sum + file.covered, 0),
    coverable: children.reduce((sum, file) => sum + file.coverable, 0),
    prevRun: {
      covered: children.reduce((sum, file) => sum + file.prevRun.covered, 0),
      coverable: children.reduce((sum, file) => sum + file.prevRun.coverable, 0),
    }
  };

  ReactDOM.render(e(App, {root, prevFilesMap}), document.getElementById('root'));
}());
</script>
</body>
</html>